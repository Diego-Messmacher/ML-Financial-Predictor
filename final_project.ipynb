{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9ac00da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holden Cormier & Diego Messmacher \n",
    "# Predicting Financial Statements Using Machine Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fcaac1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Using Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e4cbbb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "_data_file = \"./data/Cleaned_Data.xlsx\"\n",
    "data = pd.read_excel(_data_file,index_col=False,sheet_name = [0,1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3b626cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0:                0         1        2         3         4        5       6   \\\n",
       " JUN '07     1.863     0.650    0.100     1.213     5.352   -4.139   0.170   \n",
       " JUN '08     8.781     4.555    0.100     4.226    10.094   -5.868   0.010   \n",
       " JUN '09    19.315     7.851    0.164    11.464    17.295   -5.831  -0.027   \n",
       " JUN '10    43.329    16.190    0.369    27.139    55.338  -28.199  -1.226   \n",
       " JUN '11    92.641    31.575    1.472    61.066    50.506   10.560   0.606   \n",
       " DEC '12   243.712   104.009   13.506   139.703   174.787  -35.084  -0.896   \n",
       " DEC '13   424.650   155.259   23.525   269.391   335.658  -66.267  -4.930   \n",
       " DEC '14   682.563   248.776   42.059   433.787   584.422 -150.635   5.354   \n",
       " DEC '15  1005.480   329.413   60.356   676.067   842.432 -166.365   4.450   \n",
       " DEC '16  1390.513   398.682   83.082   991.831  1143.639 -151.808   6.035   \n",
       " DEC '17  1918.494   499.862  112.900  1418.632  1480.628  -61.996   4.384   \n",
       " DEC '18  2608.816   622.658  148.200  1986.158  2027.584  -41.426  40.915   \n",
       " DEC '19  3460.437   796.645  202.500  2663.792  2621.669   42.123  58.345   \n",
       " DEC '20  4519.484   987.113  271.000  3532.371  3333.508  198.863  29.682   \n",
       " DEC '21  5896.000  1353.000  388.000  4543.000  4286.000  257.000  23.000   \n",
       " DEC '22  7245.000  1573.000  342.000  5672.000  5317.000  355.000  71.000   \n",
       " \n",
       "              7        8        9   ...        20         21        22  \\\n",
       " JUN '07   0.000    0.000   -3.969  ...       NaN        NaN       NaN   \n",
       " JUN '08   0.000    0.000   -5.858  ...  0.417734  -0.941176  0.000000   \n",
       " JUN '09   0.000    0.000   -5.858  ... -0.006305  -3.700000  0.000000   \n",
       " JUN '10   0.000    0.000  -29.425  ...  3.836049  44.407407  0.000000   \n",
       " JUN '11   0.000    0.000   11.166  ... -1.374481  -1.494290  0.000000   \n",
       " DEC '12   0.000    0.000  -35.980  ... -4.322348  -2.478548  0.000000   \n",
       " DEC '13   0.000    0.000  -71.197  ...  0.888810   4.502232  0.000000   \n",
       " DEC '14  29.059    1.200 -175.540  ...  1.273153  -2.086004  0.000000   \n",
       " DEC '15  31.097    0.000 -193.012  ...  0.104425  -0.168846  0.070133   \n",
       " DEC '16  33.278  271.000 -450.051  ... -0.087500   0.356180  0.070135   \n",
       " DEC '17  53.394    2.400 -113.406  ... -0.591616  -0.273571  0.604483   \n",
       " DEC '18  52.733  -14.220  -39.024  ... -0.331796   8.332801 -0.012380   \n",
       " DEC '19  33.283    0.000   67.185  ... -2.016825   0.426005 -0.368839   \n",
       " DEC '20  32.746   46.614  149.185  ...  3.721008  -0.491267 -0.016134   \n",
       " DEC '21  28.000    3.000  249.000  ...  0.292347  -0.225120 -0.144934   \n",
       " DEC '22  27.000    0.000  399.000  ...  0.381323   2.086957 -0.035714   \n",
       " \n",
       "                23        24         25         26         27         28  \\\n",
       " JUN '07       NaN       NaN        NaN        NaN        NaN        NaN   \n",
       " JUN '08  0.000000  0.475939  10.500000   0.480987   0.480978   0.481595   \n",
       " JUN '09  0.000000  0.000000   1.086957   0.004251   0.110511   0.111801   \n",
       " JUN '10  0.000000  4.023045   4.833333   4.029631   3.646328   3.646182   \n",
       " JUN '11  0.000000 -1.379473   3.771429  -1.076485  -1.054011  -1.054108   \n",
       " DEC '12  0.000000 -4.222282   0.023952 -17.573944 -38.813122 -38.777778   \n",
       " DEC '13  0.000000  0.978794   0.835526   0.957404   0.068333   0.058824   \n",
       " DEC '14  0.000000  1.465553   0.532059   1.433752   1.256709   1.277778   \n",
       " DEC '15 -1.000000  0.099533   0.407330   0.106134   0.037458   0.032520   \n",
       " DEC '16 -0.935642  1.331725  -0.676210   1.276940   0.250049   1.165354   \n",
       " DEC '17 -0.991144 -0.748015   0.962350  -0.741379  -0.577658  -0.751782   \n",
       " DEC '18 -6.925000 -0.655891  -4.581395  -0.771460  -0.693633  -0.779959   \n",
       " DEC '19 -1.000000 -2.721633  44.415016 -24.468319 -16.416166 -22.155792   \n",
       " DEC '20 -0.935642  1.220511  -1.054837  -0.810909  -0.765102  -0.815804   \n",
       " DEC '21 -0.935642  0.669069  -0.380744   0.940879   0.530527   0.934222   \n",
       " DEC '22 -1.000000  0.602410   2.894737   0.413043   0.397727   0.410476   \n",
       " \n",
       "                29  \n",
       " JUN '07       NaN  \n",
       " JUN '08  0.000000  \n",
       " JUN '09  0.000000  \n",
       " JUN '10  3.910888  \n",
       " JUN '11 -1.432339  \n",
       " DEC '12 -2.793384  \n",
       " DEC '13  0.980814  \n",
       " DEC '14  1.540265  \n",
       " DEC '15 -0.023642  \n",
       " DEC '16 -0.351697  \n",
       " DEC '17 -1.740680  \n",
       " DEC '18  1.097556  \n",
       " DEC '19  1.291035  \n",
       " DEC '20  0.920764  \n",
       " DEC '21  0.372741  \n",
       " DEC '22  0.080620  \n",
       " \n",
       " [16 rows x 30 columns],\n",
       " 1:                0        1       2         3         4       5       6   \\\n",
       " DEC '13   148.512   33.160  12.060   115.352   102.233  13.119  -1.444   \n",
       " DEC '14   215.109   38.084  13.316   177.025   155.494  21.531   0.925   \n",
       " DEC '15   319.521   52.972  15.511   266.549   266.132   0.417  -1.092   \n",
       " DEC '16   457.058   75.869  21.926   381.189   387.069  -5.880   0.973   \n",
       " DEC '17   619.936  134.430  61.546   485.506   548.592 -63.086   3.434   \n",
       " DEC '18   880.978  208.914  79.435   672.064   722.063 -49.999   7.134   \n",
       " DEC '19  1210.127  238.376  70.248   971.751  1022.229 -50.478  22.071   \n",
       " DEC '20  1614.173  281.026  97.398  1333.147  1305.239  27.908  11.446   \n",
       " DEC '21  2089.132  346.707  92.848  1742.425  1674.778  67.647  37.948   \n",
       " DEC '22  2802.882  474.886  93.958  2327.996  2421.486 -93.490 -20.776   \n",
       " \n",
       "               7        8        9   ...         20        21        22  \\\n",
       " DEC '13    0.272      NaN   11.403  ...        NaN       NaN       NaN   \n",
       " DEC '14    0.228      NaN   22.228  ...   0.641207 -1.640582 -0.161765   \n",
       " DEC '15    0.074      NaN   -0.749  ...  -0.980633 -2.180541 -0.675439   \n",
       " DEC '16    0.000      NaN   -4.907  ... -15.100719 -1.891026 -1.000000   \n",
       " DEC '17    0.000      NaN  -59.652  ...   9.728912  2.529291  0.000000   \n",
       " DEC '18    6.806    8.460  -58.131  ...  -0.207447  1.077461  0.000000   \n",
       " DEC '19   40.241  536.908 -605.556  ...   0.009580  2.093776  4.912577   \n",
       " DEC '20   49.610  335.953 -346.209  ...  -1.552875 -0.481401  0.232822   \n",
       " DEC '21  122.713  617.546 -634.664  ...   1.423929  2.315394  1.473554   \n",
       " DEC '22   25.824  424.482 -564.572  ...  -2.382027 -1.547486 -0.789558   \n",
       " \n",
       "                 23         24         25         26        27         28  \\\n",
       " DEC '13        NaN        NaN        NaN        NaN       NaN        NaN   \n",
       " DEC '14   0.000000   0.949312   4.056075   0.763962  0.763962   0.800000   \n",
       " DEC '15   0.000000  -1.033696  -3.317930  -0.643083 -0.643079  -0.666667   \n",
       " DEC '16   0.000000   5.551402   0.233386  -0.354539 -0.303847  -0.333333   \n",
       " DEC '17   0.000000  11.156511   0.847845 -10.719643 -9.462348 -10.500000   \n",
       " DEC '18   0.000000  -0.025498  -4.224924   1.668737  1.431384   1.582632   \n",
       " DEC '19  62.464303   9.417092  -0.420173   4.621174  1.359194   4.445690   \n",
       " DEC '20  -0.374282  -0.428279  -0.861375  -0.450059 -0.570080  -0.464037   \n",
       " DEC '21   0.838192   0.833182  12.869741   0.985761  1.241987   0.947214   \n",
       " DEC '22  -0.312631  -0.110440  -0.196250  -0.118037  0.183339  -0.130666   \n",
       " \n",
       "                 29  \n",
       " DEC '13        NaN  \n",
       " DEC '14   0.383971  \n",
       " DEC '15  -0.542916  \n",
       " DEC '16   0.007408  \n",
       " DEC '17  -1.095974  \n",
       " DEC '18 -20.114286  \n",
       " DEC '19  -0.328373  \n",
       " DEC '20   5.338189  \n",
       " DEC '21   0.280825  \n",
       " DEC '22  -0.997084  \n",
       " \n",
       " [10 rows x 30 columns],\n",
       " 2:                  0           1          2           3          4         5   \\\n",
       " DEC '01    0.086426    0.014228   0.010025    0.072198   0.048851   0.01097   \n",
       " DEC '02    0.439508    0.131510   0.018030    0.307998   0.099897   0.18646   \n",
       " DEC '03    1.465934    0.625854   0.050185    0.840080   0.497616   0.34246   \n",
       " DEC '04    3.189223    1.457653   0.148473    1.731570   0.879035   0.85254   \n",
       " DEC '05    6.138560    2.571509   0.293812    3.567051   1.437773   2.03928   \n",
       " DEC '06   10.604917    4.225027   0.571939    6.379890   2.789094   3.59080   \n",
       " DEC '07   16.593986    6.649085   0.967658    9.944901   4.860501   5.08440   \n",
       " DEC '08   21.795550    8.621506   1.499887   13.174044   6.542075   6.63197   \n",
       " DEC '09   23.325858    8.844115   1.524308   14.481743   6.494262   7.98748   \n",
       " DEC '10   29.118000   10.417000   1.396000   18.701000   8.523000  10.17800   \n",
       " DEC '11   37.862000   13.188000   1.851000   24.674000  12.475000  12.19900   \n",
       " DEC '12   49.958000   20.505000   2.962000   29.453000  16.334000  13.11900   \n",
       " DEC '13   59.730000   25.824000   3.939000   33.906000  19.912000  13.99400   \n",
       " DEC '14   65.830000   25.313000   4.602000   40.517000  23.814000  16.70300   \n",
       " DEC '15   73.590000   28.164000   5.063000   45.426000  27.465000  17.96100   \n",
       " DEC '16   89.733000   35.138000   6.144000   54.595000  31.418000  23.17700   \n",
       " DEC '17  111.024000   45.583000   6.915000   65.441000  36.390000  29.05100   \n",
       " DEC '18  136.958000   59.549000   9.035000   77.409000  45.878000  31.53100   \n",
       " DEC '19  161.402000   71.896000  11.781000   89.506000  54.033000  35.47300   \n",
       " DEC '20  182.350000   84.732000  13.697000   97.618000  56.571000  41.04700   \n",
       " DEC '21  257.488000  110.939000  12.441000  146.549000  67.984000  78.56500   \n",
       " DEC '22  280.875000  126.203000  15.928000  154.672000  81.791000  72.88100   \n",
       " \n",
       "                6         7          8          9   ...         20         21  \\\n",
       " DEC '01  0.000861  0.001758   0.022000   0.010068  ...        NaN        NaN   \n",
       " DEC '02  0.001015  0.002570   0.022000   0.184915  ...  15.997265   0.178862   \n",
       " DEC '03  0.006123  0.001931   0.022000   0.346654  ...   0.836641   5.032512   \n",
       " DEC '04  0.010906  0.000862   0.212343   0.650234  ...   1.489459   0.781153   \n",
       " DEC '05  0.125178  0.000776   0.022000   2.141677  ...   1.392005  10.477902   \n",
       " DEC '06  0.461303  0.000257   0.040800   4.011040  ...   0.760818   2.685176   \n",
       " DEC '07  0.590785  0.001203   0.000000   5.673980  ...   0.415952   0.280688   \n",
       " DEC '08  0.316383  0.000000   1.094757   5.853596  ...   0.304376  -0.464470   \n",
       " DEC '09  0.471373  0.000000   0.077668   8.381189  ...   0.204390   0.489881   \n",
       " DEC '10  0.984000  0.000000   0.366000  10.796000  ...   0.274244   1.087519   \n",
       " DEC '11  1.122000  0.058000   0.937000  12.326000  ...   0.198566   0.140244   \n",
       " DEC '12  1.455000  0.084000   1.104000  13.386000  ...   0.075416   0.296791   \n",
       " DEC '13  0.595000  0.083000   0.010000  14.496000  ...   0.066697  -0.591065   \n",
       " DEC '14  1.213000  0.101000   0.556000  17.259000  ...   0.193583   1.038655   \n",
       " DEC '15  2.096000  0.104000   0.302000  19.651000  ...   0.075316   0.727947   \n",
       " DEC '16  1.472000  0.124000   0.375000  24.150000  ...   0.290407  -0.297710   \n",
       " DEC '17  1.111000  0.109000   2.860000  27.193000  ...   0.253441  -0.245245   \n",
       " DEC '18  4.396000  0.114000   0.900000  34.913000  ...   0.085367   2.956796   \n",
       " DEC '19  3.056000  0.100000  -1.196000  39.625000  ...   0.125020  -0.304823   \n",
       " DEC '20  2.011000  0.135000  -5.159000  48.082000  ...   0.157134  -0.341950   \n",
       " DEC '21  2.117000  0.346000 -10.398000  90.734000  ...   0.914025   0.052710   \n",
       " DEC '22  2.109000  0.357000   3.305000  71.328000  ...  -0.072348  -0.003779   \n",
       " \n",
       "                22         23         24         25         26        27  \\\n",
       " DEC '01       NaN        NaN        NaN        NaN        NaN       NaN   \n",
       " DEC '02  0.461889   0.000000  17.366607  26.654557  13.267144  9.914530   \n",
       " DEC '03 -0.248638   0.000000   0.874667   1.826751   0.060127 -0.053543   \n",
       " DEC '04 -0.553599   8.651955   0.875744   0.041945   2.777819  4.197021   \n",
       " DEC '05 -0.099768  -0.896394   2.293702   1.693109   2.671579  1.526527   \n",
       " DEC '06 -0.668814   0.854545   0.872850   0.380484   1.100077  1.535854   \n",
       " DEC '07  3.680934  -1.000000   0.414591   0.574839   0.365977  0.033319   \n",
       " DEC '08 -1.000000   0.000000   0.031656   0.106429   0.005504  0.182924   \n",
       " DEC '09  0.000000  -0.929055   0.431802   0.143848   0.542623  0.308916   \n",
       " DEC '10  0.000000   3.712365   0.288123   0.231230   0.304358  0.316730   \n",
       " DEC '11  0.000000   1.560109   0.141719   0.130074   0.144856  0.171874   \n",
       " DEC '12  0.448276   0.178228   0.085997   0.003476   0.107939  0.090501   \n",
       " DEC '13 -0.011905  -0.990942   0.082922  -0.121632   0.132184  0.037063   \n",
       " DEC '14  0.216867  54.600000   0.190604   0.594654   0.115114  0.116056   \n",
       " DEC '15  0.029703  -0.456835   0.138594  -0.092333   0.161968  0.153540   \n",
       " DEC '16  0.192308   0.241722   0.228945   0.414472   0.230760  0.220729   \n",
       " DEC '17 -0.120968   6.626667   0.126004   2.110231  -0.349933 -0.262312   \n",
       " DEC '18  0.045872  -0.685315   0.283897  -0.712546   1.427421  1.139890   \n",
       " DEC '19 -0.122807  -2.328889   0.134964   0.264544   0.117354  0.075452   \n",
       " DEC '20  0.350000   3.313545   0.213426   0.479175   0.172553  0.112428   \n",
       " DEC '21  1.562963   1.015507   0.887068   0.881608   0.888127  0.901468   \n",
       " DEC '22  0.031792  -1.317850  -0.213878  -0.227536  -0.211237 -0.125853   \n",
       " \n",
       "                28        29  \n",
       " DEC '01       NaN       NaN  \n",
       " DEC '02  9.300000  8.737619  \n",
       " DEC '03 -0.058252  0.920094  \n",
       " DEC '04  2.762887  1.549435  \n",
       " DEC '05  2.441096  1.330736  \n",
       " DEC '06  0.980096  0.784217  \n",
       " DEC '07  0.337354  0.453865  \n",
       " DEC '08  0.001503  0.343652  \n",
       " DEC '09  0.533173  0.169694  \n",
       " DEC '10  0.289211  0.216806  \n",
       " DEC '11  0.131075  0.213928  \n",
       " DEC '12  0.085672  0.144555  \n",
       " DEC '13  0.111194  0.115167  \n",
       " DEC '14  0.085151  0.188033  \n",
       " DEC '15  0.171402  0.080685  \n",
       " DEC '16  0.220578  0.273497  \n",
       " DEC '17 -0.354473  0.226629  \n",
       " DEC '18  1.428540  0.127899  \n",
       " DEC '19  0.124886  0.164867  \n",
       " DEC '20  0.192262  0.158505  \n",
       " DEC '21  0.914184  0.662392  \n",
       " DEC '22 -0.238899 -0.024141  \n",
       " \n",
       " [22 rows x 30 columns],\n",
       " 3:                 0          1         2          3           4          5   \\\n",
       " JAN '01      5.435      3.422     0.861      2.013     35.2355   -33.2225   \n",
       " JAN '02     22.409      6.047     2.403     16.362     38.2300   -21.8680   \n",
       " JAN '03     50.991     10.363     2.664     40.628     51.1280   -10.5000   \n",
       " JAN '04     96.023     17.273     2.591     78.750     78.4770     0.2730   \n",
       " JAN '05    176.375     33.454     3.147    142.921    136.4010     6.5200   \n",
       " JAN '06    309.857     69.126     6.027    240.731    220.9140    19.8170   \n",
       " JAN '07    497.098    118.890    12.504    378.208    381.8060    -3.5980   \n",
       " JAN '08    748.700    171.591    24.219    577.109    556.8000    20.3090   \n",
       " JAN '09   1076.769    220.471    35.971    856.298    792.5560    63.7420   \n",
       " JAN '10   1305.583    257.925    53.177   1047.658    932.3860   115.2720   \n",
       " JAN '11   1657.139    328.022    75.746   1329.117   1231.6200    97.4970   \n",
       " JAN '12   2266.539    496.136   157.286   1770.403   1805.4880   -35.0850   \n",
       " JAN '13   3050.195    694.501   216.795   2355.694   2466.4040  -110.7100   \n",
       " JAN '14   4071.003   1005.607   369.423   3065.396   3351.4700  -286.0740   \n",
       " JAN '15   5373.586   1353.943   448.296   4019.643   4165.2760  -145.6330   \n",
       " JAN '16   6667.216   1735.336   525.750   4931.880   4857.2100    74.6700   \n",
       " JAN '17   8391.984   2334.131   632.245   6057.853   5980.6160    77.2370   \n",
       " JAN '18  10540.000   3486.000  1345.000   7054.000   6600.0000   454.0000   \n",
       " JAN '19  13282.000   4420.000  1699.000   8862.000   8300.0000   562.0000   \n",
       " JAN '20  17098.000   5463.000  3011.000  11635.000  11132.0000   503.0000   \n",
       " JAN '21  21252.000   6955.000  3904.000  14297.000  13842.0000   455.0000   \n",
       " JAN '22  26492.000   9101.000  4646.000  17391.000  16843.0000   548.0000   \n",
       " JAN '23  31352.000  10944.000  5454.000  20408.000  18550.0000  1858.0000   \n",
       " \n",
       "                6        7          8         9   ...         20         21  \\\n",
       " JAN '01     1.778    0.042     0.3775   -31.864  ...        NaN        NaN   \n",
       " JAN '02    -6.894    0.272        NaN   -29.034  ...  -0.341771  -4.877390   \n",
       " JAN '03     0.569    0.077        NaN   -10.008  ...  -0.519846  -1.082536   \n",
       " JAN '04     3.988    0.022        NaN     4.239  ...  -1.026000   6.008787   \n",
       " JAN '05     2.670    0.037        NaN     9.153  ...  22.882784  -0.330491   \n",
       " JAN '06     8.450    0.069        NaN    28.198  ...   2.039417   2.164794   \n",
       " JAN '07    16.287    0.193        NaN    12.496  ...  -1.181561   0.927456   \n",
       " JAN '08    25.950    0.046        NaN    46.213  ...  -6.644525   0.593295   \n",
       " JAN '09    21.850    0.000        NaN    85.592  ...   2.138608  -0.157996   \n",
       " JAN '10    27.918    2.000    -1.1910   142.381  ...   0.808415   0.277712   \n",
       " JAN '11    33.034   24.909     1.3240   104.298  ...  -0.154200   0.183251   \n",
       " JAN '12    20.743   17.045     1.9300   -33.317  ...  -1.359857  -0.372071   \n",
       " JAN '13    -2.727   30.948   -16.5910  -127.794  ...   2.155480  -1.131466   \n",
       " JAN '14     5.242   77.211    -0.1080  -357.935  ...   1.583994  -2.922259   \n",
       " JAN '15    17.297   73.237    11.5120  -213.085  ...  -0.490925   2.299695   \n",
       " JAN '16    51.263   72.485   -10.8310    64.279  ...  -1.512727   1.963693   \n",
       " JAN '17   138.873   88.988   101.7390    25.383  ...   0.034378   1.709030   \n",
       " JAN '18    38.000   87.000   -15.0000   420.000  ...   4.878012  -0.726369   \n",
       " JAN '19   568.000  154.000    -7.0000   983.000  ...   0.237885  13.947368   \n",
       " JAN '20   549.000  131.000   215.0000   706.000  ...  -0.104982  -0.033451   \n",
       " JAN '21  2232.000  126.000     0.0000  2561.000  ...  -0.095427   3.065574   \n",
       " JAN '22   286.000  220.000  -918.0000  1532.000  ...   0.204396  -0.871864   \n",
       " JAN '23   227.000  287.000  1138.0000   660.000  ...   2.390511  -0.206294   \n",
       " \n",
       "                 22          23         24        25         26         27  \\\n",
       " JAN '01        NaN         NaN        NaN       NaN        NaN        NaN   \n",
       " JAN '02   5.476190   -1.000000  -0.088815  0.000000  -0.096682  -0.882138   \n",
       " JAN '03  -0.716912    0.000000  -0.655301  0.000000  -0.660387  -0.660394   \n",
       " JAN '04  -0.714286    0.000000  -1.423561  0.000000  -1.361671  -1.361661   \n",
       " JAN '05   0.681818    0.000000   1.159236  1.249538   1.090495   0.940260   \n",
       " JAN '06   0.864865    0.000000   2.080739 -2.076417   2.876123   2.619416   \n",
       " JAN '07   1.797101    0.000000  -0.556848 -8.477099  -0.983107  -0.983303   \n",
       " JAN '08  -0.761658    0.000000   2.698223  1.387443  37.162162  36.447552   \n",
       " JAN '09  -1.000000    0.000000   0.852120  0.606030   1.365875   1.312872   \n",
       " JAN '10   0.000000    0.000000   0.663485  0.536039   0.858686   0.798046   \n",
       " JAN '11  11.454500   -2.111671  -0.267472 -0.400215  -0.201254  -0.232162   \n",
       " JAN '12  -0.315709    0.457704  -1.319440 -1.628450  -1.179483  -1.157783   \n",
       " JAN '13   0.815664   -9.596373   2.835699 -7.560175  22.370636  25.438155   \n",
       " JAN '14   1.494862   -0.993490   1.800875 -1.881592  -0.141508  -0.221667   \n",
       " JAN '15  -0.051469 -107.592593  -0.404682 -1.394426   0.131422   0.049747   \n",
       " JAN '16  -0.010268   -1.940844  -1.301659  1.251981  -0.819459  -0.796212   \n",
       " JAN '17   0.227675  -10.393315  -0.605112 -2.380860  -4.787627  -5.309040   \n",
       " JAN '18  -0.022340   -1.147436  15.546508 -1.388981   1.004097   0.327332   \n",
       " JAN '19   0.770115   -0.533333   1.340476 -3.116667   2.083333   1.998749   \n",
       " JAN '20  -0.149351  -31.714286  -0.281790 -5.566929  -0.886486  -0.771873   \n",
       " JAN '21  -0.038168   -1.000000   2.627479 -3.605172  31.317460  12.460116   \n",
       " JAN '22   0.746032    0.000000  -0.401796 -1.058240  -0.645383  -0.812083   \n",
       " JAN '23   0.304545   -2.239651  -0.569191  4.136364  -0.855956   0.224637   \n",
       " \n",
       "                 28        29  \n",
       " JAN '01        NaN       NaN  \n",
       " JAN '02  -0.883193 -0.398514  \n",
       " JAN '03  -0.660432 -0.597431  \n",
       " JAN '04  -1.360169 -1.365493  \n",
       " JAN '05   1.058824  2.375349  \n",
       " JAN '06   2.428571  1.673425  \n",
       " JAN '07  -0.983333 -0.655394  \n",
       " JAN '08  36.500000  3.999775  \n",
       " JAN '09   1.333333  1.239333  \n",
       " JAN '10   0.800000  0.689338  \n",
       " JAN '11  -0.253968  0.028460  \n",
       " JAN '12  -1.191489 -0.294627  \n",
       " JAN '13  20.333333 -0.131881  \n",
       " JAN '14  -0.187500 -0.214319  \n",
       " JAN '15   0.076923  2.631273  \n",
       " JAN '16  -0.833333  0.983791  \n",
       " JAN '17  -4.714286  0.181643  \n",
       " JAN '18   0.884615  1.535653  \n",
       " JAN '19   1.918367  0.256809  \n",
       " JAN '20  -0.896364  0.554180  \n",
       " JAN '21  28.544534  0.240467  \n",
       " JAN '22  -0.661391  0.191558  \n",
       " JAN '23  -0.859301  0.407778  \n",
       " \n",
       " [23 rows x 30 columns],\n",
       " 4:                0         1        2         3         4        5       6   \\\n",
       " DEC '13    49.920    25.868    0.610    24.052    50.902  -26.850  -0.004   \n",
       " DEC '14    88.846    41.423    1.756    47.423    73.806  -26.383  -0.062   \n",
       " DEC '15   166.919    75.724    4.226    91.195   125.388  -34.193   0.011   \n",
       " DEC '16   277.335   122.963    8.315   154.372   191.727  -41.215   0.317   \n",
       " DEC '17   399.020   187.490   18.764   211.530   276.132  -65.774   3.071   \n",
       " DEC '18   650.067   302.355   26.095   347.712   454.326 -113.735   8.982   \n",
       " DEC '19  1134.468   560.649  133.623   573.819   927.804 -353.985  32.640   \n",
       " DEC '20  1761.776   885.108  188.055   876.668  1347.804 -471.136  26.318   \n",
       " DEC '21  2841.839  1527.469  307.164  1314.370  2214.960 -900.590 -16.380   \n",
       " DEC '22  3826.321  2061.410  326.287  1764.911  2758.378 -993.467 -38.324   \n",
       " \n",
       "              7        8         9   ...        20         21        22  \\\n",
       " DEC '13   0.000    0.300   -26.854  ...       NaN        NaN       NaN   \n",
       " DEC '14   0.000    0.300   -26.745  ... -0.017393  14.500000  0.000000   \n",
       " DEC '15   0.000    1.200   -35.382  ...  0.296024  -1.177419  0.000000   \n",
       " DEC '16   0.000    0.100   -40.998  ...  0.205364  27.818182  0.000000   \n",
       " DEC '17   0.000    0.300   -63.003  ...  0.595875   8.687697  0.000000   \n",
       " DEC '18  14.905    1.500  -121.158  ...  0.729179   1.924780  0.000000   \n",
       " DEC '19  25.071   15.800  -362.216  ...  2.112366   2.633935  0.682053   \n",
       " DEC '20  24.980   34.628  -504.426  ...  0.330949  -0.193689 -0.003630   \n",
       " DEC '21  24.980   43.959  -960.929  ...  0.911529  -1.622388  0.000000   \n",
       " DEC '22  24.980  211.841 -1243.632  ...  0.103129   1.339683  0.000000   \n",
       " \n",
       "                23        24         25        26        27        28        29  \n",
       " DEC '13       NaN       NaN        NaN       NaN       NaN       NaN       NaN  \n",
       " DEC '14  0.000000 -0.004059   0.000000 -0.003575 -0.011398 -0.003526 -0.061471  \n",
       " DEC '15  3.000000  0.322939   8.384615  0.326856  0.433482  0.453522  0.216835  \n",
       " DEC '16 -0.916667  0.158725   1.672131  0.163925  0.756639  0.726046  0.097874  \n",
       " DEC '17  2.000000  0.536733   1.162577  0.541671 -0.103784 -0.102564  0.428875  \n",
       " DEC '18  4.000000  0.923051   0.121986  0.914187  0.788216  0.793571  0.864284  \n",
       " DEC '19  9.533333  1.989617 -70.725664  1.517962  0.828133  0.880127  1.514400  \n",
       " DEC '20  1.191646  0.392611  -0.756187  0.598952  0.398116  0.417750  0.284618  \n",
       " DEC '21  0.269464  0.904995  -0.179817  0.934706  0.658663  0.629564  1.096312  \n",
       " DEC '22  3.819059  0.294198  -2.134554  0.322397  0.147281  0.258715  0.124285  \n",
       " \n",
       " [10 rows x 30 columns],\n",
       " 5:               0        1       2        3       4       5       6      7   \\\n",
       " DEC '12   5618.0   3079.0   382.0   2539.0  1684.0   855.0    53.0    0.0   \n",
       " DEC '13   6731.0   3740.0   453.0   2991.0  1896.0  1095.0   -14.0    0.0   \n",
       " DEC '14   8061.0   4387.0   516.0   3674.0  2370.0  1304.0   -39.0    2.0   \n",
       " DEC '15   9066.0   4351.0   608.0   4715.0  3388.0  1327.0   192.0    0.0   \n",
       " DEC '16  10723.0   5215.0   724.0   5508.0  4041.0  1467.0   154.0    0.0   \n",
       " DEC '17  13077.0   6240.0   543.0   6837.0  4595.0  2242.0   -32.0    0.0   \n",
       " DEC '18  15481.0   7549.0   514.0   7932.0  5399.0  2533.0   308.0   77.0   \n",
       " DEC '19  17534.0   8368.0   614.0   9166.0  6614.0  2552.0   659.0  115.0   \n",
       " DEC '20  21434.0   9629.0  1189.0  11805.0  8397.0  3408.0  2013.0  209.0   \n",
       " DEC '21  25561.0  13450.0  1265.0  12111.0  8646.0  4514.0  -134.0  232.0   \n",
       " DEC '22  27056.0  14258.0  1317.0  12798.0  9216.0  3582.0   -18.0  304.0   \n",
       " \n",
       "             8       9   ...        20         21        22         23  \\\n",
       " DEC '12   17.0   891.0  ...       NaN        NaN       NaN        NaN   \n",
       " DEC '13   -3.0  1084.0  ...  0.280702  -1.264151  0.000000  -1.176471   \n",
       " DEC '14    2.0  1261.0  ...  0.190868   1.785714  0.000000  -1.666667   \n",
       " DEC '15   31.0  1488.0  ...  0.017638  -5.923077 -1.000000  14.500000   \n",
       " DEC '16  -10.0  1631.0  ...  0.105501  -0.197917  0.000000  -1.322581   \n",
       " DEC '17   10.0  2200.0  ...  0.528289  -1.207792  0.000000  -2.000000   \n",
       " DEC '18  388.0  2376.0  ...  0.129795 -10.625000  0.000000  37.800000   \n",
       " DEC '19   98.0  2998.0  ...  0.007501   1.139610  0.493506  -0.747423   \n",
       " DEC '20  147.0  5065.0  ...  0.335423   2.054628  0.817391   0.500000   \n",
       " DEC '21   49.0  4099.0  ...  0.324531  -1.066567  0.110048  -0.666667   \n",
       " DEC '22 -106.0  3366.0  ... -0.206469  -0.865672  0.310345  -3.163265   \n",
       " \n",
       "                24         25        26        27        28        29  \n",
       " DEC '12       NaN        NaN       NaN       NaN       NaN       NaN  \n",
       " DEC '13  0.216611   0.141593  0.227506  0.206355  0.227458  0.251415  \n",
       " DEC '14  0.163284   5.527132 -0.561257 -0.556914 -0.561536  0.175711  \n",
       " DEC '15  0.180016  -0.691211  1.930788  1.947815  1.908668  0.063187  \n",
       " DEC '16  0.096102  -0.115385  0.140879  0.125542  0.150000  0.132300  \n",
       " DEC '17  0.348866   0.760870  0.281228  0.289507  0.278261  0.271109  \n",
       " DEC '18  0.080000  -0.212346  0.145961  0.311567  0.163197  0.094075  \n",
       " DEC '19  0.261785   0.689655  0.195430  0.099164  0.210539  0.039055  \n",
       " DEC '20  0.689460   0.601113  0.708825  0.704592  0.710228  0.451990  \n",
       " DEC '21 -0.190721  -1.081112 -0.007853 -0.022778 -0.007006  0.257124  \n",
       " DEC '22 -0.178824 -14.528571 -0.419765 -0.428664 -0.405724 -0.152275  \n",
       " \n",
       " [11 rows x 30 columns],\n",
       " 6:                0        1        2         3         4         5       6   \\\n",
       " JAN '09    18.156    2.797    0.758    15.359    30.427   -15.068   0.332   \n",
       " JAN '10    35.000    3.290    0.938    31.710    39.013    -7.303  -0.069   \n",
       " JAN '11    66.245    6.656    0.958    59.589    62.883    -3.294  -0.387   \n",
       " JAN '12   120.960   11.605    2.120   109.355   118.041    -8.686  -2.128   \n",
       " JAN '13   198.944   21.424    4.700   177.520   199.553   -22.033   0.152   \n",
       " JAN '14   302.623   33.725    6.692   268.898   345.105   -76.207  -0.695   \n",
       " JAN '15   450.875   68.378   12.494   382.497   598.307  -215.810   0.970   \n",
       " JAN '16   668.435  114.122   19.491   554.313   840.536  -286.223   1.279   \n",
       " JAN '17   949.955  191.053   32.113   758.902  1102.733  -343.831  -3.022   \n",
       " JAN '18  1309.132  256.409   40.941  1052.723  1238.133  -185.410   5.343   \n",
       " JAN '19  1803.010  344.676   52.430  1458.334  1703.507  -245.173  29.945   \n",
       " JAN '20  2358.926  433.569   67.500  1925.357  2188.792  -263.435  51.735   \n",
       " JAN '21  2229.385  564.875  118.010  1664.510  2433.572  -769.062  -4.738   \n",
       " JAN '22  2673.664  733.969  108.291  1939.695  3061.752 -1122.057   0.644   \n",
       " JAN '23  3653.708  836.517   99.794  2817.191  3084.826  -267.635  16.081   \n",
       " \n",
       "               7       8         9   ...        20         21        22  \\\n",
       " JAN '09    0.000     NaN   -14.736  ...       NaN        NaN       NaN   \n",
       " JAN '10    0.000     NaN    -7.372  ... -0.515331  -1.207831  0.000000   \n",
       " JAN '11    0.000     NaN    -3.681  ... -0.548952   4.608696  0.000000   \n",
       " JAN '12      NaN     NaN   -10.814  ...  1.636916   4.498708  0.000000   \n",
       " JAN '13    0.000  14.087   -35.968  ...  1.536611  -1.071429  0.000000   \n",
       " JAN '14    0.000   2.100   -79.002  ...  2.458766  -5.572368  0.000000   \n",
       " JAN '15    0.000   0.000  -214.840  ...  1.831892  -2.395683  0.000000   \n",
       " JAN '16    0.000   1.700  -286.644  ...  0.326273   0.318557  0.000000   \n",
       " JAN '17    2.829   0.000  -349.682  ...  0.201270  -3.362783  0.000000   \n",
       " JAN '18    8.794   0.000  -188.861  ... -0.460753  -2.768034  2.108519   \n",
       " JAN '19   41.963   6.000  -263.191  ...  0.322329   4.604529  3.771776   \n",
       " JAN '20   96.249  23.702  -331.651  ...  0.074486   0.727667  1.293663   \n",
       " JAN '21  123.076   4.172  -901.048  ...  1.919362  -1.091582  0.278725   \n",
       " JAN '22  174.598  55.200 -1351.211  ...  0.458994  -1.135922  0.418619   \n",
       " JAN '23   46.026   0.000  -297.580  ... -0.761478  23.970497 -0.736389   \n",
       " \n",
       "                 23        24          25        26        27        28  \\\n",
       " JAN '09        NaN       NaN         NaN       NaN       NaN       NaN   \n",
       " JAN '10   0.000000 -0.499729    1.194444 -0.495600 -0.495599 -0.495519   \n",
       " JAN '11   0.000000 -0.500678    0.582278 -0.489196 -0.489194 -0.489848   \n",
       " JAN '12   0.000000  1.937789    0.424000  1.888071  1.888055  1.890547   \n",
       " JAN '13   0.000000  2.326059    3.005618  2.337063  1.875045  2.958692   \n",
       " JAN '14  -0.850926  1.196452   -0.991585  1.153922  1.208058  0.630435   \n",
       " JAN '15  -1.000000  1.719425  378.333333  1.748026  1.456278  1.413333   \n",
       " JAN '16   0.000000  0.334221   -4.458699  0.283977  0.208179  0.215470   \n",
       " JAN '17  -1.000000  0.219917   -1.699568  0.274120  0.211127  0.204545   \n",
       " JAN '18   0.000000 -0.459906   -0.753586 -0.464460 -0.487265 -0.486792   \n",
       " JAN '19   0.000000  0.393570    8.127487  0.448743  0.369472  0.390662   \n",
       " JAN '20   2.950333  0.260115   -0.594946  0.221684  0.131002  0.171522   \n",
       " JAN '21  -0.823981  1.716856    0.381702  1.696960  1.689655  1.565329   \n",
       " JAN '22  12.231064  0.499599   -2.747548  0.474809  0.420125  0.457618   \n",
       " JAN '23  -1.000000 -0.779768    0.627703 -0.792500 -0.787319 -0.793461   \n",
       " \n",
       "                29  \n",
       " JAN '09       NaN  \n",
       " JAN '10 -0.555206  \n",
       " JAN '11 -0.632993  \n",
       " JAN '12  1.810788  \n",
       " JAN '13  1.639811  \n",
       " JAN '14  3.010558  \n",
       " JAN '15  1.924779  \n",
       " JAN '16  0.311909  \n",
       " JAN '17  0.168656  \n",
       " JAN '18 -0.536539  \n",
       " JAN '19  0.334148  \n",
       " JAN '20  0.016561  \n",
       " JAN '21  2.322796  \n",
       " JAN '22  0.557120  \n",
       " JAN '23 -0.834438  \n",
       " \n",
       " [15 rows x 30 columns],\n",
       " 7:                  0          1          2           3          4         5   \\\n",
       " JUN '85    0.140417   0.030447   0.003462    0.109970   0.069063   0.04091   \n",
       " JUN '86    0.197514   0.040862   0.005754    0.156652   0.095746   0.06091   \n",
       " JUN '87    0.345890   0.073854   0.007551    0.272036   0.145149   0.12689   \n",
       " JUN '88    0.590827   0.148000   0.016035    0.442827   0.255380   0.18745   \n",
       " JUN '89    0.803530   0.204185   0.024191    0.599345   0.357115   0.24223   \n",
       " JUN '90    1.183446   0.252668   0.046318    0.930778   0.537540   0.39324   \n",
       " JUN '91    1.843432   0.362589   0.075762    1.480843   0.831001   0.64984   \n",
       " JUN '92    2.758725   0.466424   0.112321    2.292301   1.296322   0.99598   \n",
       " JUN '93    3.753000   0.633000   0.151000    3.120000   1.794000   1.32600   \n",
       " JUN '94    4.649000   0.763000   0.237000    3.886000   2.160000   1.72600   \n",
       " JUN '95    5.937000   0.877000   0.269000    5.060000   3.022000   2.03800   \n",
       " JUN '96    8.671000   1.188000   0.480000    7.483000   4.405000   3.07800   \n",
       " JUN '97   11.358000   1.085000   0.557000   10.273000   5.143000   5.13000   \n",
       " JUN '98   14.484000   1.197000   1.024000   13.287000   6.347000   6.71000   \n",
       " JUN '99   19.747000   2.814000   1.010000   16.933000   6.890000   9.92800   \n",
       " JUN '00   22.956000   3.002000   0.748000   19.954000   8.925000  10.93700   \n",
       " JUN '01   25.296000   3.455000   1.266000   21.841000  10.121000  11.72000   \n",
       " JUN '02   28.365000   5.191000   1.014000   23.174000  10.604000  12.57000   \n",
       " JUN '03   32.187000   5.686000   1.090000   26.501000  12.261000  14.24000   \n",
       " JUN '04   36.835000   6.716000   0.817000   30.119000  18.560000  11.55900   \n",
       " JUN '05   39.731000   6.200000   0.884000   33.531000  16.947000  16.58400   \n",
       " JUN '06   44.116000   7.650000   0.990000   36.466000  18.840000  17.62600   \n",
       " JUN '07   50.954000  10.693000   1.406000   40.261000  21.394000  18.86700   \n",
       " JUN '08   60.316000  11.598000   1.872000   48.718000  24.506000  24.21200   \n",
       " JUN '09   57.553000  12.155000   2.291000   45.398000  25.306000  20.09200   \n",
       " JUN '10   61.989000  12.395000   2.507000   49.594000  25.932000  23.66200   \n",
       " JUN '11   69.950000  15.577000   2.651000   54.373000  27.205000  27.16800   \n",
       " JUN '12   73.750000  17.530000   2.875000   56.220000  28.237000  27.98300   \n",
       " JUN '13   77.654000  20.249000   3.549000   57.405000  30.836000  26.56900   \n",
       " JUN '14   86.729000  26.934000   4.445000   59.795000  32.013000  27.78200   \n",
       " JUN '15   92.972000  33.038000   5.479000   59.934000  32.370000  27.56400   \n",
       " JUN '16   84.695000  32.780000   5.947000   51.915000  31.248000  20.66700   \n",
       " JUN '17   96.016000  34.620000   7.855000   61.396000  32.620000  28.77600   \n",
       " JUN '18  110.175000  38.970000   9.954000   71.205000  36.332000  34.87300   \n",
       " JUN '19  125.502000  42.910000  11.600000   82.592000  39.974000  42.61800   \n",
       " JUN '20  143.015000  46.078000  12.300000   96.937000  43.978000  52.95900   \n",
       " JUN '21  168.088000  52.232000  10.900000  115.856000  45.940000  69.91600   \n",
       " JUN '22  198.270000  62.650000  14.460000  135.620000  52.237000  83.38300   \n",
       " \n",
       "                6         7       8          9   ...        20        21  \\\n",
       " JUN '85  0.001940  0.000000     NaN   0.042843  ...       NaN       NaN   \n",
       " JUN '86  0.005080       NaN     NaN   0.065984  ...  0.488878  1.618557   \n",
       " JUN '87 -0.005550       NaN     NaN   0.121338  ...  1.083238 -2.092520   \n",
       " JUN '88 -0.003710       NaN     NaN   0.183738  ...  0.477264 -0.331532   \n",
       " JUN '89  0.008570       NaN     NaN   0.250796  ...  0.292238 -3.309973   \n",
       " JUN '90  0.020920  0.003589     NaN   0.410564  ...  0.623416  1.441074   \n",
       " JUN '91  0.025320  0.004515     NaN   0.670644  ...  0.652528  0.210325   \n",
       " JUN '92  0.047272  0.001988     NaN   1.041265  ...  0.532654  0.866983   \n",
       " JUN '93  0.075000  0.000000     NaN   1.401000  ...  0.331352  0.586563   \n",
       " JUN '94  0.086000  0.000000   0.090   1.722000  ...  0.301659  0.146667   \n",
       " JUN '95  0.175000  0.000000   0.046   2.167000  ...  0.180765  1.034884   \n",
       " JUN '96  0.301000  0.000000     NaN   3.379000  ...  0.510304  0.720000   \n",
       " JUN '97  0.184000  0.000000     NaN   5.314000  ...  0.666667 -0.388704   \n",
       " JUN '98  0.703000  0.000000   0.296   7.117000  ...  0.307992  2.820652   \n",
       " JUN '99  1.963000  0.000000     NaN  11.891000  ...  0.479583  1.792319   \n",
       " JUN '00  3.338000  0.000000     NaN  14.275000  ...  0.101632  0.700458   \n",
       " JUN '01  3.725000  0.000000   3.920  11.525000  ...  0.071592  0.115938   \n",
       " JUN '02  3.926000  0.000000   4.983  11.513000  ...  0.072526  0.053960   \n",
       " JUN '03  2.657000  0.000000   2.171  14.726000  ...  0.132856 -0.323230   \n",
       " JUN '04  3.244000  0.000000   2.607  12.196000  ... -0.188272  0.220926   \n",
       " JUN '05  2.538000  0.000000   2.494  16.628000  ...  0.434726 -0.217633   \n",
       " JUN '06  2.440000  0.000000   1.804  18.262000  ...  0.062832 -0.038613   \n",
       " JUN '07  2.103000  0.000000   0.869  20.101000  ...  0.070407 -0.138115   \n",
       " JUN '08  1.512000  0.000000   1.910  23.814000  ...  0.283299 -0.281027   \n",
       " JUN '09  1.762000       NaN   2.033  19.821000  ... -0.170164  0.165344   \n",
       " JUN '10  1.770000  0.151000   0.268  25.013000  ...  0.177683  0.004540   \n",
       " JUN '11  1.355000  0.295000   0.157  28.071000  ...  0.148170 -0.234463   \n",
       " JUN '12  1.519000  0.380000   6.855  22.267000  ...  0.029999  0.121033   \n",
       " JUN '13  1.316000  0.429000   0.404  27.052000  ... -0.050531 -0.133641   \n",
       " JUN '14  1.196000  0.597000   0.561  27.820000  ...  0.045655 -0.091185   \n",
       " JUN '15  2.341000  0.781000  10.617  18.507000  ... -0.007847  0.957358   \n",
       " JUN '16  2.202000  1.243000   1.875  19.751000  ... -0.250218 -0.059376   \n",
       " JUN '17  4.218000  2.222000   0.871  29.901000  ...  0.392365  0.915531   \n",
       " JUN '18  4.568000  2.733000   0.234  36.474000  ...  0.211878  0.082978   \n",
       " JUN '19  3.159000  2.686000  -0.597  43.688000  ...  0.222092 -0.308450   \n",
       " JUN '20  2.545000  2.591000  -0.123  53.036000  ...  0.242644 -0.194365   \n",
       " JUN '21  2.488000  2.346000  -1.044  71.102000  ...  0.320191 -0.022397   \n",
       " JUN '22  2.040000  2.063000  -0.356  83.716000  ...  0.192617 -0.180064   \n",
       " \n",
       "                22         23        24        25        26        27  \\\n",
       " JUN '85       NaN        NaN       NaN       NaN       NaN       NaN   \n",
       " JUN '86  0.000000   0.000000  0.540135  0.426209  0.628729  0.000000   \n",
       " JUN '87  0.000000   0.000000  0.838900  0.850355  0.831100  0.000000   \n",
       " JUN '88  0.000000   0.000000  0.514266  0.209664  0.723865  2.413640   \n",
       " JUN '89  0.000000   0.000000  0.364965  0.341434  0.376328  0.365854   \n",
       " JUN '90  0.000000   0.000000  0.637044  0.636946  0.637090  0.542173   \n",
       " JUN '91  0.258011   0.000000  0.633470  0.582464  0.657472  0.582040   \n",
       " JUN '92 -0.559690   0.000000  0.552634  0.602710  0.530137  0.465020   \n",
       " JUN '93 -1.000000   0.000000  0.345479  0.344518  0.345931  0.305962   \n",
       " JUN '94  0.000000   0.000000  0.229122  0.285714  0.202518  0.260306   \n",
       " JUN '95  0.000000  -0.488889  0.258420  0.239583  0.267888  0.195143   \n",
       " JUN '96  0.000000  -1.000000  0.559299  0.658263  0.510668  0.447895   \n",
       " JUN '97  0.000000   0.000000  0.572655  0.570946  0.573576  0.528534   \n",
       " JUN '98  0.000000   0.000000  0.339292  0.412366  0.299942  0.328852   \n",
       " JUN '99  0.000000  -1.000000  0.670788  0.563000  0.733853  0.624947   \n",
       " JUN '00  0.000000   0.000000  0.200488  0.182172  0.210148  0.201010   \n",
       " JUN '01  0.000000   0.000000 -0.192644 -0.216316 -0.180448  0.104767   \n",
       " JUN '02  0.000000   0.271173 -0.001041 -0.031546  0.013988  0.085514   \n",
       " JUN '03  0.000000  -0.564319  0.279076  0.284745  0.276408  0.038223   \n",
       " JUN '04  0.000000   0.200829 -0.171805 -0.148954 -0.182628 -0.132967   \n",
       " JUN '05  0.000000  -0.043345  0.363398  0.085899  0.500245  0.399433   \n",
       " JUN '06  0.000000  -0.276664  0.098268  0.294696  0.028154  0.025400   \n",
       " JUN '07  0.000000  -0.518293  0.100701  0.065866  0.116358  0.127605   \n",
       " JUN '08  0.000000   1.197929  0.184717  0.016070  0.257092  0.353031   \n",
       " JUN '09  0.000000   0.064398 -0.167674 -0.143649 -0.176008 -0.114801   \n",
       " JUN '10  0.000000  -0.868175  0.261944  0.190594  0.287666  0.193968   \n",
       " JUN '11  0.953642  -0.414179  0.122256 -0.213018  0.234009  0.275306   \n",
       " JUN '12  0.288136  42.662420 -0.206761  0.074782 -0.266609 -0.054199   \n",
       " JUN '13  0.128947  -0.941065  0.214892 -0.018907  0.287725  0.021281   \n",
       " JUN '14  0.391608   0.388614  0.028390  0.107342  0.009651  0.023066   \n",
       " JUN '15  0.308208  17.925134 -0.334759  0.098851 -0.447631 -0.111144   \n",
       " JUN '16  0.591549  -0.823396  0.067218 -0.532309  0.377676 -0.049412   \n",
       " JUN '17  0.787611  -0.535467  0.513898  0.494074  0.517383  0.474385   \n",
       " JUN '18  0.229973  -0.731343  0.219825  3.511106 -0.349876 -0.355662   \n",
       " JUN '19 -0.017197  -3.551282  0.197785 -0.776516  1.367992  1.332110   \n",
       " JUN '20 -0.035369  -0.793970  0.213972  0.968300  0.128466  0.148767   \n",
       " JUN '21 -0.094558   7.487805  0.340637  0.122901  0.383686  0.383350   \n",
       " JUN '22 -0.120631  -0.659004  0.177407  0.116672  0.187152  0.208165   \n",
       " \n",
       "                28        29  \n",
       " JUN '85       NaN       NaN  \n",
       " JUN '86  0.000000  0.502366  \n",
       " JUN '87  0.000000  1.016802  \n",
       " JUN '88  2.422222  0.513538  \n",
       " JUN '89  0.363636  0.309318  \n",
       " JUN '90  0.547619  0.649876  \n",
       " JUN '91  0.584615  0.650742  \n",
       " JUN '92  0.462136  0.527426  \n",
       " JUN '93  0.306773  0.332672  \n",
       " JUN '94  0.194106  0.329045  \n",
       " JUN '95  0.234043  0.175242  \n",
       " JUN '96  0.478621  0.542263  \n",
       " JUN '97  0.533582  0.598370  \n",
       " JUN '98  0.269769  0.359944  \n",
       " JUN '99  0.700599  0.414275  \n",
       " JUN '00  0.197183  0.068294  \n",
       " JUN '01 -0.188235  0.111339  \n",
       " JUN '02  0.021739  0.046050  \n",
       " JUN '03  0.304965  0.128534  \n",
       " JUN '04 -0.184783 -0.192694  \n",
       " JUN '05  0.493333  0.411441  \n",
       " JUN '06  0.071429  0.065720  \n",
       " JUN '07  0.183333  0.089009  \n",
       " JUN '08  0.316901  0.286637  \n",
       " JUN '09 -0.133690 -0.141888  \n",
       " JUN '10  0.296296  0.169146  \n",
       " JUN '11  0.280952  0.139478  \n",
       " JUN '12 -0.256506  0.034844  \n",
       " JUN '13  0.290000 -0.023981  \n",
       " JUN '14  0.019380  0.070025  \n",
       " JUN '15 -0.437262  0.025320  \n",
       " JUN '16  0.418919 -0.194565  \n",
       " JUN '17  0.547619  0.376381  \n",
       " JUN '18 -0.344615  0.223745  \n",
       " JUN '19  1.375587  0.209494  \n",
       " JUN '20  0.139032  0.203641  \n",
       " JUN '21  0.397328  0.238389  \n",
       " JUN '22  0.197864  0.210688  \n",
       " \n",
       " [38 rows x 30 columns],\n",
       " 8:                0        1        2         3         4        5       6   \\\n",
       " JAN '15    41.010   21.522    4.715    19.488    78.270  -58.782  -0.199   \n",
       " JAN '16    85.907   44.462   11.327    41.445   117.433  -75.988  -0.019   \n",
       " JAN '17   160.326   69.683   18.302    90.643   173.766  -83.123   0.039   \n",
       " JAN '18   256.547   96.036   22.181   160.511   272.464 -111.953   1.682   \n",
       " JAN '19   399.254  134.273   28.853   264.981   383.503 -118.522   9.180   \n",
       " JAN '20   586.067  187.970   46.403   398.097   580.480 -182.383  17.089   \n",
       " JAN '21   835.424  257.342   76.526   578.082   782.241 -204.159  12.891   \n",
       " JAN '22  1300.201  396.405  107.612   903.796  1614.232 -710.436   9.768   \n",
       " JAN '23  1858.000  546.000  114.000  1312.000  2088.000 -776.000  22.000   \n",
       " \n",
       "              7       8        9   ...        20         21        22  \\\n",
       " JAN '15   0.000     NaN  -58.981  ...       NaN        NaN       NaN   \n",
       " JAN '16   0.000     NaN  -76.007  ...  0.292709  -0.904523  0.000000   \n",
       " JAN '17   0.000     NaN  -83.084  ...  0.093896  -3.052632  0.000000   \n",
       " JAN '18   0.000     NaN -110.170  ...  0.346835  42.128205  0.000000   \n",
       " JAN '19  15.072   1.100 -125.514  ...  0.058676   4.457788  0.000000   \n",
       " JAN '20  27.017  18.021 -210.332  ...  0.538811   0.861547  0.792529   \n",
       " JAN '21  72.660   2.263 -266.191  ...  0.119397  -0.245655  1.689418   \n",
       " JAN '22  92.182  56.846 -849.696  ...  2.479817  -0.242262  0.268676   \n",
       " JAN '23  11.000  36.000 -801.000  ...  0.092287   1.252252 -0.880671   \n",
       " \n",
       "                 23        24         25        26        27        28  \\\n",
       " JAN '15        NaN       NaN        NaN       NaN       NaN       NaN   \n",
       " JAN '16   0.000000  0.288669   1.269231  0.290826  0.000000 -0.000001   \n",
       " JAN '17   0.000000  0.093110   0.440678  0.094454  4.312381  4.312341   \n",
       " JAN '18   0.000000  0.326007  -1.755294  0.315415 -0.698293 -0.698295   \n",
       " JAN '19   0.000000  0.139276  -0.947040  0.142450 -0.123325 -0.117878   \n",
       " JAN '20  15.382727  0.675765  82.470588  0.664685  0.443362  0.526640   \n",
       " JAN '21  -0.874424  0.265575  -1.099366  0.274846  0.242777  0.174728   \n",
       " JAN '22  24.119753  2.192054 -10.113475  2.185539  1.624654  1.737438   \n",
       " JAN '23  -0.366710 -0.057310 -11.894942 -0.039381 -0.085002 -0.100085   \n",
       " \n",
       "                29  \n",
       " JAN '15       NaN  \n",
       " JAN '16  0.195942  \n",
       " JAN '17  0.002474  \n",
       " JAN '18  0.384922  \n",
       " JAN '19 -0.001147  \n",
       " JAN '20  0.516466  \n",
       " JAN '21 -0.061384  \n",
       " JAN '22  3.723105  \n",
       " JAN '23  0.098165  \n",
       " \n",
       " [9 rows x 30 columns],\n",
       " 9:                0        1        2         3         4        5       6   \\\n",
       " JUL '15    53.707   14.431    2.854    39.276    51.694  -12.418  -0.181   \n",
       " JUL '16    80.325   20.127    4.872    60.198    87.041  -26.843  -0.127   \n",
       " JUL '17   125.717   27.472    6.840    98.245   133.318  -35.073   0.490   \n",
       " JUL '18   190.174   37.875   21.169   152.299   178.884  -26.585   2.315   \n",
       " JUL '19   302.836   60.065   29.957   242.771   265.005  -22.234   7.401   \n",
       " JUL '20   431.269   97.087   59.595   334.182   429.036  -94.854   6.253   \n",
       " JUL '21   673.100  150.644   98.011   522.456   729.852 -207.396   3.998   \n",
       " JUL '22  1090.946  243.317  143.623   847.629  1175.058 -327.429   0.378   \n",
       " JAN '23  1348.012  298.254  168.097  1049.758  1353.209 -303.451  20.593   \n",
       " \n",
       "              7       8        9   ...        20         21        22  \\\n",
       " JUL '15   0.000     NaN  -12.599  ...       NaN        NaN       NaN   \n",
       " JUL '16   0.000     NaN  -26.970  ...  1.161620  -0.298343  0.000000   \n",
       " JUL '17   0.000     NaN  -34.583  ...  0.306598  -4.858268  0.000000   \n",
       " JUL '18   0.000   8.039  -32.309  ... -0.242010   3.724490  0.000000   \n",
       " JUL '19   0.000  13.079  -27.912  ... -0.163664   2.196976  0.000000   \n",
       " JUL '20   5.025  19.102 -112.728  ...  3.266169  -0.155114  0.000000   \n",
       " JUL '21  53.364   0.416 -257.178  ...  1.186476  -0.360627  9.619701   \n",
       " JUL '22  56.579   0.000 -383.630  ...  0.578762  -0.905453  0.060247   \n",
       " JAN '23  31.368   0.000 -314.226  ... -0.073231  53.478836 -0.445589   \n",
       " \n",
       "                23        24        25        26        27        28        29  \n",
       " JUL '15       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       " JUL '16  0.000000  1.140646  1.008584  1.138248  1.780334  1.778899  1.297261  \n",
       " JUL '17  0.000000  0.282277  0.873932  0.292368  0.247853  0.247937  0.285012  \n",
       " JUL '18  0.000000 -0.065755  0.524515 -0.051156  0.422619  0.655556 -0.808168  \n",
       " JUL '19  0.626944 -0.136092 -0.444278 -0.148339 -0.706529 -0.629434 -2.425960  \n",
       " JUL '20  0.460509  3.038693  2.213997  3.017309  3.985476  2.838292 -5.565454  \n",
       " JUL '21 -0.978222  1.281403  1.031407  1.276217  1.452438  1.170093  2.102328  \n",
       " JUL '22 -1.000000  0.491691  0.370439  0.489446  0.435637  0.434044  0.680358  \n",
       " JAN '23  0.000000 -0.180914  0.571300 -0.168101 -0.188917 -0.178448 -0.263604  \n",
       " \n",
       " [9 rows x 30 columns]}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0,len(data)):\n",
    "    data[i]=data[i].T\n",
    "    data[i]=data[i].reindex(index=data[i].index[::-1])\n",
    "data\n",
    "\n",
    "\n",
    "# y = customers[0][0].to_numpy(),customers[1][0].to_numpy()\n",
    "# X1 = [len(y[0]),len(y[1])]\n",
    "# X2 = [0,1]\n",
    "\n",
    "# fig = plt.figure()\n",
    "# # ax = fig.add_subplot(111, projection='3d')\n",
    "# ax = plt.axes(projection='3d')\n",
    "# p = ax.scatter(X1, X2, y, c=y, cmap='Greens')\n",
    "# ax.set_xlabel('$x_{1}$')\n",
    "# ax.set_ylabel('$x_{2}$')\n",
    "# ax.set_zlabel('$y$', rotation=0)\n",
    "\n",
    "# fig.colorbar(p, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2729ff07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JUN '07         NaN\n",
       "JUN '08    3.713366\n",
       "JUN '09    1.199636\n",
       "JUN '10    1.243282\n",
       "JUN '11    1.138083\n",
       "DEC '12    1.630714\n",
       "DEC '13    0.742425\n",
       "DEC '14    0.607354\n",
       "DEC '15    0.473095\n",
       "DEC '16    0.382935\n",
       "DEC '17    0.379702\n",
       "DEC '18    0.359825\n",
       "DEC '19    0.326440\n",
       "DEC '20    0.306044\n",
       "DEC '21    0.304574\n",
       "DEC '22    0.228799\n",
       "Name: 15, dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "565cf9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.71336554, 1.19963558, 1.24328242, 1.13808304, 1.63071426],\n",
       "       [0.44842841, 0.48539113, 0.43044745, 0.35636177, 0.42107895],\n",
       "       [4.08536783, 2.33539776, 1.17555702, 0.92478231, 0.72759035],\n",
       "       [3.12309108, 1.27546968, 0.88313624, 0.83679952, 0.75680794],\n",
       "       [0.77976763, 0.87874524, 0.6614945 , 0.43876539, 0.62915894],\n",
       "       [0.19811321, 0.19759323, 0.12467436, 0.18277079, 0.21952812],\n",
       "       [0.92773739, 0.89271429, 0.82594913, 0.64470899, 0.52114665],\n",
       "       [0.40662455, 0.75121764, 0.70813553, 0.36000894, 0.47280873],\n",
       "       [1.09478176, 0.86627399, 0.60015843, 0.55626065, 0.46790514],\n",
       "       [0.4956151 , 0.56510426, 0.51271507, 0.59241537, 0.42410083]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding input features\n",
    "\n",
    "m = 50\n",
    "x1 = data[0][15][1:6]\n",
    "x2 = data[1][15][1:6]\n",
    "x3 = data[2][15][1:6]\n",
    "x4 = data[3][15][1:6]\n",
    "x5 = data[4][15][1:6]\n",
    "x6 = data[5][15][1:6]\n",
    "x7 = data[6][15][1:6]\n",
    "x8 = data[7][15][1:6]\n",
    "x9 = data[8][15][1:6]\n",
    "x10 = data[9][15][1:6]\n",
    "\n",
    "X = np.array((x1, x2, x3, x4, x5, x6, x7, x8, x9, x10))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "78f118aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74242549, 0.37361773, 0.56474454, 0.60428198, 0.7451555 ,\n",
       "       0.18383421, 0.48989006, 0.55768155, 0.42547524, 0.56074283])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding y vector -> validate results\n",
    "y = np.array((data[0][15][6], data[1][15][6], data[2][15][6], data[3][15][6], data[4][15][6], data[5][15][6], data[6][15][6],data[7][15][6],data[8][15][6],data[9][15][6]))\n",
    "\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "40a9a0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0e1b73f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting data into test and training sets. 20% for test 80% for training\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "72992e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4a94263f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10702088040360741\n",
      "[-0.19129708  0.35235931 -0.1012761   0.25664592  0.49687377]\n"
     ]
    }
   ],
   "source": [
    "print(lin_reg.intercept_)\n",
    "print(lin_reg.coef_)\n",
    "theta_best = np.c_[lin_reg.intercept_, lin_reg.coef_[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8874a7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.537499557919785"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "34bed8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9d836709",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39484b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e7a7ce0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008788550477213643"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(ridge_regression.predict(X_val),y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "25359c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fit(degree, lambda_val):\n",
    "    poly_features = PolynomialFeatures(degree=degree, include_bias = False)\n",
    "    std_scaler = StandardScaler()\n",
    "    ridge_reg = Ridge(alpha=lambda_val,solver=\"sag\", random_state=42)\n",
    "    ridge_regression = Pipeline([\n",
    "    (\"poly_features\", poly_features),\n",
    "    (\"std_scaler\", std_scaler),\n",
    "    (\"ridge_reg\", ridge_reg),\n",
    "    \n",
    "    ])\n",
    "    ridge_regression.fit(X_train, y_train)\n",
    "    return mean_squared_error(ridge_regression.predict(X_val),y_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9a42502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best(degrees, lambdas):\n",
    "    best_degree = -1\n",
    "    best_lambda = -1\n",
    "    best = 10000000000000000000\n",
    "    for degree in range(degrees[0], degrees[1]):\n",
    "        for lambda_val in lambdas:\n",
    "            if get_fit(degree, lambda_val) < best:\n",
    "                best_degree = degree\n",
    "                best_lambda = lambda_val\n",
    "                best = get_fit(degree, lambda_val)\n",
    "            print(\"degree: \", degree)\n",
    "            print(\"lambda \", lambda_val)\n",
    "            print(\"loss: \", get_fit(degree, lambda_val))\n",
    "    return [best_degree, best_lambda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5f5cfec0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree:  1\n",
      "lambda  0.1\n",
      "loss:  0.17925453588904147\n",
      "degree:  1\n",
      "lambda  1\n",
      "loss:  0.05924734606027031\n",
      "degree:  1\n",
      "lambda  2\n",
      "loss:  0.04174542792472002\n",
      "degree:  1\n",
      "lambda  5\n",
      "loss:  0.032593651656200824\n",
      "degree:  1\n",
      "lambda  10\n",
      "loss:  0.03254935897963311\n",
      "degree:  2\n",
      "lambda  0.1\n",
      "loss:  0.12578513716787706\n",
      "degree:  2\n",
      "lambda  1\n",
      "loss:  0.14243970466008454\n",
      "degree:  2\n",
      "lambda  2\n",
      "loss:  0.12183210055740581\n",
      "degree:  2\n",
      "lambda  5\n",
      "loss:  0.08036508474887215\n",
      "degree:  2\n",
      "lambda  10\n",
      "loss:  0.05377395461140161\n",
      "degree:  3\n",
      "lambda  0.1\n",
      "loss:  0.008788550477213643\n",
      "degree:  3\n",
      "lambda  1\n",
      "loss:  0.10586622102558742\n",
      "degree:  3\n",
      "lambda  2\n",
      "loss:  0.14921045614654704\n",
      "degree:  3\n",
      "lambda  5\n",
      "loss:  0.1687290763534951\n",
      "degree:  3\n",
      "lambda  10\n",
      "loss:  0.14243820157044387\n",
      "degree:  4\n",
      "lambda  0.1\n",
      "loss:  0.1232412311183601\n",
      "degree:  4\n",
      "lambda  1\n",
      "loss:  0.015767817904234444\n",
      "degree:  4\n",
      "lambda  2\n",
      "loss:  0.05284872987881153\n",
      "degree:  4\n",
      "lambda  5\n",
      "loss:  0.16369210254212138\n",
      "degree:  4\n",
      "lambda  10\n",
      "loss:  0.23769389070019492\n",
      "degree:  5\n",
      "lambda  0.1\n",
      "loss:  0.7035817846932713\n",
      "degree:  5\n",
      "lambda  1\n",
      "loss:  0.24886730443218288\n",
      "degree:  5\n",
      "lambda  2\n",
      "loss:  0.08189429918272384\n",
      "degree:  5\n",
      "lambda  5\n",
      "loss:  0.041769268531784545\n",
      "degree:  5\n",
      "lambda  10\n",
      "loss:  0.2018761137632933\n",
      "degree:  6\n",
      "lambda  0.1\n",
      "loss:  2.7754785062503426\n",
      "degree:  6\n",
      "lambda  1\n",
      "loss:  1.7962236655120263\n",
      "degree:  6\n",
      "lambda  2\n",
      "loss:  1.1111995466907882\n",
      "degree:  6\n",
      "lambda  5\n",
      "loss:  0.22515705992772694\n",
      "degree:  6\n",
      "lambda  10\n",
      "loss:  0.03956481856325881\n",
      "degree:  7\n",
      "lambda  0.1\n",
      "loss:  10.030431523044106\n",
      "degree:  7\n",
      "lambda  1\n",
      "loss:  7.754679707546519\n",
      "degree:  7\n",
      "lambda  2\n",
      "loss:  5.859308621008619\n",
      "degree:  7\n",
      "lambda  5\n",
      "loss:  2.5019582198941803\n",
      "degree:  7\n",
      "lambda  10\n",
      "loss:  0.42129933840304373\n",
      "degree:  8\n",
      "lambda  0.1\n",
      "loss:  33.28478856789985\n",
      "degree:  8\n",
      "lambda  1\n",
      "loss:  27.995441305715254\n",
      "degree:  8\n",
      "lambda  2\n",
      "loss:  23.029347871060576\n",
      "degree:  8\n",
      "lambda  5\n",
      "loss:  12.638024841784869\n",
      "degree:  8\n",
      "lambda  10\n",
      "loss:  4.196212120270355\n",
      "degree:  9\n",
      "lambda  0.1\n",
      "loss:  98.94623991032103\n",
      "degree:  9\n",
      "lambda  1\n",
      "loss:  85.81124737974562\n",
      "degree:  9\n",
      "lambda  2\n",
      "loss:  73.5422460231736\n",
      "degree:  9\n",
      "lambda  5\n",
      "loss:  45.760549972149626\n",
      "degree:  9\n",
      "lambda  10\n",
      "loss:  19.729319692870483\n",
      "degree:  10\n",
      "lambda  0.1\n",
      "loss:  256.6423844062326\n",
      "degree:  10\n",
      "lambda  1\n",
      "loss:  227.7943060031028\n",
      "degree:  10\n",
      "lambda  2\n",
      "loss:  199.88451575437233\n",
      "degree:  10\n",
      "lambda  5\n",
      "loss:  133.69462558392797\n",
      "degree:  10\n",
      "lambda  10\n",
      "loss:  65.39910482119379\n",
      "degree:  11\n",
      "lambda  0.1\n",
      "loss:  579.0638696633242\n",
      "degree:  11\n",
      "lambda  1\n",
      "loss:  519.1689491614198\n",
      "degree:  11\n",
      "lambda  2\n",
      "loss:  462.6390992972709\n",
      "degree:  11\n",
      "lambda  5\n",
      "loss:  319.64270888486817\n",
      "degree:  11\n",
      "lambda  10\n",
      "loss:  164.84276169008945\n",
      "degree:  12\n",
      "lambda  0.1\n",
      "loss:  1079.8008308268163\n",
      "degree:  12\n",
      "lambda  1\n",
      "loss:  970.1860623461139\n",
      "degree:  12\n",
      "lambda  2\n",
      "loss:  863.0270385690446\n",
      "degree:  12\n",
      "lambda  5\n",
      "loss:  599.5433134835788\n",
      "degree:  12\n",
      "lambda  10\n",
      "loss:  302.0222220088043\n",
      "degree:  13\n",
      "lambda  0.1\n",
      "loss:  1464.529836639591\n",
      "degree:  13\n",
      "lambda  1\n",
      "loss:  1300.466545257128\n",
      "degree:  13\n",
      "lambda  2\n",
      "loss:  1140.17120251829\n",
      "degree:  13\n",
      "lambda  5\n",
      "loss:  738.1655940405354\n",
      "degree:  13\n",
      "lambda  10\n",
      "loss:  299.3095563649126\n",
      "degree:  14\n",
      "lambda  0.1\n",
      "loss:  863.7690970644584\n",
      "degree:  14\n",
      "lambda  1\n",
      "loss:  699.3751753290578\n",
      "degree:  14\n",
      "lambda  2\n",
      "loss:  546.9226067021159\n",
      "degree:  14\n",
      "lambda  5\n",
      "loss:  217.27915225383873\n",
      "degree:  14\n",
      "lambda  10\n",
      "loss:  2.4459783395297316\n",
      "degree:  15\n",
      "lambda  0.1\n",
      "loss:  405.9202296039249\n",
      "degree:  15\n",
      "lambda  1\n",
      "loss:  576.0763001026611\n",
      "degree:  15\n",
      "lambda  2\n",
      "loss:  763.0542932632322\n",
      "degree:  15\n",
      "lambda  5\n",
      "loss:  1517.1361389541112\n",
      "degree:  15\n",
      "lambda  10\n",
      "loss:  3173.8892952468627\n",
      "degree:  16\n",
      "lambda  0.1\n",
      "loss:  28593.3960788644\n",
      "degree:  16\n",
      "lambda  1\n",
      "loss:  30286.6340500403\n",
      "degree:  16\n",
      "lambda  2\n",
      "loss:  32098.460784357532\n",
      "degree:  16\n",
      "lambda  5\n",
      "loss:  37479.376875707\n",
      "degree:  16\n",
      "lambda  10\n",
      "loss:  46822.04990828362\n",
      "degree:  17\n",
      "lambda  0.1\n",
      "loss:  299610.3049435583\n",
      "degree:  17\n",
      "lambda  1\n",
      "loss:  305137.5197387386\n",
      "degree:  17\n",
      "lambda  2\n",
      "loss:  312191.6959472578\n",
      "degree:  17\n",
      "lambda  5\n",
      "loss:  334659.4344459552\n",
      "degree:  17\n",
      "lambda  10\n",
      "loss:  370281.13896720466\n",
      "degree:  18\n",
      "lambda  0.1\n",
      "loss:  2044055.477826562\n",
      "degree:  18\n",
      "lambda  1\n",
      "loss:  2069305.5182393517\n",
      "degree:  18\n",
      "lambda  2\n",
      "loss:  2090623.6502517795\n",
      "degree:  18\n",
      "lambda  5\n",
      "loss:  2164348.4980950113\n",
      "degree:  18\n",
      "lambda  10\n",
      "loss:  2279501.7895788956\n",
      "degree:  19\n",
      "lambda  0.1\n",
      "loss:  11606573.672002176\n",
      "degree:  19\n",
      "lambda  1\n",
      "loss:  11675491.4442105\n",
      "degree:  19\n",
      "lambda  2\n",
      "loss:  11747442.35909202\n",
      "degree:  19\n",
      "lambda  5\n",
      "loss:  11981478.082582027\n",
      "degree:  19\n",
      "lambda  10\n",
      "loss:  12333648.826593153\n",
      "[3, 0.1]\n"
     ]
    }
   ],
   "source": [
    "lambdas = {0.1, 1,2,5,10}\n",
    "degrees = [1,20]\n",
    "print(find_best(degrees, lambdas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "03d443d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e009e923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('poly_features',\n",
       "                 PolynomialFeatures(degree=3, include_bias=False)),\n",
       "                ('std_scaler', StandardScaler()),\n",
       "                ('ridge_reg', Ridge(alpha=0.1, random_state=42, solver='sag'))])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_features = PolynomialFeatures(degree=3, include_bias = False)\n",
    "std_scaler = StandardScaler()\n",
    "ridge_reg = Ridge(alpha=0.1,solver=\"sag\", random_state=42)\n",
    "ridge_regression = Pipeline([\n",
    "    (\"poly_features\", poly_features),\n",
    "    (\"std_scaler\", std_scaler),\n",
    "    (\"ridge_reg\", ridge_reg),\n",
    "    \n",
    "])\n",
    "ridge_regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d2aa9b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008788550477213643"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(ridge_regression.predict(X_val),y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "548f3a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JUN '07          NaN\n",
       "JUN '08    10.500000\n",
       "JUN '09     1.086957\n",
       "JUN '10     4.833333\n",
       "JUN '11     3.771429\n",
       "DEC '12     0.023952\n",
       "DEC '13     0.835526\n",
       "DEC '14     0.532059\n",
       "DEC '15     0.407330\n",
       "DEC '16    -0.676210\n",
       "DEC '17     0.962350\n",
       "DEC '18    -4.581395\n",
       "DEC '19    44.415016\n",
       "DEC '20    -1.054837\n",
       "DEC '21    -0.380744\n",
       "DEC '22     2.894737\n",
       "Name: 25, dtype: float64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array of linear regression models for each row \n",
    "data[0][25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "dfd99833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.537499557919785\n",
      "-2.7350071400665965\n",
      "-17.162778692311043\n",
      "-53.39321898775143\n",
      "-36.206529131137096\n",
      "-3293.2909373942234\n",
      "-25.10783238902046\n",
      "-3.5763579842807163\n",
      "-10.403490091098616\n",
      "0.3529290792318406\n",
      "-265221163.33122963\n",
      "-6.465655881781788\n",
      "-46.804649212351734\n",
      "-9.970508354701288\n"
     ]
    }
   ],
   "source": [
    "modelArray = np.array([])\n",
    "\n",
    "for row in range(15, 29):\n",
    "    # splitting data into x and y vectors\n",
    "    m = 50\n",
    "    x1 = data[0][row][1:6]\n",
    "    x2 = data[1][row][1:6]\n",
    "    x3 = data[2][row][1:6]\n",
    "    x4 = data[3][row][1:6]\n",
    "    x5 = data[4][row][1:6]\n",
    "    x6 = data[5][row][1:6]\n",
    "    x7 = data[6][row][1:6]\n",
    "    x8 = data[7][row][1:6]\n",
    "    x9 = data[8][row][1:6]\n",
    "    x10 = data[9][row][1:6]\n",
    "\n",
    "    # x vector\n",
    "    X = np.array((x1, x2, x3, x4, x5, x6, x7, x8, x9, x10))\n",
    "    \n",
    "    # y vector\n",
    "    y = np.array((data[0][row][6], data[1][row][6], data[2][row][6], data[3][row][6], data[4][row][6], data[5][row][6], data[6][row][6],data[7][row][6],data[8][row][6],data[9][row][6]))\n",
    "\n",
    "    # linear regression variable\n",
    "    lin_reg = LinearRegression()\n",
    "    \n",
    "    # test/ train split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "    print(lin_reg.score(X_test, y_test))\n",
    "    \n",
    "    modelArray = np.append(modelArray, lin_reg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2c640489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelArray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be91d034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1980ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating all poly models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "84bf7a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree:  1\n",
      "lambda  0.1\n",
      "loss:  0.17925453588904147\n",
      "degree:  1\n",
      "lambda  1\n",
      "loss:  0.05924734606027031\n",
      "degree:  1\n",
      "lambda  2\n",
      "loss:  0.04174542792472002\n",
      "degree:  1\n",
      "lambda  5\n",
      "loss:  0.032593651656200824\n",
      "degree:  1\n",
      "lambda  10\n",
      "loss:  0.03254935897963311\n",
      "degree:  2\n",
      "lambda  0.1\n",
      "loss:  0.12578513716787706\n",
      "degree:  2\n",
      "lambda  1\n",
      "loss:  0.14243970466008454\n",
      "degree:  2\n",
      "lambda  2\n",
      "loss:  0.12183210055740581\n",
      "degree:  2\n",
      "lambda  5\n",
      "loss:  0.08036508474887215\n",
      "degree:  2\n",
      "lambda  10\n",
      "loss:  0.05377395461140161\n",
      "degree:  3\n",
      "lambda  0.1\n",
      "loss:  0.008788550477213643\n",
      "degree:  3\n",
      "lambda  1\n",
      "loss:  0.10586622102558742\n",
      "degree:  3\n",
      "lambda  2\n",
      "loss:  0.14921045614654704\n",
      "degree:  3\n",
      "lambda  5\n",
      "loss:  0.1687290763534951\n",
      "degree:  3\n",
      "lambda  10\n",
      "loss:  0.14243820157044387\n",
      "degree:  4\n",
      "lambda  0.1\n",
      "loss:  0.1232412311183601\n",
      "degree:  4\n",
      "lambda  1\n",
      "loss:  0.015767817904234444\n",
      "degree:  4\n",
      "lambda  2\n",
      "loss:  0.05284872987881153\n",
      "degree:  4\n",
      "lambda  5\n",
      "loss:  0.16369210254212138\n",
      "degree:  4\n",
      "lambda  10\n",
      "loss:  0.23769389070019492\n",
      "degree:  5\n",
      "lambda  0.1\n",
      "loss:  0.7035817846932713\n",
      "degree:  5\n",
      "lambda  1\n",
      "loss:  0.24886730443218288\n",
      "degree:  5\n",
      "lambda  2\n",
      "loss:  0.08189429918272384\n",
      "degree:  5\n",
      "lambda  5\n",
      "loss:  0.041769268531784545\n",
      "degree:  5\n",
      "lambda  10\n",
      "loss:  0.2018761137632933\n",
      "degree:  6\n",
      "lambda  0.1\n",
      "loss:  2.7754785062503426\n",
      "degree:  6\n",
      "lambda  1\n",
      "loss:  1.7962236655120263\n",
      "degree:  6\n",
      "lambda  2\n",
      "loss:  1.1111995466907882\n",
      "degree:  6\n",
      "lambda  5\n",
      "loss:  0.22515705992772694\n",
      "degree:  6\n",
      "lambda  10\n",
      "loss:  0.03956481856325881\n",
      "degree:  7\n",
      "lambda  0.1\n",
      "loss:  10.030431523044106\n",
      "degree:  7\n",
      "lambda  1\n",
      "loss:  7.754679707546519\n",
      "degree:  7\n",
      "lambda  2\n",
      "loss:  5.859308621008619\n",
      "degree:  7\n",
      "lambda  5\n",
      "loss:  2.5019582198941803\n",
      "degree:  7\n",
      "lambda  10\n",
      "loss:  0.42129933840304373\n",
      "degree:  8\n",
      "lambda  0.1\n",
      "loss:  33.28478856789985\n",
      "degree:  8\n",
      "lambda  1\n",
      "loss:  27.995441305715254\n",
      "degree:  8\n",
      "lambda  2\n",
      "loss:  23.029347871060576\n",
      "degree:  8\n",
      "lambda  5\n",
      "loss:  12.638024841784869\n",
      "degree:  8\n",
      "lambda  10\n",
      "loss:  4.196212120270355\n",
      "degree:  9\n",
      "lambda  0.1\n",
      "loss:  98.94623991032103\n",
      "degree:  9\n",
      "lambda  1\n",
      "loss:  85.81124737974562\n",
      "degree:  9\n",
      "lambda  2\n",
      "loss:  73.5422460231736\n",
      "degree:  9\n",
      "lambda  5\n",
      "loss:  45.760549972149626\n",
      "degree:  9\n",
      "lambda  10\n",
      "loss:  19.729319692870483\n",
      "degree:  10\n",
      "lambda  0.1\n",
      "loss:  256.6423844062326\n",
      "degree:  10\n",
      "lambda  1\n",
      "loss:  227.7943060031028\n",
      "degree:  10\n",
      "lambda  2\n",
      "loss:  199.88451575437233\n",
      "degree:  10\n",
      "lambda  5\n",
      "loss:  133.69462558392797\n",
      "degree:  10\n",
      "lambda  10\n",
      "loss:  65.39910482119379\n",
      "degree:  11\n",
      "lambda  0.1\n",
      "loss:  579.0638696633242\n",
      "degree:  11\n",
      "lambda  1\n",
      "loss:  519.1689491614198\n",
      "degree:  11\n",
      "lambda  2\n",
      "loss:  462.6390992972709\n",
      "degree:  11\n",
      "lambda  5\n",
      "loss:  319.64270888486817\n",
      "degree:  11\n",
      "lambda  10\n",
      "loss:  164.84276169008945\n",
      "degree:  12\n",
      "lambda  0.1\n",
      "loss:  1079.8008308268163\n",
      "degree:  12\n",
      "lambda  1\n",
      "loss:  970.1860623461139\n",
      "degree:  12\n",
      "lambda  2\n",
      "loss:  863.0270385690446\n",
      "degree:  12\n",
      "lambda  5\n",
      "loss:  599.5433134835788\n",
      "degree:  12\n",
      "lambda  10\n",
      "loss:  302.0222220088043\n",
      "degree:  13\n",
      "lambda  0.1\n",
      "loss:  1464.529836639591\n",
      "degree:  13\n",
      "lambda  1\n",
      "loss:  1300.466545257128\n",
      "degree:  13\n",
      "lambda  2\n",
      "loss:  1140.17120251829\n",
      "degree:  13\n",
      "lambda  5\n",
      "loss:  738.1655940405354\n",
      "degree:  13\n",
      "lambda  10\n",
      "loss:  299.3095563649126\n",
      "degree:  14\n",
      "lambda  0.1\n",
      "loss:  863.7690970644584\n",
      "degree:  14\n",
      "lambda  1\n",
      "loss:  699.3751753290578\n",
      "degree:  14\n",
      "lambda  2\n",
      "loss:  546.9226067021159\n",
      "degree:  14\n",
      "lambda  5\n",
      "loss:  217.27915225383873\n",
      "degree:  14\n",
      "lambda  10\n",
      "loss:  2.4459783395297316\n",
      "degree:  15\n",
      "lambda  0.1\n",
      "loss:  405.9202296039249\n",
      "degree:  15\n",
      "lambda  1\n",
      "loss:  576.0763001026611\n",
      "degree:  15\n",
      "lambda  2\n",
      "loss:  763.0542932632322\n",
      "degree:  15\n",
      "lambda  5\n",
      "loss:  1517.1361389541112\n",
      "degree:  15\n",
      "lambda  10\n",
      "loss:  3173.8892952468627\n",
      "degree:  16\n",
      "lambda  0.1\n",
      "loss:  28593.3960788644\n",
      "degree:  16\n",
      "lambda  1\n",
      "loss:  30286.6340500403\n",
      "degree:  16\n",
      "lambda  2\n",
      "loss:  32098.460784357532\n",
      "degree:  16\n",
      "lambda  5\n",
      "loss:  37479.376875707\n",
      "degree:  16\n",
      "lambda  10\n",
      "loss:  46822.04990828362\n",
      "degree:  17\n",
      "lambda  0.1\n",
      "loss:  299610.3049435583\n",
      "degree:  17\n",
      "lambda  1\n",
      "loss:  305137.5197387386\n",
      "degree:  17\n",
      "lambda  2\n",
      "loss:  312191.6959472578\n",
      "degree:  17\n",
      "lambda  5\n",
      "loss:  334659.4344459552\n",
      "degree:  17\n",
      "lambda  10\n",
      "loss:  370281.13896720466\n",
      "degree:  18\n",
      "lambda  0.1\n",
      "loss:  2044055.477826562\n",
      "degree:  18\n",
      "lambda  1\n",
      "loss:  2069305.5182393517\n",
      "degree:  18\n",
      "lambda  2\n",
      "loss:  2090623.6502517795\n",
      "degree:  18\n",
      "lambda  5\n",
      "loss:  2164348.4980950113\n",
      "degree:  18\n",
      "lambda  10\n",
      "loss:  2279501.7895788956\n",
      "degree:  19\n",
      "lambda  0.1\n",
      "loss:  11606573.672002176\n",
      "degree:  19\n",
      "lambda  1\n",
      "loss:  11675491.4442105\n",
      "degree:  19\n",
      "lambda  2\n",
      "loss:  11747442.35909202\n",
      "degree:  19\n",
      "lambda  5\n",
      "loss:  11981478.082582027\n",
      "degree:  19\n",
      "lambda  10\n",
      "loss:  12333648.826593153\n",
      "degree:  1\n",
      "lambda  0.1\n",
      "loss:  0.3275920887954752\n",
      "degree:  1\n",
      "lambda  1\n",
      "loss:  0.0583335252114832\n",
      "degree:  1\n",
      "lambda  2\n",
      "loss:  0.08971201221946984\n",
      "degree:  1\n",
      "lambda  5\n",
      "loss:  0.11737818216939375\n",
      "degree:  1\n",
      "lambda  10\n",
      "loss:  0.10659330957949784\n",
      "degree:  2\n",
      "lambda  0.1\n",
      "loss:  1.7858624878039462\n",
      "degree:  2\n",
      "lambda  1\n",
      "loss:  0.44108561269855007\n",
      "degree:  2\n",
      "lambda  2\n",
      "loss:  0.13345685959897033\n",
      "degree:  2\n",
      "lambda  5\n",
      "loss:  0.06014122079460994\n",
      "degree:  2\n",
      "lambda  10\n",
      "loss:  0.11910380573903115\n",
      "degree:  3\n",
      "lambda  0.1\n",
      "loss:  8.153592366475726\n",
      "degree:  3\n",
      "lambda  1\n",
      "loss:  4.576558109893314\n",
      "degree:  3\n",
      "lambda  2\n",
      "loss:  2.6633235272149647\n",
      "degree:  3\n",
      "lambda  5\n",
      "loss:  0.6916916883668116\n",
      "degree:  3\n",
      "lambda  10\n",
      "loss:  0.10616010693899836\n",
      "degree:  4\n",
      "lambda  0.1\n",
      "loss:  35.84584319737832\n",
      "degree:  4\n",
      "lambda  1\n",
      "loss:  27.081749409499828\n",
      "degree:  4\n",
      "lambda  2\n",
      "loss:  20.51174420370751\n",
      "degree:  4\n",
      "lambda  5\n",
      "loss:  10.22172566339966\n",
      "degree:  4\n",
      "lambda  10\n",
      "loss:  3.9325796637011\n",
      "degree:  5\n",
      "lambda  0.1\n",
      "loss:  164.33296720728376\n",
      "degree:  5\n",
      "lambda  1\n",
      "loss:  138.71615988012502\n",
      "degree:  5\n",
      "lambda  2\n",
      "loss:  118.02771558452967\n",
      "degree:  5\n",
      "lambda  5\n",
      "loss:  77.21280163459895\n",
      "degree:  5\n",
      "lambda  10\n",
      "loss:  42.671827263745136\n",
      "degree:  6\n",
      "lambda  0.1\n",
      "loss:  713.8000642673484\n",
      "degree:  6\n",
      "lambda  1\n",
      "loss:  645.0344286142922\n",
      "degree:  6\n",
      "lambda  2\n",
      "loss:  580.8804935719446\n",
      "degree:  6\n",
      "lambda  5\n",
      "loss:  437.03466239427286\n",
      "degree:  6\n",
      "lambda  10\n",
      "loss:  289.0588586369509\n",
      "degree:  7\n",
      "lambda  0.1\n",
      "loss:  2836.078856928592\n",
      "degree:  7\n",
      "lambda  1\n",
      "loss:  2648.219066824441\n",
      "degree:  7\n",
      "lambda  2\n",
      "loss:  2463.2491442028263\n",
      "degree:  7\n",
      "lambda  5\n",
      "loss:  2006.5286177022617\n",
      "degree:  7\n",
      "lambda  10\n",
      "loss:  1478.3288875351911\n",
      "degree:  8\n",
      "lambda  0.1\n",
      "loss:  10585.986152277286\n",
      "degree:  8\n",
      "lambda  1\n",
      "loss:  10067.804168861232\n",
      "degree:  8\n",
      "lambda  2\n",
      "loss:  9525.920522372817\n",
      "degree:  8\n",
      "lambda  5\n",
      "loss:  8167.817002803469\n",
      "degree:  8\n",
      "lambda  10\n",
      "loss:  6465.922941066135\n",
      "degree:  9\n",
      "lambda  0.1\n",
      "loss:  39156.28544068015\n",
      "degree:  9\n",
      "lambda  1\n",
      "loss:  37676.65438343043\n",
      "degree:  9\n",
      "lambda  2\n",
      "loss:  36147.14431526879\n",
      "degree:  9\n",
      "lambda  5\n",
      "loss:  32025.821607051806\n",
      "degree:  9\n",
      "lambda  10\n",
      "loss:  26601.27061678887\n",
      "degree:  10\n",
      "lambda  0.1\n",
      "loss:  151592.15000552716\n",
      "degree:  10\n",
      "lambda  1\n",
      "loss:  147389.99375391944\n",
      "degree:  10\n",
      "lambda  2\n",
      "loss:  142559.28090326593\n",
      "degree:  10\n",
      "lambda  5\n",
      "loss:  129524.97156484993\n",
      "degree:  10\n",
      "lambda  10\n",
      "loss:  111392.62631326483\n",
      "degree:  11\n",
      "lambda  0.1\n",
      "loss:  629244.7493389791\n",
      "degree:  11\n",
      "lambda  1\n",
      "loss:  615423.9412658131\n",
      "degree:  11\n",
      "lambda  2\n",
      "loss:  598977.9455869378\n",
      "degree:  11\n",
      "lambda  5\n",
      "loss:  553392.2558461676\n",
      "degree:  11\n",
      "lambda  10\n",
      "loss:  488714.41176452936\n",
      "degree:  12\n",
      "lambda  0.1\n",
      "loss:  2657304.266292047\n",
      "degree:  12\n",
      "lambda  1\n",
      "loss:  2607375.410347817\n",
      "degree:  12\n",
      "lambda  2\n",
      "loss:  2550342.2787259524\n",
      "degree:  12\n",
      "lambda  5\n",
      "loss:  2387819.895175354\n",
      "degree:  12\n",
      "lambda  10\n",
      "loss:  2153727.14064575\n",
      "degree:  13\n",
      "lambda  0.1\n",
      "loss:  10769394.560922464\n",
      "degree:  13\n",
      "lambda  1\n",
      "loss:  10572657.312318025\n",
      "degree:  13\n",
      "lambda  2\n",
      "loss:  10386466.10388614\n",
      "degree:  13\n",
      "lambda  5\n",
      "loss:  9832931.89910591\n",
      "degree:  13\n",
      "lambda  10\n",
      "loss:  9011008.560887901\n",
      "degree:  14\n",
      "lambda  0.1\n",
      "loss:  41850478.79292102\n",
      "degree:  14\n",
      "lambda  1\n",
      "loss:  41237362.83821836\n",
      "degree:  14\n",
      "lambda  2\n",
      "loss:  40669689.17068133\n",
      "degree:  14\n",
      "lambda  5\n",
      "loss:  38874483.20707116\n",
      "degree:  14\n",
      "lambda  10\n",
      "loss:  36104765.29532768\n",
      "degree:  15\n",
      "lambda  0.1\n",
      "loss:  162836318.2440801\n",
      "degree:  15\n",
      "lambda  1\n",
      "loss:  160667249.44647527\n",
      "degree:  15\n",
      "lambda  2\n",
      "loss:  158407934.01503167\n",
      "degree:  15\n",
      "lambda  5\n",
      "loss:  152725799.79324028\n",
      "degree:  15\n",
      "lambda  10\n",
      "loss:  143487169.28818426\n",
      "degree:  16\n",
      "lambda  0.1\n",
      "loss:  659183334.5602508\n",
      "degree:  16\n",
      "lambda  1\n",
      "loss:  653767716.5109094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree:  16\n",
      "lambda  2\n",
      "loss:  645367324.0643737\n",
      "degree:  16\n",
      "lambda  5\n",
      "loss:  625848948.996963\n",
      "degree:  16\n",
      "lambda  10\n",
      "loss:  592819619.2604784\n",
      "degree:  17\n",
      "lambda  0.1\n",
      "loss:  2817648353.883451\n",
      "degree:  17\n",
      "lambda  1\n",
      "loss:  2797267417.71625\n",
      "degree:  17\n",
      "lambda  2\n",
      "loss:  2769585559.9946594\n",
      "degree:  17\n",
      "lambda  5\n",
      "loss:  2694160036.3751645\n",
      "degree:  17\n",
      "lambda  10\n",
      "loss:  2575066143.047201\n",
      "degree:  18\n",
      "lambda  0.1\n",
      "loss:  12026936572.37197\n",
      "degree:  18\n",
      "lambda  1\n",
      "loss:  11923547647.169811\n",
      "degree:  18\n",
      "lambda  2\n",
      "loss:  11815333011.632843\n",
      "degree:  18\n",
      "lambda  5\n",
      "loss:  11546467047.960201\n",
      "degree:  18\n",
      "lambda  10\n",
      "loss:  11105511935.996609\n",
      "degree:  19\n",
      "lambda  0.1\n",
      "loss:  48894485988.224075\n",
      "degree:  19\n",
      "lambda  1\n",
      "loss:  48500623834.523964\n",
      "degree:  19\n",
      "lambda  2\n",
      "loss:  48197906779.30215\n",
      "degree:  19\n",
      "lambda  5\n",
      "loss:  47193403529.09056\n",
      "degree:  19\n",
      "lambda  10\n",
      "loss:  45638960899.06559\n",
      "degree:  1\n",
      "lambda  0.1\n",
      "loss:  8.444084315553924\n",
      "degree:  1\n",
      "lambda  1\n",
      "loss:  9.747110753937786\n",
      "degree:  1\n",
      "lambda  2\n",
      "loss:  8.875970401429324\n",
      "degree:  1\n",
      "lambda  5\n",
      "loss:  7.360019906386167\n",
      "degree:  1\n",
      "lambda  10\n",
      "loss:  6.4940120340710585\n",
      "degree:  2\n",
      "lambda  0.1\n",
      "loss:  67.04966412925087\n",
      "degree:  2\n",
      "lambda  1\n",
      "loss:  72.00841340502353\n",
      "degree:  2\n",
      "lambda  2\n",
      "loss:  68.76406019700569\n",
      "degree:  2\n",
      "lambda  5\n",
      "loss:  54.63923423712326\n",
      "degree:  2\n",
      "lambda  10\n",
      "loss:  39.039683403242364\n",
      "degree:  3\n",
      "lambda  0.1\n",
      "loss:  1692.2320265210503\n",
      "degree:  3\n",
      "lambda  1\n",
      "loss:  1568.7386322734064\n",
      "degree:  3\n",
      "lambda  2\n",
      "loss:  1446.1871508650438\n",
      "degree:  3\n",
      "lambda  5\n",
      "loss:  1170.0308823593512\n",
      "degree:  3\n",
      "lambda  10\n",
      "loss:  871.6119874948436\n",
      "degree:  4\n",
      "lambda  0.1\n",
      "loss:  51275.57470480653\n",
      "degree:  4\n",
      "lambda  1\n",
      "loss:  47318.2219312928\n",
      "degree:  4\n",
      "lambda  2\n",
      "loss:  43843.16390923971\n",
      "degree:  4\n",
      "lambda  5\n",
      "loss:  35684.37558036629\n",
      "degree:  4\n",
      "lambda  10\n",
      "loss:  27155.437907780786\n",
      "degree:  5\n",
      "lambda  0.1\n",
      "loss:  2065516.5734895924\n",
      "degree:  5\n",
      "lambda  1\n",
      "loss:  1930022.1671888102\n",
      "degree:  5\n",
      "lambda  2\n",
      "loss:  1792326.224177142\n",
      "degree:  5\n",
      "lambda  5\n",
      "loss:  1473876.4348219952\n",
      "degree:  5\n",
      "lambda  10\n",
      "loss:  1134158.1535437317\n",
      "degree:  6\n",
      "lambda  0.1\n",
      "loss:  92530732.92559853\n",
      "degree:  6\n",
      "lambda  1\n",
      "loss:  87203676.34309384\n",
      "degree:  6\n",
      "lambda  2\n",
      "loss:  82178478.68316026\n",
      "degree:  6\n",
      "lambda  5\n",
      "loss:  69483156.9942565\n",
      "degree:  6\n",
      "lambda  10\n",
      "loss:  54669073.63592855\n",
      "degree:  7\n",
      "lambda  0.1\n",
      "loss:  4377979599.974312\n",
      "degree:  7\n",
      "lambda  1\n",
      "loss:  4179684876.332032\n",
      "degree:  7\n",
      "lambda  2\n",
      "loss:  3968347033.908838\n",
      "degree:  7\n",
      "lambda  5\n",
      "loss:  3445426086.619721\n",
      "degree:  7\n",
      "lambda  10\n",
      "loss:  2794423210.612006\n",
      "degree:  8\n",
      "lambda  0.1\n",
      "loss:  212584785109.00662\n",
      "degree:  8\n",
      "lambda  1\n",
      "loss:  203009636645.06122\n",
      "degree:  8\n",
      "lambda  2\n",
      "loss:  194842429080.4932\n",
      "degree:  8\n",
      "lambda  5\n",
      "loss:  172957078967.35727\n",
      "degree:  8\n",
      "lambda  10\n",
      "loss:  144898906384.0925\n",
      "degree:  9\n",
      "lambda  0.1\n",
      "loss:  10249060325994.965\n",
      "degree:  9\n",
      "lambda  1\n",
      "loss:  9945731408915.06\n",
      "degree:  9\n",
      "lambda  2\n",
      "loss:  9607634444167.049\n",
      "degree:  9\n",
      "lambda  5\n",
      "loss:  8682370728227.754\n",
      "degree:  9\n",
      "lambda  10\n",
      "loss:  7459758151499.868\n",
      "degree:  10\n",
      "lambda  0.1\n",
      "loss:  496505102242184.5\n",
      "degree:  10\n",
      "lambda  1\n",
      "loss:  484043052365119.6\n",
      "degree:  10\n",
      "lambda  2\n",
      "loss:  469948265986537.44\n",
      "degree:  10\n",
      "lambda  5\n",
      "loss:  431769435291891.7\n",
      "degree:  10\n",
      "lambda  10\n",
      "loss:  378823659888414.2\n",
      "degree:  11\n",
      "lambda  0.1\n",
      "loss:  2.3946237765261504e+16\n",
      "degree:  11\n",
      "lambda  1\n",
      "loss:  2.3376961324385624e+16\n",
      "degree:  11\n",
      "lambda  2\n",
      "loss:  2.2838741631668332e+16\n",
      "degree:  11\n",
      "lambda  5\n",
      "loss:  2.1271658905593988e+16\n",
      "degree:  11\n",
      "lambda  10\n",
      "loss:  1.8986075345697188e+16\n",
      "degree:  12\n",
      "lambda  0.1\n",
      "loss:  1.142284808033728e+18\n",
      "degree:  12\n",
      "lambda  1\n",
      "loss:  1.1208863988152609e+18\n",
      "degree:  12\n",
      "lambda  2\n",
      "loss:  1.0985230189776169e+18\n",
      "degree:  12\n",
      "lambda  5\n",
      "loss:  1.034820183938394e+18\n",
      "degree:  12\n",
      "lambda  10\n",
      "loss:  9.387996067196297e+17\n",
      "degree:  13\n",
      "lambda  0.1\n",
      "loss:  5.397159373863275e+19\n",
      "degree:  13\n",
      "lambda  1\n",
      "loss:  5.308403014843157e+19\n",
      "degree:  13\n",
      "lambda  2\n",
      "loss:  5.215717789735791e+19\n",
      "degree:  13\n",
      "lambda  5\n",
      "loss:  4.960594602032327e+19\n",
      "degree:  13\n",
      "lambda  10\n",
      "loss:  4.5630851205811315e+19\n",
      "degree:  14\n",
      "lambda  0.1\n",
      "loss:  2.525088763776627e+21\n",
      "degree:  14\n",
      "lambda  1\n",
      "loss:  2.49368420029325e+21\n",
      "degree:  14\n",
      "lambda  2\n",
      "loss:  2.455228789365069e+21\n",
      "degree:  14\n",
      "lambda  5\n",
      "loss:  2.3492254241290144e+21\n",
      "degree:  14\n",
      "lambda  10\n",
      "loss:  2.191235070101031e+21\n",
      "degree:  15\n",
      "lambda  0.1\n",
      "loss:  1.1696560386600456e+23\n",
      "degree:  15\n",
      "lambda  1\n",
      "loss:  1.1568627378562989e+23\n",
      "degree:  15\n",
      "lambda  2\n",
      "loss:  1.1434034337616533e+23\n",
      "degree:  15\n",
      "lambda  5\n",
      "loss:  1.104194657050337e+23\n",
      "degree:  15\n",
      "lambda  10\n",
      "loss:  1.038047389858573e+23\n",
      "degree:  16\n",
      "lambda  0.1\n",
      "loss:  5.387002903220013e+24\n",
      "degree:  16\n",
      "lambda  1\n",
      "loss:  5.334672413029477e+24\n",
      "degree:  16\n",
      "lambda  2\n",
      "loss:  5.279750268141341e+24\n",
      "degree:  16\n",
      "lambda  5\n",
      "loss:  5.119182476743907e+24\n",
      "degree:  16\n",
      "lambda  10\n",
      "loss:  4.864776978560291e+24\n",
      "degree:  17\n",
      "lambda  0.1\n",
      "loss:  2.461222269747275e+26\n",
      "degree:  17\n",
      "lambda  1\n",
      "loss:  2.4449688859963254e+26\n",
      "degree:  17\n",
      "lambda  2\n",
      "loss:  2.4173871590689325e+26\n",
      "degree:  17\n",
      "lambda  5\n",
      "loss:  2.3565948881838184e+26\n",
      "degree:  17\n",
      "lambda  10\n",
      "loss:  2.2562785490468884e+26\n",
      "degree:  18\n",
      "lambda  0.1\n",
      "loss:  1.1199015701611766e+28\n",
      "degree:  18\n",
      "lambda  1\n",
      "loss:  1.1110847551666974e+28\n",
      "degree:  18\n",
      "lambda  2\n",
      "loss:  1.1042079805153707e+28\n",
      "degree:  18\n",
      "lambda  5\n",
      "loss:  1.079368159188371e+28\n",
      "degree:  18\n",
      "lambda  10\n",
      "loss:  1.040188678563206e+28\n",
      "degree:  19\n",
      "lambda  0.1\n",
      "loss:  5.0835327004107246e+29\n",
      "degree:  19\n",
      "lambda  1\n",
      "loss:  5.046996443281392e+29\n",
      "degree:  19\n",
      "lambda  2\n",
      "loss:  5.019455090388248e+29\n",
      "degree:  19\n",
      "lambda  5\n",
      "loss:  4.927731631275097e+29\n",
      "degree:  19\n",
      "lambda  10\n",
      "loss:  4.7760560109170716e+29\n",
      "degree:  1\n",
      "lambda  0.1\n",
      "loss:  0.050296391865654225\n",
      "degree:  1\n",
      "lambda  1\n",
      "loss:  0.014050596425285469\n",
      "degree:  1\n",
      "lambda  2\n",
      "loss:  0.022130449447436945\n",
      "degree:  1\n",
      "lambda  5\n",
      "loss:  0.03557990825469283\n",
      "degree:  1\n",
      "lambda  10\n",
      "loss:  0.04762611579769579\n",
      "degree:  2\n",
      "lambda  0.1\n",
      "loss:  0.0003498155554411056\n",
      "degree:  2\n",
      "lambda  1\n",
      "loss:  0.005635323259901576\n",
      "degree:  2\n",
      "lambda  2\n",
      "loss:  0.010025593987165406\n",
      "degree:  2\n",
      "lambda  5\n",
      "loss:  0.01853743884987612\n",
      "degree:  2\n",
      "lambda  10\n",
      "loss:  0.026770887512602405\n",
      "degree:  3\n",
      "lambda  0.1\n",
      "loss:  0.009450348605085155\n",
      "degree:  3\n",
      "lambda  1\n",
      "loss:  0.004171984368149722\n",
      "degree:  3\n",
      "lambda  2\n",
      "loss:  0.006025125132877712\n",
      "degree:  3\n",
      "lambda  5\n",
      "loss:  0.011844113522974965\n",
      "degree:  3\n",
      "lambda  10\n",
      "loss:  0.018211841673657417\n",
      "degree:  4\n",
      "lambda  0.1\n",
      "loss:  0.034487175892011744\n",
      "degree:  4\n",
      "lambda  1\n",
      "loss:  0.006897011213201789\n",
      "degree:  4\n",
      "lambda  2\n",
      "loss:  0.004709942319837831\n",
      "degree:  4\n",
      "lambda  5\n",
      "loss:  0.007988891847472077\n",
      "degree:  4\n",
      "lambda  10\n",
      "loss:  0.013231543801123076\n",
      "degree:  5\n",
      "lambda  0.1\n",
      "loss:  0.056700910453190825\n",
      "degree:  5\n",
      "lambda  1\n",
      "loss:  0.010188263646326386\n",
      "degree:  5\n",
      "lambda  2\n",
      "loss:  0.004190443585221874\n",
      "degree:  5\n",
      "lambda  5\n",
      "loss:  0.0056863970453823005\n",
      "degree:  5\n",
      "lambda  10\n",
      "loss:  0.009966838345707532\n",
      "degree:  6\n",
      "lambda  0.1\n",
      "loss:  0.027714968397897773\n",
      "degree:  6\n",
      "lambda  1\n",
      "loss:  0.004540774214621811\n",
      "degree:  6\n",
      "lambda  2\n",
      "loss:  0.0021493631534021743\n",
      "degree:  6\n",
      "lambda  5\n",
      "loss:  0.00442443518763037\n",
      "degree:  6\n",
      "lambda  10\n",
      "loss:  0.008151796312526677\n",
      "degree:  7\n",
      "lambda  0.1\n",
      "loss:  0.0003994369196725244\n",
      "degree:  7\n",
      "lambda  1\n",
      "loss:  0.001722861314397799\n",
      "degree:  7\n",
      "lambda  2\n",
      "loss:  0.00255154174978583\n",
      "degree:  7\n",
      "lambda  5\n",
      "loss:  0.0043605786498909505\n",
      "degree:  7\n",
      "lambda  10\n",
      "loss:  0.0074196912162837305\n",
      "degree:  8\n",
      "lambda  0.1\n",
      "loss:  0.026779195858254428\n",
      "degree:  8\n",
      "lambda  1\n",
      "loss:  0.017985331598876112\n",
      "degree:  8\n",
      "lambda  2\n",
      "loss:  0.012370049574664534\n",
      "degree:  8\n",
      "lambda  5\n",
      "loss:  0.006863708030658441\n",
      "degree:  8\n",
      "lambda  10\n",
      "loss:  0.007599808927441956\n",
      "degree:  9\n",
      "lambda  0.1\n",
      "loss:  0.06416474599884327\n",
      "degree:  9\n",
      "lambda  1\n",
      "loss:  0.042674750069577064\n",
      "degree:  9\n",
      "lambda  2\n",
      "loss:  0.02874142363030601\n",
      "degree:  9\n",
      "lambda  5\n",
      "loss:  0.01162831886235298\n",
      "degree:  9\n",
      "lambda  10\n",
      "loss:  0.008415130012301089\n",
      "degree:  10\n",
      "lambda  0.1\n",
      "loss:  0.07144363133383186\n",
      "degree:  10\n",
      "lambda  1\n",
      "loss:  0.04935283491144927\n",
      "degree:  10\n",
      "lambda  2\n",
      "loss:  0.03315424579816777\n",
      "degree:  10\n",
      "lambda  5\n",
      "loss:  0.013267876493954937\n",
      "degree:  10\n",
      "lambda  10\n",
      "loss:  0.008994122692799643\n",
      "degree:  11\n",
      "lambda  0.1\n",
      "loss:  0.03784970282354132\n",
      "degree:  11\n",
      "lambda  1\n",
      "loss:  0.02613360718254114\n",
      "degree:  11\n",
      "lambda  2\n",
      "loss:  0.017913217522903743\n",
      "degree:  11\n",
      "lambda  5\n",
      "loss:  0.009074373599556873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree:  11\n",
      "lambda  10\n",
      "loss:  0.010665439843567392\n",
      "degree:  12\n",
      "lambda  0.1\n",
      "loss:  0.007959232522719267\n",
      "degree:  12\n",
      "lambda  1\n",
      "loss:  0.008596413505329173\n",
      "degree:  12\n",
      "lambda  2\n",
      "loss:  0.010222500855576364\n",
      "degree:  12\n",
      "lambda  5\n",
      "loss:  0.01693203307965812\n",
      "degree:  12\n",
      "lambda  10\n",
      "loss:  0.0252013965250234\n",
      "degree:  13\n",
      "lambda  0.1\n",
      "loss:  0.06825077091183895\n",
      "degree:  13\n",
      "lambda  1\n",
      "loss:  0.07321018808720316\n",
      "degree:  13\n",
      "lambda  2\n",
      "loss:  0.0767830388130529\n",
      "degree:  13\n",
      "lambda  5\n",
      "loss:  0.08411906812235953\n",
      "degree:  13\n",
      "lambda  10\n",
      "loss:  0.08258589605602719\n",
      "degree:  14\n",
      "lambda  0.1\n",
      "loss:  0.30090319999881393\n",
      "degree:  14\n",
      "lambda  1\n",
      "loss:  0.29671350010391806\n",
      "degree:  14\n",
      "lambda  2\n",
      "loss:  0.29042821772633853\n",
      "degree:  14\n",
      "lambda  5\n",
      "loss:  0.26684971129065554\n",
      "degree:  14\n",
      "lambda  10\n",
      "loss:  0.2236749634534538\n",
      "degree:  15\n",
      "lambda  0.1\n",
      "loss:  0.7335669305301893\n",
      "degree:  15\n",
      "lambda  1\n",
      "loss:  0.707433525029407\n",
      "degree:  15\n",
      "lambda  2\n",
      "loss:  0.6784005752216666\n",
      "degree:  15\n",
      "lambda  5\n",
      "loss:  0.5948851570858197\n",
      "degree:  15\n",
      "lambda  10\n",
      "loss:  0.46927223205178786\n",
      "degree:  16\n",
      "lambda  0.1\n",
      "loss:  1.295204537514503\n",
      "degree:  16\n",
      "lambda  1\n",
      "loss:  1.242037817593067\n",
      "degree:  16\n",
      "lambda  2\n",
      "loss:  1.1815581290170383\n",
      "degree:  16\n",
      "lambda  5\n",
      "loss:  1.0218239159184408\n",
      "degree:  16\n",
      "lambda  10\n",
      "loss:  0.7890266907880642\n",
      "degree:  17\n",
      "lambda  0.1\n",
      "loss:  1.8099237017532062\n",
      "degree:  17\n",
      "lambda  1\n",
      "loss:  1.7300579449270357\n",
      "degree:  17\n",
      "lambda  2\n",
      "loss:  1.6401100678096094\n",
      "degree:  17\n",
      "lambda  5\n",
      "loss:  1.4026442159898926\n",
      "degree:  17\n",
      "lambda  10\n",
      "loss:  1.0671018749246832\n",
      "degree:  18\n",
      "lambda  0.1\n",
      "loss:  1.99953522010766\n",
      "degree:  18\n",
      "lambda  1\n",
      "loss:  1.9069773022010668\n",
      "degree:  18\n",
      "lambda  2\n",
      "loss:  1.80606485244548\n",
      "degree:  18\n",
      "lambda  5\n",
      "loss:  1.5164951253365992\n",
      "degree:  18\n",
      "lambda  10\n",
      "loss:  1.1193702306684108\n",
      "degree:  19\n",
      "lambda  0.1\n",
      "loss:  1.622443402359205\n",
      "degree:  19\n",
      "lambda  1\n",
      "loss:  1.5229297262017276\n",
      "degree:  19\n",
      "lambda  2\n",
      "loss:  1.4312019091204882\n",
      "degree:  19\n",
      "lambda  5\n",
      "loss:  1.1635635046402149\n",
      "degree:  19\n",
      "lambda  10\n",
      "loss:  0.7860681646618956\n",
      "degree:  1\n",
      "lambda  0.1\n",
      "loss:  0.15634998999692595\n",
      "degree:  1\n",
      "lambda  1\n",
      "loss:  0.10670387586766038\n",
      "degree:  1\n",
      "lambda  2\n",
      "loss:  0.1034584669413335\n",
      "degree:  1\n",
      "lambda  5\n",
      "loss:  0.10353919150909426\n",
      "degree:  1\n",
      "lambda  10\n",
      "loss:  0.10346471259359216\n",
      "degree:  2\n",
      "lambda  0.1\n",
      "loss:  0.318923006685116\n",
      "degree:  2\n",
      "lambda  1\n",
      "loss:  0.2809030925880321\n",
      "degree:  2\n",
      "lambda  2\n",
      "loss:  0.23088032160496522\n",
      "degree:  2\n",
      "lambda  5\n",
      "loss:  0.18240772563947794\n",
      "degree:  2\n",
      "lambda  10\n",
      "loss:  0.16340683421770616\n",
      "degree:  3\n",
      "lambda  0.1\n",
      "loss:  0.23803828383759984\n",
      "degree:  3\n",
      "lambda  1\n",
      "loss:  0.36795652614468943\n",
      "degree:  3\n",
      "lambda  2\n",
      "loss:  0.38705237829129213\n",
      "degree:  3\n",
      "lambda  5\n",
      "loss:  0.369247551533172\n",
      "degree:  3\n",
      "lambda  10\n",
      "loss:  0.3549952603774625\n",
      "degree:  4\n",
      "lambda  0.1\n",
      "loss:  0.16206633473897974\n",
      "degree:  4\n",
      "lambda  1\n",
      "loss:  0.09956829229223843\n",
      "degree:  4\n",
      "lambda  2\n",
      "loss:  0.11516232405822323\n",
      "degree:  4\n",
      "lambda  5\n",
      "loss:  0.21979496473588928\n",
      "degree:  4\n",
      "lambda  10\n",
      "loss:  0.370346416717356\n",
      "degree:  5\n",
      "lambda  0.1\n",
      "loss:  6.0877086509226475\n",
      "degree:  5\n",
      "lambda  1\n",
      "loss:  4.436219613324392\n",
      "degree:  5\n",
      "lambda  2\n",
      "loss:  3.2238139613567895\n",
      "degree:  5\n",
      "lambda  5\n",
      "loss:  1.339905733561549\n",
      "degree:  5\n",
      "lambda  10\n",
      "loss:  0.3132392631011215\n",
      "degree:  6\n",
      "lambda  0.1\n",
      "loss:  70.58591101796571\n",
      "degree:  6\n",
      "lambda  1\n",
      "loss:  60.42464068129364\n",
      "degree:  6\n",
      "lambda  2\n",
      "loss:  51.25905888135083\n",
      "degree:  6\n",
      "lambda  5\n",
      "loss:  32.65636510421127\n",
      "degree:  6\n",
      "lambda  10\n",
      "loss:  16.418917660323213\n",
      "degree:  7\n",
      "lambda  0.1\n",
      "loss:  524.9441241774421\n",
      "degree:  7\n",
      "lambda  1\n",
      "loss:  474.089210699251\n",
      "degree:  7\n",
      "lambda  2\n",
      "loss:  426.13595240103234\n",
      "degree:  7\n",
      "lambda  5\n",
      "loss:  315.02788334712056\n",
      "degree:  7\n",
      "lambda  10\n",
      "loss:  199.46927935305285\n",
      "degree:  8\n",
      "lambda  0.1\n",
      "loss:  3174.382547543224\n",
      "degree:  8\n",
      "lambda  1\n",
      "loss:  2947.258066053372\n",
      "degree:  8\n",
      "lambda  2\n",
      "loss:  2727.6540860507685\n",
      "degree:  8\n",
      "lambda  5\n",
      "loss:  2168.688156724693\n",
      "degree:  8\n",
      "lambda  10\n",
      "loss:  1537.0336959568492\n",
      "degree:  9\n",
      "lambda  0.1\n",
      "loss:  16984.005292291797\n",
      "degree:  9\n",
      "lambda  1\n",
      "loss:  16057.881565736485\n",
      "degree:  9\n",
      "lambda  2\n",
      "loss:  15072.839471610787\n",
      "degree:  9\n",
      "lambda  5\n",
      "loss:  12623.471624404969\n",
      "degree:  9\n",
      "lambda  10\n",
      "loss:  9591.072807490369\n",
      "degree:  10\n",
      "lambda  0.1\n",
      "loss:  83847.3345489218\n",
      "degree:  10\n",
      "lambda  1\n",
      "loss:  80204.20559411439\n",
      "degree:  10\n",
      "lambda  2\n",
      "loss:  76253.84464564631\n",
      "degree:  10\n",
      "lambda  5\n",
      "loss:  66088.90900936088\n",
      "degree:  10\n",
      "lambda  10\n",
      "loss:  52776.355561405355\n",
      "degree:  11\n",
      "lambda  0.1\n",
      "loss:  392395.110706679\n",
      "degree:  11\n",
      "lambda  1\n",
      "loss:  378192.9523110989\n",
      "degree:  11\n",
      "lambda  2\n",
      "loss:  363571.67144513904\n",
      "degree:  11\n",
      "lambda  5\n",
      "loss:  323412.6496994552\n",
      "degree:  11\n",
      "lambda  10\n",
      "loss:  269262.35899110546\n",
      "degree:  12\n",
      "lambda  0.1\n",
      "loss:  1772448.336351866\n",
      "degree:  12\n",
      "lambda  1\n",
      "loss:  1720092.912539534\n",
      "degree:  12\n",
      "lambda  2\n",
      "loss:  1665819.5350716829\n",
      "degree:  12\n",
      "lambda  5\n",
      "loss:  1514839.3453016763\n",
      "degree:  12\n",
      "lambda  10\n",
      "loss:  1303706.540529866\n",
      "degree:  13\n",
      "lambda  0.1\n",
      "loss:  7851407.444504425\n",
      "degree:  13\n",
      "lambda  1\n",
      "loss:  7673158.991763634\n",
      "degree:  13\n",
      "lambda  2\n",
      "loss:  7466249.547315003\n",
      "degree:  13\n",
      "lambda  5\n",
      "loss:  6908930.625271022\n",
      "degree:  13\n",
      "lambda  10\n",
      "loss:  6096017.039877513\n",
      "degree:  14\n",
      "lambda  0.1\n",
      "loss:  34477586.56375406\n",
      "degree:  14\n",
      "lambda  1\n",
      "loss:  33847267.91885744\n",
      "degree:  14\n",
      "lambda  2\n",
      "loss:  33137156.47273816\n",
      "degree:  14\n",
      "lambda  5\n",
      "loss:  31057890.571990956\n",
      "degree:  14\n",
      "lambda  10\n",
      "loss:  28040272.544983447\n",
      "degree:  15\n",
      "lambda  0.1\n",
      "loss:  151406699.76417497\n",
      "degree:  15\n",
      "lambda  1\n",
      "loss:  148978426.52064797\n",
      "degree:  15\n",
      "lambda  2\n",
      "loss:  146420736.3075482\n",
      "degree:  15\n",
      "lambda  5\n",
      "loss:  139014990.94170058\n",
      "degree:  15\n",
      "lambda  10\n",
      "loss:  127380901.28102773\n",
      "degree:  16\n",
      "lambda  0.1\n",
      "loss:  667416189.4762309\n",
      "degree:  16\n",
      "lambda  1\n",
      "loss:  657837100.4557467\n",
      "degree:  16\n",
      "lambda  2\n",
      "loss:  648636935.5325787\n",
      "degree:  16\n",
      "lambda  5\n",
      "loss:  620980927.134377\n",
      "degree:  16\n",
      "lambda  10\n",
      "loss:  577108456.784471\n",
      "degree:  17\n",
      "lambda  0.1\n",
      "loss:  2951392387.749599\n",
      "degree:  17\n",
      "lambda  1\n",
      "loss:  2916461964.7011333\n",
      "degree:  17\n",
      "lambda  2\n",
      "loss:  2879623486.7988057\n",
      "degree:  17\n",
      "lambda  5\n",
      "loss:  2775536045.8442364\n",
      "degree:  17\n",
      "lambda  10\n",
      "loss:  2607516561.4028673\n",
      "degree:  18\n",
      "lambda  0.1\n",
      "loss:  13096457816.91721\n",
      "degree:  18\n",
      "lambda  1\n",
      "loss:  12972065085.197594\n",
      "degree:  18\n",
      "lambda  2\n",
      "loss:  12838499546.217607\n",
      "degree:  18\n",
      "lambda  5\n",
      "loss:  12428082484.36855\n",
      "degree:  18\n",
      "lambda  10\n",
      "loss:  11763447327.306837\n",
      "degree:  19\n",
      "lambda  0.1\n",
      "loss:  58184016413.72014\n",
      "degree:  19\n",
      "lambda  1\n",
      "loss:  57660743343.26512\n",
      "degree:  19\n",
      "lambda  2\n",
      "loss:  57106657221.09334\n",
      "degree:  19\n",
      "lambda  5\n",
      "loss:  55565952013.53112\n",
      "degree:  19\n",
      "lambda  10\n",
      "loss:  52926982611.8144\n",
      "degree:  1\n",
      "lambda  0.1\n",
      "loss:  1.622507820991841\n",
      "degree:  1\n",
      "lambda  1\n",
      "loss:  1.5167428551880662\n",
      "degree:  1\n",
      "lambda  2\n",
      "loss:  1.4652482870874872\n",
      "degree:  1\n",
      "lambda  5\n",
      "loss:  1.3980674192405251\n",
      "degree:  1\n",
      "lambda  10\n",
      "loss:  1.361505684099309\n",
      "degree:  2\n",
      "lambda  0.1\n",
      "loss:  1.7479526458245813\n",
      "degree:  2\n",
      "lambda  1\n",
      "loss:  1.633818498129016\n",
      "degree:  2\n",
      "lambda  2\n",
      "loss:  1.5512208389984303\n",
      "degree:  2\n",
      "lambda  5\n",
      "loss:  1.4177464972105671\n",
      "degree:  2\n",
      "lambda  10\n",
      "loss:  1.335465904847255\n",
      "degree:  3\n",
      "lambda  0.1\n",
      "loss:  1.8229269892273317\n",
      "degree:  3\n",
      "lambda  1\n",
      "loss:  1.756990847621681\n",
      "degree:  3\n",
      "lambda  2\n",
      "loss:  1.6992267403203891\n",
      "degree:  3\n",
      "lambda  5\n",
      "loss:  1.579323364052822\n",
      "degree:  3\n",
      "lambda  10\n",
      "loss:  1.4735069179345657\n",
      "degree:  4\n",
      "lambda  0.1\n",
      "loss:  2.0807034886871065\n",
      "degree:  4\n",
      "lambda  1\n",
      "loss:  2.026686189829733\n",
      "degree:  4\n",
      "lambda  2\n",
      "loss:  1.9720996422187065\n",
      "degree:  4\n",
      "lambda  5\n",
      "loss:  1.8361435135913644\n",
      "degree:  4\n",
      "lambda  10\n",
      "loss:  1.6737619856777537\n",
      "degree:  5\n",
      "lambda  0.1\n",
      "loss:  2.7698212352361145\n",
      "degree:  5\n",
      "lambda  1\n",
      "loss:  2.7567504599236\n",
      "degree:  5\n",
      "lambda  2\n",
      "loss:  2.743539901156551\n",
      "degree:  5\n",
      "lambda  5\n",
      "loss:  2.706858106999043\n",
      "degree:  5\n",
      "lambda  10\n",
      "loss:  2.6530509660444297\n",
      "degree:  6\n",
      "lambda  0.1\n",
      "loss:  5.033363482353959\n",
      "degree:  6\n",
      "lambda  1\n",
      "loss:  4.958407587244178\n",
      "degree:  6\n",
      "lambda  2\n",
      "loss:  4.878327603406877\n",
      "degree:  6\n",
      "lambda  5\n",
      "loss:  4.652689896811243\n",
      "degree:  6\n",
      "lambda  10\n",
      "loss:  4.33087133083183\n",
      "degree:  7\n",
      "lambda  0.1\n",
      "loss:  7.894509185912437\n",
      "degree:  7\n",
      "lambda  1\n",
      "loss:  7.890820358091124\n",
      "degree:  7\n",
      "lambda  2\n",
      "loss:  7.884822198070174\n",
      "degree:  7\n",
      "lambda  5\n",
      "loss:  7.864478414932742\n",
      "degree:  7\n",
      "lambda  10\n",
      "loss:  7.828600568575585\n",
      "degree:  8\n",
      "lambda  0.1\n",
      "loss:  30.492193587615397\n",
      "degree:  8\n",
      "lambda  1\n",
      "loss:  30.182383539187803\n",
      "degree:  8\n",
      "lambda  2\n",
      "loss:  29.86788099500386\n",
      "degree:  8\n",
      "lambda  5\n",
      "loss:  28.95141068477758\n",
      "degree:  8\n",
      "lambda  10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  27.572104635044717\n",
      "degree:  9\n",
      "lambda  0.1\n",
      "loss:  34.78305996157411\n",
      "degree:  9\n",
      "lambda  1\n",
      "loss:  34.750247862263066\n",
      "degree:  9\n",
      "lambda  2\n",
      "loss:  34.71394006110439\n",
      "degree:  9\n",
      "lambda  5\n",
      "loss:  34.60662660752146\n",
      "degree:  9\n",
      "lambda  10\n",
      "loss:  34.42868135297959\n",
      "degree:  10\n",
      "lambda  0.1\n",
      "loss:  228.82404877480636\n",
      "degree:  10\n",
      "lambda  1\n",
      "loss:  227.72417193055796\n",
      "degree:  10\n",
      "lambda  2\n",
      "loss:  226.39313532880277\n",
      "degree:  10\n",
      "lambda  5\n",
      "loss:  222.51986920587237\n",
      "degree:  10\n",
      "lambda  10\n",
      "loss:  216.36390130669244\n",
      "degree:  11\n",
      "lambda  0.1\n",
      "loss:  320.0702333224075\n",
      "degree:  11\n",
      "lambda  1\n",
      "loss:  319.5774265715029\n",
      "degree:  11\n",
      "lambda  2\n",
      "loss:  319.08418515840356\n",
      "degree:  11\n",
      "lambda  5\n",
      "loss:  317.49570716996686\n",
      "degree:  11\n",
      "lambda  10\n",
      "loss:  314.97294942463253\n",
      "degree:  12\n",
      "lambda  0.1\n",
      "loss:  1768.9356989942723\n",
      "degree:  12\n",
      "lambda  1\n",
      "loss:  1764.3045728942855\n",
      "degree:  12\n",
      "lambda  2\n",
      "loss:  1758.365244728527\n",
      "degree:  12\n",
      "lambda  5\n",
      "loss:  1740.6843625456308\n",
      "degree:  12\n",
      "lambda  10\n",
      "loss:  1714.6081326289138\n",
      "degree:  13\n",
      "lambda  0.1\n",
      "loss:  3965.6499191733\n",
      "degree:  13\n",
      "lambda  1\n",
      "loss:  3961.1053785392064\n",
      "degree:  13\n",
      "lambda  2\n",
      "loss:  3956.076479512618\n",
      "degree:  13\n",
      "lambda  5\n",
      "loss:  3938.06625695805\n",
      "degree:  13\n",
      "lambda  10\n",
      "loss:  3912.841521212891\n",
      "degree:  14\n",
      "lambda  0.1\n",
      "loss:  18957.600476680145\n",
      "degree:  14\n",
      "lambda  1\n",
      "loss:  18928.51538033386\n",
      "degree:  14\n",
      "lambda  2\n",
      "loss:  18886.82260956104\n",
      "degree:  14\n",
      "lambda  5\n",
      "loss:  18773.31379603719\n",
      "degree:  14\n",
      "lambda  10\n",
      "loss:  18608.397602969064\n",
      "degree:  15\n",
      "lambda  0.1\n",
      "loss:  51151.94324124062\n",
      "degree:  15\n",
      "lambda  1\n",
      "loss:  51110.534404591766\n",
      "degree:  15\n",
      "lambda  2\n",
      "loss:  51064.64868690436\n",
      "degree:  15\n",
      "lambda  5\n",
      "loss:  50912.192944034534\n",
      "degree:  15\n",
      "lambda  10\n",
      "loss:  50642.61692402067\n",
      "degree:  16\n",
      "lambda  0.1\n",
      "loss:  222280.30646228945\n",
      "degree:  16\n",
      "lambda  1\n",
      "loss:  221978.74927462864\n",
      "degree:  16\n",
      "lambda  2\n",
      "loss:  221755.68531503915\n",
      "degree:  16\n",
      "lambda  5\n",
      "loss:  220999.57058793426\n",
      "degree:  16\n",
      "lambda  10\n",
      "loss:  219807.1107600549\n",
      "degree:  17\n",
      "lambda  0.1\n",
      "loss:  658289.657616099\n",
      "degree:  17\n",
      "lambda  1\n",
      "loss:  657913.1077309548\n",
      "degree:  17\n",
      "lambda  2\n",
      "loss:  657495.4799784969\n",
      "degree:  17\n",
      "lambda  5\n",
      "loss:  656031.9677696946\n",
      "degree:  17\n",
      "lambda  10\n",
      "loss:  653972.1329081964\n",
      "degree:  18\n",
      "lambda  0.1\n",
      "loss:  2604790.3646070394\n",
      "degree:  18\n",
      "lambda  1\n",
      "loss:  2603307.140062084\n",
      "degree:  18\n",
      "lambda  2\n",
      "loss:  2600644.437316956\n",
      "degree:  18\n",
      "lambda  5\n",
      "loss:  2594646.990104773\n",
      "degree:  18\n",
      "lambda  10\n",
      "loss:  2585509.445400104\n",
      "degree:  19\n",
      "lambda  0.1\n",
      "loss:  8354230.82274531\n",
      "degree:  19\n",
      "lambda  1\n",
      "loss:  8350918.190793183\n",
      "degree:  19\n",
      "lambda  2\n",
      "loss:  8347242.069494364\n",
      "degree:  19\n",
      "lambda  5\n",
      "loss:  8336242.547159019\n",
      "degree:  19\n",
      "lambda  10\n",
      "loss:  8312101.375873875\n",
      "degree:  1\n",
      "lambda  0.1\n",
      "loss:  1328.0787419859548\n",
      "degree:  1\n",
      "lambda  1\n",
      "loss:  738.1010187828767\n",
      "degree:  1\n",
      "lambda  2\n",
      "loss:  451.82909556997424\n",
      "degree:  1\n",
      "lambda  5\n",
      "loss:  150.70936338547565\n",
      "degree:  1\n",
      "lambda  10\n",
      "loss:  36.66693215620536\n",
      "degree:  2\n",
      "lambda  0.1\n",
      "loss:  22031.92201202578\n",
      "degree:  2\n",
      "lambda  1\n",
      "loss:  18324.706106451235\n",
      "degree:  2\n",
      "lambda  2\n",
      "loss:  15219.99283575188\n",
      "degree:  2\n",
      "lambda  5\n",
      "loss:  9544.133486961564\n",
      "degree:  2\n",
      "lambda  10\n",
      "loss:  5337.394980013606\n",
      "degree:  3\n",
      "lambda  0.1\n",
      "loss:  133229.2314500337\n",
      "degree:  3\n",
      "lambda  1\n",
      "loss:  124426.91313409286\n",
      "degree:  3\n",
      "lambda  2\n",
      "loss:  115740.41904322321\n",
      "degree:  3\n",
      "lambda  5\n",
      "loss:  94643.67087496628\n",
      "degree:  3\n",
      "lambda  10\n",
      "loss:  70636.23342562078\n",
      "degree:  4\n",
      "lambda  0.1\n",
      "loss:  3577627.8662167313\n",
      "degree:  4\n",
      "lambda  1\n",
      "loss:  3391650.1654718174\n",
      "degree:  4\n",
      "lambda  2\n",
      "loss:  3199392.1423773197\n",
      "degree:  4\n",
      "lambda  5\n",
      "loss:  2726065.336763358\n",
      "degree:  4\n",
      "lambda  10\n",
      "loss:  2127166.743071443\n",
      "degree:  5\n",
      "lambda  0.1\n",
      "loss:  40751132.252061605\n",
      "degree:  5\n",
      "lambda  1\n",
      "loss:  39704118.02543087\n",
      "degree:  5\n",
      "lambda  2\n",
      "loss:  38650832.72182004\n",
      "degree:  5\n",
      "lambda  5\n",
      "loss:  35651271.34971784\n",
      "degree:  5\n",
      "lambda  10\n",
      "loss:  31486824.03252893\n",
      "degree:  6\n",
      "lambda  0.1\n",
      "loss:  1360690406.6423612\n",
      "degree:  6\n",
      "lambda  1\n",
      "loss:  1332502673.8086493\n",
      "degree:  6\n",
      "lambda  2\n",
      "loss:  1302120762.4811153\n",
      "degree:  6\n",
      "lambda  5\n",
      "loss:  1214400393.3721898\n",
      "degree:  6\n",
      "lambda  10\n",
      "loss:  1082601180.6025255\n",
      "degree:  7\n",
      "lambda  0.1\n",
      "loss:  60408092608.694374\n",
      "degree:  7\n",
      "lambda  1\n",
      "loss:  59532053633.73815\n",
      "degree:  7\n",
      "lambda  2\n",
      "loss:  58698670265.5936\n",
      "degree:  7\n",
      "lambda  5\n",
      "loss:  56197283751.243965\n",
      "degree:  7\n",
      "lambda  10\n",
      "loss:  52434287601.91741\n",
      "degree:  8\n",
      "lambda  0.1\n",
      "loss:  777777239008.8623\n",
      "degree:  8\n",
      "lambda  1\n",
      "loss:  769950411400.9384\n",
      "degree:  8\n",
      "lambda  2\n",
      "loss:  761379003515.449\n",
      "degree:  8\n",
      "lambda  5\n",
      "loss:  736430977056.3973\n",
      "degree:  8\n",
      "lambda  10\n",
      "loss:  694735455520.4288\n",
      "degree:  9\n",
      "lambda  0.1\n",
      "loss:  81014020091515.6\n",
      "degree:  9\n",
      "lambda  1\n",
      "loss:  80499354565911.97\n",
      "degree:  9\n",
      "lambda  2\n",
      "loss:  79785136363163.12\n",
      "degree:  9\n",
      "lambda  5\n",
      "loss:  78129333319416.53\n",
      "degree:  9\n",
      "lambda  10\n",
      "loss:  75348823913742.19\n",
      "degree:  10\n",
      "lambda  0.1\n",
      "loss:  1013647447953686.5\n",
      "degree:  10\n",
      "lambda  1\n",
      "loss:  1008542002424197.8\n",
      "degree:  10\n",
      "lambda  2\n",
      "loss:  1002911456562667.8\n",
      "degree:  10\n",
      "lambda  5\n",
      "loss:  984375259025226.2\n",
      "degree:  10\n",
      "lambda  10\n",
      "loss:  957642753768847.8\n",
      "degree:  11\n",
      "lambda  0.1\n",
      "loss:  1.1833214174150972e+16\n",
      "degree:  11\n",
      "lambda  1\n",
      "loss:  1.1795163182432602e+16\n",
      "degree:  11\n",
      "lambda  2\n",
      "loss:  1.1753111356150388e+16\n",
      "degree:  11\n",
      "lambda  5\n",
      "loss:  1.1589517658799104e+16\n",
      "degree:  11\n",
      "lambda  10\n",
      "loss:  1.1369454898067294e+16\n",
      "degree:  12\n",
      "lambda  0.1\n",
      "loss:  7.217196161260252e+17\n",
      "degree:  12\n",
      "lambda  1\n",
      "loss:  7.194700391310149e+17\n",
      "degree:  12\n",
      "lambda  2\n",
      "loss:  7.169814731173096e+17\n",
      "degree:  12\n",
      "lambda  5\n",
      "loss:  7.080725865974926e+17\n",
      "degree:  12\n",
      "lambda  10\n",
      "loss:  6.960305046106278e+17\n",
      "degree:  13\n",
      "lambda  0.1\n",
      "loss:  1.2377809460543476e+19\n",
      "degree:  13\n",
      "lambda  1\n",
      "loss:  1.2356322250008945e+19\n",
      "degree:  13\n",
      "lambda  2\n",
      "loss:  1.2313086139743042e+19\n",
      "degree:  13\n",
      "lambda  5\n",
      "loss:  1.2242479559071384e+19\n",
      "degree:  13\n",
      "lambda  10\n",
      "loss:  1.2126282384132987e+19\n",
      "degree:  14\n",
      "lambda  0.1\n",
      "loss:  9.704768156034466e+20\n",
      "degree:  14\n",
      "lambda  1\n",
      "loss:  9.665714380634578e+20\n",
      "degree:  14\n",
      "lambda  2\n",
      "loss:  9.645189643403673e+20\n",
      "degree:  14\n",
      "lambda  5\n",
      "loss:  9.563510023757331e+20\n",
      "degree:  14\n",
      "lambda  10\n",
      "loss:  9.463104589579429e+20\n",
      "degree:  15\n",
      "lambda  0.1\n",
      "loss:  2.2063736926180387e+23\n",
      "degree:  15\n",
      "lambda  1\n",
      "loss:  2.2036797148989973e+23\n",
      "degree:  15\n",
      "lambda  2\n",
      "loss:  2.2006921667964192e+23\n",
      "degree:  15\n",
      "lambda  5\n",
      "loss:  2.191765753078872e+23\n",
      "degree:  15\n",
      "lambda  10\n",
      "loss:  2.1770082456772113e+23\n",
      "degree:  16\n",
      "lambda  0.1\n",
      "loss:  3.601708943034471e+24\n",
      "degree:  16\n",
      "lambda  1\n",
      "loss:  3.598464141839622e+24\n",
      "degree:  16\n",
      "lambda  2\n",
      "loss:  3.594864309932204e+24\n",
      "degree:  16\n",
      "lambda  5\n",
      "loss:  3.584099453176247e+24\n",
      "degree:  16\n",
      "lambda  10\n",
      "loss:  3.566272786876265e+24\n",
      "degree:  17\n",
      "lambda  0.1\n",
      "loss:  9.108875845577637e+25\n",
      "degree:  17\n",
      "lambda  1\n",
      "loss:  9.102427210870089e+25\n",
      "degree:  17\n",
      "lambda  2\n",
      "loss:  9.09527061992609e+25\n",
      "degree:  17\n",
      "lambda  5\n",
      "loss:  9.073854760650882e+25\n",
      "degree:  17\n",
      "lambda  10\n",
      "loss:  9.026529412875814e+25\n",
      "degree:  18\n",
      "lambda  0.1\n",
      "loss:  1.9402294839251294e+29\n",
      "degree:  18\n",
      "lambda  1\n",
      "loss:  1.938970135256333e+29\n",
      "degree:  18\n",
      "lambda  2\n",
      "loss:  1.9375722757195434e+29\n",
      "degree:  18\n",
      "lambda  5\n",
      "loss:  1.9333876255771758e+29\n",
      "degree:  18\n",
      "lambda  10\n",
      "loss:  1.9264428512972132e+29\n",
      "degree:  19\n",
      "lambda  0.1\n",
      "loss:  3.829583646243176e+29\n",
      "degree:  19\n",
      "lambda  1\n",
      "loss:  3.827629684586915e+29\n",
      "degree:  19\n",
      "lambda  2\n",
      "loss:  3.82546041090824e+29\n",
      "degree:  19\n",
      "lambda  5\n",
      "loss:  3.818963905369419e+29\n",
      "degree:  19\n",
      "lambda  10\n",
      "loss:  3.8081739908131926e+29\n",
      "degree:  1\n",
      "lambda  0.1\n",
      "loss:  8.790611692477471\n",
      "degree:  1\n",
      "lambda  1\n",
      "loss:  8.431558889754113\n",
      "degree:  1\n",
      "lambda  2\n",
      "loss:  8.08513287148875\n",
      "degree:  1\n",
      "lambda  5\n",
      "loss:  7.398135411770104\n",
      "degree:  1\n",
      "lambda  10\n",
      "loss:  6.77120295066401\n",
      "degree:  2\n",
      "lambda  0.1\n",
      "loss:  8.820547303636626\n",
      "degree:  2\n",
      "lambda  1\n",
      "loss:  8.61118645248521\n",
      "degree:  2\n",
      "lambda  2\n",
      "loss:  8.402960596514738\n",
      "degree:  2\n",
      "lambda  5\n",
      "loss:  7.913680330764848\n",
      "degree:  2\n",
      "lambda  10\n",
      "loss:  7.380405504619299\n",
      "degree:  3\n",
      "lambda  0.1\n",
      "loss:  8.839326032414963\n",
      "degree:  3\n",
      "lambda  1\n",
      "loss:  8.69328032251658\n",
      "degree:  3\n",
      "lambda  2\n",
      "loss:  8.541578496850484\n",
      "degree:  3\n",
      "lambda  5\n",
      "loss:  8.163340843770795\n",
      "degree:  3\n",
      "lambda  10\n",
      "loss:  7.707577815157075\n",
      "degree:  4\n",
      "lambda  0.1\n",
      "loss:  8.83157180327099\n",
      "degree:  4\n",
      "lambda  1\n",
      "loss:  8.716900167578084\n",
      "degree:  4\n",
      "lambda  2\n",
      "loss:  8.599440594391037\n",
      "degree:  4\n",
      "lambda  5\n",
      "loss:  8.291978231729958\n",
      "degree:  4\n",
      "lambda  10\n",
      "loss:  7.897772130219954\n",
      "degree:  5\n",
      "lambda  0.1\n",
      "loss:  8.803945346902406\n",
      "degree:  5\n",
      "lambda  1\n",
      "loss:  8.711549331067861\n",
      "degree:  5\n",
      "lambda  2\n",
      "loss:  8.616861307718938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree:  5\n",
      "lambda  5\n",
      "loss:  8.361080856895539\n",
      "degree:  5\n",
      "lambda  10\n",
      "loss:  8.020184955633814\n",
      "degree:  6\n",
      "lambda  0.1\n",
      "loss:  8.755015702479652\n",
      "degree:  6\n",
      "lambda  1\n",
      "loss:  8.680412861909305\n",
      "degree:  6\n",
      "lambda  2\n",
      "loss:  8.6001831661529\n",
      "degree:  6\n",
      "lambda  5\n",
      "loss:  8.386931326912777\n",
      "degree:  6\n",
      "lambda  10\n",
      "loss:  8.092402768248132\n",
      "degree:  7\n",
      "lambda  0.1\n",
      "loss:  8.685990281371973\n",
      "degree:  7\n",
      "lambda  1\n",
      "loss:  8.625512978429363\n",
      "degree:  7\n",
      "lambda  2\n",
      "loss:  8.558706422368473\n",
      "degree:  7\n",
      "lambda  5\n",
      "loss:  8.378179284063267\n",
      "degree:  7\n",
      "lambda  10\n",
      "loss:  8.122149838263988\n",
      "degree:  8\n",
      "lambda  0.1\n",
      "loss:  8.59858351811909\n",
      "degree:  8\n",
      "lambda  1\n",
      "loss:  8.54323654161207\n",
      "degree:  8\n",
      "lambda  2\n",
      "loss:  8.493728480328214\n",
      "degree:  8\n",
      "lambda  5\n",
      "loss:  8.339412774979824\n",
      "degree:  8\n",
      "lambda  10\n",
      "loss:  8.11827145061289\n",
      "degree:  9\n",
      "lambda  0.1\n",
      "loss:  8.479170573433118\n",
      "degree:  9\n",
      "lambda  1\n",
      "loss:  8.437853231003798\n",
      "degree:  9\n",
      "lambda  2\n",
      "loss:  8.393954584427972\n",
      "degree:  9\n",
      "lambda  5\n",
      "loss:  8.265899165386665\n",
      "degree:  9\n",
      "lambda  10\n",
      "loss:  8.081247257979198\n",
      "degree:  10\n",
      "lambda  0.1\n",
      "loss:  8.342751967376461\n",
      "degree:  10\n",
      "lambda  1\n",
      "loss:  8.310287882833162\n",
      "degree:  10\n",
      "lambda  2\n",
      "loss:  8.273356014008042\n",
      "degree:  10\n",
      "lambda  5\n",
      "loss:  8.171524963657095\n",
      "degree:  10\n",
      "lambda  10\n",
      "loss:  8.013649091704147\n",
      "degree:  11\n",
      "lambda  0.1\n",
      "loss:  8.188542868661653\n",
      "degree:  11\n",
      "lambda  1\n",
      "loss:  8.160375750386638\n",
      "degree:  11\n",
      "lambda  2\n",
      "loss:  8.133663269860186\n",
      "degree:  11\n",
      "lambda  5\n",
      "loss:  8.045790457249945\n",
      "degree:  11\n",
      "lambda  10\n",
      "loss:  7.916675399288216\n",
      "degree:  12\n",
      "lambda  0.1\n",
      "loss:  8.01645471034353\n",
      "degree:  12\n",
      "lambda  1\n",
      "loss:  7.994244827615633\n",
      "degree:  12\n",
      "lambda  2\n",
      "loss:  7.970939067870358\n",
      "degree:  12\n",
      "lambda  5\n",
      "loss:  7.903054967934468\n",
      "degree:  12\n",
      "lambda  10\n",
      "loss:  7.798659186016938\n",
      "degree:  13\n",
      "lambda  0.1\n",
      "loss:  7.836547047191619\n",
      "degree:  13\n",
      "lambda  1\n",
      "loss:  7.82090152575949\n",
      "degree:  13\n",
      "lambda  2\n",
      "loss:  7.799619368442802\n",
      "degree:  13\n",
      "lambda  5\n",
      "loss:  7.748198156704598\n",
      "degree:  13\n",
      "lambda  10\n",
      "loss:  7.6654015483852405\n",
      "degree:  14\n",
      "lambda  0.1\n",
      "loss:  7.65479519929064\n",
      "degree:  14\n",
      "lambda  1\n",
      "loss:  7.640235650143439\n",
      "degree:  14\n",
      "lambda  2\n",
      "loss:  7.626205253975243\n",
      "degree:  14\n",
      "lambda  5\n",
      "loss:  7.5844096538352055\n",
      "degree:  14\n",
      "lambda  10\n",
      "loss:  7.518170646528915\n",
      "degree:  15\n",
      "lambda  0.1\n",
      "loss:  7.472418091970358\n",
      "degree:  15\n",
      "lambda  1\n",
      "loss:  7.462733276225416\n",
      "degree:  15\n",
      "lambda  2\n",
      "loss:  7.4518380585768345\n",
      "degree:  15\n",
      "lambda  5\n",
      "loss:  7.420436886831082\n",
      "degree:  15\n",
      "lambda  10\n",
      "loss:  7.368144370476664\n",
      "degree:  16\n",
      "lambda  0.1\n",
      "loss:  7.298738618901661\n",
      "degree:  16\n",
      "lambda  1\n",
      "loss:  7.291885221439893\n",
      "degree:  16\n",
      "lambda  2\n",
      "loss:  7.282345440438064\n",
      "degree:  16\n",
      "lambda  5\n",
      "loss:  7.257487360754222\n",
      "degree:  16\n",
      "lambda  10\n",
      "loss:  7.217972043990131\n",
      "degree:  17\n",
      "lambda  0.1\n",
      "loss:  7.134853923141638\n",
      "degree:  17\n",
      "lambda  1\n",
      "loss:  7.129271191276935\n",
      "degree:  17\n",
      "lambda  2\n",
      "loss:  7.121987036487577\n",
      "degree:  17\n",
      "lambda  5\n",
      "loss:  7.103496362989009\n",
      "degree:  17\n",
      "lambda  10\n",
      "loss:  7.074477858517506\n",
      "degree:  18\n",
      "lambda  0.1\n",
      "loss:  6.982551496800433\n",
      "degree:  18\n",
      "lambda  1\n",
      "loss:  6.9788772601346984\n",
      "degree:  18\n",
      "lambda  2\n",
      "loss:  6.973525594823652\n",
      "degree:  18\n",
      "lambda  5\n",
      "loss:  6.96016573865592\n",
      "degree:  18\n",
      "lambda  10\n",
      "loss:  6.936637215455303\n",
      "degree:  19\n",
      "lambda  0.1\n",
      "loss:  6.844712651865013\n",
      "degree:  19\n",
      "lambda  1\n",
      "loss:  6.841811739316973\n",
      "degree:  19\n",
      "lambda  2\n",
      "loss:  6.837507898640716\n",
      "degree:  19\n",
      "lambda  5\n",
      "loss:  6.828155636360263\n",
      "degree:  19\n",
      "lambda  10\n",
      "loss:  6.81027658059562\n",
      "degree:  1\n",
      "lambda  0.1\n",
      "loss:  1975.6840095326104\n",
      "degree:  1\n",
      "lambda  1\n",
      "loss:  1614.4403829691014\n",
      "degree:  1\n",
      "lambda  2\n",
      "loss:  1432.2544251365016\n",
      "degree:  1\n",
      "lambda  5\n",
      "loss:  1087.207798145821\n",
      "degree:  1\n",
      "lambda  10\n",
      "loss:  770.3012294528285\n",
      "degree:  2\n",
      "lambda  0.1\n",
      "loss:  217.74188147721642\n",
      "degree:  2\n",
      "lambda  1\n",
      "loss:  295.2672869524802\n",
      "degree:  2\n",
      "lambda  2\n",
      "loss:  282.58962952022694\n",
      "degree:  2\n",
      "lambda  5\n",
      "loss:  244.48701276858034\n",
      "degree:  2\n",
      "lambda  10\n",
      "loss:  205.64112478458867\n",
      "degree:  3\n",
      "lambda  0.1\n",
      "loss:  1335.8919257200873\n",
      "degree:  3\n",
      "lambda  1\n",
      "loss:  1014.8028696795649\n",
      "degree:  3\n",
      "lambda  2\n",
      "loss:  957.4905115045408\n",
      "degree:  3\n",
      "lambda  5\n",
      "loss:  900.467862559085\n",
      "degree:  3\n",
      "lambda  10\n",
      "loss:  855.9184412931018\n",
      "degree:  4\n",
      "lambda  0.1\n",
      "loss:  215.99217459461897\n",
      "degree:  4\n",
      "lambda  1\n",
      "loss:  283.2531379501466\n",
      "degree:  4\n",
      "lambda  2\n",
      "loss:  299.4590574037599\n",
      "degree:  4\n",
      "lambda  5\n",
      "loss:  306.81869568118316\n",
      "degree:  4\n",
      "lambda  10\n",
      "loss:  304.2140449834474\n",
      "degree:  5\n",
      "lambda  0.1\n",
      "loss:  1805.8329650572616\n",
      "degree:  5\n",
      "lambda  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\holde\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\holde\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  1651.5664544941637\n",
      "degree:  5\n",
      "lambda  2\n",
      "loss:  1567.1007695089104\n",
      "degree:  5\n",
      "lambda  5\n",
      "loss:  1489.3626788423885\n",
      "degree:  5\n",
      "lambda  10\n",
      "loss:  1446.4145330931433\n",
      "degree:  6\n",
      "lambda  0.1\n",
      "loss:  903.4224664667447\n",
      "degree:  6\n",
      "lambda  1\n",
      "loss:  932.9090227945371\n",
      "degree:  6\n",
      "lambda  2\n",
      "loss:  950.5277933395055\n",
      "degree:  6\n",
      "lambda  5\n",
      "loss:  965.7618172388019\n",
      "degree:  6\n",
      "lambda  10\n",
      "loss:  971.9974613640901\n",
      "degree:  7\n",
      "lambda  0.1\n",
      "loss:  3654.6938105368718\n",
      "degree:  7\n",
      "lambda  1\n",
      "loss:  3634.039260412565\n",
      "degree:  7\n",
      "lambda  2\n",
      "loss:  3616.529181254026\n",
      "degree:  7\n",
      "lambda  5\n",
      "loss:  3581.0879996132567\n",
      "degree:  7\n",
      "lambda  10\n",
      "loss:  3546.539110552473\n",
      "degree:  8\n",
      "lambda  0.1\n",
      "loss:  4034.132160326983\n",
      "degree:  8\n",
      "lambda  1\n",
      "loss:  4039.2455803279945\n",
      "degree:  8\n",
      "lambda  2\n",
      "loss:  4043.9889344228122\n",
      "degree:  8\n",
      "lambda  5\n",
      "loss:  4054.14915561975\n",
      "degree:  8\n",
      "lambda  10\n",
      "loss:  4063.286169541313\n",
      "degree:  9\n",
      "lambda  0.1\n",
      "loss:  11850.926480932647\n",
      "degree:  9\n",
      "lambda  1\n",
      "loss:  11843.655829882287\n",
      "degree:  9\n",
      "lambda  2\n",
      "loss:  11836.111899956773\n",
      "degree:  9\n",
      "lambda  5\n",
      "loss:  11816.154751604661\n",
      "degree:  9\n",
      "lambda  10\n",
      "loss:  11789.238221744263\n",
      "degree:  10\n",
      "lambda  0.1\n",
      "loss:  19144.626218497342\n",
      "degree:  10\n",
      "lambda  1\n",
      "loss:  19149.581254924065\n",
      "degree:  10\n",
      "lambda  2\n",
      "loss:  19154.395479050592\n",
      "degree:  10\n",
      "lambda  5\n",
      "loss:  19166.544348833082\n",
      "degree:  10\n",
      "lambda  10\n",
      "loss:  19179.788166980354\n",
      "degree:  11\n",
      "lambda  0.1\n",
      "loss:  49707.771683409665\n",
      "degree:  11\n",
      "lambda  1\n",
      "loss:  49703.5913125243\n",
      "degree:  11\n",
      "lambda  2\n",
      "loss:  49699.17552608499\n",
      "degree:  11\n",
      "lambda  5\n",
      "loss:  49686.17122507888\n",
      "degree:  11\n",
      "lambda  10\n",
      "loss:  49665.67706397063\n",
      "degree:  12\n",
      "lambda  0.1\n",
      "loss:  99520.30365544496\n",
      "degree:  12\n",
      "lambda  1\n",
      "loss:  99527.56107518973\n",
      "degree:  12\n",
      "lambda  2\n",
      "loss:  99534.67127447863\n",
      "degree:  12\n",
      "lambda  5\n",
      "loss:  99554.41510743018\n",
      "degree:  12\n",
      "lambda  10\n",
      "loss:  99577.75250651385\n",
      "degree:  13\n",
      "lambda  0.1\n",
      "loss:  249099.99708729642\n",
      "degree:  13\n",
      "lambda  1\n",
      "loss:  249101.43171703938\n",
      "degree:  13\n",
      "lambda  2\n",
      "loss:  249101.30645737928\n",
      "degree:  13\n",
      "lambda  5\n",
      "loss:  249101.40884050916\n",
      "degree:  13\n",
      "lambda  10\n",
      "loss:  249095.3580669473\n",
      "degree:  14\n",
      "lambda  0.1\n",
      "loss:  564183.8235108637\n",
      "degree:  14\n",
      "lambda  1\n",
      "loss:  564196.4100059498\n",
      "degree:  14\n",
      "lambda  2\n",
      "loss:  564207.9458928483\n",
      "degree:  14\n",
      "lambda  5\n",
      "loss:  564242.1789783678\n",
      "degree:  14\n",
      "lambda  10\n",
      "loss:  564284.0355458461\n",
      "degree:  15\n",
      "lambda  0.1\n",
      "loss:  1419708.8759154219\n",
      "degree:  15\n",
      "lambda  1\n",
      "loss:  1419715.9185594062\n",
      "degree:  15\n",
      "lambda  2\n",
      "loss:  1419721.4557206559\n",
      "degree:  15\n",
      "lambda  5\n",
      "loss:  1419739.8396396802\n",
      "degree:  15\n",
      "lambda  10\n",
      "loss:  1419750.372699562\n",
      "degree:  16\n",
      "lambda  0.1\n",
      "loss:  3465456.4342910233\n",
      "degree:  16\n",
      "lambda  1\n",
      "loss:  3465470.118810757\n",
      "degree:  16\n",
      "lambda  2\n",
      "loss:  3465484.7144599683\n",
      "degree:  16\n",
      "lambda  5\n",
      "loss:  3465526.4194919346\n",
      "degree:  16\n",
      "lambda  10\n",
      "loss:  3465580.0979699264\n",
      "degree:  17\n",
      "lambda  0.1\n",
      "loss:  8915438.371953394\n",
      "degree:  17\n",
      "lambda  1\n",
      "loss:  8915441.968523989\n",
      "degree:  17\n",
      "lambda  2\n",
      "loss:  8915469.213559782\n",
      "degree:  17\n",
      "lambda  5\n",
      "loss:  8915450.402939562\n",
      "degree:  17\n",
      "lambda  10\n",
      "loss:  8915407.483090412\n",
      "degree:  18\n",
      "lambda  0.1\n",
      "loss:  22878191.468202617\n",
      "degree:  18\n",
      "lambda  1\n",
      "loss:  22878237.07407972\n",
      "degree:  18\n",
      "lambda  2\n",
      "loss:  22878194.203952216\n",
      "degree:  18\n",
      "lambda  5\n",
      "loss:  22878143.10611036\n",
      "degree:  18\n",
      "lambda  10\n",
      "loss:  22878004.80537131\n",
      "degree:  19\n",
      "lambda  0.1\n",
      "loss:  60461738.01267131\n",
      "degree:  19\n",
      "lambda  1\n",
      "loss:  60461667.86665765\n",
      "degree:  19\n",
      "lambda  2\n",
      "loss:  60461561.26306682\n",
      "degree:  19\n",
      "lambda  5\n",
      "loss:  60461188.092397794\n",
      "degree:  19\n",
      "lambda  10\n",
      "loss:  60460489.980294965\n",
      "degree:  1\n",
      "lambda  0.1\n",
      "loss:  1.285871829231686\n",
      "degree:  1\n",
      "lambda  1\n",
      "loss:  1.2133491090593205\n",
      "degree:  1\n",
      "lambda  2\n",
      "loss:  1.1702946681008062\n",
      "degree:  1\n",
      "lambda  5\n",
      "loss:  1.1066072509714098\n",
      "degree:  1\n",
      "lambda  10\n",
      "loss:  1.0678838177597247\n",
      "degree:  2\n",
      "lambda  0.1\n",
      "loss:  3.5354173761957997\n",
      "degree:  2\n",
      "lambda  1\n",
      "loss:  3.232541605908951\n",
      "degree:  2\n",
      "lambda  2\n",
      "loss:  2.9766778739636184\n",
      "degree:  2\n",
      "lambda  5\n",
      "loss:  2.472082904522656\n",
      "degree:  2\n",
      "lambda  10\n",
      "loss:  2.0193499593222373\n",
      "degree:  3\n",
      "lambda  0.1\n",
      "loss:  2.707808942094001\n",
      "degree:  3\n",
      "lambda  1\n",
      "loss:  2.762883549112579\n",
      "degree:  3\n",
      "lambda  2\n",
      "loss:  2.8018381831505152\n",
      "degree:  3\n",
      "lambda  5\n",
      "loss:  2.8268911209854566\n",
      "degree:  3\n",
      "lambda  10\n",
      "loss:  2.723597579219594\n",
      "degree:  4\n",
      "lambda  0.1\n",
      "loss:  9.000768812799308\n",
      "degree:  4\n",
      "lambda  1\n",
      "loss:  8.874215909902256\n",
      "degree:  4\n",
      "lambda  2\n",
      "loss:  8.744398930627048\n",
      "degree:  4\n",
      "lambda  5\n",
      "loss:  8.401561910234815\n",
      "degree:  4\n",
      "lambda  10\n",
      "loss:  7.910211608398308\n",
      "degree:  5\n",
      "lambda  0.1\n",
      "loss:  12.290905700106602\n",
      "degree:  5\n",
      "lambda  1\n",
      "loss:  12.52052791030998\n",
      "degree:  5\n",
      "lambda  2\n",
      "loss:  12.73627426438092\n",
      "degree:  5\n",
      "lambda  5\n",
      "loss:  13.221515080179975\n",
      "degree:  5\n",
      "lambda  10\n",
      "loss:  13.648248217297636\n",
      "degree:  6\n",
      "lambda  0.1\n",
      "loss:  49.04049993388681\n",
      "degree:  6\n",
      "lambda  1\n",
      "loss:  49.139207280881756\n",
      "degree:  6\n",
      "lambda  2\n",
      "loss:  49.229216589069885\n",
      "degree:  6\n",
      "lambda  5\n",
      "loss:  49.40561930873332\n",
      "degree:  6\n",
      "lambda  10\n",
      "loss:  49.40469332970005\n",
      "degree:  7\n",
      "lambda  0.1\n",
      "loss:  129.48408748868383\n",
      "degree:  7\n",
      "lambda  1\n",
      "loss:  130.5468351832976\n",
      "degree:  7\n",
      "lambda  2\n",
      "loss:  131.63283136706679\n",
      "degree:  7\n",
      "lambda  5\n",
      "loss:  134.35211401573162\n",
      "degree:  7\n",
      "lambda  10\n",
      "loss:  137.72679471141765\n",
      "degree:  8\n",
      "lambda  0.1\n",
      "loss:  460.4237814651554\n",
      "degree:  8\n",
      "lambda  1\n",
      "loss:  463.2264275317755\n",
      "degree:  8\n",
      "lambda  2\n",
      "loss:  466.0634602575546\n",
      "degree:  8\n",
      "lambda  5\n",
      "loss:  473.76788639925513\n",
      "degree:  8\n",
      "lambda  10\n",
      "loss:  483.9109854956782\n",
      "degree:  9\n",
      "lambda  0.1\n",
      "loss:  1911.4631889850732\n",
      "degree:  9\n",
      "lambda  1\n",
      "loss:  1922.47525865687\n",
      "degree:  9\n",
      "lambda  2\n",
      "loss:  1934.611993725042\n",
      "degree:  9\n",
      "lambda  5\n",
      "loss:  1965.8555957102546\n",
      "degree:  9\n",
      "lambda  10\n",
      "loss:  2011.9780265720294\n",
      "degree:  10\n",
      "lambda  0.1\n",
      "loss:  7215.119093166455\n",
      "degree:  10\n",
      "lambda  1\n",
      "loss:  7250.951384255543\n",
      "degree:  10\n",
      "lambda  2\n",
      "loss:  7286.774240161856\n",
      "degree:  10\n",
      "lambda  5\n",
      "loss:  7391.229270987071\n",
      "degree:  10\n",
      "lambda  10\n",
      "loss:  7538.960767170415\n",
      "degree:  11\n",
      "lambda  0.1\n",
      "loss:  30432.65583124235\n",
      "degree:  11\n",
      "lambda  1\n",
      "loss:  30535.87306063737\n",
      "degree:  11\n",
      "lambda  2\n",
      "loss:  30652.049358229146\n",
      "degree:  11\n",
      "lambda  5\n",
      "loss:  30980.1053400061\n",
      "degree:  11\n",
      "lambda  10\n",
      "loss:  31454.785301309123\n",
      "degree:  12\n",
      "lambda  0.1\n",
      "loss:  111124.75263742142\n",
      "degree:  12\n",
      "lambda  1\n",
      "loss:  111453.4090188225\n",
      "degree:  12\n",
      "lambda  2\n",
      "loss:  111823.25429118636\n",
      "degree:  12\n",
      "lambda  5\n",
      "loss:  112865.14488304227\n",
      "degree:  12\n",
      "lambda  10\n",
      "loss:  114451.95498330412\n",
      "degree:  13\n",
      "lambda  0.1\n",
      "loss:  432015.1776234083\n",
      "degree:  13\n",
      "lambda  1\n",
      "loss:  433170.92449062545\n",
      "degree:  13\n",
      "lambda  2\n",
      "loss:  434472.50031897594\n",
      "degree:  13\n",
      "lambda  5\n",
      "loss:  438057.410695077\n",
      "degree:  13\n",
      "lambda  10\n",
      "loss:  443575.2051800878\n",
      "degree:  14\n",
      "lambda  0.1\n",
      "loss:  1777571.0016144814\n",
      "degree:  14\n",
      "lambda  1\n",
      "loss:  1781321.5622698378\n",
      "degree:  14\n",
      "lambda  2\n",
      "loss:  1785298.7157506964\n",
      "degree:  14\n",
      "lambda  5\n",
      "loss:  1796715.6722524753\n",
      "degree:  14\n",
      "lambda  10\n",
      "loss:  1814636.9936769311\n",
      "degree:  15\n",
      "lambda  0.1\n",
      "loss:  6901148.380528411\n",
      "degree:  15\n",
      "lambda  1\n",
      "loss:  6915660.253180666\n",
      "degree:  15\n",
      "lambda  2\n",
      "loss:  6930327.365322123\n",
      "degree:  15\n",
      "lambda  5\n",
      "loss:  6973562.428265579\n",
      "degree:  15\n",
      "lambda  10\n",
      "loss:  7041639.3866338255\n",
      "degree:  16\n",
      "lambda  0.1\n",
      "loss:  29624658.292921696\n",
      "degree:  16\n",
      "lambda  1\n",
      "loss:  29672780.00278665\n",
      "degree:  16\n",
      "lambda  2\n",
      "loss:  29736096.343574855\n",
      "degree:  16\n",
      "lambda  5\n",
      "loss:  29906947.027023196\n",
      "degree:  16\n",
      "lambda  10\n",
      "loss:  30176421.428098\n",
      "degree:  17\n",
      "lambda  0.1\n",
      "loss:  147756414.28015712\n",
      "degree:  17\n",
      "lambda  1\n",
      "loss:  147961890.5545736\n",
      "degree:  17\n",
      "lambda  2\n",
      "loss:  148160101.25338903\n",
      "degree:  17\n",
      "lambda  5\n",
      "loss:  148785431.94131204\n",
      "degree:  17\n",
      "lambda  10\n",
      "loss:  149773593.9277416\n",
      "degree:  18\n",
      "lambda  0.1\n",
      "loss:  763979934.6003433\n",
      "degree:  18\n",
      "lambda  1\n",
      "loss:  764618602.5221765\n",
      "degree:  18\n",
      "lambda  2\n",
      "loss:  765421637.7686793\n",
      "degree:  18\n",
      "lambda  5\n",
      "loss:  767662886.1050171\n",
      "degree:  18\n",
      "lambda  10\n",
      "loss:  771127306.0645384\n",
      "degree:  19\n",
      "lambda  0.1\n",
      "loss:  3684880805.8532815\n",
      "degree:  19\n",
      "lambda  1\n",
      "loss:  3687380063.8097343\n",
      "degree:  19\n",
      "lambda  2\n",
      "loss:  3689977017.9286056\n",
      "degree:  19\n",
      "lambda  5\n",
      "loss:  3697641788.0665064\n",
      "degree:  19\n",
      "lambda  10\n",
      "loss:  3709864933.060683\n",
      "degree:  1\n",
      "lambda  0.1\n",
      "loss:  1019288.1506828307\n",
      "degree:  1\n",
      "lambda  1\n",
      "loss:  527188.5096568997\n",
      "degree:  1\n",
      "lambda  2\n",
      "loss:  331092.85316034005\n",
      "degree:  1\n",
      "lambda  5\n",
      "loss:  152355.70434842652\n",
      "degree:  1\n",
      "lambda  10\n",
      "loss:  81993.18898021436\n",
      "degree:  2\n",
      "lambda  0.1\n",
      "loss:  30448689.30287947\n",
      "degree:  2\n",
      "lambda  1\n",
      "loss:  24944911.403494492\n",
      "degree:  2\n",
      "lambda  2\n",
      "loss:  20415060.75403732\n",
      "degree:  2\n",
      "lambda  5\n",
      "loss:  12355371.358242\n",
      "degree:  2\n",
      "lambda  10\n",
      "loss:  6617849.124858293\n",
      "degree:  3\n",
      "lambda  0.1\n",
      "loss:  554043976.9795207\n",
      "degree:  3\n",
      "lambda  1\n",
      "loss:  534069356.9665597\n",
      "degree:  3\n",
      "lambda  2\n",
      "loss:  513940038.5626548\n",
      "degree:  3\n",
      "lambda  5\n",
      "loss:  455819437.06621885\n",
      "degree:  3\n",
      "lambda  10\n",
      "loss:  378552503.2590147\n",
      "degree:  4\n",
      "lambda  0.1\n",
      "loss:  8414997495.2374\n",
      "degree:  4\n",
      "lambda  1\n",
      "loss:  8264344973.861965\n",
      "degree:  4\n",
      "lambda  2\n",
      "loss:  8100678398.805431\n",
      "degree:  4\n",
      "lambda  5\n",
      "loss:  7653264978.682001\n",
      "degree:  4\n",
      "lambda  10\n",
      "loss:  6957884737.185659\n",
      "degree:  5\n",
      "lambda  0.1\n",
      "loss:  429852515214.82153\n",
      "degree:  5\n",
      "lambda  1\n",
      "loss:  426932550402.4993\n",
      "degree:  5\n",
      "lambda  2\n",
      "loss:  423427536958.4645\n",
      "degree:  5\n",
      "lambda  5\n",
      "loss:  412880066034.7558\n",
      "degree:  5\n",
      "lambda  10\n",
      "loss:  395778919071.6491\n",
      "degree:  6\n",
      "lambda  0.1\n",
      "loss:  11406977122794.777\n",
      "degree:  6\n",
      "lambda  1\n",
      "loss:  11363049609732.203\n",
      "degree:  6\n",
      "lambda  2\n",
      "loss:  11309385944599.393\n",
      "degree:  6\n",
      "lambda  5\n",
      "loss:  11152496809840.334\n",
      "degree:  6\n",
      "lambda  10\n",
      "loss:  10899246280072.49\n",
      "degree:  7\n",
      "lambda  0.1\n",
      "loss:  556146799457671.56\n",
      "degree:  7\n",
      "lambda  1\n",
      "loss:  555049458897325.56\n",
      "degree:  7\n",
      "lambda  2\n",
      "loss:  553611119307552.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree:  7\n",
      "lambda  5\n",
      "loss:  549584440769251.1\n",
      "degree:  7\n",
      "lambda  10\n",
      "loss:  542711645883626.06\n",
      "degree:  8\n",
      "lambda  0.1\n",
      "loss:  1.9978567733425256e+16\n",
      "degree:  8\n",
      "lambda  1\n",
      "loss:  1.995222711846974e+16\n",
      "degree:  8\n",
      "lambda  2\n",
      "loss:  1.992366243299729e+16\n",
      "degree:  8\n",
      "lambda  5\n",
      "loss:  1.983637830297871e+16\n",
      "degree:  8\n",
      "lambda  10\n",
      "loss:  1.9689688822062532e+16\n",
      "degree:  9\n",
      "lambda  0.1\n",
      "loss:  8.559812763315258e+17\n",
      "degree:  9\n",
      "lambda  1\n",
      "loss:  8.553536027553313e+17\n",
      "degree:  9\n",
      "lambda  2\n",
      "loss:  8.546227238567846e+17\n",
      "degree:  9\n",
      "lambda  5\n",
      "loss:  8.525615027816237e+17\n",
      "degree:  9\n",
      "lambda  10\n",
      "loss:  8.489377747218268e+17\n",
      "degree:  10\n",
      "lambda  0.1\n",
      "loss:  4.391199050318023e+19\n",
      "degree:  10\n",
      "lambda  1\n",
      "loss:  4.389112135583264e+19\n",
      "degree:  10\n",
      "lambda  2\n",
      "loss:  4.3867704244320035e+19\n",
      "degree:  10\n",
      "lambda  5\n",
      "loss:  4.3800826237987365e+19\n",
      "degree:  10\n",
      "lambda  10\n",
      "loss:  4.368814225161792e+19\n",
      "degree:  11\n",
      "lambda  0.1\n",
      "loss:  1.9831493739064478e+21\n",
      "degree:  11\n",
      "lambda  1\n",
      "loss:  1.9828483954299023e+21\n",
      "degree:  11\n",
      "lambda  2\n",
      "loss:  1.9821476288380527e+21\n",
      "degree:  11\n",
      "lambda  5\n",
      "loss:  1.9804981438365743e+21\n",
      "degree:  11\n",
      "lambda  10\n",
      "loss:  1.9774250507576782e+21\n",
      "degree:  12\n",
      "lambda  0.1\n",
      "loss:  1.2491195482226927e+23\n",
      "degree:  12\n",
      "lambda  1\n",
      "loss:  1.2489794702847232e+23\n",
      "degree:  12\n",
      "lambda  2\n",
      "loss:  1.2486816684359375e+23\n",
      "degree:  12\n",
      "lambda  5\n",
      "loss:  1.2479706747528166e+23\n",
      "degree:  12\n",
      "lambda  10\n",
      "loss:  1.2467899626935858e+23\n",
      "degree:  13\n",
      "lambda  0.1\n",
      "loss:  6.07800472488193e+24\n",
      "degree:  13\n",
      "lambda  1\n",
      "loss:  6.077471232500584e+24\n",
      "degree:  13\n",
      "lambda  2\n",
      "loss:  6.076865820004239e+24\n",
      "degree:  13\n",
      "lambda  5\n",
      "loss:  6.074909608923051e+24\n",
      "degree:  13\n",
      "lambda  10\n",
      "loss:  6.071848949634387e+24\n",
      "degree:  14\n",
      "lambda  0.1\n",
      "loss:  4.0123003478220104e+26\n",
      "degree:  14\n",
      "lambda  1\n",
      "loss:  4.012151361252017e+26\n",
      "degree:  14\n",
      "lambda  2\n",
      "loss:  4.011938812615332e+26\n",
      "degree:  14\n",
      "lambda  5\n",
      "loss:  4.011437999773608e+26\n",
      "degree:  14\n",
      "lambda  10\n",
      "loss:  4.0103809832172914e+26\n",
      "degree:  15\n",
      "lambda  0.1\n",
      "loss:  2.051916350561273e+28\n",
      "degree:  15\n",
      "lambda  1\n",
      "loss:  2.0518104701671234e+28\n",
      "degree:  15\n",
      "lambda  2\n",
      "loss:  2.0517542570927502e+28\n",
      "degree:  15\n",
      "lambda  5\n",
      "loss:  2.0517853729271616e+28\n",
      "degree:  15\n",
      "lambda  10\n",
      "loss:  2.051586712170664e+28\n",
      "degree:  16\n",
      "lambda  0.1\n",
      "loss:  1.2553461551207301e+30\n",
      "degree:  16\n",
      "lambda  1\n",
      "loss:  1.2553533433133492e+30\n",
      "degree:  16\n",
      "lambda  2\n",
      "loss:  1.2553604914265827e+30\n",
      "degree:  16\n",
      "lambda  5\n",
      "loss:  1.2553651402310896e+30\n",
      "degree:  16\n",
      "lambda  10\n",
      "loss:  1.2553610623648509e+30\n",
      "degree:  17\n",
      "lambda  0.1\n",
      "loss:  7.441244377031736e+31\n",
      "degree:  17\n",
      "lambda  1\n",
      "loss:  7.441386366024649e+31\n",
      "degree:  17\n",
      "lambda  2\n",
      "loss:  7.44151934862602e+31\n",
      "degree:  17\n",
      "lambda  5\n",
      "loss:  7.441776684291711e+31\n",
      "degree:  17\n",
      "lambda  10\n",
      "loss:  7.442152445228096e+31\n",
      "degree:  18\n",
      "lambda  0.1\n",
      "loss:  4.411584898278876e+33\n",
      "degree:  18\n",
      "lambda  1\n",
      "loss:  4.411535204305518e+33\n",
      "degree:  18\n",
      "lambda  2\n",
      "loss:  4.411659899264595e+33\n",
      "degree:  18\n",
      "lambda  5\n",
      "loss:  4.412056878537988e+33\n",
      "degree:  18\n",
      "lambda  10\n",
      "loss:  4.412375918206482e+33\n",
      "degree:  19\n",
      "lambda  0.1\n",
      "loss:  3.063327329738946e+35\n",
      "degree:  19\n",
      "lambda  1\n",
      "loss:  3.063311240513934e+35\n",
      "degree:  19\n",
      "lambda  2\n",
      "loss:  3.063413279339012e+35\n",
      "degree:  19\n",
      "lambda  5\n",
      "loss:  3.0635967087112113e+35\n",
      "degree:  19\n",
      "lambda  10\n",
      "loss:  3.0638648428932836e+35\n",
      "degree:  1\n",
      "lambda  0.1\n",
      "loss:  90.49700995906295\n",
      "degree:  1\n",
      "lambda  1\n",
      "loss:  11.725484269857727\n",
      "degree:  1\n",
      "lambda  2\n",
      "loss:  2.8867823712932608\n",
      "degree:  1\n",
      "lambda  5\n",
      "loss:  0.5196217258972391\n",
      "degree:  1\n",
      "lambda  10\n",
      "loss:  0.45841582297856215\n",
      "degree:  2\n",
      "lambda  0.1\n",
      "loss:  45.02649005007096\n",
      "degree:  2\n",
      "lambda  1\n",
      "loss:  40.51179459974062\n",
      "degree:  2\n",
      "lambda  2\n",
      "loss:  36.46871661153549\n",
      "degree:  2\n",
      "lambda  5\n",
      "loss:  28.369897784120276\n",
      "degree:  2\n",
      "lambda  10\n",
      "loss:  20.456263313887455\n",
      "degree:  3\n",
      "lambda  0.1\n",
      "loss:  181.3952001591786\n",
      "degree:  3\n",
      "lambda  1\n",
      "loss:  184.7169051523952\n",
      "degree:  3\n",
      "lambda  2\n",
      "loss:  187.6829042305797\n",
      "degree:  3\n",
      "lambda  5\n",
      "loss:  191.30362797273636\n",
      "degree:  3\n",
      "lambda  10\n",
      "loss:  188.24367700709823\n",
      "degree:  4\n",
      "lambda  0.1\n",
      "loss:  2299.7417130190724\n",
      "degree:  4\n",
      "lambda  1\n",
      "loss:  2328.8501803032145\n",
      "degree:  4\n",
      "lambda  2\n",
      "loss:  2357.1623454334444\n",
      "degree:  4\n",
      "lambda  5\n",
      "loss:  2424.3344636956854\n",
      "degree:  4\n",
      "lambda  10\n",
      "loss:  2487.95143964152\n",
      "degree:  5\n",
      "lambda  0.1\n",
      "loss:  13430.915085576435\n",
      "degree:  5\n",
      "lambda  1\n",
      "loss:  13789.583159941685\n",
      "degree:  5\n",
      "lambda  2\n",
      "loss:  14146.334303836966\n",
      "degree:  5\n",
      "lambda  5\n",
      "loss:  15206.589891187701\n",
      "degree:  5\n",
      "lambda  10\n",
      "loss:  16719.801073356317\n",
      "degree:  6\n",
      "lambda  0.1\n",
      "loss:  109282.16170475197\n",
      "degree:  6\n",
      "lambda  1\n",
      "loss:  112396.98215056368\n",
      "degree:  6\n",
      "lambda  2\n",
      "loss:  115400.81098108212\n",
      "degree:  6\n",
      "lambda  5\n",
      "loss:  124937.91728672614\n",
      "degree:  6\n",
      "lambda  10\n",
      "loss:  139523.7590339691\n",
      "degree:  7\n",
      "lambda  0.1\n",
      "loss:  1257780.2956497055\n",
      "degree:  7\n",
      "lambda  1\n",
      "loss:  1285183.350804628\n",
      "degree:  7\n",
      "lambda  2\n",
      "loss:  1320254.782582747\n",
      "degree:  7\n",
      "lambda  5\n",
      "loss:  1415240.4760132737\n",
      "degree:  7\n",
      "lambda  10\n",
      "loss:  1567823.4677095264\n",
      "degree:  8\n",
      "lambda  0.1\n",
      "loss:  27630180.522068884\n",
      "degree:  8\n",
      "lambda  1\n",
      "loss:  27991144.66795801\n",
      "degree:  8\n",
      "lambda  2\n",
      "loss:  28391019.019728698\n",
      "degree:  8\n",
      "lambda  5\n",
      "loss:  29674681.722517215\n",
      "degree:  8\n",
      "lambda  10\n",
      "loss:  31814569.5704765\n",
      "degree:  9\n",
      "lambda  0.1\n",
      "loss:  438714017.5909963\n",
      "degree:  9\n",
      "lambda  1\n",
      "loss:  443250506.7218809\n",
      "degree:  9\n",
      "lambda  2\n",
      "loss:  448283572.62348664\n",
      "degree:  9\n",
      "lambda  5\n",
      "loss:  464858967.35151607\n",
      "degree:  9\n",
      "lambda  10\n",
      "loss:  489686776.21603256\n",
      "degree:  10\n",
      "lambda  0.1\n",
      "loss:  7478547345.520485\n",
      "degree:  10\n",
      "lambda  1\n",
      "loss:  7541141539.754326\n",
      "degree:  10\n",
      "lambda  2\n",
      "loss:  7610653696.046237\n",
      "degree:  10\n",
      "lambda  5\n",
      "loss:  7850995910.404158\n",
      "degree:  10\n",
      "lambda  10\n",
      "loss:  8196169476.193365\n",
      "degree:  11\n",
      "lambda  0.1\n",
      "loss:  129959679331.03114\n",
      "degree:  11\n",
      "lambda  1\n",
      "loss:  130870978949.82245\n",
      "degree:  11\n",
      "lambda  2\n",
      "loss:  131883580873.0467\n",
      "degree:  11\n",
      "lambda  5\n",
      "loss:  134921413473.32584\n",
      "degree:  11\n",
      "lambda  10\n",
      "loss:  140616435727.37213\n",
      "degree:  12\n",
      "lambda  0.1\n",
      "loss:  1986690670059.432\n",
      "degree:  12\n",
      "lambda  1\n",
      "loss:  1999744630815.1091\n",
      "degree:  12\n",
      "lambda  2\n",
      "loss:  2014259404243.594\n",
      "degree:  12\n",
      "lambda  5\n",
      "loss:  2057866192525.6453\n",
      "degree:  12\n",
      "lambda  10\n",
      "loss:  2141649362138.9673\n",
      "degree:  13\n",
      "lambda  0.1\n",
      "loss:  26711294495781.68\n",
      "degree:  13\n",
      "lambda  1\n",
      "loss:  26892716761133.477\n",
      "degree:  13\n",
      "lambda  2\n",
      "loss:  27094589007031.473\n",
      "degree:  13\n",
      "lambda  5\n",
      "loss:  27702012034074.953\n",
      "degree:  13\n",
      "lambda  10\n",
      "loss:  29297080214214.75\n",
      "degree:  14\n",
      "lambda  0.1\n",
      "loss:  463361499214255.8\n",
      "degree:  14\n",
      "lambda  1\n",
      "loss:  466138838533139.5\n",
      "degree:  14\n",
      "lambda  2\n",
      "loss:  469229468953812.8\n",
      "degree:  14\n",
      "lambda  5\n",
      "loss:  478530623655032.25\n",
      "degree:  14\n",
      "lambda  10\n",
      "loss:  494127630548536.9\n",
      "degree:  15\n",
      "lambda  0.1\n",
      "loss:  8708099955141966.0\n",
      "degree:  15\n",
      "lambda  1\n",
      "loss:  8754464177224363.0\n",
      "degree:  15\n",
      "lambda  2\n",
      "loss:  8806057972173571.0\n",
      "degree:  15\n",
      "lambda  5\n",
      "loss:  8961327030617550.0\n",
      "degree:  15\n",
      "lambda  10\n",
      "loss:  9296932306883042.0\n",
      "degree:  16\n",
      "lambda  0.1\n",
      "loss:  1.467302064956215e+17\n",
      "degree:  16\n",
      "lambda  1\n",
      "loss:  1.4751183662406275e+17\n",
      "degree:  16\n",
      "lambda  2\n",
      "loss:  1.483818588088134e+17\n",
      "degree:  16\n",
      "lambda  5\n",
      "loss:  1.5100160962040544e+17\n",
      "degree:  16\n",
      "lambda  10\n",
      "loss:  1.569727767536753e+17\n",
      "degree:  17\n",
      "lambda  0.1\n",
      "loss:  2.8267668882043105e+18\n",
      "degree:  17\n",
      "lambda  1\n",
      "loss:  2.840434764578765e+18\n",
      "degree:  17\n",
      "lambda  2\n",
      "loss:  2.855647396561587e+18\n",
      "degree:  17\n",
      "lambda  5\n",
      "loss:  2.901449250977231e+18\n",
      "degree:  17\n",
      "lambda  10\n",
      "loss:  3.0137457382921487e+18\n",
      "degree:  18\n",
      "lambda  0.1\n",
      "loss:  7.628537353864562e+19\n",
      "degree:  18\n",
      "lambda  1\n",
      "loss:  7.656663251871526e+19\n",
      "degree:  18\n",
      "lambda  2\n",
      "loss:  7.68795377587498e+19\n",
      "degree:  18\n",
      "lambda  5\n",
      "loss:  7.872355855794194e+19\n",
      "degree:  18\n",
      "lambda  10\n",
      "loss:  8.119740428818137e+19\n",
      "degree:  19\n",
      "lambda  0.1\n",
      "loss:  2.082690736577578e+21\n",
      "degree:  19\n",
      "lambda  1\n",
      "loss:  2.0885674385940024e+21\n",
      "degree:  19\n",
      "lambda  2\n",
      "loss:  2.0951032024943677e+21\n",
      "degree:  19\n",
      "lambda  5\n",
      "loss:  2.1147488403314167e+21\n",
      "degree:  19\n",
      "lambda  10\n",
      "loss:  2.1476184846718287e+21\n",
      "degree:  1\n",
      "lambda  0.1\n",
      "loss:  490.57917124758154\n",
      "degree:  1\n",
      "lambda  1\n",
      "loss:  15.376344130310134\n",
      "degree:  1\n",
      "lambda  2\n",
      "loss:  2.6028845262449916\n",
      "degree:  1\n",
      "lambda  5\n",
      "loss:  0.08702882963997974\n",
      "degree:  1\n",
      "lambda  10\n",
      "loss:  0.001152758726499813\n",
      "degree:  2\n",
      "lambda  0.1\n",
      "loss:  2.3935771792283553\n",
      "degree:  2\n",
      "lambda  1\n",
      "loss:  2.413748031325175\n",
      "degree:  2\n",
      "lambda  2\n",
      "loss:  2.378417698483136\n",
      "degree:  2\n",
      "lambda  5\n",
      "loss:  2.248170350307923\n",
      "degree:  2\n",
      "lambda  10\n",
      "loss:  2.0133891640040624\n",
      "degree:  3\n",
      "lambda  0.1\n",
      "loss:  22.072173725074702\n",
      "degree:  3\n",
      "lambda  1\n",
      "loss:  19.16638486209501\n",
      "degree:  3\n",
      "lambda  2\n",
      "loss:  16.86596236606765\n",
      "degree:  3\n",
      "lambda  5\n",
      "loss:  13.805184124927228\n",
      "degree:  3\n",
      "lambda  10\n",
      "loss:  13.146868451610192\n",
      "degree:  4\n",
      "lambda  0.1\n",
      "loss:  4045.037859693378\n",
      "degree:  4\n",
      "lambda  1\n",
      "loss:  4000.5624489247157\n",
      "degree:  4\n",
      "lambda  2\n",
      "loss:  3955.171772321864\n",
      "degree:  4\n",
      "lambda  5\n",
      "loss:  3891.067008939725\n",
      "degree:  4\n",
      "lambda  10\n",
      "loss:  3878.0478143435407\n",
      "degree:  5\n",
      "lambda  0.1\n",
      "loss:  255438.94305825632\n",
      "degree:  5\n",
      "lambda  1\n",
      "loss:  253973.5958186394\n",
      "degree:  5\n",
      "lambda  2\n",
      "loss:  252674.57508635943\n",
      "degree:  5\n",
      "lambda  5\n",
      "loss:  249967.03481432327\n",
      "degree:  5\n",
      "lambda  10\n",
      "loss:  247982.2525382448\n",
      "degree:  6\n",
      "lambda  0.1\n",
      "loss:  8265536.57689156\n",
      "degree:  6\n",
      "lambda  1\n",
      "loss:  8240684.835010979\n",
      "degree:  6\n",
      "lambda  2\n",
      "loss:  8212521.339400891\n",
      "degree:  6\n",
      "lambda  5\n",
      "loss:  8160291.200304775\n",
      "degree:  6\n",
      "lambda  10\n",
      "loss:  8128774.097843151\n",
      "degree:  7\n",
      "lambda  0.1\n",
      "loss:  19264122.981753346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree:  7\n",
      "lambda  1\n",
      "loss:  19095265.959226616\n",
      "degree:  7\n",
      "lambda  2\n",
      "loss:  18970040.60721656\n",
      "degree:  7\n",
      "lambda  5\n",
      "loss:  18750898.079945903\n",
      "degree:  7\n",
      "lambda  10\n",
      "loss:  19196638.15695289\n",
      "degree:  8\n",
      "lambda  0.1\n",
      "loss:  10988360156.393213\n",
      "degree:  8\n",
      "lambda  1\n",
      "loss:  10997158414.040617\n",
      "degree:  8\n",
      "lambda  2\n",
      "loss:  11001283293.74153\n",
      "degree:  8\n",
      "lambda  5\n",
      "loss:  11016815947.749699\n",
      "degree:  8\n",
      "lambda  10\n",
      "loss:  10988632107.503315\n",
      "degree:  9\n",
      "lambda  0.1\n",
      "loss:  1391714032476.5054\n",
      "degree:  9\n",
      "lambda  1\n",
      "loss:  1393744891904.5864\n",
      "degree:  9\n",
      "lambda  2\n",
      "loss:  1395682024867.55\n",
      "degree:  9\n",
      "lambda  5\n",
      "loss:  1397908759239.8335\n",
      "degree:  9\n",
      "lambda  10\n",
      "loss:  1399441040531.2256\n",
      "degree:  10\n",
      "lambda  0.1\n",
      "loss:  58485064484423.73\n",
      "degree:  10\n",
      "lambda  1\n",
      "loss:  58537657424720.93\n",
      "degree:  10\n",
      "lambda  2\n",
      "loss:  58590928220244.914\n",
      "degree:  10\n",
      "lambda  5\n",
      "loss:  58801268240939.695\n",
      "degree:  10\n",
      "lambda  10\n",
      "loss:  58989973282925.97\n",
      "degree:  11\n",
      "lambda  0.1\n",
      "loss:  1346901007675495.0\n",
      "degree:  11\n",
      "lambda  1\n",
      "loss:  1350091059315695.0\n",
      "degree:  11\n",
      "lambda  2\n",
      "loss:  1351978490433939.2\n",
      "degree:  11\n",
      "lambda  5\n",
      "loss:  1357026701656783.0\n",
      "degree:  11\n",
      "lambda  10\n",
      "loss:  1366133101352746.2\n",
      "degree:  12\n",
      "lambda  0.1\n",
      "loss:  2.0436295483028424e+16\n",
      "degree:  12\n",
      "lambda  1\n",
      "loss:  2.0480088748970572e+16\n",
      "degree:  12\n",
      "lambda  2\n",
      "loss:  2.0524734406496344e+16\n",
      "degree:  12\n",
      "lambda  5\n",
      "loss:  2.0659868512039156e+16\n",
      "degree:  12\n",
      "lambda  10\n",
      "loss:  2.0857780596905948e+16\n",
      "degree:  13\n",
      "lambda  0.1\n",
      "loss:  4.922307172656262e+17\n",
      "degree:  13\n",
      "lambda  1\n",
      "loss:  4.9293885330237165e+17\n",
      "degree:  13\n",
      "lambda  2\n",
      "loss:  4.945169005843788e+17\n",
      "degree:  13\n",
      "lambda  5\n",
      "loss:  5.000134927500278e+17\n",
      "degree:  13\n",
      "lambda  10\n",
      "loss:  5.050105043558946e+17\n",
      "degree:  14\n",
      "lambda  0.1\n",
      "loss:  7.570631202079128e+19\n",
      "degree:  14\n",
      "lambda  1\n",
      "loss:  7.586688830381269e+19\n",
      "degree:  14\n",
      "lambda  2\n",
      "loss:  7.602781403424232e+19\n",
      "degree:  14\n",
      "lambda  5\n",
      "loss:  7.6233251816416e+19\n",
      "degree:  14\n",
      "lambda  10\n",
      "loss:  7.71340067402355e+19\n",
      "degree:  15\n",
      "lambda  0.1\n",
      "loss:  1.4418732314994246e+22\n",
      "degree:  15\n",
      "lambda  1\n",
      "loss:  1.4425261926741424e+22\n",
      "degree:  15\n",
      "lambda  2\n",
      "loss:  1.4442104275081676e+22\n",
      "degree:  15\n",
      "lambda  5\n",
      "loss:  1.448392565839482e+22\n",
      "degree:  15\n",
      "lambda  10\n",
      "loss:  1.4553797474945002e+22\n",
      "degree:  16\n",
      "lambda  0.1\n",
      "loss:  1.5879160038908083e+24\n",
      "degree:  16\n",
      "lambda  1\n",
      "loss:  1.5883801248119584e+24\n",
      "degree:  16\n",
      "lambda  2\n",
      "loss:  1.589692882906931e+24\n",
      "degree:  16\n",
      "lambda  5\n",
      "loss:  1.592775289432024e+24\n",
      "degree:  16\n",
      "lambda  10\n",
      "loss:  1.5983071744270297e+24\n",
      "degree:  17\n",
      "lambda  0.1\n",
      "loss:  1.0428881280635962e+26\n",
      "degree:  17\n",
      "lambda  1\n",
      "loss:  1.0435886586416928e+26\n",
      "degree:  17\n",
      "lambda  2\n",
      "loss:  1.0438494620726294e+26\n",
      "degree:  17\n",
      "lambda  5\n",
      "loss:  1.0455551463534028e+26\n",
      "degree:  17\n",
      "lambda  10\n",
      "loss:  1.047708226531371e+26\n",
      "degree:  18\n",
      "lambda  0.1\n",
      "loss:  4.777922802661488e+27\n",
      "degree:  18\n",
      "lambda  1\n",
      "loss:  4.778917011854645e+27\n",
      "degree:  18\n",
      "lambda  2\n",
      "loss:  4.7800158089489493e+27\n",
      "degree:  18\n",
      "lambda  5\n",
      "loss:  4.793295005375446e+27\n",
      "degree:  18\n",
      "lambda  10\n",
      "loss:  4.802752856706014e+27\n",
      "degree:  19\n",
      "lambda  0.1\n",
      "loss:  1.742693075528984e+29\n",
      "degree:  19\n",
      "lambda  1\n",
      "loss:  1.7430510345533504e+29\n",
      "degree:  19\n",
      "lambda  2\n",
      "loss:  1.743447104077163e+29\n",
      "degree:  19\n",
      "lambda  5\n",
      "loss:  1.7463385816329657e+29\n",
      "degree:  19\n",
      "lambda  10\n",
      "loss:  1.7499889822218e+29\n",
      "degree:  1\n",
      "lambda  0.1\n",
      "loss:  563.9434891195458\n",
      "degree:  1\n",
      "lambda  1\n",
      "loss:  6.165287113209169\n",
      "degree:  1\n",
      "lambda  2\n",
      "loss:  0.026106239586371434\n",
      "degree:  1\n",
      "lambda  5\n",
      "loss:  1.4161631407831188\n",
      "degree:  1\n",
      "lambda  10\n",
      "loss:  1.7783063553749296\n",
      "degree:  2\n",
      "lambda  0.1\n",
      "loss:  46.13455650224788\n",
      "degree:  2\n",
      "lambda  1\n",
      "loss:  49.34433475531867\n",
      "degree:  2\n",
      "lambda  2\n",
      "loss:  52.20088514818425\n",
      "degree:  2\n",
      "lambda  5\n",
      "loss:  56.61666186809216\n",
      "degree:  2\n",
      "lambda  10\n",
      "loss:  55.42101133217437\n",
      "degree:  3\n",
      "lambda  0.1\n",
      "loss:  584.4063825803477\n",
      "degree:  3\n",
      "lambda  1\n",
      "loss:  619.9687223130557\n",
      "degree:  3\n",
      "lambda  2\n",
      "loss:  660.1893285087498\n",
      "degree:  3\n",
      "lambda  5\n",
      "loss:  807.4907060367359\n",
      "degree:  3\n",
      "lambda  10\n",
      "loss:  1050.4015620308883\n",
      "degree:  4\n",
      "lambda  0.1\n",
      "loss:  20842.58125100162\n",
      "degree:  4\n",
      "lambda  1\n",
      "loss:  19214.617294335865\n",
      "degree:  4\n",
      "lambda  2\n",
      "loss:  17421.353769129404\n",
      "degree:  4\n",
      "lambda  5\n",
      "loss:  12324.381842043305\n",
      "degree:  4\n",
      "lambda  10\n",
      "loss:  5679.579668941986\n",
      "degree:  5\n",
      "lambda  0.1\n",
      "loss:  7224322.512181239\n",
      "degree:  5\n",
      "lambda  1\n",
      "loss:  7091641.880735515\n",
      "degree:  5\n",
      "lambda  2\n",
      "loss:  6920333.7324498035\n",
      "degree:  5\n",
      "lambda  5\n",
      "loss:  6426431.823034261\n",
      "degree:  5\n",
      "lambda  10\n",
      "loss:  5536401.972487835\n",
      "degree:  6\n",
      "lambda  0.1\n",
      "loss:  1043772269.2207409\n",
      "degree:  6\n",
      "lambda  1\n",
      "loss:  1036848185.9679759\n",
      "degree:  6\n",
      "lambda  2\n",
      "loss:  1025220835.7702397\n",
      "degree:  6\n",
      "lambda  5\n",
      "loss:  996099789.5511563\n",
      "degree:  6\n",
      "lambda  10\n",
      "loss:  938474281.4739835\n",
      "degree:  7\n",
      "lambda  0.1\n",
      "loss:  115772691732.45068\n",
      "degree:  7\n",
      "lambda  1\n",
      "loss:  115406091152.99397\n",
      "degree:  7\n",
      "lambda  2\n",
      "loss:  115086808526.99545\n",
      "degree:  7\n",
      "lambda  5\n",
      "loss:  113421025327.0002\n",
      "degree:  7\n",
      "lambda  10\n",
      "loss:  110836267692.22804\n",
      "degree:  8\n",
      "lambda  0.1\n",
      "loss:  12233731043685.969\n",
      "degree:  8\n",
      "lambda  1\n",
      "loss:  12223594976848.531\n",
      "degree:  8\n",
      "lambda  2\n",
      "loss:  12223386326262.336\n",
      "degree:  8\n",
      "lambda  5\n",
      "loss:  12153644708770.457\n",
      "degree:  8\n",
      "lambda  10\n",
      "loss:  12024906089529.428\n",
      "degree:  9\n",
      "lambda  0.1\n",
      "loss:  1312289168041624.8\n",
      "degree:  9\n",
      "lambda  1\n",
      "loss:  1312522900337721.8\n",
      "degree:  9\n",
      "lambda  2\n",
      "loss:  1314056999384691.0\n",
      "degree:  9\n",
      "lambda  5\n",
      "loss:  1313376227847891.0\n",
      "degree:  9\n",
      "lambda  10\n",
      "loss:  1308482775893637.2\n",
      "degree:  10\n",
      "lambda  0.1\n",
      "loss:  1.3785552989609267e+17\n",
      "degree:  10\n",
      "lambda  1\n",
      "loss:  1.3795815303273429e+17\n",
      "degree:  10\n",
      "lambda  2\n",
      "loss:  1.3820984604941034e+17\n",
      "degree:  10\n",
      "lambda  5\n",
      "loss:  1.3830658530773566e+17\n",
      "degree:  10\n",
      "lambda  10\n",
      "loss:  1.3841304460485685e+17\n",
      "degree:  11\n",
      "lambda  0.1\n",
      "loss:  1.4996629200675535e+19\n",
      "degree:  11\n",
      "lambda  1\n",
      "loss:  1.5011573883448492e+19\n",
      "degree:  11\n",
      "lambda  2\n",
      "loss:  1.501261581801226e+19\n",
      "degree:  11\n",
      "lambda  5\n",
      "loss:  1.505400310752419e+19\n",
      "degree:  11\n",
      "lambda  10\n",
      "loss:  1.5111989633106995e+19\n",
      "degree:  12\n",
      "lambda  0.1\n",
      "loss:  1.6683268667061777e+21\n",
      "degree:  12\n",
      "lambda  1\n",
      "loss:  1.670149517370593e+21\n",
      "degree:  12\n",
      "lambda  2\n",
      "loss:  1.6705134462032352e+21\n",
      "degree:  12\n",
      "lambda  5\n",
      "loss:  1.6757340441896079e+21\n",
      "degree:  12\n",
      "lambda  10\n",
      "loss:  1.680825316498884e+21\n",
      "degree:  13\n",
      "lambda  0.1\n",
      "loss:  1.890424449451947e+23\n",
      "degree:  13\n",
      "lambda  1\n",
      "loss:  1.890926314069633e+23\n",
      "degree:  13\n",
      "lambda  2\n",
      "loss:  1.8930772867020747e+23\n",
      "degree:  13\n",
      "lambda  5\n",
      "loss:  1.8960889165525282e+23\n",
      "degree:  13\n",
      "lambda  10\n",
      "loss:  1.902765750301663e+23\n",
      "degree:  14\n",
      "lambda  0.1\n",
      "loss:  2.186334522143949e+25\n",
      "degree:  14\n",
      "lambda  1\n",
      "loss:  2.1887137567555622e+25\n",
      "degree:  14\n",
      "lambda  2\n",
      "loss:  2.189373363126556e+25\n",
      "degree:  14\n",
      "lambda  5\n",
      "loss:  2.19466017270877e+25\n",
      "degree:  14\n",
      "lambda  10\n",
      "loss:  2.200862417981881e+25\n",
      "degree:  15\n",
      "lambda  0.1\n",
      "loss:  2.5376412690432684e+27\n",
      "degree:  15\n",
      "lambda  1\n",
      "loss:  2.53836986360105e+27\n",
      "degree:  15\n",
      "lambda  2\n",
      "loss:  2.541226270226011e+27\n",
      "degree:  15\n",
      "lambda  5\n",
      "loss:  2.5454213886269843e+27\n",
      "degree:  15\n",
      "lambda  10\n",
      "loss:  2.5561482888066077e+27\n",
      "degree:  16\n",
      "lambda  0.1\n",
      "loss:  3.0207818484835186e+29\n",
      "degree:  16\n",
      "lambda  1\n",
      "loss:  3.023739813813306e+29\n",
      "degree:  16\n",
      "lambda  2\n",
      "loss:  3.0245898613577534e+29\n",
      "degree:  16\n",
      "lambda  5\n",
      "loss:  3.0315238105875686e+29\n",
      "degree:  16\n",
      "lambda  10\n",
      "loss:  3.0375738321344526e+29\n",
      "degree:  17\n",
      "lambda  0.1\n",
      "loss:  3.626282574846364e+31\n",
      "degree:  17\n",
      "lambda  1\n",
      "loss:  3.627115280520317e+31\n",
      "degree:  17\n",
      "lambda  2\n",
      "loss:  3.6280339197421354e+31\n",
      "degree:  17\n",
      "lambda  5\n",
      "loss:  3.633268210269347e+31\n",
      "degree:  17\n",
      "lambda  10\n",
      "loss:  3.642546548317532e+31\n",
      "degree:  18\n",
      "lambda  0.1\n",
      "loss:  4.418480485318484e+33\n",
      "degree:  18\n",
      "lambda  1\n",
      "loss:  4.4193777950327405e+33\n",
      "degree:  18\n",
      "lambda  2\n",
      "loss:  4.4233692760745504e+33\n",
      "degree:  18\n",
      "lambda  5\n",
      "loss:  4.426277271825457e+33\n",
      "degree:  18\n",
      "lambda  10\n",
      "loss:  4.4400448429692195e+33\n",
      "degree:  19\n",
      "lambda  0.1\n",
      "loss:  5.466475169458276e+35\n",
      "degree:  19\n",
      "lambda  1\n",
      "loss:  5.467441061370049e+35\n",
      "degree:  19\n",
      "lambda  2\n",
      "loss:  5.472072533447356e+35\n",
      "degree:  19\n",
      "lambda  5\n",
      "loss:  5.4787405729575786e+35\n",
      "degree:  19\n",
      "lambda  10\n",
      "loss:  5.4838305907604995e+35\n"
     ]
    }
   ],
   "source": [
    "polyModelArray = np.array([])\n",
    "\n",
    "for row in range(15, 29):\n",
    "    # splitting data into x and y vectors\n",
    "    m = 50\n",
    "    x1 = data[0][row][1:6]\n",
    "    x2 = data[1][row][1:6]\n",
    "    x3 = data[2][row][1:6]\n",
    "    x4 = data[3][row][1:6]\n",
    "    x5 = data[4][row][1:6]\n",
    "    x6 = data[5][row][1:6]\n",
    "    x7 = data[6][row][1:6]\n",
    "    x8 = data[7][row][1:6]\n",
    "    x9 = data[8][row][1:6]\n",
    "    x10 = data[9][row][1:6]\n",
    "\n",
    "    # x vector\n",
    "    X = np.array((x1, x2, x3, x4, x5, x6, x7, x8, x9, x10))\n",
    "    \n",
    "    # y vector\n",
    "    y = np.array((data[0][row][6], data[1][row][6], data[2][row][6], data[3][row][6], data[4][row][6], data[5][row][6], data[6][row][6],data[7][row][6],data[8][row][6],data[9][row][6]))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "    \n",
    "    # find best values for current model\n",
    "    lambdas = {0.1, 1,2,5,10}\n",
    "    degrees = [1,20]\n",
    "    best_vals = find_best(degrees, lambdas)\n",
    "    \n",
    "    # creating model\n",
    "    poly_features = PolynomialFeatures(degree=best_vals[0], include_bias = False)\n",
    "    std_scaler = StandardScaler()\n",
    "    ridge_reg = Ridge(alpha=best_vals[1],solver=\"sag\", random_state=42)\n",
    "    ridge_regression = Pipeline([\n",
    "    (\"poly_features\", poly_features),\n",
    "    (\"std_scaler\", std_scaler),\n",
    "    (\"ridge_reg\", ridge_reg),\n",
    "    \n",
    "    ])\n",
    "    ridge_regression.fit(X_train, y_train)\n",
    "    print(ridge_regression.head)\n",
    "    polyModelArray = np.append(polyModelArray, ridge_regression)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ce12615a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polyModelArray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "94453841",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'toString'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [197]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpolyModelArray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoString\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'toString'"
     ]
    }
   ],
   "source": [
    "polyModelArray."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
