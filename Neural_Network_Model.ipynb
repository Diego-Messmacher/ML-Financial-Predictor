{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54fb76a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting income statement rows using neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3b865446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c92c0b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data file\n",
    "_data_file = \"./data/Cleaned_Data.xlsx\"\n",
    "data = pd.read_excel(_data_file,index_col=False,sheet_name = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5c5c09d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0:                0        1        2         3         4        5       6   \\\n",
       " JAN '17    52.745   34.006    3.021    18.739   109.295  -90.556   0.067   \n",
       " JAN '18   118.752   54.486    7.739    64.266   195.706 -131.440  -0.709   \n",
       " JAN '19   249.824   87.238   15.398   162.586   299.450 -136.864   2.158   \n",
       " JAN '20   481.413  141.791   23.513   339.622   485.687 -146.065  13.221   \n",
       " JAN '21   874.438  229.936   47.929   644.502   733.273  -88.771   6.219   \n",
       " JAN '22  1451.594  385.365   77.913  1066.229  1202.577 -136.348  23.856   \n",
       " JAN '23  2241.236  603.889  103.250  1637.347  1824.795 -187.448  54.548   \n",
       " \n",
       "              7       8        9   ...        20         21         22  \\\n",
       " JAN '17   0.615   0.149  -91.253  ...       NaN        NaN        NaN   \n",
       " JAN '18   2.148   0.264 -134.561  ...  0.451478 -11.582090   2.492683   \n",
       " JAN '19   0.428   3.576 -138.710  ...  0.041266  -4.043724  -0.800745   \n",
       " JAN '20   0.442   6.496 -139.782  ...  0.067227   5.126506   0.032710   \n",
       " JAN '21   1.559   3.758  -87.869  ... -0.392250  -0.529612   2.527149   \n",
       " JAN '22  25.231  22.300 -160.023  ...  0.535952   2.835986  15.184092   \n",
       " JAN '23  25.319   1.664 -159.883  ...  0.374776   1.286553   0.003488   \n",
       " \n",
       "                 23        24         25        26        27        28  \\\n",
       " JAN '17        NaN       NaN        NaN       NaN       NaN       NaN   \n",
       " JAN '18   0.771812  0.474593   9.678161  0.483359  0.304030  0.304564   \n",
       " JAN '19  12.545455  0.030834   0.471475  0.033855 -0.025393 -0.009028   \n",
       " JAN '20   0.816555  0.007728   0.460863  0.012150 -0.066001 -0.052242   \n",
       " JAN '21  -0.421490 -0.371385   1.383575 -0.346666 -0.358668 -0.361069   \n",
       " JAN '22   4.934007  0.821154  14.200630  1.534865  1.334871  1.429948   \n",
       " JAN '23  -0.925381 -0.000875  -0.690388 -0.219576 -0.190680 -0.239625   \n",
       " \n",
       "                29  \n",
       " JAN '17       NaN  \n",
       " JAN '18  0.413160  \n",
       " JAN '19 -0.018068  \n",
       " JAN '20  0.008941  \n",
       " JAN '21 -0.666737  \n",
       " JAN '22  0.430758  \n",
       " JAN '23  0.440883  \n",
       " \n",
       " [7 rows x 30 columns],\n",
       " 1:                0         1        2         3         4        5       6   \\\n",
       " DEC '06   123.466    40.964    3.509    82.502    88.499   -5.997   1.873   \n",
       " DEC '07   155.366    56.652    4.153    98.714   120.291  -21.577   1.516   \n",
       " DEC '08   211.791    65.472    4.234   146.319   141.392    4.927   4.324   \n",
       " DEC '09   252.115    69.975    5.935   182.140   156.806   25.334   2.179   \n",
       " DEC '10   324.696    85.206    5.696   239.490   184.149   55.341   1.000   \n",
       " DEC '11   430.976   113.598    7.000   317.378   231.074   86.304   5.769   \n",
       " DEC '12   533.639   147.420   11.564   386.219   286.356   99.863   4.521   \n",
       " DEC '13   615.297   180.174   15.623   435.123   364.476   70.647   3.851   \n",
       " DEC '14   770.364   228.605   22.028   541.759   478.181   63.578   2.225   \n",
       " DEC '15  1009.268   285.184   31.589   724.084   698.314   25.770   2.128   \n",
       " DEC '16  1275.443   343.123   48.520   932.320   885.079   47.241   0.204   \n",
       " DEC '17  1494.930   388.857   55.476  1106.073   994.129  111.944  14.190   \n",
       " DEC '18  1801.200   453.100   55.700  1348.100  1117.100  231.000  19.900   \n",
       " DEC '19  2163.000   509.200   61.600  1653.800  1302.800  351.000  35.000   \n",
       " DEC '20  2594.400   574.100   68.800  2020.300  1528.700  491.600  50.100   \n",
       " DEC '21  3342.200   801.500   84.400  2540.700  1894.900  645.800  -2.500   \n",
       " DEC '22  4417.400  1108.200  104.300  3309.200  2344.200  965.000   8.500   \n",
       " \n",
       "            7       8        9   ...        20         21        22        23  \\\n",
       " DEC '06   0.0     NaN   -4.124  ...       NaN        NaN       NaN       NaN   \n",
       " DEC '07   0.0     NaN  -20.061  ...  2.597966  -0.190603  0.000000  0.000000   \n",
       " DEC '08   0.0     NaN    9.251  ... -1.228345   1.852243  0.000000  0.000000   \n",
       " DEC '09   0.0     NaN   27.513  ...  4.141871  -0.496068  0.000000  0.000000   \n",
       " DEC '10   0.0     NaN   56.341  ...  1.184456  -0.541074  0.000000  0.000000   \n",
       " DEC '11   0.0     NaN   92.073  ...  0.559495   4.769000  0.000000  0.000000   \n",
       " DEC '12   0.0  -0.612  104.996  ...  0.157107  -0.216329  0.000000  0.000000   \n",
       " DEC '13   0.0  -1.443   75.941  ... -0.292561  -0.148197  0.000000  1.357843   \n",
       " DEC '14   0.0   4.254   61.549  ... -0.100061  -0.422228  0.000000 -3.948025   \n",
       " DEC '15   0.0  10.893   17.005  ... -0.594671  -0.043596  0.000000  1.560649   \n",
       " DEC '16   0.0   4.297   43.148  ...  0.833178  -0.904135  0.000000 -0.605526   \n",
       " DEC '17   0.0   2.140  123.994  ...  1.369637  68.558824  0.000000 -0.501978   \n",
       " DEC '18   0.0   0.000  250.900  ...  1.063532   0.402396  0.000000 -1.000000   \n",
       " DEC '19   0.0   0.000  386.000  ...  0.519481   0.758794  0.000000  0.000000   \n",
       " DEC '20   0.0   0.000  541.700  ...  0.400570   0.431429  0.000000  0.000000   \n",
       " DEC '21  14.9     NaN  628.400  ...  0.313670  -1.049900  0.000000  0.000000   \n",
       " DEC '22  18.0   0.000  955.500  ...  0.494271  -4.400000  0.208054  0.000000   \n",
       " \n",
       "                24         25        26        27        28        29  \n",
       " DEC '06       NaN        NaN       NaN       NaN       NaN       NaN  \n",
       " DEC '07  3.864452   0.459836  3.087201  3.087038  3.125000  6.003215  \n",
       " DEC '08 -1.461144   0.060079 -1.337103 -1.337113 -1.333333 -1.525769  \n",
       " DEC '09  1.974057 -18.301907  7.173163  6.116226  6.090909  2.413274  \n",
       " DEC '10  1.047796  -1.462132 -0.314628 -0.324396 -0.320513  0.951997  \n",
       " DEC '11  0.634210   0.959526  0.515141  0.446920  0.433962  0.528647  \n",
       " DEC '12  0.140356   0.290017  0.069513  0.046375  0.057895  0.194236  \n",
       " DEC '13 -0.276725  -0.170126 -0.337588 -0.355713 -0.345771 -0.225771  \n",
       " DEC '14 -0.189516   0.143299 -0.427574 -0.349641 -0.431559 -0.007697  \n",
       " DEC '15 -0.723716  -0.750925 -0.684844 -0.470187 -0.695652 -0.329965  \n",
       " DEC '16  1.537371   0.215458  3.029924  1.251819  3.010989  0.669503  \n",
       " DEC '17  1.873691   7.447678 -0.024482 -0.074428 -0.032877  0.748311  \n",
       " DEC '18  1.023485  -1.878017  9.579955  9.322922  9.804533  0.712460  \n",
       " DEC '19  0.538462  -1.667897 -0.001505 -0.006070 -0.006030  0.439135  \n",
       " DEC '20  0.403368  -0.020258  0.472716  0.536823  0.536798  0.358216  \n",
       " DEC '21  0.160052  -0.734962  0.242170  0.246631  0.246653  0.302998  \n",
       " DEC '22  0.520528   1.184397  0.412821  0.465803  0.465785  0.464393  \n",
       " \n",
       " [17 rows x 30 columns],\n",
       " 2:                0         1        2         3         4        5       6   \\\n",
       " JUN '07     1.863     0.650    0.100     1.213     5.352   -4.139   0.170   \n",
       " JUN '08     8.781     4.555    0.100     4.226    10.094   -5.868   0.010   \n",
       " JUN '09    19.315     7.851    0.164    11.464    17.295   -5.831  -0.027   \n",
       " JUN '10    43.329    16.190    0.369    27.139    55.338  -28.199  -1.226   \n",
       " JUN '11    92.641    31.575    1.472    61.066    50.506   10.560   0.606   \n",
       " DEC '12   243.712   104.009   13.506   139.703   174.787  -35.084  -0.896   \n",
       " DEC '13   424.650   155.259   23.525   269.391   335.658  -66.267  -4.930   \n",
       " DEC '14   682.563   248.776   42.059   433.787   584.422 -150.635   5.354   \n",
       " DEC '15  1005.480   329.413   60.356   676.067   842.432 -166.365   4.450   \n",
       " DEC '16  1390.513   398.682   83.082   991.831  1143.639 -151.808   6.035   \n",
       " DEC '17  1918.494   499.862  112.900  1418.632  1480.628  -61.996   4.384   \n",
       " DEC '18  2608.816   622.658  148.200  1986.158  2027.584  -41.426  40.915   \n",
       " DEC '19  3460.437   796.645  202.500  2663.792  2621.669   42.123  58.345   \n",
       " DEC '20  4519.484   987.113  271.000  3532.371  3333.508  198.863  29.682   \n",
       " DEC '21  5896.000  1353.000  388.000  4543.000  4286.000  257.000  23.000   \n",
       " DEC '22  7245.000  1573.000  342.000  5672.000  5317.000  355.000  71.000   \n",
       " \n",
       "              7        8        9   ...        20         21        22  \\\n",
       " JUN '07   0.000    0.000   -3.969  ...       NaN        NaN       NaN   \n",
       " JUN '08   0.000    0.000   -5.858  ...  0.417734  -0.941176  0.000000   \n",
       " JUN '09   0.000    0.000   -5.858  ... -0.006305  -3.700000  0.000000   \n",
       " JUN '10   0.000    0.000  -29.425  ...  3.836049  44.407407  0.000000   \n",
       " JUN '11   0.000    0.000   11.166  ... -1.374481  -1.494290  0.000000   \n",
       " DEC '12   0.000    0.000  -35.980  ... -4.322348  -2.478548  0.000000   \n",
       " DEC '13   0.000    0.000  -71.197  ...  0.888810   4.502232  0.000000   \n",
       " DEC '14  29.059    1.200 -175.540  ...  1.273153  -2.086004  0.000000   \n",
       " DEC '15  31.097    0.000 -193.012  ...  0.104425  -0.168846  0.070133   \n",
       " DEC '16  33.278  271.000 -450.051  ... -0.087500   0.356180  0.070135   \n",
       " DEC '17  53.394    2.400 -113.406  ... -0.591616  -0.273571  0.604483   \n",
       " DEC '18  52.733  -14.220  -39.024  ... -0.331796   8.332801 -0.012380   \n",
       " DEC '19  33.283    0.000   67.185  ... -2.016825   0.426005 -0.368839   \n",
       " DEC '20  32.746   46.614  149.185  ...  3.721008  -0.491267 -0.016134   \n",
       " DEC '21  28.000    3.000  249.000  ...  0.292347  -0.225120 -0.144934   \n",
       " DEC '22  27.000    0.000  399.000  ...  0.381323   2.086957 -0.035714   \n",
       " \n",
       "                23        24         25         26         27         28  \\\n",
       " JUN '07       NaN       NaN        NaN        NaN        NaN        NaN   \n",
       " JUN '08  0.000000  0.475939  10.500000   0.480987   0.480978   0.481595   \n",
       " JUN '09  0.000000  0.000000   1.086957   0.004251   0.110511   0.111801   \n",
       " JUN '10  0.000000  4.023045   4.833333   4.029631   3.646328   3.646182   \n",
       " JUN '11  0.000000 -1.379473   3.771429  -1.076485  -1.054011  -1.054108   \n",
       " DEC '12  0.000000 -4.222282   0.023952 -17.573944 -38.813122 -38.777778   \n",
       " DEC '13  0.000000  0.978794   0.835526   0.957404   0.068333   0.058824   \n",
       " DEC '14  0.000000  1.465553   0.532059   1.433752   1.256709   1.277778   \n",
       " DEC '15 -1.000000  0.099533   0.407330   0.106134   0.037458   0.032520   \n",
       " DEC '16 -0.935642  1.331725  -0.676210   1.276940   0.250049   1.165354   \n",
       " DEC '17 -0.991144 -0.748015   0.962350  -0.741379  -0.577658  -0.751782   \n",
       " DEC '18 -6.925000 -0.655891  -4.581395  -0.771460  -0.693633  -0.779959   \n",
       " DEC '19 -1.000000 -2.721633  44.415016 -24.468319 -16.416166 -22.155792   \n",
       " DEC '20 -0.935642  1.220511  -1.054837  -0.810909  -0.765102  -0.815804   \n",
       " DEC '21 -0.935642  0.669069  -0.380744   0.940879   0.530527   0.934222   \n",
       " DEC '22 -1.000000  0.602410   2.894737   0.413043   0.397727   0.410476   \n",
       " \n",
       "                29  \n",
       " JUN '07       NaN  \n",
       " JUN '08  0.000000  \n",
       " JUN '09  0.000000  \n",
       " JUN '10  3.910888  \n",
       " JUN '11 -1.432339  \n",
       " DEC '12 -2.793384  \n",
       " DEC '13  0.980814  \n",
       " DEC '14  1.540265  \n",
       " DEC '15 -0.023642  \n",
       " DEC '16 -0.351697  \n",
       " DEC '17 -1.740680  \n",
       " DEC '18  1.097556  \n",
       " DEC '19  1.291035  \n",
       " DEC '20  0.920764  \n",
       " DEC '21  0.372741  \n",
       " DEC '22  0.080620  \n",
       " \n",
       " [16 rows x 30 columns],\n",
       " 3:                  0           1          2           3          4         5   \\\n",
       " DEC '01    0.086426    0.014228   0.010025    0.072198   0.048851   0.01097   \n",
       " DEC '02    0.439508    0.131510   0.018030    0.307998   0.099897   0.18646   \n",
       " DEC '03    1.465934    0.625854   0.050185    0.840080   0.497616   0.34246   \n",
       " DEC '04    3.189223    1.457653   0.148473    1.731570   0.879035   0.85254   \n",
       " DEC '05    6.138560    2.571509   0.293812    3.567051   1.437773   2.03928   \n",
       " DEC '06   10.604917    4.225027   0.571939    6.379890   2.789094   3.59080   \n",
       " DEC '07   16.593986    6.649085   0.967658    9.944901   4.860501   5.08440   \n",
       " DEC '08   21.795550    8.621506   1.499887   13.174044   6.542075   6.63197   \n",
       " DEC '09   23.325858    8.844115   1.524308   14.481743   6.494262   7.98748   \n",
       " DEC '10   29.118000   10.417000   1.396000   18.701000   8.523000  10.17800   \n",
       " DEC '11   37.862000   13.188000   1.851000   24.674000  12.475000  12.19900   \n",
       " DEC '12   49.958000   20.505000   2.962000   29.453000  16.334000  13.11900   \n",
       " DEC '13   59.730000   25.824000   3.939000   33.906000  19.912000  13.99400   \n",
       " DEC '14   65.830000   25.313000   4.602000   40.517000  23.814000  16.70300   \n",
       " DEC '15   73.590000   28.164000   5.063000   45.426000  27.465000  17.96100   \n",
       " DEC '16   89.733000   35.138000   6.144000   54.595000  31.418000  23.17700   \n",
       " DEC '17  111.024000   45.583000   6.915000   65.441000  36.390000  29.05100   \n",
       " DEC '18  136.958000   59.549000   9.035000   77.409000  45.878000  31.53100   \n",
       " DEC '19  161.402000   71.896000  11.781000   89.506000  54.033000  35.47300   \n",
       " DEC '20  182.350000   84.732000  13.697000   97.618000  56.571000  41.04700   \n",
       " DEC '21  257.488000  110.939000  12.441000  146.549000  67.984000  78.56500   \n",
       " DEC '22  280.875000  126.203000  15.928000  154.672000  81.791000  72.88100   \n",
       " \n",
       "                6         7          8          9   ...         20         21  \\\n",
       " DEC '01  0.000861  0.001758   0.022000   0.010068  ...        NaN        NaN   \n",
       " DEC '02  0.001015  0.002570   0.022000   0.184915  ...  15.997265   0.178862   \n",
       " DEC '03  0.006123  0.001931   0.022000   0.346654  ...   0.836641   5.032512   \n",
       " DEC '04  0.010906  0.000862   0.212343   0.650234  ...   1.489459   0.781153   \n",
       " DEC '05  0.125178  0.000776   0.022000   2.141677  ...   1.392005  10.477902   \n",
       " DEC '06  0.461303  0.000257   0.040800   4.011040  ...   0.760818   2.685176   \n",
       " DEC '07  0.590785  0.001203   0.000000   5.673980  ...   0.415952   0.280688   \n",
       " DEC '08  0.316383  0.000000   1.094757   5.853596  ...   0.304376  -0.464470   \n",
       " DEC '09  0.471373  0.000000   0.077668   8.381189  ...   0.204390   0.489881   \n",
       " DEC '10  0.984000  0.000000   0.366000  10.796000  ...   0.274244   1.087519   \n",
       " DEC '11  1.122000  0.058000   0.937000  12.326000  ...   0.198566   0.140244   \n",
       " DEC '12  1.455000  0.084000   1.104000  13.386000  ...   0.075416   0.296791   \n",
       " DEC '13  0.595000  0.083000   0.010000  14.496000  ...   0.066697  -0.591065   \n",
       " DEC '14  1.213000  0.101000   0.556000  17.259000  ...   0.193583   1.038655   \n",
       " DEC '15  2.096000  0.104000   0.302000  19.651000  ...   0.075316   0.727947   \n",
       " DEC '16  1.472000  0.124000   0.375000  24.150000  ...   0.290407  -0.297710   \n",
       " DEC '17  1.111000  0.109000   2.860000  27.193000  ...   0.253441  -0.245245   \n",
       " DEC '18  4.396000  0.114000   0.900000  34.913000  ...   0.085367   2.956796   \n",
       " DEC '19  3.056000  0.100000  -1.196000  39.625000  ...   0.125020  -0.304823   \n",
       " DEC '20  2.011000  0.135000  -5.159000  48.082000  ...   0.157134  -0.341950   \n",
       " DEC '21  2.117000  0.346000 -10.398000  90.734000  ...   0.914025   0.052710   \n",
       " DEC '22  2.109000  0.357000   3.305000  71.328000  ...  -0.072348  -0.003779   \n",
       " \n",
       "                22         23         24         25         26        27  \\\n",
       " DEC '01       NaN        NaN        NaN        NaN        NaN       NaN   \n",
       " DEC '02  0.461889   0.000000  17.366607  26.654557  13.267144  9.914530   \n",
       " DEC '03 -0.248638   0.000000   0.874667   1.826751   0.060127 -0.053543   \n",
       " DEC '04 -0.553599   8.651955   0.875744   0.041945   2.777819  4.197021   \n",
       " DEC '05 -0.099768  -0.896394   2.293702   1.693109   2.671579  1.526527   \n",
       " DEC '06 -0.668814   0.854545   0.872850   0.380484   1.100077  1.535854   \n",
       " DEC '07  3.680934  -1.000000   0.414591   0.574839   0.365977  0.033319   \n",
       " DEC '08 -1.000000   0.000000   0.031656   0.106429   0.005504  0.182924   \n",
       " DEC '09  0.000000  -0.929055   0.431802   0.143848   0.542623  0.308916   \n",
       " DEC '10  0.000000   3.712365   0.288123   0.231230   0.304358  0.316730   \n",
       " DEC '11  0.000000   1.560109   0.141719   0.130074   0.144856  0.171874   \n",
       " DEC '12  0.448276   0.178228   0.085997   0.003476   0.107939  0.090501   \n",
       " DEC '13 -0.011905  -0.990942   0.082922  -0.121632   0.132184  0.037063   \n",
       " DEC '14  0.216867  54.600000   0.190604   0.594654   0.115114  0.116056   \n",
       " DEC '15  0.029703  -0.456835   0.138594  -0.092333   0.161968  0.153540   \n",
       " DEC '16  0.192308   0.241722   0.228945   0.414472   0.230760  0.220729   \n",
       " DEC '17 -0.120968   6.626667   0.126004   2.110231  -0.349933 -0.262312   \n",
       " DEC '18  0.045872  -0.685315   0.283897  -0.712546   1.427421  1.139890   \n",
       " DEC '19 -0.122807  -2.328889   0.134964   0.264544   0.117354  0.075452   \n",
       " DEC '20  0.350000   3.313545   0.213426   0.479175   0.172553  0.112428   \n",
       " DEC '21  1.562963   1.015507   0.887068   0.881608   0.888127  0.901468   \n",
       " DEC '22  0.031792  -1.317850  -0.213878  -0.227536  -0.211237 -0.125853   \n",
       " \n",
       "                28        29  \n",
       " DEC '01       NaN       NaN  \n",
       " DEC '02  9.300000  8.737619  \n",
       " DEC '03 -0.058252  0.920094  \n",
       " DEC '04  2.762887  1.549435  \n",
       " DEC '05  2.441096  1.330736  \n",
       " DEC '06  0.980096  0.784217  \n",
       " DEC '07  0.337354  0.453865  \n",
       " DEC '08  0.001503  0.343652  \n",
       " DEC '09  0.533173  0.169694  \n",
       " DEC '10  0.289211  0.216806  \n",
       " DEC '11  0.131075  0.213928  \n",
       " DEC '12  0.085672  0.144555  \n",
       " DEC '13  0.111194  0.115167  \n",
       " DEC '14  0.085151  0.188033  \n",
       " DEC '15  0.171402  0.080685  \n",
       " DEC '16  0.220578  0.273497  \n",
       " DEC '17 -0.354473  0.226629  \n",
       " DEC '18  1.428540  0.127899  \n",
       " DEC '19  0.124886  0.164867  \n",
       " DEC '20  0.192262  0.158505  \n",
       " DEC '21  0.914184  0.662392  \n",
       " DEC '22 -0.238899 -0.024141  \n",
       " \n",
       " [22 rows x 30 columns],\n",
       " 4:                 0          1         2          3           4          5   \\\n",
       " JAN '01      5.435      3.422     0.861      2.013     35.2355   -33.2225   \n",
       " JAN '02     22.409      6.047     2.403     16.362     38.2300   -21.8680   \n",
       " JAN '03     50.991     10.363     2.664     40.628     51.1280   -10.5000   \n",
       " JAN '04     96.023     17.273     2.591     78.750     78.4770     0.2730   \n",
       " JAN '05    176.375     33.454     3.147    142.921    136.4010     6.5200   \n",
       " JAN '06    309.857     69.126     6.027    240.731    220.9140    19.8170   \n",
       " JAN '07    497.098    118.890    12.504    378.208    381.8060    -3.5980   \n",
       " JAN '08    748.700    171.591    24.219    577.109    556.8000    20.3090   \n",
       " JAN '09   1076.769    220.471    35.971    856.298    792.5560    63.7420   \n",
       " JAN '10   1305.583    257.925    53.177   1047.658    932.3860   115.2720   \n",
       " JAN '11   1657.139    328.022    75.746   1329.117   1231.6200    97.4970   \n",
       " JAN '12   2266.539    496.136   157.286   1770.403   1805.4880   -35.0850   \n",
       " JAN '13   3050.195    694.501   216.795   2355.694   2466.4040  -110.7100   \n",
       " JAN '14   4071.003   1005.607   369.423   3065.396   3351.4700  -286.0740   \n",
       " JAN '15   5373.586   1353.943   448.296   4019.643   4165.2760  -145.6330   \n",
       " JAN '16   6667.216   1735.336   525.750   4931.880   4857.2100    74.6700   \n",
       " JAN '17   8391.984   2334.131   632.245   6057.853   5980.6160    77.2370   \n",
       " JAN '18  10540.000   3486.000  1345.000   7054.000   6600.0000   454.0000   \n",
       " JAN '19  13282.000   4420.000  1699.000   8862.000   8300.0000   562.0000   \n",
       " JAN '20  17098.000   5463.000  3011.000  11635.000  11132.0000   503.0000   \n",
       " JAN '21  21252.000   6955.000  3904.000  14297.000  13842.0000   455.0000   \n",
       " JAN '22  26492.000   9101.000  4646.000  17391.000  16843.0000   548.0000   \n",
       " JAN '23  31352.000  10944.000  5454.000  20408.000  18550.0000  1858.0000   \n",
       " \n",
       "                6        7          8         9   ...         20         21  \\\n",
       " JAN '01     1.778    0.042     0.3775   -31.864  ...        NaN        NaN   \n",
       " JAN '02    -6.894    0.272        NaN   -29.034  ...  -0.341771  -4.877390   \n",
       " JAN '03     0.569    0.077        NaN   -10.008  ...  -0.519846  -1.082536   \n",
       " JAN '04     3.988    0.022        NaN     4.239  ...  -1.026000   6.008787   \n",
       " JAN '05     2.670    0.037        NaN     9.153  ...  22.882784  -0.330491   \n",
       " JAN '06     8.450    0.069        NaN    28.198  ...   2.039417   2.164794   \n",
       " JAN '07    16.287    0.193        NaN    12.496  ...  -1.181561   0.927456   \n",
       " JAN '08    25.950    0.046        NaN    46.213  ...  -6.644525   0.593295   \n",
       " JAN '09    21.850    0.000        NaN    85.592  ...   2.138608  -0.157996   \n",
       " JAN '10    27.918    2.000    -1.1910   142.381  ...   0.808415   0.277712   \n",
       " JAN '11    33.034   24.909     1.3240   104.298  ...  -0.154200   0.183251   \n",
       " JAN '12    20.743   17.045     1.9300   -33.317  ...  -1.359857  -0.372071   \n",
       " JAN '13    -2.727   30.948   -16.5910  -127.794  ...   2.155480  -1.131466   \n",
       " JAN '14     5.242   77.211    -0.1080  -357.935  ...   1.583994  -2.922259   \n",
       " JAN '15    17.297   73.237    11.5120  -213.085  ...  -0.490925   2.299695   \n",
       " JAN '16    51.263   72.485   -10.8310    64.279  ...  -1.512727   1.963693   \n",
       " JAN '17   138.873   88.988   101.7390    25.383  ...   0.034378   1.709030   \n",
       " JAN '18    38.000   87.000   -15.0000   420.000  ...   4.878012  -0.726369   \n",
       " JAN '19   568.000  154.000    -7.0000   983.000  ...   0.237885  13.947368   \n",
       " JAN '20   549.000  131.000   215.0000   706.000  ...  -0.104982  -0.033451   \n",
       " JAN '21  2232.000  126.000     0.0000  2561.000  ...  -0.095427   3.065574   \n",
       " JAN '22   286.000  220.000  -918.0000  1532.000  ...   0.204396  -0.871864   \n",
       " JAN '23   227.000  287.000  1138.0000   660.000  ...   2.390511  -0.206294   \n",
       " \n",
       "                 22          23         24        25         26         27  \\\n",
       " JAN '01        NaN         NaN        NaN       NaN        NaN        NaN   \n",
       " JAN '02   5.476190   -1.000000  -0.088815  0.000000  -0.096682  -0.882138   \n",
       " JAN '03  -0.716912    0.000000  -0.655301  0.000000  -0.660387  -0.660394   \n",
       " JAN '04  -0.714286    0.000000  -1.423561  0.000000  -1.361671  -1.361661   \n",
       " JAN '05   0.681818    0.000000   1.159236  1.249538   1.090495   0.940260   \n",
       " JAN '06   0.864865    0.000000   2.080739 -2.076417   2.876123   2.619416   \n",
       " JAN '07   1.797101    0.000000  -0.556848 -8.477099  -0.983107  -0.983303   \n",
       " JAN '08  -0.761658    0.000000   2.698223  1.387443  37.162162  36.447552   \n",
       " JAN '09  -1.000000    0.000000   0.852120  0.606030   1.365875   1.312872   \n",
       " JAN '10   0.000000    0.000000   0.663485  0.536039   0.858686   0.798046   \n",
       " JAN '11  11.454500   -2.111671  -0.267472 -0.400215  -0.201254  -0.232162   \n",
       " JAN '12  -0.315709    0.457704  -1.319440 -1.628450  -1.179483  -1.157783   \n",
       " JAN '13   0.815664   -9.596373   2.835699 -7.560175  22.370636  25.438155   \n",
       " JAN '14   1.494862   -0.993490   1.800875 -1.881592  -0.141508  -0.221667   \n",
       " JAN '15  -0.051469 -107.592593  -0.404682 -1.394426   0.131422   0.049747   \n",
       " JAN '16  -0.010268   -1.940844  -1.301659  1.251981  -0.819459  -0.796212   \n",
       " JAN '17   0.227675  -10.393315  -0.605112 -2.380860  -4.787627  -5.309040   \n",
       " JAN '18  -0.022340   -1.147436  15.546508 -1.388981   1.004097   0.327332   \n",
       " JAN '19   0.770115   -0.533333   1.340476 -3.116667   2.083333   1.998749   \n",
       " JAN '20  -0.149351  -31.714286  -0.281790 -5.566929  -0.886486  -0.771873   \n",
       " JAN '21  -0.038168   -1.000000   2.627479 -3.605172  31.317460  12.460116   \n",
       " JAN '22   0.746032    0.000000  -0.401796 -1.058240  -0.645383  -0.812083   \n",
       " JAN '23   0.304545   -2.239651  -0.569191  4.136364  -0.855956   0.224637   \n",
       " \n",
       "                 28        29  \n",
       " JAN '01        NaN       NaN  \n",
       " JAN '02  -0.883193 -0.398514  \n",
       " JAN '03  -0.660432 -0.597431  \n",
       " JAN '04  -1.360169 -1.365493  \n",
       " JAN '05   1.058824  2.375349  \n",
       " JAN '06   2.428571  1.673425  \n",
       " JAN '07  -0.983333 -0.655394  \n",
       " JAN '08  36.500000  3.999775  \n",
       " JAN '09   1.333333  1.239333  \n",
       " JAN '10   0.800000  0.689338  \n",
       " JAN '11  -0.253968  0.028460  \n",
       " JAN '12  -1.191489 -0.294627  \n",
       " JAN '13  20.333333 -0.131881  \n",
       " JAN '14  -0.187500 -0.214319  \n",
       " JAN '15   0.076923  2.631273  \n",
       " JAN '16  -0.833333  0.983791  \n",
       " JAN '17  -4.714286  0.181643  \n",
       " JAN '18   0.884615  1.535653  \n",
       " JAN '19   1.918367  0.256809  \n",
       " JAN '20  -0.896364  0.554180  \n",
       " JAN '21  28.544534  0.240467  \n",
       " JAN '22  -0.661391  0.191558  \n",
       " JAN '23  -0.859301  0.407778  \n",
       " \n",
       " [23 rows x 30 columns],\n",
       " 5:                0         1        2         3         4        5       6   \\\n",
       " DEC '13    49.920    25.868    0.610    24.052    50.902  -26.850  -0.004   \n",
       " DEC '14    88.846    41.423    1.756    47.423    73.806  -26.383  -0.062   \n",
       " DEC '15   166.919    75.724    4.226    91.195   125.388  -34.193   0.011   \n",
       " DEC '16   277.335   122.963    8.315   154.372   191.727  -41.215   0.317   \n",
       " DEC '17   399.020   187.490   18.764   211.530   276.132  -65.774   3.071   \n",
       " DEC '18   650.067   302.355   26.095   347.712   454.326 -113.735   8.982   \n",
       " DEC '19  1134.468   560.649  133.623   573.819   927.804 -353.985  32.640   \n",
       " DEC '20  1761.776   885.108  188.055   876.668  1347.804 -471.136  26.318   \n",
       " DEC '21  2841.839  1527.469  307.164  1314.370  2214.960 -900.590 -16.380   \n",
       " DEC '22  3826.321  2061.410  326.287  1764.911  2758.378 -993.467 -38.324   \n",
       " \n",
       "              7        8         9   ...        20         21        22  \\\n",
       " DEC '13   0.000    0.300   -26.854  ...       NaN        NaN       NaN   \n",
       " DEC '14   0.000    0.300   -26.745  ... -0.017393  14.500000  0.000000   \n",
       " DEC '15   0.000    1.200   -35.382  ...  0.296024  -1.177419  0.000000   \n",
       " DEC '16   0.000    0.100   -40.998  ...  0.205364  27.818182  0.000000   \n",
       " DEC '17   0.000    0.300   -63.003  ...  0.595875   8.687697  0.000000   \n",
       " DEC '18  14.905    1.500  -121.158  ...  0.729179   1.924780  0.000000   \n",
       " DEC '19  25.071   15.800  -362.216  ...  2.112366   2.633935  0.682053   \n",
       " DEC '20  24.980   34.628  -504.426  ...  0.330949  -0.193689 -0.003630   \n",
       " DEC '21  24.980   43.959  -960.929  ...  0.911529  -1.622388  0.000000   \n",
       " DEC '22  24.980  211.841 -1243.632  ...  0.103129   1.339683  0.000000   \n",
       " \n",
       "                23        24         25        26        27        28        29  \n",
       " DEC '13       NaN       NaN        NaN       NaN       NaN       NaN       NaN  \n",
       " DEC '14  0.000000 -0.004059   0.000000 -0.003575 -0.011398 -0.003526 -0.061471  \n",
       " DEC '15  3.000000  0.322939   8.384615  0.326856  0.433482  0.453522  0.216835  \n",
       " DEC '16 -0.916667  0.158725   1.672131  0.163925  0.756639  0.726046  0.097874  \n",
       " DEC '17  2.000000  0.536733   1.162577  0.541671 -0.103784 -0.102564  0.428875  \n",
       " DEC '18  4.000000  0.923051   0.121986  0.914187  0.788216  0.793571  0.864284  \n",
       " DEC '19  9.533333  1.989617 -70.725664  1.517962  0.828133  0.880127  1.514400  \n",
       " DEC '20  1.191646  0.392611  -0.756187  0.598952  0.398116  0.417750  0.284618  \n",
       " DEC '21  0.269464  0.904995  -0.179817  0.934706  0.658663  0.629564  1.096312  \n",
       " DEC '22  3.819059  0.294198  -2.134554  0.322397  0.147281  0.258715  0.124285  \n",
       " \n",
       " [10 rows x 30 columns],\n",
       " 6:               0        1       2        3       4       5       6      7   \\\n",
       " DEC '12   5618.0   3079.0   382.0   2539.0  1684.0   855.0    53.0    0.0   \n",
       " DEC '13   6731.0   3740.0   453.0   2991.0  1896.0  1095.0   -14.0    0.0   \n",
       " DEC '14   8061.0   4387.0   516.0   3674.0  2370.0  1304.0   -39.0    2.0   \n",
       " DEC '15   9066.0   4351.0   608.0   4715.0  3388.0  1327.0   192.0    0.0   \n",
       " DEC '16  10723.0   5215.0   724.0   5508.0  4041.0  1467.0   154.0    0.0   \n",
       " DEC '17  13077.0   6240.0   543.0   6837.0  4595.0  2242.0   -32.0    0.0   \n",
       " DEC '18  15481.0   7549.0   514.0   7932.0  5399.0  2533.0   308.0   77.0   \n",
       " DEC '19  17534.0   8368.0   614.0   9166.0  6614.0  2552.0   659.0  115.0   \n",
       " DEC '20  21434.0   9629.0  1189.0  11805.0  8397.0  3408.0  2013.0  209.0   \n",
       " DEC '21  25561.0  13450.0  1265.0  12111.0  8646.0  4514.0  -134.0  232.0   \n",
       " DEC '22  27056.0  14258.0  1317.0  12798.0  9216.0  3582.0   -18.0  304.0   \n",
       " \n",
       "             8       9   ...        20         21        22         23  \\\n",
       " DEC '12   17.0   891.0  ...       NaN        NaN       NaN        NaN   \n",
       " DEC '13   -3.0  1084.0  ...  0.280702  -1.264151  0.000000  -1.176471   \n",
       " DEC '14    2.0  1261.0  ...  0.190868   1.785714  0.000000  -1.666667   \n",
       " DEC '15   31.0  1488.0  ...  0.017638  -5.923077 -1.000000  14.500000   \n",
       " DEC '16  -10.0  1631.0  ...  0.105501  -0.197917  0.000000  -1.322581   \n",
       " DEC '17   10.0  2200.0  ...  0.528289  -1.207792  0.000000  -2.000000   \n",
       " DEC '18  388.0  2376.0  ...  0.129795 -10.625000  0.000000  37.800000   \n",
       " DEC '19   98.0  2998.0  ...  0.007501   1.139610  0.493506  -0.747423   \n",
       " DEC '20  147.0  5065.0  ...  0.335423   2.054628  0.817391   0.500000   \n",
       " DEC '21   49.0  4099.0  ...  0.324531  -1.066567  0.110048  -0.666667   \n",
       " DEC '22 -106.0  3366.0  ... -0.206469  -0.865672  0.310345  -3.163265   \n",
       " \n",
       "                24         25        26        27        28        29  \n",
       " DEC '12       NaN        NaN       NaN       NaN       NaN       NaN  \n",
       " DEC '13  0.216611   0.141593  0.227506  0.206355  0.227458  0.251415  \n",
       " DEC '14  0.163284   5.527132 -0.561257 -0.556914 -0.561536  0.175711  \n",
       " DEC '15  0.180016  -0.691211  1.930788  1.947815  1.908668  0.063187  \n",
       " DEC '16  0.096102  -0.115385  0.140879  0.125542  0.150000  0.132300  \n",
       " DEC '17  0.348866   0.760870  0.281228  0.289507  0.278261  0.271109  \n",
       " DEC '18  0.080000  -0.212346  0.145961  0.311567  0.163197  0.094075  \n",
       " DEC '19  0.261785   0.689655  0.195430  0.099164  0.210539  0.039055  \n",
       " DEC '20  0.689460   0.601113  0.708825  0.704592  0.710228  0.451990  \n",
       " DEC '21 -0.190721  -1.081112 -0.007853 -0.022778 -0.007006  0.257124  \n",
       " DEC '22 -0.178824 -14.528571 -0.419765 -0.428664 -0.405724 -0.152275  \n",
       " \n",
       " [11 rows x 30 columns],\n",
       " 7:                0        1        2         3         4         5       6   \\\n",
       " JAN '09    18.156    2.797    0.758    15.359    30.427   -15.068   0.332   \n",
       " JAN '10    35.000    3.290    0.938    31.710    39.013    -7.303  -0.069   \n",
       " JAN '11    66.245    6.656    0.958    59.589    62.883    -3.294  -0.387   \n",
       " JAN '12   120.960   11.605    2.120   109.355   118.041    -8.686  -2.128   \n",
       " JAN '13   198.944   21.424    4.700   177.520   199.553   -22.033   0.152   \n",
       " JAN '14   302.623   33.725    6.692   268.898   345.105   -76.207  -0.695   \n",
       " JAN '15   450.875   68.378   12.494   382.497   598.307  -215.810   0.970   \n",
       " JAN '16   668.435  114.122   19.491   554.313   840.536  -286.223   1.279   \n",
       " JAN '17   949.955  191.053   32.113   758.902  1102.733  -343.831  -3.022   \n",
       " JAN '18  1309.132  256.409   40.941  1052.723  1238.133  -185.410   5.343   \n",
       " JAN '19  1803.010  344.676   52.430  1458.334  1703.507  -245.173  29.945   \n",
       " JAN '20  2358.926  433.569   67.500  1925.357  2188.792  -263.435  51.735   \n",
       " JAN '21  2229.385  564.875  118.010  1664.510  2433.572  -769.062  -4.738   \n",
       " JAN '22  2673.664  733.969  108.291  1939.695  3061.752 -1122.057   0.644   \n",
       " JAN '23  3653.708  836.517   99.794  2817.191  3084.826  -267.635  16.081   \n",
       " \n",
       "               7       8         9   ...        20         21        22  \\\n",
       " JAN '09    0.000     NaN   -14.736  ...       NaN        NaN       NaN   \n",
       " JAN '10    0.000     NaN    -7.372  ... -0.515331  -1.207831  0.000000   \n",
       " JAN '11    0.000     NaN    -3.681  ... -0.548952   4.608696  0.000000   \n",
       " JAN '12      NaN     NaN   -10.814  ...  1.636916   4.498708  0.000000   \n",
       " JAN '13    0.000  14.087   -35.968  ...  1.536611  -1.071429  0.000000   \n",
       " JAN '14    0.000   2.100   -79.002  ...  2.458766  -5.572368  0.000000   \n",
       " JAN '15    0.000   0.000  -214.840  ...  1.831892  -2.395683  0.000000   \n",
       " JAN '16    0.000   1.700  -286.644  ...  0.326273   0.318557  0.000000   \n",
       " JAN '17    2.829   0.000  -349.682  ...  0.201270  -3.362783  0.000000   \n",
       " JAN '18    8.794   0.000  -188.861  ... -0.460753  -2.768034  2.108519   \n",
       " JAN '19   41.963   6.000  -263.191  ...  0.322329   4.604529  3.771776   \n",
       " JAN '20   96.249  23.702  -331.651  ...  0.074486   0.727667  1.293663   \n",
       " JAN '21  123.076   4.172  -901.048  ...  1.919362  -1.091582  0.278725   \n",
       " JAN '22  174.598  55.200 -1351.211  ...  0.458994  -1.135922  0.418619   \n",
       " JAN '23   46.026   0.000  -297.580  ... -0.761478  23.970497 -0.736389   \n",
       " \n",
       "                 23        24          25        26        27        28  \\\n",
       " JAN '09        NaN       NaN         NaN       NaN       NaN       NaN   \n",
       " JAN '10   0.000000 -0.499729    1.194444 -0.495600 -0.495599 -0.495519   \n",
       " JAN '11   0.000000 -0.500678    0.582278 -0.489196 -0.489194 -0.489848   \n",
       " JAN '12   0.000000  1.937789    0.424000  1.888071  1.888055  1.890547   \n",
       " JAN '13   0.000000  2.326059    3.005618  2.337063  1.875045  2.958692   \n",
       " JAN '14  -0.850926  1.196452   -0.991585  1.153922  1.208058  0.630435   \n",
       " JAN '15  -1.000000  1.719425  378.333333  1.748026  1.456278  1.413333   \n",
       " JAN '16   0.000000  0.334221   -4.458699  0.283977  0.208179  0.215470   \n",
       " JAN '17  -1.000000  0.219917   -1.699568  0.274120  0.211127  0.204545   \n",
       " JAN '18   0.000000 -0.459906   -0.753586 -0.464460 -0.487265 -0.486792   \n",
       " JAN '19   0.000000  0.393570    8.127487  0.448743  0.369472  0.390662   \n",
       " JAN '20   2.950333  0.260115   -0.594946  0.221684  0.131002  0.171522   \n",
       " JAN '21  -0.823981  1.716856    0.381702  1.696960  1.689655  1.565329   \n",
       " JAN '22  12.231064  0.499599   -2.747548  0.474809  0.420125  0.457618   \n",
       " JAN '23  -1.000000 -0.779768    0.627703 -0.792500 -0.787319 -0.793461   \n",
       " \n",
       "                29  \n",
       " JAN '09       NaN  \n",
       " JAN '10 -0.555206  \n",
       " JAN '11 -0.632993  \n",
       " JAN '12  1.810788  \n",
       " JAN '13  1.639811  \n",
       " JAN '14  3.010558  \n",
       " JAN '15  1.924779  \n",
       " JAN '16  0.311909  \n",
       " JAN '17  0.168656  \n",
       " JAN '18 -0.536539  \n",
       " JAN '19  0.334148  \n",
       " JAN '20  0.016561  \n",
       " JAN '21  2.322796  \n",
       " JAN '22  0.557120  \n",
       " JAN '23 -0.834438  \n",
       " \n",
       " [15 rows x 30 columns],\n",
       " 8:                  0          1          2           3          4         5   \\\n",
       " JUN '85    0.140417   0.030447   0.003462    0.109970   0.069063   0.04091   \n",
       " JUN '86    0.197514   0.040862   0.005754    0.156652   0.095746   0.06091   \n",
       " JUN '87    0.345890   0.073854   0.007551    0.272036   0.145149   0.12689   \n",
       " JUN '88    0.590827   0.148000   0.016035    0.442827   0.255380   0.18745   \n",
       " JUN '89    0.803530   0.204185   0.024191    0.599345   0.357115   0.24223   \n",
       " JUN '90    1.183446   0.252668   0.046318    0.930778   0.537540   0.39324   \n",
       " JUN '91    1.843432   0.362589   0.075762    1.480843   0.831001   0.64984   \n",
       " JUN '92    2.758725   0.466424   0.112321    2.292301   1.296322   0.99598   \n",
       " JUN '93    3.753000   0.633000   0.151000    3.120000   1.794000   1.32600   \n",
       " JUN '94    4.649000   0.763000   0.237000    3.886000   2.160000   1.72600   \n",
       " JUN '95    5.937000   0.877000   0.269000    5.060000   3.022000   2.03800   \n",
       " JUN '96    8.671000   1.188000   0.480000    7.483000   4.405000   3.07800   \n",
       " JUN '97   11.358000   1.085000   0.557000   10.273000   5.143000   5.13000   \n",
       " JUN '98   14.484000   1.197000   1.024000   13.287000   6.347000   6.71000   \n",
       " JUN '99   19.747000   2.814000   1.010000   16.933000   6.890000   9.92800   \n",
       " JUN '00   22.956000   3.002000   0.748000   19.954000   8.925000  10.93700   \n",
       " JUN '01   25.296000   3.455000   1.266000   21.841000  10.121000  11.72000   \n",
       " JUN '02   28.365000   5.191000   1.014000   23.174000  10.604000  12.57000   \n",
       " JUN '03   32.187000   5.686000   1.090000   26.501000  12.261000  14.24000   \n",
       " JUN '04   36.835000   6.716000   0.817000   30.119000  18.560000  11.55900   \n",
       " JUN '05   39.731000   6.200000   0.884000   33.531000  16.947000  16.58400   \n",
       " JUN '06   44.116000   7.650000   0.990000   36.466000  18.840000  17.62600   \n",
       " JUN '07   50.954000  10.693000   1.406000   40.261000  21.394000  18.86700   \n",
       " JUN '08   60.316000  11.598000   1.872000   48.718000  24.506000  24.21200   \n",
       " JUN '09   57.553000  12.155000   2.291000   45.398000  25.306000  20.09200   \n",
       " JUN '10   61.989000  12.395000   2.507000   49.594000  25.932000  23.66200   \n",
       " JUN '11   69.950000  15.577000   2.651000   54.373000  27.205000  27.16800   \n",
       " JUN '12   73.750000  17.530000   2.875000   56.220000  28.237000  27.98300   \n",
       " JUN '13   77.654000  20.249000   3.549000   57.405000  30.836000  26.56900   \n",
       " JUN '14   86.729000  26.934000   4.445000   59.795000  32.013000  27.78200   \n",
       " JUN '15   92.972000  33.038000   5.479000   59.934000  32.370000  27.56400   \n",
       " JUN '16   84.695000  32.780000   5.947000   51.915000  31.248000  20.66700   \n",
       " JUN '17   96.016000  34.620000   7.855000   61.396000  32.620000  28.77600   \n",
       " JUN '18  110.175000  38.970000   9.954000   71.205000  36.332000  34.87300   \n",
       " JUN '19  125.502000  42.910000  11.600000   82.592000  39.974000  42.61800   \n",
       " JUN '20  143.015000  46.078000  12.300000   96.937000  43.978000  52.95900   \n",
       " JUN '21  168.088000  52.232000  10.900000  115.856000  45.940000  69.91600   \n",
       " JUN '22  198.270000  62.650000  14.460000  135.620000  52.237000  83.38300   \n",
       " \n",
       "                6         7       8          9   ...        20        21  \\\n",
       " JUN '85  0.001940  0.000000     NaN   0.042843  ...       NaN       NaN   \n",
       " JUN '86  0.005080       NaN     NaN   0.065984  ...  0.488878  1.618557   \n",
       " JUN '87 -0.005550       NaN     NaN   0.121338  ...  1.083238 -2.092520   \n",
       " JUN '88 -0.003710       NaN     NaN   0.183738  ...  0.477264 -0.331532   \n",
       " JUN '89  0.008570       NaN     NaN   0.250796  ...  0.292238 -3.309973   \n",
       " JUN '90  0.020920  0.003589     NaN   0.410564  ...  0.623416  1.441074   \n",
       " JUN '91  0.025320  0.004515     NaN   0.670644  ...  0.652528  0.210325   \n",
       " JUN '92  0.047272  0.001988     NaN   1.041265  ...  0.532654  0.866983   \n",
       " JUN '93  0.075000  0.000000     NaN   1.401000  ...  0.331352  0.586563   \n",
       " JUN '94  0.086000  0.000000   0.090   1.722000  ...  0.301659  0.146667   \n",
       " JUN '95  0.175000  0.000000   0.046   2.167000  ...  0.180765  1.034884   \n",
       " JUN '96  0.301000  0.000000     NaN   3.379000  ...  0.510304  0.720000   \n",
       " JUN '97  0.184000  0.000000     NaN   5.314000  ...  0.666667 -0.388704   \n",
       " JUN '98  0.703000  0.000000   0.296   7.117000  ...  0.307992  2.820652   \n",
       " JUN '99  1.963000  0.000000     NaN  11.891000  ...  0.479583  1.792319   \n",
       " JUN '00  3.338000  0.000000     NaN  14.275000  ...  0.101632  0.700458   \n",
       " JUN '01  3.725000  0.000000   3.920  11.525000  ...  0.071592  0.115938   \n",
       " JUN '02  3.926000  0.000000   4.983  11.513000  ...  0.072526  0.053960   \n",
       " JUN '03  2.657000  0.000000   2.171  14.726000  ...  0.132856 -0.323230   \n",
       " JUN '04  3.244000  0.000000   2.607  12.196000  ... -0.188272  0.220926   \n",
       " JUN '05  2.538000  0.000000   2.494  16.628000  ...  0.434726 -0.217633   \n",
       " JUN '06  2.440000  0.000000   1.804  18.262000  ...  0.062832 -0.038613   \n",
       " JUN '07  2.103000  0.000000   0.869  20.101000  ...  0.070407 -0.138115   \n",
       " JUN '08  1.512000  0.000000   1.910  23.814000  ...  0.283299 -0.281027   \n",
       " JUN '09  1.762000       NaN   2.033  19.821000  ... -0.170164  0.165344   \n",
       " JUN '10  1.770000  0.151000   0.268  25.013000  ...  0.177683  0.004540   \n",
       " JUN '11  1.355000  0.295000   0.157  28.071000  ...  0.148170 -0.234463   \n",
       " JUN '12  1.519000  0.380000   6.855  22.267000  ...  0.029999  0.121033   \n",
       " JUN '13  1.316000  0.429000   0.404  27.052000  ... -0.050531 -0.133641   \n",
       " JUN '14  1.196000  0.597000   0.561  27.820000  ...  0.045655 -0.091185   \n",
       " JUN '15  2.341000  0.781000  10.617  18.507000  ... -0.007847  0.957358   \n",
       " JUN '16  2.202000  1.243000   1.875  19.751000  ... -0.250218 -0.059376   \n",
       " JUN '17  4.218000  2.222000   0.871  29.901000  ...  0.392365  0.915531   \n",
       " JUN '18  4.568000  2.733000   0.234  36.474000  ...  0.211878  0.082978   \n",
       " JUN '19  3.159000  2.686000  -0.597  43.688000  ...  0.222092 -0.308450   \n",
       " JUN '20  2.545000  2.591000  -0.123  53.036000  ...  0.242644 -0.194365   \n",
       " JUN '21  2.488000  2.346000  -1.044  71.102000  ...  0.320191 -0.022397   \n",
       " JUN '22  2.040000  2.063000  -0.356  83.716000  ...  0.192617 -0.180064   \n",
       " \n",
       "                22         23        24        25        26        27  \\\n",
       " JUN '85       NaN        NaN       NaN       NaN       NaN       NaN   \n",
       " JUN '86  0.000000   0.000000  0.540135  0.426209  0.628729  0.000000   \n",
       " JUN '87  0.000000   0.000000  0.838900  0.850355  0.831100  0.000000   \n",
       " JUN '88  0.000000   0.000000  0.514266  0.209664  0.723865  2.413640   \n",
       " JUN '89  0.000000   0.000000  0.364965  0.341434  0.376328  0.365854   \n",
       " JUN '90  0.000000   0.000000  0.637044  0.636946  0.637090  0.542173   \n",
       " JUN '91  0.258011   0.000000  0.633470  0.582464  0.657472  0.582040   \n",
       " JUN '92 -0.559690   0.000000  0.552634  0.602710  0.530137  0.465020   \n",
       " JUN '93 -1.000000   0.000000  0.345479  0.344518  0.345931  0.305962   \n",
       " JUN '94  0.000000   0.000000  0.229122  0.285714  0.202518  0.260306   \n",
       " JUN '95  0.000000  -0.488889  0.258420  0.239583  0.267888  0.195143   \n",
       " JUN '96  0.000000  -1.000000  0.559299  0.658263  0.510668  0.447895   \n",
       " JUN '97  0.000000   0.000000  0.572655  0.570946  0.573576  0.528534   \n",
       " JUN '98  0.000000   0.000000  0.339292  0.412366  0.299942  0.328852   \n",
       " JUN '99  0.000000  -1.000000  0.670788  0.563000  0.733853  0.624947   \n",
       " JUN '00  0.000000   0.000000  0.200488  0.182172  0.210148  0.201010   \n",
       " JUN '01  0.000000   0.000000 -0.192644 -0.216316 -0.180448  0.104767   \n",
       " JUN '02  0.000000   0.271173 -0.001041 -0.031546  0.013988  0.085514   \n",
       " JUN '03  0.000000  -0.564319  0.279076  0.284745  0.276408  0.038223   \n",
       " JUN '04  0.000000   0.200829 -0.171805 -0.148954 -0.182628 -0.132967   \n",
       " JUN '05  0.000000  -0.043345  0.363398  0.085899  0.500245  0.399433   \n",
       " JUN '06  0.000000  -0.276664  0.098268  0.294696  0.028154  0.025400   \n",
       " JUN '07  0.000000  -0.518293  0.100701  0.065866  0.116358  0.127605   \n",
       " JUN '08  0.000000   1.197929  0.184717  0.016070  0.257092  0.353031   \n",
       " JUN '09  0.000000   0.064398 -0.167674 -0.143649 -0.176008 -0.114801   \n",
       " JUN '10  0.000000  -0.868175  0.261944  0.190594  0.287666  0.193968   \n",
       " JUN '11  0.953642  -0.414179  0.122256 -0.213018  0.234009  0.275306   \n",
       " JUN '12  0.288136  42.662420 -0.206761  0.074782 -0.266609 -0.054199   \n",
       " JUN '13  0.128947  -0.941065  0.214892 -0.018907  0.287725  0.021281   \n",
       " JUN '14  0.391608   0.388614  0.028390  0.107342  0.009651  0.023066   \n",
       " JUN '15  0.308208  17.925134 -0.334759  0.098851 -0.447631 -0.111144   \n",
       " JUN '16  0.591549  -0.823396  0.067218 -0.532309  0.377676 -0.049412   \n",
       " JUN '17  0.787611  -0.535467  0.513898  0.494074  0.517383  0.474385   \n",
       " JUN '18  0.229973  -0.731343  0.219825  3.511106 -0.349876 -0.355662   \n",
       " JUN '19 -0.017197  -3.551282  0.197785 -0.776516  1.367992  1.332110   \n",
       " JUN '20 -0.035369  -0.793970  0.213972  0.968300  0.128466  0.148767   \n",
       " JUN '21 -0.094558   7.487805  0.340637  0.122901  0.383686  0.383350   \n",
       " JUN '22 -0.120631  -0.659004  0.177407  0.116672  0.187152  0.208165   \n",
       " \n",
       "                28        29  \n",
       " JUN '85       NaN       NaN  \n",
       " JUN '86  0.000000  0.502366  \n",
       " JUN '87  0.000000  1.016802  \n",
       " JUN '88  2.422222  0.513538  \n",
       " JUN '89  0.363636  0.309318  \n",
       " JUN '90  0.547619  0.649876  \n",
       " JUN '91  0.584615  0.650742  \n",
       " JUN '92  0.462136  0.527426  \n",
       " JUN '93  0.306773  0.332672  \n",
       " JUN '94  0.194106  0.329045  \n",
       " JUN '95  0.234043  0.175242  \n",
       " JUN '96  0.478621  0.542263  \n",
       " JUN '97  0.533582  0.598370  \n",
       " JUN '98  0.269769  0.359944  \n",
       " JUN '99  0.700599  0.414275  \n",
       " JUN '00  0.197183  0.068294  \n",
       " JUN '01 -0.188235  0.111339  \n",
       " JUN '02  0.021739  0.046050  \n",
       " JUN '03  0.304965  0.128534  \n",
       " JUN '04 -0.184783 -0.192694  \n",
       " JUN '05  0.493333  0.411441  \n",
       " JUN '06  0.071429  0.065720  \n",
       " JUN '07  0.183333  0.089009  \n",
       " JUN '08  0.316901  0.286637  \n",
       " JUN '09 -0.133690 -0.141888  \n",
       " JUN '10  0.296296  0.169146  \n",
       " JUN '11  0.280952  0.139478  \n",
       " JUN '12 -0.256506  0.034844  \n",
       " JUN '13  0.290000 -0.023981  \n",
       " JUN '14  0.019380  0.070025  \n",
       " JUN '15 -0.437262  0.025320  \n",
       " JUN '16  0.418919 -0.194565  \n",
       " JUN '17  0.547619  0.376381  \n",
       " JUN '18 -0.344615  0.223745  \n",
       " JUN '19  1.375587  0.209494  \n",
       " JUN '20  0.139032  0.203641  \n",
       " JUN '21  0.397328  0.238389  \n",
       " JUN '22  0.197864  0.210688  \n",
       " \n",
       " [38 rows x 30 columns],\n",
       " 9:                0        1        2         3         4        5       6   \\\n",
       " JAN '15    41.010   21.522    4.715    19.488    78.270  -58.782  -0.199   \n",
       " JAN '16    85.907   44.462   11.327    41.445   117.433  -75.988  -0.019   \n",
       " JAN '17   160.326   69.683   18.302    90.643   173.766  -83.123   0.039   \n",
       " JAN '18   256.547   96.036   22.181   160.511   272.464 -111.953   1.682   \n",
       " JAN '19   399.254  134.273   28.853   264.981   383.503 -118.522   9.180   \n",
       " JAN '20   586.067  187.970   46.403   398.097   580.480 -182.383  17.089   \n",
       " JAN '21   835.424  257.342   76.526   578.082   782.241 -204.159  12.891   \n",
       " JAN '22  1300.201  396.405  107.612   903.796  1614.232 -710.436   9.768   \n",
       " JAN '23  1858.000  546.000  114.000  1312.000  2088.000 -776.000  22.000   \n",
       " \n",
       "              7       8        9   ...        20         21        22  \\\n",
       " JAN '15   0.000     NaN  -58.981  ...       NaN        NaN       NaN   \n",
       " JAN '16   0.000     NaN  -76.007  ...  0.292709  -0.904523  0.000000   \n",
       " JAN '17   0.000     NaN  -83.084  ...  0.093896  -3.052632  0.000000   \n",
       " JAN '18   0.000     NaN -110.170  ...  0.346835  42.128205  0.000000   \n",
       " JAN '19  15.072   1.100 -125.514  ...  0.058676   4.457788  0.000000   \n",
       " JAN '20  27.017  18.021 -210.332  ...  0.538811   0.861547  0.792529   \n",
       " JAN '21  72.660   2.263 -266.191  ...  0.119397  -0.245655  1.689418   \n",
       " JAN '22  92.182  56.846 -849.696  ...  2.479817  -0.242262  0.268676   \n",
       " JAN '23  11.000  36.000 -801.000  ...  0.092287   1.252252 -0.880671   \n",
       " \n",
       "                 23        24         25        26        27        28  \\\n",
       " JAN '15        NaN       NaN        NaN       NaN       NaN       NaN   \n",
       " JAN '16   0.000000  0.288669   1.269231  0.290826  0.000000 -0.000001   \n",
       " JAN '17   0.000000  0.093110   0.440678  0.094454  4.312381  4.312341   \n",
       " JAN '18   0.000000  0.326007  -1.755294  0.315415 -0.698293 -0.698295   \n",
       " JAN '19   0.000000  0.139276  -0.947040  0.142450 -0.123325 -0.117878   \n",
       " JAN '20  15.382727  0.675765  82.470588  0.664685  0.443362  0.526640   \n",
       " JAN '21  -0.874424  0.265575  -1.099366  0.274846  0.242777  0.174728   \n",
       " JAN '22  24.119753  2.192054 -10.113475  2.185539  1.624654  1.737438   \n",
       " JAN '23  -0.366710 -0.057310 -11.894942 -0.039381 -0.085002 -0.100085   \n",
       " \n",
       "                29  \n",
       " JAN '15       NaN  \n",
       " JAN '16  0.195942  \n",
       " JAN '17  0.002474  \n",
       " JAN '18  0.384922  \n",
       " JAN '19 -0.001147  \n",
       " JAN '20  0.516466  \n",
       " JAN '21 -0.061384  \n",
       " JAN '22  3.723105  \n",
       " JAN '23  0.098165  \n",
       " \n",
       " [9 rows x 30 columns],\n",
       " 10:                0        1        2         3         4        5       6   \\\n",
       " JUL '15    53.707   14.431    2.854    39.276    51.694  -12.418  -0.181   \n",
       " JUL '16    80.325   20.127    4.872    60.198    87.041  -26.843  -0.127   \n",
       " JUL '17   125.717   27.472    6.840    98.245   133.318  -35.073   0.490   \n",
       " JUL '18   190.174   37.875   21.169   152.299   178.884  -26.585   2.315   \n",
       " JUL '19   302.836   60.065   29.957   242.771   265.005  -22.234   7.401   \n",
       " JUL '20   431.269   97.087   59.595   334.182   429.036  -94.854   6.253   \n",
       " JUL '21   673.100  150.644   98.011   522.456   729.852 -207.396   3.998   \n",
       " JUL '22  1090.946  243.317  143.623   847.629  1175.058 -327.429   0.378   \n",
       " JAN '23  1348.012  298.254  168.097  1049.758  1353.209 -303.451  20.593   \n",
       " \n",
       "              7       8        9   ...        20         21        22  \\\n",
       " JUL '15   0.000     NaN  -12.599  ...       NaN        NaN       NaN   \n",
       " JUL '16   0.000     NaN  -26.970  ...  1.161620  -0.298343  0.000000   \n",
       " JUL '17   0.000     NaN  -34.583  ...  0.306598  -4.858268  0.000000   \n",
       " JUL '18   0.000   8.039  -32.309  ... -0.242010   3.724490  0.000000   \n",
       " JUL '19   0.000  13.079  -27.912  ... -0.163664   2.196976  0.000000   \n",
       " JUL '20   5.025  19.102 -112.728  ...  3.266169  -0.155114  0.000000   \n",
       " JUL '21  53.364   0.416 -257.178  ...  1.186476  -0.360627  9.619701   \n",
       " JUL '22  56.579   0.000 -383.630  ...  0.578762  -0.905453  0.060247   \n",
       " JAN '23  31.368   0.000 -314.226  ... -0.073231  53.478836 -0.445589   \n",
       " \n",
       "                23        24        25        26        27        28        29  \n",
       " JUL '15       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       " JUL '16  0.000000  1.140646  1.008584  1.138248  1.780334  1.778899  1.297261  \n",
       " JUL '17  0.000000  0.282277  0.873932  0.292368  0.247853  0.247937  0.285012  \n",
       " JUL '18  0.000000 -0.065755  0.524515 -0.051156  0.422619  0.655556 -0.808168  \n",
       " JUL '19  0.626944 -0.136092 -0.444278 -0.148339 -0.706529 -0.629434 -2.425960  \n",
       " JUL '20  0.460509  3.038693  2.213997  3.017309  3.985476  2.838292 -5.565454  \n",
       " JUL '21 -0.978222  1.281403  1.031407  1.276217  1.452438  1.170093  2.102328  \n",
       " JUL '22 -1.000000  0.491691  0.370439  0.489446  0.435637  0.434044  0.680358  \n",
       " JAN '23  0.000000 -0.180914  0.571300 -0.168101 -0.188917 -0.178448 -0.263604  \n",
       " \n",
       " [9 rows x 30 columns],\n",
       " 11:                 0          1        2         3         4        5        6   \\\n",
       " DEC '12    203.449    138.898    3.579    64.551   139.400  -74.849   -0.018   \n",
       " DEC '13    552.433    423.648    8.272   128.785   215.768  -86.983   -0.273   \n",
       " DEC '14    850.192    631.868   18.586   218.324   344.234 -125.910   -1.104   \n",
       " DEC '15   1267.118    910.145   27.626   356.973   476.822 -119.849   -1.935   \n",
       " DEC '16   1708.721   1160.219   37.745   548.502   667.720 -119.218    0.780   \n",
       " DEC '17   2214.253   1405.491   37.279   808.762   795.950   12.812    1.595   \n",
       " DEC '18   3298.177   2047.268   60.961  1250.909  1194.746   56.163   23.516   \n",
       " DEC '19   4713.500   2891.699  105.294  1821.801  1668.285  153.516  373.172   \n",
       " DEC '20   9497.578   6837.065  154.465  2660.513  2491.606  168.907  295.806   \n",
       " DEC '21  17661.203  13353.491  217.893  4307.712  3849.376  458.336   26.841   \n",
       " DEC '22  17531.587  11854.011  470.334  5677.576  5545.971  131.605   93.824   \n",
       " \n",
       "              7        8        9   ...        20         21        22  \\\n",
       " DEC '12   0.005   10.327  -85.199  ...       NaN        NaN       NaN   \n",
       " DEC '13   0.000   16.724 -103.980  ...  0.162113  14.166667 -1.000000   \n",
       " DEC '14   1.058   24.581 -152.653  ...  0.447524   3.043956  0.000000   \n",
       " DEC '15   1.163   53.124 -176.071  ... -0.048138   0.752717  0.099244   \n",
       " DEC '16     NaN   51.235 -169.673  ... -0.005265  -1.403101 -1.000000   \n",
       " DEC '17  10.053   67.018  -62.664  ... -1.107467   1.044872  0.000000   \n",
       " DEC '18  17.982   97.824  -36.127  ...  3.383625  13.743574  0.788720   \n",
       " DEC '19  21.516  126.959  378.213  ...  1.733401  14.868855  0.196530   \n",
       " DEC '20  56.943  191.803  215.967  ...  0.100257  -0.207320  1.646542   \n",
       " DEC '21  33.124  294.591  157.462  ...  1.713541  -0.909261 -0.418295   \n",
       " DEC '22  36.228  754.518 -565.317  ... -0.712863   2.495548  0.093708   \n",
       " \n",
       "                23         24         25         26         27        28  \\\n",
       " DEC '12       NaN        NaN        NaN        NaN        NaN       NaN   \n",
       " DEC '13  0.619444   0.220437   0.000000   0.226458   0.190025  0.226422   \n",
       " DEC '14  0.469804   0.468100   1.807018   0.474673   0.475288  0.474738   \n",
       " DEC '15  1.161181   0.153407   1.601389   0.166938   0.265925  0.363930   \n",
       " DEC '16 -0.035558  -0.036338  -0.488254  -0.045752  -0.238687 -0.210111   \n",
       " DEC '17  0.308051  -0.630678  -0.922274  -0.633936  -0.894518 -0.668800   \n",
       " DEC '18  0.459668  -0.423481  14.610738  -0.387818  -2.765412 -0.427536   \n",
       " DEC '19  0.297831 -11.468984   0.189596 -10.763764  12.462709 -9.497890   \n",
       " DEC '20  0.510748  -0.428980   0.034333  -0.432395  -0.276843 -0.451341   \n",
       " DEC '21  0.535904  -0.270898  -1.476590  -0.219709   0.030433 -0.250226   \n",
       " DEC '22  1.561239  -4.590180   8.026393  -4.251948  -1.029281 -3.818346   \n",
       " \n",
       "                29  \n",
       " DEC '12       NaN  \n",
       " DEC '13  0.104406  \n",
       " DEC '14  0.363520  \n",
       " DEC '15 -0.140705  \n",
       " DEC '16 -0.116565  \n",
       " DEC '17 -1.614817  \n",
       " DEC '18  1.338224  \n",
       " DEC '19  1.209709  \n",
       " DEC '20  0.249457  \n",
       " DEC '21  1.091180  \n",
       " DEC '22 -0.109859  \n",
       " \n",
       " [11 rows x 30 columns],\n",
       " 12:               0        1       2        3        4       5      6       7   \\\n",
       " DEC '16  124.371   14.219   3.060  110.152  145.985 -35.833 -0.532   0.000   \n",
       " DEC '17  187.727   25.588   4.692  162.139  202.899 -40.760 -0.091   0.000   \n",
       " DEC '18  267.360   43.167   6.192  224.193  296.774 -72.581  1.424   0.000   \n",
       " DEC '19  354.586   60.818   6.880  293.768  380.567 -86.799  5.150   0.000   \n",
       " DEC '20  440.221   77.554  10.633  362.667  398.761 -36.094 -0.641   0.000   \n",
       " DEC '21  541.130  106.396  16.170  434.734  469.601 -34.867 -1.965   6.896   \n",
       " DEC '22  683.191  154.789  22.194  528.402  593.575 -65.173  1.527  19.001   \n",
       " \n",
       "             8       9   ...        20         21        22         23  \\\n",
       " DEC '16  0.000 -36.365  ...       NaN        NaN       NaN        NaN   \n",
       " DEC '17  0.000 -40.851  ...  0.137499  -0.828947  0.000000   0.000000   \n",
       " DEC '18  0.000 -71.157  ...  0.780692 -16.648352  0.000000   0.000000   \n",
       " DEC '19  4.000 -85.649  ...  0.195891   2.616573  0.000000   0.000000   \n",
       " DEC '20  0.339 -37.074  ... -0.584166  -1.124466  0.000000  -0.915250   \n",
       " DEC '21  6.901 -50.629  ... -0.033995   2.065523  0.000000  19.356932   \n",
       " DEC '22  2.642 -85.289  ...  0.869189  -1.777099  1.755365  -0.617157   \n",
       " \n",
       "                24         25        26        27        28        29  \n",
       " DEC '16       NaN        NaN       NaN       NaN       NaN       NaN  \n",
       " DEC '17  0.123360  -0.797153  0.102505  0.073543  0.073375  0.100540  \n",
       " DEC '18  0.741867  12.824561  0.792233  2.068064  2.068359  0.840662  \n",
       " DEC '19  0.203662   4.653130  0.346731 -0.272798 -0.251669  0.203799  \n",
       " DEC '20 -0.567140  -0.576699 -0.568430 -0.580178 -0.589798 -0.681415  \n",
       " DEC '21  0.365620  -1.698604  0.092345 -0.065017  0.037352 -0.265661  \n",
       " DEC '22  0.684588  -2.754302  0.975748  1.063914  0.887876  1.298711  \n",
       " \n",
       " [7 rows x 30 columns],\n",
       " 13:                0         1        2         3         4        5       6   \\\n",
       " DEC '09    25.245    20.505    3.262     4.740    56.135  -51.395   1.544   \n",
       " DEC '10    68.055    39.864    5.313    28.191    84.252  -56.061   0.164   \n",
       " JAN '12   134.427    65.368    9.319    69.059   147.503  -78.444  -0.042   \n",
       " JAN '13   273.657   116.535   17.722   157.122   274.985 -117.863   0.160   \n",
       " JAN '14   468.938   176.810   34.695   292.128   445.410 -153.282   2.069   \n",
       " JAN '15   787.860   264.803   59.205   523.057   738.759 -215.702   0.790   \n",
       " JAN '16  1162.343   374.427   85.939   787.916  1052.578 -264.662   6.669   \n",
       " JAN '17  1573.805   483.545  115.885  1090.260  1443.981 -353.721  11.263   \n",
       " JAN '18  2141.541   629.413  136.974  1512.128  1816.860 -304.732  39.221   \n",
       " JAN '19  2829.192   834.950  198.111  1994.242  2425.514 -431.272  42.028   \n",
       " JAN '20  3621.064  1065.258  343.603  2555.806  3064.178 -508.372  74.882   \n",
       " JAN '21  4299.216  1186.132  378.033  3113.084  3306.463 -193.379  46.721   \n",
       " JAN '22  5147.557  1428.095  429.958  3719.462  3827.153 -107.691  12.337   \n",
       " JAN '23  6198.438  1715.178  456.107  4483.260  4722.840 -239.580  98.867   \n",
       " \n",
       "               7        8        9   ...        20         21         22  \\\n",
       " DEC '09    0.000    0.000  -49.851  ...       NaN        NaN        NaN   \n",
       " DEC '10    0.221    0.000  -56.118  ...  0.090787  -0.893782   0.000000   \n",
       " JAN '12    0.976    0.000  -79.462  ...  0.399262  -1.256098   3.416290   \n",
       " JAN '13    1.363    0.000 -119.066  ...  0.502511  -4.809524   0.396516   \n",
       " JAN '14   19.618    0.000 -170.831  ...  0.300510  11.931250  13.393250   \n",
       " JAN '15   31.060    0.000 -245.972  ...  0.407223  -0.618173   0.583240   \n",
       " JAN '16   31.932   -1.024 -288.901  ...  0.226980   7.441772   0.028075   \n",
       " JAN '17   30.103   12.952 -385.513  ...  0.336501   0.688859  -0.057278   \n",
       " JAN '18   44.549    4.726 -314.786  ... -0.138496   2.482287   0.479886   \n",
       " JAN '19   60.209  -25.701 -423.752  ...  0.415250   0.071569   0.351523   \n",
       " JAN '20   58.685   -9.728 -482.447  ...  0.178773   0.781717  -0.025312   \n",
       " JAN '21   68.806   59.670 -275.134  ... -0.619611  -0.376072   0.172463   \n",
       " JAN '22   16.602 -128.138   16.182  ... -0.443109  -0.735943  -0.758713   \n",
       " JAN '23  102.353   16.884 -259.950  ...  1.224698   7.013861   5.165101   \n",
       " \n",
       "                 23         24         25         26        27         28  \\\n",
       " DEC '09        NaN        NaN        NaN        NaN       NaN        NaN   \n",
       " DEC '10   0.000000   0.125715   0.065934   0.125606  0.125604   0.125533   \n",
       " JAN '12   0.000000   0.415981   0.721649   0.422592  0.422593   0.422539   \n",
       " JAN '13   0.000000   0.498402  -0.257485   0.497518  0.476793   0.476766   \n",
       " JAN '14   0.000000   0.434759  12.532258   0.440480  0.395935   0.400055   \n",
       " JAN '15   0.000000   0.439856   0.197855   0.437502  0.340431   0.336634   \n",
       " JAN '16   0.000000   0.174528  -0.494030   0.169109  0.133055   0.133333   \n",
       " JAN '17 -13.648437   0.334412  -1.800393   0.326923  0.239001   0.267974   \n",
       " JAN '18  -0.635114  -0.183462  -8.906634  -0.165004 -0.192599  -0.201031   \n",
       " JAN '19  -6.438214   0.346159  -1.853636   0.302084  0.315160   0.244710   \n",
       " JAN '20  -0.621493   0.138513  -0.677284   0.149228  0.066310   0.096667   \n",
       " JAN '21  -7.133840  -0.429711  -5.115623  -0.412427 -0.526801  -0.436809   \n",
       " JAN '22  -3.147444  -1.058815  -2.807729  -1.104001 -0.766130  -1.097012   \n",
       " JAN '23  -1.131764 -17.064145  -9.096354 -13.485922  4.865589 -13.449827   \n",
       " \n",
       "                29  \n",
       " DEC '09       NaN  \n",
       " DEC '10  0.054329  \n",
       " JAN '12  0.362123  \n",
       " JAN '13  0.448694  \n",
       " JAN '14  0.184200  \n",
       " JAN '15  0.319681  \n",
       " JAN '16  0.142022  \n",
       " JAN '17  0.330752  \n",
       " JAN '18 -0.294648  \n",
       " JAN '19  0.389865  \n",
       " JAN '20 -0.293325  \n",
       " JAN '21 -2.120684  \n",
       " JAN '22  0.745248  \n",
       " JAN '23 -0.328113  \n",
       " \n",
       " [14 rows x 30 columns],\n",
       " 14:                0        1       2         3         4        5       6   \\\n",
       " JUN '13   148.512   33.160  12.060   115.352   102.233   13.119  -1.444   \n",
       " JUN '14   215.109   38.084  13.316   177.025   155.494   21.531   0.925   \n",
       " JUN '15   319.521   52.972  15.511   266.549   266.132    0.417  -1.092   \n",
       " JUN '16   457.058   75.869  21.926   381.189   387.069   -5.880   0.973   \n",
       " JUN '17   619.936  134.430  61.546   485.506   548.592  -63.086   3.434   \n",
       " JUN '18   880.978  208.914  79.435   672.064   722.063  -49.999   7.134   \n",
       " JUN '19  1210.127  238.376  70.248   971.751  1022.229  -50.478  22.071   \n",
       " JUN '20  1614.173  281.026  97.398  1333.147  1305.239   27.908  11.446   \n",
       " JUN '21  2089.132  346.707  92.848  1742.425  1674.778   67.647  37.948   \n",
       " JUN '22  2802.882  474.886  93.958  2327.996  2421.486  -93.490 -20.776   \n",
       " DEC '22  3180.428  556.379  77.609  2624.049  2808.734 -184.685  20.064   \n",
       " \n",
       "               7        8        9   ...         20        21        22  \\\n",
       " JUN '13    0.272      NaN   11.403  ...        NaN       NaN       NaN   \n",
       " JUN '14    0.228      NaN   22.228  ...   0.641207 -1.640582 -0.161765   \n",
       " JUN '15    0.074      NaN   -0.749  ...  -0.980633 -2.180541 -0.675439   \n",
       " JUN '16    0.000      NaN   -4.907  ... -15.100719 -1.891026 -1.000000   \n",
       " JUN '17    0.000      NaN  -59.652  ...   9.728912  2.529291  0.000000   \n",
       " JUN '18    6.806    8.460  -58.131  ...  -0.207447  1.077461  0.000000   \n",
       " JUN '19   40.241  536.908 -605.556  ...   0.009580  2.093776  4.912577   \n",
       " JUN '20   49.610  335.953 -346.209  ...  -1.552875 -0.481401  0.232822   \n",
       " JUN '21  122.713  617.546 -634.664  ...   1.423929  2.315394  1.473554   \n",
       " JUN '22   25.824  424.482 -564.572  ...  -2.382027 -1.547486 -0.789558   \n",
       " DEC '22   26.264      NaN -209.665  ...   0.975452 -1.965730  0.017038   \n",
       " \n",
       "                 23         24         25         26        27         28  \\\n",
       " JUN '13        NaN        NaN        NaN        NaN       NaN        NaN   \n",
       " JUN '14   0.000000   0.949312   4.056075   0.763962  0.763962   0.800000   \n",
       " JUN '15   0.000000  -1.033696  -3.317930  -0.643083 -0.643079  -0.666667   \n",
       " JUN '16   0.000000   5.551402   0.233386  -0.354539 -0.303847  -0.333333   \n",
       " JUN '17   0.000000  11.156511   0.847845 -10.719643 -9.462348 -10.500000   \n",
       " JUN '18   0.000000  -0.025498  -4.224924   1.668737  1.431384   1.582632   \n",
       " JUN '19  62.464303   9.417092  -0.420173   4.621174  1.359194   4.445690   \n",
       " JUN '20  -0.374282  -0.428279  -0.861375  -0.450059 -0.570080  -0.464037   \n",
       " JUN '21   0.838192   0.833182  12.869741   0.985761  1.241987   0.947214   \n",
       " JUN '22  -0.312631  -0.110440  -0.196250  -0.118037  0.183339  -0.130666   \n",
       " DEC '22  -1.000000  -0.628630   1.939478  -0.421417  0.109714  -0.425796   \n",
       " \n",
       "                  29  \n",
       " JUN '13         NaN  \n",
       " JUN '14    0.383971  \n",
       " JUN '15   -0.542916  \n",
       " JUN '16    0.007408  \n",
       " JUN '17   -1.095974  \n",
       " JUN '18  -20.114286  \n",
       " JUN '19   -0.328373  \n",
       " JUN '20    5.338189  \n",
       " JUN '21    0.280825  \n",
       " JUN '22   -0.997084  \n",
       " DEC '22 -229.794872  \n",
       " \n",
       " [11 rows x 30 columns],\n",
       " 15:               0        1       2        3        4        5      6      7   \\\n",
       " JAN '16   40.751    8.597   0.567   32.154   46.503  -14.349  0.000  0.000   \n",
       " JAN '17   66.964   14.133   0.989   52.831   67.986  -15.155  0.000  0.029   \n",
       " JAN '18  111.253   21.682   4.076   89.571  138.549  -48.978  0.000  0.435   \n",
       " JAN '19  177.722   33.849   7.704  143.873  198.957  -55.084  1.492    NaN   \n",
       " JAN '20  270.882   52.900  21.420  217.982  321.756 -103.774  7.948    NaN   \n",
       " JAN '21  385.513   85.539  29.179  299.974  419.469 -119.495  1.740    NaN   \n",
       " JAN '22  550.832  116.473  36.670  434.359  604.295 -169.936 -0.765  0.000   \n",
       " JAN '23  766.915  165.285  42.924  601.630  829.500 -227.870  8.846  0.000   \n",
       " \n",
       "             8        9   ...        20         21    22         23        24  \\\n",
       " JAN '16    NaN  -14.349  ...       NaN        NaN   NaN        NaN       NaN   \n",
       " JAN '17    NaN  -15.184  ...  0.056171   0.000000   0.0   0.000000  0.058192   \n",
       " JAN '18    NaN  -49.413  ...  2.231805   0.000000  14.0   0.000000  2.254281   \n",
       " JAN '19    NaN  -53.592  ...  0.124668   0.000000  -1.0   0.000000  0.084573   \n",
       " JAN '20    NaN  -95.826  ...  0.883923   4.327078   0.0   0.000000  0.788065   \n",
       " JAN '21  0.977 -118.732  ...  0.151493  -0.781077   0.0   0.000000  0.239037   \n",
       " JAN '22  0.100 -170.801  ...  0.422118  -1.439655   0.0  -0.897646  0.438542   \n",
       " JAN '23 -6.234 -212.790  ...  0.340917 -12.563399   0.0 -63.340000  0.245836   \n",
       " \n",
       "                 25        26        27        28        29  \n",
       " JAN '16        NaN       NaN       NaN       NaN       NaN  \n",
       " JAN '17   0.000000  0.058192  0.058192  0.058205  0.027862  \n",
       " JAN '18   0.000000  2.234062  2.534240  2.533466  2.169702  \n",
       " JAN '19  -1.954397  0.097320  0.215448  0.215491  0.055187  \n",
       " JAN '20  -0.610922  0.780458  0.310096  0.310137  0.738160  \n",
       " JAN '21 -33.921053  0.198447  0.115573  0.122247  0.096680  \n",
       " JAN '22  -1.078870  0.488072  0.437179  0.429216  0.475553  \n",
       " JAN '23   8.625000  0.260332  0.242462  0.217343  0.387796  \n",
       " \n",
       " [8 rows x 30 columns],\n",
       " 16:                 0          1         2          3          4          5   \\\n",
       " MAY '88    282.113     51.241    12.973    230.872    166.977     63.895   \n",
       " MAY '89    583.673    100.987    23.156    482.686    359.726    122.960   \n",
       " MAY '90    970.844    160.426    44.078    810.418    620.623    189.795   \n",
       " MAY '91   1027.949    282.688    70.727    745.261    718.482     26.779   \n",
       " MAY '92   1178.496    296.417    65.778    882.079    768.416    113.663   \n",
       " MAY '93   1502.768    369.676    79.204   1133.092    892.113    240.979   \n",
       " MAY '94   2001.147    538.531   104.563   1462.616   1042.663    419.953   \n",
       " MAY '95   2966.878    779.012   147.772   2187.866   1538.145    649.721   \n",
       " MAY '96   4223.300   1096.013   219.494   3127.287   2171.465    955.822   \n",
       " MAY '97   5684.336   1550.466   264.773   4133.870   2834.085   1299.785   \n",
       " MAY '98   7143.866   2311.642   328.563   4832.224   3420.970   1411.254   \n",
       " MAY '99   8827.252   3152.709   375.384   5674.543   3801.662   1872.881   \n",
       " MAY '00  10130.128   2942.679   390.925   7187.449   4107.289   3080.160   \n",
       " MAY '01  10859.672   2796.040   346.896   8063.632   4286.541   3777.091   \n",
       " MAY '02   9673.000   2406.000   363.000   7267.000   3696.000   3571.000   \n",
       " MAY '03   9475.000   2342.000   327.000   7133.000   3693.000   3440.000   \n",
       " MAY '04  10156.000   2353.000   234.000   7803.000   3885.000   3918.000   \n",
       " MAY '05  11799.000   2870.000   425.000   8929.000   4552.000   4377.000   \n",
       " MAY '06  14380.000   3818.000   806.000  10562.000   5604.000   4958.000   \n",
       " MAY '07  17996.000   5069.000  1127.000  12927.000   6794.000   6133.000   \n",
       " MAY '08  22430.000   6193.000  1480.000  16237.000   8228.000   8009.000   \n",
       " MAY '09  23252.000   6507.000  1976.000  16745.000   8190.000   8555.000   \n",
       " MAY '10  26820.000   7737.000  2271.000  19083.000   9245.000   9838.000   \n",
       " MAY '11  35622.000  10826.000  2796.000  24796.000  12068.000  12728.000   \n",
       " MAY '12  37121.000  10288.000  2916.000  26833.000  12776.000  14057.000   \n",
       " MAY '13  37180.000   9498.000  2931.000  27682.000  13250.000  14432.000   \n",
       " MAY '14  38275.000   9536.000  2908.000  28739.000  13756.000  14983.000   \n",
       " MAY '15  38226.000   9681.000  2861.000  28545.000  14256.000  14289.000   \n",
       " MAY '16  37047.000   9117.000  2509.000  27930.000  14826.000  13104.000   \n",
       " MAY '17  37728.000   8920.000  2451.000  28808.000  15532.000  13276.000   \n",
       " MAY '18  39383.000   9680.000  2785.000  29703.000  15799.000  13904.000   \n",
       " MAY '19  39506.000   9684.000  2919.000  29822.000  15767.000  14055.000   \n",
       " MAY '20  39068.000   9524.000  2968.000  29544.000  15331.000  14213.000   \n",
       " MAY '21  40479.000   9234.000  2916.000  31245.000  15463.000  15782.000   \n",
       " MAY '22  42440.000  10027.000  3122.000  32413.000  16551.000  15862.000   \n",
       " FEB '23  47958.000  15210.000  5353.000  32748.000  18817.000  13931.000   \n",
       " \n",
       "                6         7       8          9   ...        20         21  \\\n",
       " MAY '88     2.624     1.540     NaN     64.979  ...       NaN        NaN   \n",
       " MAY '89     1.603     4.318     NaN    120.245  ...  0.924407  -0.389101   \n",
       " MAY '90    -5.039    12.096     NaN    172.660  ...  0.543551  -4.143481   \n",
       " MAY '91    -7.141    24.008     NaN    -13.242  ... -0.858906   0.417146   \n",
       " MAY '92     1.116    18.649     NaN     96.130  ...  3.244483  -1.156281   \n",
       " MAY '93    10.023     8.961     NaN    218.041  ...  1.120118   7.981183   \n",
       " MAY '94    10.381     6.871     NaN    423.463  ...  0.742695   0.035718   \n",
       " MAY '95    16.231     6.970     NaN    658.982  ...  0.547128   0.563530   \n",
       " MAY '96    21.251     6.632     NaN    919.510  ...  0.471127   0.309285   \n",
       " MAY '97    27.348     6.806     NaN   1283.527  ...  0.359861   0.286904   \n",
       " MAY '98   100.277    16.658     NaN   1327.819  ...  0.085760   2.666703   \n",
       " MAY '99   130.621    21.424     NaN   1982.078  ...  0.327104   0.302602   \n",
       " MAY '00  7062.168    18.894     NaN  10123.434  ...  0.644611  53.066100   \n",
       " MAY '01   218.138    23.999     NaN   3971.230  ...  0.226265  -0.969112   \n",
       " MAY '02   137.000    20.000   244.0   3444.000  ... -0.054563  -0.371957   \n",
       " MAY '03   112.000    16.000   111.0   3425.000  ... -0.036684  -0.182482   \n",
       " MAY '04   139.000    21.000    54.0   3982.000  ...  0.138953   0.241071   \n",
       " MAY '05   193.400   135.000   342.4   4093.000  ...  0.117152   0.391367   \n",
       " MAY '06   260.000   169.000   198.0   4851.000  ...  0.132739   0.344364   \n",
       " MAY '07   398.000   343.000   131.0   6057.000  ...  0.236991   0.530769   \n",
       " MAY '08   421.000   394.000   142.0   7894.000  ...  0.305886   0.057789   \n",
       " MAY '09   167.000   583.000   221.0   7918.000  ...  0.068173  -0.603325   \n",
       " MAY '10    23.000   713.000   810.0   8338.000  ...  0.149971  -0.862275   \n",
       " MAY '11   322.000   808.000   734.0  11508.000  ...  0.293759  13.000000   \n",
       " MAY '12    98.000   766.000   308.0  13081.000  ...  0.104415  -0.695652   \n",
       " MAY '13   187.000   797.000  -188.0  14010.000  ...  0.026677   0.908163   \n",
       " MAY '14    26.000   914.000   293.0  13802.000  ...  0.038179  -0.860963   \n",
       " MAY '15   159.000  1143.000   358.0  12947.000  ... -0.046319   5.115385   \n",
       " MAY '16   324.000  1467.000   403.0  11558.000  ... -0.082931   1.037736   \n",
       " MAY '17   723.000  1798.000   566.0  11635.000  ...  0.013126   1.231481   \n",
       " MAY '18  1320.000  2025.000   640.0  12559.000  ...  0.047303   0.825726   \n",
       " MAY '19   967.000  2082.000   520.0  12420.000  ...  0.010860  -0.267424   \n",
       " MAY '20   330.000  1995.000   321.0  12227.000  ...  0.011242  -0.658738   \n",
       " MAY '21   446.000  2496.000   553.0  13179.000  ...  0.110392   0.351515   \n",
       " MAY '22  -338.000  2755.000  4936.0   7833.000  ...  0.005069  -1.757848   \n",
       " FEB '23  -386.000  3255.000   474.0   9816.000  ... -0.121737   0.142012   \n",
       " \n",
       "                22        23        24         25        26        27  \\\n",
       " MAY '88       NaN       NaN       NaN        NaN       NaN       NaN   \n",
       " MAY '89  1.803896  0.000000  0.850521   0.741683  0.906590  0.805950   \n",
       " MAY '90  1.801297  0.000000  0.435902   0.435848  0.435927  0.335115   \n",
       " MAY '91  0.984788  0.000000 -1.076694  -1.015222 -1.105621 -1.104639   \n",
       " MAY '92 -0.223217  0.000000 -8.259477 -42.165279 -5.960084 -5.787579   \n",
       " MAY '93 -0.519492  0.000000  1.268189   1.204362  1.304113  0.122861   \n",
       " MAY '94 -0.233233  0.000000  0.942126   0.831134  1.001891  2.966262   \n",
       " MAY '95  0.014408  0.000000  0.556174   0.556171  0.556175  0.556177   \n",
       " MAY '96 -0.048494  0.000000  0.395349   0.454176  0.366375  0.355650   \n",
       " MAY '97  0.026236  0.000000  0.395882   0.461179  0.361654  0.357196   \n",
       " MAY '98  1.447546  0.000000  0.034508   0.112654 -0.009449  0.000029   \n",
       " MAY '99  0.286109  0.000000  0.492732   0.346601  0.585063  0.601468   \n",
       " MAY '00 -0.118092  0.000000  4.107485   4.527258  3.882159  1.417084   \n",
       " MAY '01  0.270192  0.000000 -0.607719  -0.631495 -0.593270 -0.168365   \n",
       " MAY '02 -0.166632  0.000000 -0.132762  -0.160363 -0.131622 -0.036035   \n",
       " MAY '03 -0.200000 -0.545082 -0.005517  -0.055743  0.037320  0.045589   \n",
       " MAY '04  0.312500 -0.513514  0.162628   0.130590  0.162115  0.159795   \n",
       " MAY '05  5.428571  5.340741  0.027875  -0.078323  0.076464  0.170533   \n",
       " MAY '06  0.251852 -0.421729  0.185194   0.226609  0.171518  0.114100   \n",
       " MAY '07  1.029586 -0.338384  0.248609   0.198041  0.264123  0.244634   \n",
       " MAY '08  0.148688  0.083969  0.303285   0.351051  0.291764  0.297248   \n",
       " MAY '09  0.479695  0.556338  0.003040  -0.031128  0.013041  0.042384   \n",
       " MAY '10  0.222985  2.665158  0.053044  -0.059349  0.096907  0.179134   \n",
       " MAY '11  0.133240 -0.093827  0.380187   0.358634  0.393154  0.337454   \n",
       " MAY '12 -0.051980 -0.580381  0.136688   0.040852  0.167778  0.132642   \n",
       " MAY '13  0.040470 -1.610390  0.071019  -0.002684  0.094580  0.113379   \n",
       " MAY '14  0.146801 -2.558511 -0.014847  -0.075345  0.002746  0.087874   \n",
       " MAY '15  0.250547  0.221843 -0.061948   0.053474 -0.092834 -0.066574   \n",
       " MAY '16  0.283465  0.125698 -0.107284  -0.122583 -0.104347 -0.057235   \n",
       " MAY '17  0.225631  0.404467  0.006662  -0.141283  0.048759  0.081799   \n",
       " MAY '18  0.126251  0.130742  0.079416   3.049954 -0.615747 -0.587409   \n",
       " MAY '19  0.028148 -0.187500 -0.011068  -0.865905  2.089769  2.221569   \n",
       " MAY '20 -0.041787 -0.382692 -0.015539   0.627004 -0.085536  0.025353   \n",
       " MAY '21  0.251128  0.722741  0.077860  -1.387448  0.356290  0.487029   \n",
       " MAY '22  0.103766  7.925859 -0.405645  -2.247657 -0.511349 -0.219288   \n",
       " FEB '23  0.181488 -0.903971  0.253160   0.360515  0.246688 -0.141075   \n",
       " \n",
       "                28        29  \n",
       " MAY '88       NaN       NaN  \n",
       " MAY '89  0.806818  0.900869  \n",
       " MAY '90  0.333333  0.600598  \n",
       " MAY '91 -1.103774 -0.583081  \n",
       " MAY '92 -5.818182  0.840307  \n",
       " MAY '93  1.264151  0.784336  \n",
       " MAY '94  0.975000  0.638176  \n",
       " MAY '95  0.563291  0.520436  \n",
       " MAY '96  0.349528  0.473763  \n",
       " MAY '97  0.356000  0.331181  \n",
       " MAY '98  0.504425  0.112018  \n",
       " MAY '99  0.507353  0.292242  \n",
       " MAY '00  0.707317  0.543895  \n",
       " MAY '01 -0.161905  0.188097  \n",
       " MAY '02 -0.113636 -0.046069  \n",
       " MAY '03  0.102564 -0.042450  \n",
       " MAY '04  0.162791  0.102203  \n",
       " MAY '05  0.100000  0.156551  \n",
       " MAY '06  0.163636  0.200333  \n",
       " MAY '07  0.265625  0.259542  \n",
       " MAY '08  0.308642  0.307025  \n",
       " MAY '09  0.028302  0.109811  \n",
       " MAY '10  0.110092  0.149843  \n",
       " MAY '11  0.380165  0.282022  \n",
       " MAY '12  0.173653  0.093339  \n",
       " MAY '13  0.153061  0.022978  \n",
       " MAY '14  0.053097  0.030409  \n",
       " MAY '15 -0.071429 -0.041417  \n",
       " MAY '16 -0.063348 -0.089621  \n",
       " MAY '17  0.067633  0.007302  \n",
       " MAY '18 -0.617014  0.061169  \n",
       " MAY '19  2.508979  0.017077  \n",
       " MAY '20  0.035960  0.012195  \n",
       " MAY '21  0.478354  0.088295  \n",
       " MAY '22 -0.469947  0.015296  \n",
       " FEB '23  0.262339  0.015803  \n",
       " \n",
       " [36 rows x 30 columns],\n",
       " 17:                0         1        2         3        4        5       6   \\\n",
       " DEC '03   381.700   245.200    0.000   136.500   69.200   67.300  17.600   \n",
       " DEC '04   429.135   265.532   24.173   163.603   74.344   89.259   5.874   \n",
       " DEC '05   491.894   354.521   79.831   137.373  113.921   23.452  -2.153   \n",
       " DEC '06   613.047   409.400   77.991   203.647  152.399   51.248  -3.893   \n",
       " DEC '07   822.684   562.571   85.608   260.113  221.150   38.963  55.477   \n",
       " DEC '08  1040.847   666.936   92.066   373.911  243.341  130.570  20.875   \n",
       " DEC '09  1126.716   665.807   83.556   460.909  244.388  216.521  12.802   \n",
       " DEC '10  1265.115   759.350   79.164   505.765  259.003  246.762   3.507   \n",
       " DEC '11  1609.955  1005.636   80.536   604.319  342.348  261.971  77.385   \n",
       " DEC '12  1906.403  1165.667   80.964   740.736  441.448  299.288  26.086   \n",
       " DEC '13  2124.449  1288.189   76.460   836.260  459.793  376.467 -13.242   \n",
       " DEC '14  2283.739  1379.684   81.677   904.055  564.650  339.405 -56.926   \n",
       " DEC '15  2447.377  1486.410   85.300   960.967  587.193  373.774 -38.652   \n",
       " DEC '16  2557.897  1575.936   81.736   981.961  639.220  342.741   3.845   \n",
       " DEC '17  2731.071  1765.528   93.188   965.543  684.736  280.807  74.296   \n",
       " DEC '18  3001.506  1973.872  103.492  1027.634  684.514  343.120  78.407   \n",
       " DEC '19  3513.761  2343.702  128.330  1170.059  778.314  391.745  70.467   \n",
       " DEC '20  3704.945  2441.532  160.199  1263.413  785.933  477.480  12.715   \n",
       " DEC '21  4020.857  2659.855  151.436  1361.002  867.550  493.452  29.322   \n",
       " DEC '22  4367.586  2868.773  116.741  1498.813  937.237  561.576  44.484   \n",
       " \n",
       "              7       8        9   ...        20         21        22  \\\n",
       " DEC '03     NaN     NaN   84.900  ...       NaN        NaN       NaN   \n",
       " DEC '04   4.976     NaN   90.157  ...  0.326285  -0.666250  0.000000   \n",
       " DEC '05  10.592     NaN   10.707  ... -0.737259  -1.366530  1.128617   \n",
       " DEC '06  13.433     NaN   33.922  ...  1.185229   0.808175  0.268221   \n",
       " DEC '07  14.114  -1.027   81.353  ... -0.239717 -15.250450  0.050696   \n",
       " DEC '08   8.465  -0.444  143.424  ...  2.351128  -0.623718 -0.400241   \n",
       " DEC '09   4.332  64.567  160.424  ...  0.658275  -0.386731 -0.488246   \n",
       " DEC '10   2.729  64.306  183.234  ...  0.139668  -0.726058 -0.370037   \n",
       " DEC '11   9.213  68.411  261.732  ...  0.061634  21.065868  2.375962   \n",
       " DEC '12  28.121  34.244  263.009  ...  0.142447  -0.662906  2.052317   \n",
       " DEC '13  38.876  18.198  306.151  ...  0.257875  -1.507629  0.382454   \n",
       " DEC '14  33.800  -0.911  249.590  ... -0.098447   3.298897 -0.130569   \n",
       " DEC '15  29.828   3.540  301.754  ...  0.101263  -0.321013 -0.117515   \n",
       " DEC '16  21.761  -4.820  329.645  ... -0.083026  -1.099477 -0.270451   \n",
       " DEC '17  39.855  -5.335  320.583  ... -0.180702  18.322757  0.831488   \n",
       " DEC '18  52.293   7.213  362.021  ...  0.221907   0.055333  0.312081   \n",
       " DEC '19  55.231   7.564  399.417  ...  0.141714  -0.101266  0.056183   \n",
       " DEC '20  51.460  38.258  400.477  ...  0.218854  -0.819561 -0.068277   \n",
       " DEC '21  50.419 -10.774  483.129  ...  0.033451   1.306095 -0.020229   \n",
       " DEC '22  57.518  83.306  465.236  ...  0.138056   0.517086  0.140800   \n",
       " \n",
       "                  23        24        25        26        27        28  \\\n",
       " DEC '03         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       " DEC '04    0.000000  0.061920  0.022424  0.065249  0.000000  0.000000   \n",
       " DEC '05    0.000000 -0.881241 -1.947985 -0.794938  0.000000  0.000000   \n",
       " DEC '06    0.000000  2.168208 -0.085509  1.325304  0.000000  0.000000   \n",
       " DEC '07    0.000000  1.398237 -3.827863 -0.373227 -3.266802 -3.343750   \n",
       " DEC '08   -0.567673  0.762984 -0.466663  4.020098  3.923840  3.750000   \n",
       " DEC '09 -146.421171  0.118530  1.886320  0.017261  0.371675  0.017544   \n",
       " DEC '10   -0.004042  0.142186  0.343085  0.116888  0.062169  0.086207   \n",
       " DEC '11    0.063835  0.428403  1.065784  0.296193  0.232012  0.285714   \n",
       " DEC '12   -0.499437  0.004879  0.109870 -0.032980 -0.141245 -0.037037   \n",
       " DEC '13   -0.468578  0.164032 -0.093332  0.288981  0.167520  0.243590   \n",
       " DEC '14   -1.050060 -0.184749 -0.192419 -0.164180 -0.173619 -0.123711   \n",
       " DEC '15   -4.885840  0.208999  0.078685  0.249034  0.300948  0.282353   \n",
       " DEC '16   -2.361582  0.092430  0.002599  0.124541  0.146290  0.174312   \n",
       " DEC '17    0.106846 -0.027490 -0.037940 -0.024373  0.038598  0.043125   \n",
       " DEC '18   -2.352015  0.129258  0.351863  0.071863  0.124276  0.088901   \n",
       " DEC '19    0.048662  0.103298  0.170536  0.081065  0.073958  0.074489   \n",
       " DEC '20    4.057906  0.002654 -0.024700  0.011135  0.076794  0.007938   \n",
       " DEC '21   -1.281614  0.206384  0.232969  0.198433  0.095915  0.215928   \n",
       " DEC '22   -8.732133 -0.037036 -0.016265 -0.043427  0.167122 -0.018646   \n",
       " \n",
       "                29  \n",
       " DEC '03       NaN  \n",
       " DEC '04  0.000000  \n",
       " DEC '05 -0.089472  \n",
       " DEC '06  0.251310  \n",
       " DEC '07 -0.036119  \n",
       " DEC '08  0.787222  \n",
       " DEC '09  0.347837  \n",
       " DEC '10  0.086141  \n",
       " DEC '11  0.050874  \n",
       " DEC '12  0.110202  \n",
       " DEC '13  0.191123  \n",
       " DEC '14 -0.070309  \n",
       " DEC '15  0.090225  \n",
       " DEC '16 -0.075363  \n",
       " DEC '17 -0.118928  \n",
       " DEC '18  0.194166  \n",
       " DEC '19  0.164490  \n",
       " DEC '20  0.226129  \n",
       " DEC '21  0.011305  \n",
       " DEC '22  0.051837  \n",
       " \n",
       " [20 rows x 30 columns],\n",
       " 18:                 0         1         2          3         4         5   \\\n",
       " DEC '04    218.756    45.436    30.188    173.320   122.913    50.407   \n",
       " DEC '05    387.074    65.192    39.461    321.882   228.287    93.595   \n",
       " DEC '06    703.904   123.382    66.573    580.522   456.183   124.339   \n",
       " DEC '07   1325.811   223.174   104.027   1102.637   867.296   235.341   \n",
       " DEC '08   1881.027   310.305   158.628   1570.722  1251.597   319.125   \n",
       " DEC '09   2023.937   359.728   198.486   1664.209  1444.914   219.295   \n",
       " DEC '10   2857.343   493.715   260.551   2363.628  1935.635   427.993   \n",
       " DEC '11   3767.096   621.987   315.871   3145.109  2409.938   735.171   \n",
       " DEC '12   4605.047   721.323   354.868   3883.724  3007.981   875.743   \n",
       " DEC '13   5207.000   730.000   337.000   4477.000  3316.000  1161.000   \n",
       " DEC '14   6035.000   917.000   345.000   5118.000  3934.000  1184.000   \n",
       " DEC '15   6647.000  1018.000   335.000   5629.000  4333.000  1296.000   \n",
       " DEC '16   7093.000  1053.000   345.000   6040.000  4549.000  1491.000   \n",
       " JAN '18   7862.000  1141.000   332.000   6721.000  4915.000  1806.000   \n",
       " JAN '19   9613.000  1552.000   458.000   8061.000  6249.000  1812.000   \n",
       " JAN '20  10811.000  1799.000   534.000   9012.000  7255.000  1757.000   \n",
       " JAN '21  11767.000  2140.000   581.000   9627.000  7434.000  2193.000   \n",
       " JAN '22  12851.000  2364.000   579.000  10487.000  8099.000  2388.000   \n",
       " JAN '23  13350.000  2553.000  1234.000  10797.000  8767.000  2030.000   \n",
       " \n",
       "               6        7      8         9   ...        20         21  \\\n",
       " DEC '04   -0.057    0.000   15.2    35.150  ...       NaN        NaN   \n",
       " DEC '05    1.745    0.000    0.0    95.340  ...  0.856786 -31.614035   \n",
       " DEC '06    1.908    0.000    3.7   122.547  ...  0.328479   0.093410   \n",
       " DEC '07   31.694   26.557    0.0   240.478  ...  0.892737  15.611111   \n",
       " DEC '08   25.360   18.600    6.6   319.285  ...  0.356011  -0.199849   \n",
       " DEC '09   17.854    6.500    7.2   223.449  ... -0.312824  -0.295978   \n",
       " DEC '10   16.351    4.069   23.9   416.375  ...  0.951677  -0.084183   \n",
       " DEC '11   63.148    3.906    0.0   794.413  ...  0.717717   2.862027   \n",
       " DEC '12   25.825    4.654    3.8   893.114  ...  0.191210  -0.591040   \n",
       " DEC '13   71.000    4.000   81.0  1147.000  ...  0.325731   1.749274   \n",
       " DEC '14   -3.000   24.000  109.0  1048.000  ...  0.019811  -1.042254   \n",
       " DEC '15   42.000   26.000   99.0  1213.000  ...  0.094595 -15.000000   \n",
       " DEC '16   66.000   26.000   58.0  1473.000  ...  0.150463   0.571429   \n",
       " JAN '18  146.000   74.000   64.0  1814.000  ...  0.211268   1.212121   \n",
       " JAN '19  187.000  134.000   36.0  1829.000  ...  0.003322   0.280822   \n",
       " JAN '20  109.000  149.000  279.0  1438.000  ... -0.030353  -0.417112   \n",
       " JAN '21   57.000  204.000 -336.0  2382.000  ...  0.248150  -0.477064   \n",
       " JAN '22  -29.000  252.000   22.0  2085.000  ...  0.088919  -1.508772   \n",
       " JAN '23   68.000  304.000    2.0  1792.000  ... -0.149916  -3.344828   \n",
       " \n",
       "                22         23        24         25        26        27  \\\n",
       " DEC '04       NaN        NaN       NaN        NaN       NaN       NaN   \n",
       " DEC '05  0.000000  -1.000000  1.712376   0.555066  2.979203  0.000000   \n",
       " DEC '06  0.000000   0.000000  0.285368   0.289410  0.283639  0.325470   \n",
       " DEC '07  0.000000  -1.000000  0.962333  -0.393435  1.544910  1.573900   \n",
       " DEC '08 -0.299620   0.000000  0.327710   0.304865  0.330049  0.221966   \n",
       " DEC '09 -0.650538   0.090909 -0.300158  -0.096083 -0.320663 -0.318657   \n",
       " DEC '10 -0.374000   2.319444  0.863401   1.236575  0.813509  0.747587   \n",
       " DEC '11 -0.040059  -1.000000  0.907927   0.195823  1.025341  0.897570   \n",
       " DEC '12  0.191500   0.000000  0.124244   1.091633  0.030066  0.028443   \n",
       " DEC '13 -0.140524  20.315789  0.284271  -0.097767  0.359793  0.432570   \n",
       " DEC '14  5.000000   0.345679 -0.086312   0.218045 -0.126233 -0.103514   \n",
       " DEC '15  0.083333  -0.091743  0.157443   0.333333  0.125282  0.128769   \n",
       " DEC '16  0.000000  -0.414141  0.214345   0.328704  0.189569  0.157259   \n",
       " JAN '18  1.846154   0.103448  0.231500   3.024390 -0.444351 -0.411469   \n",
       " JAN '19  0.810811  -0.437500  0.008269  -0.793074  1.503794  1.336346   \n",
       " JAN '20  0.111940   6.750000 -0.213778 -21.577406  2.886061  2.906120   \n",
       " JAN '21  0.369128  -2.204301  0.656467  -1.065880 -0.679039 -0.722823   \n",
       " JAN '22  0.235294  -1.065476 -0.124685  -0.182099 -0.115646  0.008929   \n",
       " JAN '23  0.206349  -0.909091 -0.140528   0.803774 -0.278022 -0.289150   \n",
       " \n",
       "                28        29  \n",
       " DEC '04       NaN       NaN  \n",
       " DEC '05  0.000000  0.650921  \n",
       " DEC '06  0.150000  0.434824  \n",
       " DEC '07  1.652174  0.777615  \n",
       " DEC '08  0.196721  0.407773  \n",
       " DEC '09 -0.328767 -0.125529  \n",
       " DEC '10  0.714286  0.648098  \n",
       " DEC '11  1.000000  0.526470  \n",
       " DEC '12  0.023810  0.170849  \n",
       " DEC '13  0.360465  0.217281  \n",
       " DEC '14 -0.128205  0.020694  \n",
       " DEC '15  0.147059  0.066710  \n",
       " DEC '16  0.195385  0.125690  \n",
       " JAN '18 -0.430073  0.164488  \n",
       " JAN '19  1.457659  0.061740  \n",
       " JAN '20  2.848571  0.009251  \n",
       " JAN '21 -0.677525  0.210825  \n",
       " JAN '22 -0.113871  0.069575  \n",
       " JAN '23 -0.283907  0.100101  \n",
       " \n",
       " [19 rows x 30 columns],\n",
       " 19:                0         1        2         3         4        5       6   \\\n",
       " JUL '09    13.352     6.276    1.180     7.076    26.116  -19.040   0.047   \n",
       " JUL '10    48.782    15.634    1.123    33.148    47.805  -14.657  -0.420   \n",
       " JUL '11   118.597    32.273    2.189    86.324    96.728  -10.404  -1.648   \n",
       " JUL '12   255.138    70.553    6.134   184.585   180.694    3.891  -0.134   \n",
       " JUL '13   396.107   109.756    9.911   286.351   304.972  -18.621  -0.035   \n",
       " JUL '14   598.179   159.628   16.931   438.551   497.025  -58.474   0.929   \n",
       " JUL '15   928.052   251.499   28.200   676.553   810.089 -133.536   0.284   \n",
       " JUL '16  1378.500   370.000   42.500  1008.500  1165.800 -157.300   8.400   \n",
       " JUL '17  1761.600   476.600   58.400  1285.000  1443.900 -158.900  10.200   \n",
       " JUL '18  2273.600   645.100   91.000  1628.500  1691.600  -63.100  28.500   \n",
       " JUL '19  2899.600   808.400  139.800  2091.200  2138.300  -47.100  66.000   \n",
       " JUL '20  3408.400  1253.900  507.900  2154.500  2336.600 -182.100  35.900   \n",
       " JUL '21  4256.100  1274.900  304.900  2981.200  3285.300 -304.100   2.400   \n",
       " JUL '22  5501.500  1718.700  337.000  3782.800  3971.600 -188.800   9.000   \n",
       " JAN '23  6155.700  1950.000  427.500  4205.700  4182.800   22.900  88.100   \n",
       " \n",
       "               7        8        9   ...        20         21         22  \\\n",
       " JUL '09    0.000      NaN  -18.993  ...       NaN        NaN        NaN   \n",
       " JUL '10    0.000    6.000  -21.077  ... -0.230200  -9.936170   0.000000   \n",
       " JUL '11    0.000      NaN  -12.052  ... -0.290169   2.923810   0.000000   \n",
       " JUL '12    0.000    0.958    2.799  ... -1.373991  -0.918689   0.000000   \n",
       " JUL '13    0.000      NaN  -18.656  ... -5.785659  -0.738806   0.000000   \n",
       " JUL '14    1.883  162.732 -222.160  ...  2.140218 -27.542857   0.000000   \n",
       " JUL '15   22.325    0.000 -155.577  ...  1.283682  -0.694295  10.856081   \n",
       " JUL '16   23.400      NaN -172.300  ...  0.177960  28.577465   0.048152   \n",
       " JUL '17   24.500   20.900 -194.100  ...  0.010172   0.214286   0.047009   \n",
       " JUL '18   29.600   41.100 -105.300  ... -0.602895   1.794118   0.208163   \n",
       " JUL '19   83.900    9.600  -74.600  ... -0.253566   1.315789   1.834459   \n",
       " JUL '20   88.700   -3.100 -231.800  ...  2.866242  -0.456061   0.057211   \n",
       " JUL '21  163.300    0.000 -465.000  ...  0.669962  -0.933148   0.841037   \n",
       " JUL '22   27.400    0.000 -207.200  ... -0.379152   2.750000  -0.832211   \n",
       " JAN '23   27.400    0.000   83.600  ... -1.121292   8.788889   0.000000   \n",
       " \n",
       "                23         24        25        26         27        28  \\\n",
       " JUL '09       NaN        NaN       NaN       NaN        NaN       NaN   \n",
       " JUL '10  0.000000   0.109725  3.666667  0.111971  -0.109022  0.112513   \n",
       " JUL '11 -1.000000  -0.428192  7.500000 -0.407183  -0.260148 -0.407372   \n",
       " JUL '12  0.000000  -1.232244  3.331933 -1.000000  -1.182182 -1.000000   \n",
       " JUL '13 -1.000000  -7.665238  4.135790  0.000000 -13.425720  0.000000   \n",
       " JUL '14  0.000000  10.908233 -0.594712  6.743008   2.557507  6.094906   \n",
       " JUL '15 -1.000000  -0.299707  1.191286 -0.271448   0.334370 -0.337759   \n",
       " JUL '16  0.000000   0.107490  1.169059  0.168006   0.094507  0.094163   \n",
       " JUL '17  0.000000   0.126524  0.102941  0.124027   0.007615  0.081444   \n",
       " JUL '18  0.966507  -0.457496 -0.248889 -0.435826  -0.542955 -0.442450   \n",
       " JUL '19 -0.766423  -0.291548 -0.568047 -0.329787  -0.219176 -0.349617   \n",
       " JUL '20 -1.322917   2.107239  3.821918  2.260073   2.491664  2.179301   \n",
       " JUL '21 -1.000000   1.006040 -0.036932  0.868539   0.863090  0.878171   \n",
       " JUL '22  0.000000  -0.554409  0.764012 -0.464823  -0.476233 -0.476204   \n",
       " JAN '23  0.000000  -1.403475 -0.175585 -1.128464  -1.114479 -1.084219   \n",
       " \n",
       "                  29  \n",
       " JUL '09         NaN  \n",
       " JUL '10   -0.242217  \n",
       " JUL '11   -0.393010  \n",
       " JUL '12   -2.220329  \n",
       " JUL '13   -1.868828  \n",
       " JUL '14    3.769575  \n",
       " JUL '15    1.535590  \n",
       " JUL '16    0.089846  \n",
       " JUL '17   -0.124564  \n",
       " JUL '18   -1.277612  \n",
       " JUL '19    2.322581  \n",
       " JUL '20    2.514563  \n",
       " JUL '21   -0.997545  \n",
       " JUL '22  184.250000  \n",
       " JAN '23    2.039136  \n",
       " \n",
       " [15 rows x 30 columns],\n",
       " 20:                0        1        2         3         4        5       6   \\\n",
       " JUL '13    30.533   26.604    2.626     3.929    48.529    -44.6  -0.054   \n",
       " JUL '14   127.127   60.912   11.582    66.215   144.534  -78.319  -5.076   \n",
       " JUL '15   241.432  100.959   16.567   140.473   259.238 -118.765 -11.994   \n",
       " JUL '16   444.928  170.787   26.408   274.141   439.158 -165.017   3.014   \n",
       " JUL '17   845.903  328.246   38.399   517.657   864.142 -346.485 -26.377   \n",
       " JUL '18  1155.457  386.944   50.302   768.513  1050.344 -281.831   5.379   \n",
       " JUL '19  1236.143  306.656   77.612   929.487   1527.96 -598.473  14.294   \n",
       " JUL '20  1307.682  288.755  124.147  1018.927  1844.846 -825.919   5.012   \n",
       " JUL '21  1394.364  294.497   129.13  1099.867  1759.229 -659.362  -5.794   \n",
       " JUL '22  1580.796   323.56  124.857  1257.236  1702.883 -445.647   2.853   \n",
       " \n",
       "              7        8         9   ...        20        21        22  \\\n",
       " JUL '13       0        0   -44.654  ...       NaN       NaN             \n",
       " JUL '14     0.0      0.0   -83.395  ...  0.756031      93.0       0.0   \n",
       " JUL '15     0.0   -6.176  -124.583  ...  0.516426  1.362884       0.0   \n",
       " JUL '16     2.3    2.004  -166.307  ...  0.389441 -1.251292       0.0   \n",
       " JUL '17     0.0    1.924  -374.786  ...  1.099693 -9.751493      -1.0   \n",
       " JUL '18  14.685   -1.423  -289.714  ...   -0.1866 -1.203928       0.0   \n",
       " JUL '19  29.313   -0.432   -613.06  ...  1.123517  1.657371  0.996118   \n",
       " JUL '20  31.312    3.002  -855.221  ...  0.380044 -0.649363  0.068195   \n",
       " JUL '21  79.932  270.685 -1015.773  ... -0.201663 -2.156026  1.552759   \n",
       " JUL '22  60.734  274.746  -778.274  ... -0.324124 -1.492406 -0.240179   \n",
       " \n",
       "                 23        24        25        26        27        28        29  \n",
       " JUL '13        NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       " JUL '14        0.0  0.867582       6.6  0.877833  0.877835  0.877767   0.58996  \n",
       " JUL '15        0.0  0.493891  1.539474  0.501458  0.552923  0.501328  0.531354  \n",
       " JUL '16  -1.324482  0.334909  0.419689  0.335947   0.28092  0.335914  0.356279  \n",
       " JUL '17   -0.03992  1.253579  1.213504  1.253058  1.461691  1.450737  1.222698  \n",
       " JUL '18  -1.739605 -0.226988  0.534831 -0.217252 -0.383767 -0.388514 -0.248492  \n",
       " JUL '19  -0.696416  1.116087  0.090238  1.090379  0.889364  0.895746  1.249658  \n",
       " JUL '20  -7.949074  0.395004  1.175391  0.405204  0.302644  0.306444  0.347331  \n",
       " JUL '21  89.168221  0.187732   0.04671  0.184878 -0.085096  0.117404 -0.244438  \n",
       " JUL '22   0.015003 -0.233811   0.04203 -0.228881 -0.329238 -0.278014 -0.395001  \n",
       " \n",
       " [10 rows x 30 columns],\n",
       " 21:                0         1        2         3         4        5        6   \\\n",
       " DEC '00    89.766   737.611  711.694  -647.845   250.365 -898.210   22.912   \n",
       " DEC '01   163.214   437.959  329.624  -274.745   259.637 -534.382   87.079   \n",
       " DEC '02   144.976    97.234   89.439    47.742   184.169 -135.448   -3.052   \n",
       " DEC '03   161.259    66.349   49.749    94.910   117.586  -22.676   12.744   \n",
       " DEC '04   210.015    47.107   18.719   162.908   114.794   48.114    2.632   \n",
       " DEC '05   283.115    54.008   12.753   229.107   145.493   83.614    2.729   \n",
       " DEC '06   428.672    92.085   23.585   336.587   237.981   98.606   18.054   \n",
       " DEC '07   636.406   190.639   71.895   445.767   304.417  141.350   25.874   \n",
       " DEC '08   790.924   251.390   98.080   539.534   328.061  211.473   25.092   \n",
       " DEC '09   859.773   291.932  122.494   567.841   347.407  220.434   16.222   \n",
       " DEC '10  1023.586   350.645  143.242   672.941   426.179  246.762   10.091   \n",
       " DEC '11  1158.538   422.521  167.878   736.017   446.802  289.215   16.546   \n",
       " DEC '12  1373.947   491.074  204.163   882.873   572.993  309.880    7.104   \n",
       " DEC '13  1577.922   568.725  184.431  1009.197   600.586  408.611    5.586   \n",
       " DEC '14  1963.874   683.053  247.406  1280.821   785.613  495.208    6.005   \n",
       " DEC '15  2197.448   807.249  299.563  1390.199   918.135  472.064   57.699   \n",
       " DEC '16  2340.049   901.423  334.302  1438.626   966.813  471.813  111.890   \n",
       " DEC '17  2489.035   982.869  372.313  1506.166  1110.839  395.327  193.342   \n",
       " DEC '18  2714.474  1066.810  434.520  1647.664  1237.968  409.696  231.792   \n",
       " DEC '19  2893.617  1104.792  440.674  1788.825  1210.834  577.991  203.427   \n",
       " DEC '20  3198.149  1257.583  478.389  1940.566  1238.892  701.674  307.368   \n",
       " DEC '21  3461.223  1398.909  550.632  2062.314  1255.112  807.202  304.205   \n",
       " DEC '22  3616.654  1518.045  592.754  2098.609  1379.755  718.854  221.025   \n",
       " \n",
       "              7         8         9   ...        20        21        22  \\\n",
       " DEC '00   8.928     1.372  -885.598  ...       NaN       NaN       NaN   \n",
       " DEC '01  18.859  1968.288 -2434.450  ... -0.405059  2.800585  1.112343   \n",
       " DEC '02  18.357    46.109  -203.945  ... -0.746533 -1.035049 -0.026619   \n",
       " DEC '03  18.324     0.396   -28.652  ... -0.832585 -5.175623 -0.001798   \n",
       " DEC '04  10.213     5.397    35.136  ... -3.121803 -0.793471 -0.442644   \n",
       " DEC '05   5.330    10.609    70.404  ...  0.737831  0.036854 -0.478116   \n",
       " DEC '06   3.171    15.020    98.469  ...  0.179300  5.615610 -0.405066   \n",
       " DEC '07   3.086    -4.067   168.205  ...  0.433483  0.433145 -0.026805   \n",
       " DEC '08   2.825    -0.795   234.535  ...  0.496095 -0.030223 -0.084576   \n",
       " DEC '09   2.839    -3.415   237.232  ...  0.042374 -0.353499  0.004956   \n",
       " DEC '10   1.697    -7.216   262.372  ...  0.119437 -0.377944 -0.402254   \n",
       " DEC '11   0.000    -1.434   307.195  ...  0.172040  0.639679 -1.000000   \n",
       " DEC '12   0.000    -4.607   321.591  ...  0.071452 -0.570652  0.000000   \n",
       " DEC '13   0.000    -5.357   419.554  ...  0.318610 -0.213682  0.000000   \n",
       " DEC '14  15.463     5.974   479.776  ...  0.211930  0.075009  0.000000   \n",
       " DEC '15  18.525    54.614   456.624  ... -0.046736  8.608493  0.198021   \n",
       " DEC '16  18.638   105.619   459.446  ... -0.000532  0.939202  0.006100   \n",
       " DEC '17  18.839   255.638   314.192  ... -0.162111  0.727965  0.010784   \n",
       " DEC '18  43.202   255.197   343.089  ...  0.036347  0.198870  1.293222   \n",
       " DEC '19  49.364   199.573   532.481  ...  0.410780 -0.122373  0.142632   \n",
       " DEC '20  69.120   323.840   616.082  ...  0.213988  0.510950  0.400211   \n",
       " DEC '21  72.332   310.854   728.221  ...  0.150395 -0.010291  0.046470   \n",
       " DEC '22  11.096   270.780   658.003  ... -0.109450 -0.273434 -0.846596   \n",
       " \n",
       "                   23        24          25        26        27        28  \\\n",
       " DEC '00          NaN       NaN         NaN       NaN       NaN       NaN   \n",
       " DEC '01  1433.612245  1.748933    4.679144  1.749552  0.018524  1.342602   \n",
       " DEC '02    -0.976574 -0.916225   -0.536723 -0.916060 -0.850993 -0.923273   \n",
       " DEC '03    -0.991412 -0.859511    0.278455 -0.856773 -0.839105 -0.861878   \n",
       " DEC '04    12.628788 -2.226302    0.227345 -2.173594 -2.122676 -2.000000   \n",
       " DEC '05     0.965722  1.003757 -334.670984  8.544814  6.815577  7.440000   \n",
       " DEC '06     0.415779  0.398628   -1.159429 -0.824996 -0.814284 -0.838863   \n",
       " DEC '07    -1.270772  0.708203    0.637236  0.758976  0.362685  0.647059   \n",
       " DEC '08    -0.804524  0.394340    0.329561  0.437480  0.437116  0.410714   \n",
       " DEC '09     3.295597  0.011499    0.021500  0.005340 -0.017693 -0.012658   \n",
       " DEC '10     1.113031  0.105972   -0.001829  0.173439  0.139136  0.153846   \n",
       " DEC '11    -0.801275  0.170838    0.166085  0.173368  0.215095  0.188889   \n",
       " DEC '12     2.212692  0.046863    0.106415  0.015356  0.036411  0.046729   \n",
       " DEC '13     0.162796  0.304620    0.071980  0.438739  0.442901  0.437500   \n",
       " DEC '14    -2.115176  0.143538    0.156750  0.137863  0.170869  0.142857   \n",
       " DEC '15     8.141948 -0.048256   -0.072757 -0.037557  0.068148 -0.032609   \n",
       " DEC '16     0.933918  0.006180    0.059874 -0.016409  0.110463  0.005618   \n",
       " DEC '17     1.420379 -0.316150   -0.362058 -0.295339  0.050754 -0.279330   \n",
       " DEC '18    -0.001725  0.091972   -0.510905  0.339401  0.212169  0.364341   \n",
       " DEC '19    -0.217965  0.552020    0.193085  0.602139  0.331330  0.650398   \n",
       " DEC '20     0.622664  0.157003   -0.139231  0.165300  0.263818  0.160774   \n",
       " DEC '21    -0.040100  0.182020    0.362550  0.169800  0.105136  0.165643   \n",
       " DEC '22    -0.128916 -0.096424    1.024836 -0.196381 -0.152203 -0.169661   \n",
       " \n",
       "                29  \n",
       " DEC '00       NaN  \n",
       " DEC '01  0.097804  \n",
       " DEC '02 -0.775301  \n",
       " DEC '03 -1.588428  \n",
       " DEC '04  1.468622  \n",
       " DEC '05  0.441907  \n",
       " DEC '06  0.267976  \n",
       " DEC '07  0.745178  \n",
       " DEC '08  0.451631  \n",
       " DEC '09  0.107817  \n",
       " DEC '10  0.137277  \n",
       " DEC '11  0.172021  \n",
       " DEC '12  0.124592  \n",
       " DEC '13  0.153682  \n",
       " DEC '14  0.252211  \n",
       " DEC '15  0.039069  \n",
       " DEC '16  0.044695  \n",
       " DEC '17 -0.047729  \n",
       " DEC '18  0.099755  \n",
       " DEC '19  0.206640  \n",
       " DEC '20  0.158441  \n",
       " DEC '21  0.150645  \n",
       " DEC '22 -0.034044  \n",
       " \n",
       " [23 rows x 30 columns],\n",
       " 22:                0        1       2         3         4        5       6   \\\n",
       " DEC '11    28.553   12.080   1.891    16.473    40.888  -24.415   0.034   \n",
       " DEC '12    51.604   16.838   2.736    34.766    53.506  -18.740   0.025   \n",
       " DEC '13    77.634   29.039   4.472    48.595    82.845  -34.250  -0.004   \n",
       " DEC '14   115.876   37.080   5.714    78.796   127.405  -48.609   0.610   \n",
       " DEC '15   181.943   47.923   7.343   134.020   180.494  -46.474   1.018   \n",
       " DEC '16   270.967   61.865  11.177   209.102   253.764  -44.662  -0.102   \n",
       " DEC '17   375.612   75.729  15.786   299.883   340.019  -40.136   3.278   \n",
       " DEC '18   512.980  100.357  23.428   412.623   460.881  -48.258   7.684   \n",
       " DEC '19   674.860  129.958  29.800   544.902   591.366  -46.464  19.036   \n",
       " DEC '20   883.026  166.959  39.200   716.067   766.895  -50.828   7.062   \n",
       " DEC '21  1300.658  258.857  48.200  1041.801  1094.408  -52.607  -6.946   \n",
       " DEC '22  1730.969  314.259  62.400  1416.710  1525.811 -109.101  -1.893   \n",
       " \n",
       "              7       8        9   ...        20          21         22  \\\n",
       " DEC '11   0.030     NaN  -24.411  ...       NaN         NaN        NaN   \n",
       " DEC '12   0.063     NaN  -18.778  ... -0.232439   -0.264706   1.100000   \n",
       " DEC '13   0.020     NaN  -34.274  ...  0.827641   -1.160000  -0.682540   \n",
       " DEC '14   0.322     NaN  -48.321  ...  0.419241 -153.500000  15.100000   \n",
       " DEC '15   0.185     NaN  -45.641  ... -0.043922    0.668852  -0.425466   \n",
       " DEC '16   0.265     NaN  -45.029  ... -0.038990   -1.100196   0.432432   \n",
       " DEC '17  13.181     NaN  -50.039  ... -0.101339  -33.137255  48.739623   \n",
       " DEC '18  21.386     NaN  -61.960  ...  0.202362    1.344112   0.622487   \n",
       " DEC '19  22.818   0.527  -50.773  ... -0.037175    1.477356   0.066960   \n",
       " DEC '20  37.049     NaN  -80.815  ...  0.093922   -0.629019   0.623674   \n",
       " DEC '21  25.390 -11.125  -73.818  ...  0.035000   -1.983574  -0.314691   \n",
       " DEC '22   3.762 -10.064 -104.692  ...  1.073888   -0.727469  -0.851831   \n",
       " \n",
       "                23        24         25        26        27        28        29  \n",
       " DEC '11       NaN       NaN        NaN       NaN       NaN       NaN       NaN  \n",
       " DEC '12  0.000000 -0.230757   0.000000 -0.230757 -0.259589 -0.259636 -0.289469  \n",
       " DEC '13  0.000000  0.825221   0.000000  0.825221  0.820245  0.820275  0.860660  \n",
       " DEC '14  0.000000  0.409844   0.000000  0.407160  2.964404  2.964508  0.440493  \n",
       " DEC '15  0.000000 -0.055462  -5.478261 -0.045118 -0.669945 -0.669048 -0.087749  \n",
       " DEC '16  0.000000 -0.013409   0.293689 -0.010662 -0.066176 -0.071942 -0.144285  \n",
       " DEC '17  0.000000  0.111262 -20.371482 -0.128353 -0.166932 -0.162791 -0.272809  \n",
       " DEC '18  0.000000  0.238234  -1.180920  0.607191  0.536194  0.533889  0.019713  \n",
       " DEC '19  0.000000 -0.180552   0.591542 -0.157956 -0.233303 -0.227997 -0.328876  \n",
       " DEC '20 -1.000000  0.591692   0.418096  0.582090  0.495785  0.485495 -0.302208  \n",
       " DEC '21  0.000000 -0.086580  -0.046727 -0.084604 -0.038848 -0.126224 -0.621001  \n",
       " DEC '22 -0.095371  0.418245   1.004728  0.448527  0.364887  0.413133  9.597005  \n",
       " \n",
       " [12 rows x 30 columns],\n",
       " 23:              0      1      2       3       4      5     6     7      8   \\\n",
       " DEC '15   603.8  407.4  149.5   196.4   502.6 -306.2  -4.2  15.2    0.0   \n",
       " DEC '16   844.8  390.6  191.1   454.2   647.7 -193.5   4.9  16.4    0.0   \n",
       " DEC '17  1106.8  368.9  181.2   737.9   851.6 -113.7  13.2  11.0    0.0   \n",
       " DEC '18  1391.7  394.7  166.8   997.0  1491.0 -494.0  13.9   0.0    0.0   \n",
       " DEC '19  1661.3  411.0  173.5  1250.3  1329.8  -79.5  38.8  10.3    1.0   \n",
       " DEC '20  1913.9  414.6  159.2  1499.3  1378.1  121.2  20.8  10.8  381.4   \n",
       " DEC '21  2157.9  444.2  151.3  1713.7  1406.8  306.9  24.0  12.7   18.9   \n",
       " DEC '22  2324.9  444.2  157.2  1880.7  1524.2  356.5  23.8  12.4  175.2   \n",
       " \n",
       "             9   ...        20        21        22          23        24  \\\n",
       " DEC '15 -325.6  ...       NaN       NaN       NaN         NaN       NaN   \n",
       " DEC '16 -205.0  ... -0.368060 -2.166667  0.078947    0.000000 -0.370393   \n",
       " DEC '17 -111.5  ... -0.412403  1.693878 -0.329268    0.000000 -0.456098   \n",
       " DEC '18 -480.1  ...  3.344767  0.053030 -1.000000    0.000000  3.305830   \n",
       " DEC '19  -52.0  ... -0.839069  1.791367  0.000000    0.000000 -0.891689   \n",
       " DEC '20 -250.2  ... -2.524528 -0.463918  0.048544  380.400000  3.811538   \n",
       " DEC '21  299.3  ...  1.532178  0.153846  0.175926   -0.950446 -2.196243   \n",
       " DEC '22  192.7  ...  0.161616 -0.008333 -0.023622    8.269841 -0.356164   \n",
       " \n",
       "                 25        26         27        28         29  \n",
       " DEC '15        NaN       NaN        NaN       NaN        NaN  \n",
       " DEC '16  16.333333 -0.355017  -0.355017 -0.354992  -0.984684  \n",
       " DEC '17  -0.961538 -0.468601  -0.468600 -0.468531 -29.125000  \n",
       " DEC '18  23.000000  3.341092   3.809611  3.808677  -5.847407  \n",
       " DEC '19  -0.854167 -0.891318  -0.906570 -0.905339  -1.287286  \n",
       " DEC '20   7.714286  3.863378  -1.204043  3.832813   1.982979  \n",
       " DEC '21  -6.983607 -2.310183  33.208783 -2.371484   0.634094  \n",
       " DEC '22   8.876712  0.647409   0.718777  0.462282   0.121126  \n",
       " \n",
       " [8 rows x 30 columns],\n",
       " 24:               0        1        2        3        4        5       6       7   \\\n",
       " DEC '16   84.791   23.962    8.355   60.829   77.858  -17.029   0.418   0.654   \n",
       " DEC '17  134.915   28.788   12.174  106.127  115.857   -9.730   0.877   0.862   \n",
       " DEC '18  192.674   43.537   18.905  149.137  234.036  -84.899  -0.196   0.992   \n",
       " DEC '19  287.022   63.423   29.479  223.599  341.845 -118.246   4.345   1.112   \n",
       " DEC '20  431.059  101.055   69.152  330.004  440.493 -110.489   6.759  24.964   \n",
       " DEC '21  656.426  147.134  120.965  509.292  657.496 -148.204   1.176  49.234   \n",
       " DEC '22  975.241  232.610  183.782  742.631  991.387 -248.756  15.454   4.984   \n",
       " \n",
       "              8        9   ...        20         21         22         23  \\\n",
       " DEC '16   0.000  -17.265  ...       NaN        NaN        NaN        NaN   \n",
       " DEC '17   0.000   -9.715  ... -0.428622   1.098086   0.318043   0.000000   \n",
       " DEC '18   0.000  -86.087  ...  7.725488  -1.223489   0.150812   0.000000   \n",
       " DEC '19   0.000 -115.013  ...  0.392784 -23.168367   0.120968   0.000000   \n",
       " DEC '20   6.279 -134.973  ... -0.065601   0.555581  21.449640   0.000000   \n",
       " DEC '21  72.614 -268.876  ...  0.341346  -0.826010   0.972200  10.564580   \n",
       " DEC '22   3.947 -242.233  ...  0.678470  12.141156  -0.898769  -0.945644   \n",
       " \n",
       "                24         25        26        27        28         29  \n",
       " DEC '16       NaN        NaN       NaN       NaN       NaN        NaN  \n",
       " DEC '17 -0.437301  13.971014 -0.379947 -0.379952 -0.379310  -1.281762  \n",
       " DEC '18  7.861245   0.042594  7.109788  7.109876  7.108333 -28.002455  \n",
       " DEC '19  0.336009  -9.528319  0.214125  0.207739  0.207948   0.345077  \n",
       " DEC '20  0.173546   0.698748  0.127962  0.087875  0.129325  -0.534320  \n",
       " DEC '21  0.992072  -0.450939  1.180690  0.748765  1.093169  -0.341050  \n",
       " DEC '22 -0.099090   4.702346 -0.257110 -0.129108 -0.289022   1.385330  \n",
       " \n",
       " [7 rows x 30 columns],\n",
       " 25:                0        1        2         3         4        5       6   \\\n",
       " JAN '14    42.733   24.129    4.431    18.604    96.733  -78.129  -0.141   \n",
       " JAN '15   174.451   78.393   15.392    96.058   276.540 -180.482  -1.412   \n",
       " JAN '16   440.333  169.193   32.254   271.140   469.421 -198.281  -2.002   \n",
       " JAN '17   727.977  253.679   50.203   474.298   689.104 -214.806   1.627   \n",
       " JAN '18  1024.762  355.281   61.744   669.481   836.915 -167.434  11.464   \n",
       " JAN '19  1359.824  460.128   70.878   899.696  1068.953 -169.257  13.599   \n",
       " JAN '20  1643.440  512.247   89.710  1131.193  1321.976 -190.783  24.514   \n",
       " JAN '21  1684.179  534.355   70.042  1149.824  1378.958 -229.134  22.276   \n",
       " JAN '22  2180.848  708.329   83.151  1472.519  1570.917  -98.398   6.579   \n",
       " JAN '23  2753.434  855.788  100.432  1897.646  1814.133   83.513  13.044   \n",
       " \n",
       "              7       8        9   ...        20        21           22  \\\n",
       " JAN '14   0.000   0.000  -78.270  ...       NaN       NaN          NaN   \n",
       " JAN '15   0.000   0.000 -181.894  ...  1.310051  9.014184     0.000000   \n",
       " JAN '16   0.000  11.900 -212.183  ...  0.098619  0.417847     0.000000   \n",
       " JAN '17   0.000  30.000 -243.179  ...  0.083341 -1.812687     0.000000   \n",
       " JAN '18   0.019   0.000 -155.989  ... -0.220534  6.046097     0.000000   \n",
       " JAN '19  21.615   0.000 -177.273  ...  0.010888  0.186235  1136.631579   \n",
       " JAN '20  27.897   0.500 -194.666  ...  0.127179  0.802633     0.290632   \n",
       " JAN '21  31.403  31.899 -270.160  ...  0.201019 -0.091295     0.125677   \n",
       " JAN '22  36.677   0.000 -128.496  ... -0.570566 -0.704660     0.167946   \n",
       " JAN '23   4.749   0.000   91.808  ... -1.848727  0.982672    -0.870518   \n",
       " \n",
       "                 23        24        25        26        27        28  \\\n",
       " JAN '14        NaN       NaN       NaN       NaN       NaN       NaN   \n",
       " JAN '15   0.000000  1.323930  3.594502  1.332340  1.332340  1.332372   \n",
       " JAN '16   0.000000  0.166520  0.173523  0.166571  1.566979  1.668727   \n",
       " JAN '17   1.521008  0.146081  0.202677  0.146497 -0.538071 -0.513514   \n",
       " JAN '18  -1.000000 -0.358542  1.060943 -0.347612 -0.343438 -0.400397   \n",
       " JAN '19   0.000000  0.136446 -0.719979  0.115613  0.017376  0.017472   \n",
       " JAN '20   0.000000  0.098114  4.804408  0.126849  0.032437  0.034214   \n",
       " JAN '21  62.798000  0.387813  0.885145  0.403454  0.222084  0.324780   \n",
       " JAN '22  -1.000000 -0.524371  0.238922 -0.492126 -0.483305 -0.524212   \n",
       " JAN '23   0.000000 -1.714481  0.269186 -1.510062 -1.449405 -1.449411   \n",
       " \n",
       "                 29  \n",
       " JAN '14        NaN  \n",
       " JAN '15   1.240088  \n",
       " JAN '16   0.005676  \n",
       " JAN '17  -0.008577  \n",
       " JAN '18  -0.357910  \n",
       " JAN '19  -0.069174  \n",
       " JAN '20   0.027384  \n",
       " JAN '21   0.574031  \n",
       " JAN '22  -0.904162  \n",
       " JAN '23 -13.064341  \n",
       " \n",
       " [10 rows x 30 columns],\n",
       " 26:                0        1       2        3        4       5      6      7   \\\n",
       " JUN '11    39.484   21.745   3.779   17.739   17.726   0.013  0.000  0.179   \n",
       " JUN '12    55.096   29.094   4.624   26.002   23.234   2.768  0.000  0.196   \n",
       " JUN '13    77.294   39.666   5.571   37.628   37.597   0.031  0.000  0.016   \n",
       " JUN '14   108.687   55.094   6.336   53.593   60.611  -7.018  0.163  0.000   \n",
       " JUN '15   152.698   70.896   8.609   81.802   95.723 -13.921  0.054  0.000   \n",
       " JUN '16   230.701   98.085  13.873  132.616  136.166  -3.550 -0.124  0.000   \n",
       " JUN '17   300.010  123.987  21.027  176.023  168.727   7.296  0.073  0.000   \n",
       " JUN '18   377.527  149.197  30.202  228.330  210.045  18.285  0.802  0.000   \n",
       " JUN '19   467.633  153.851  34.564  313.782  257.135  56.647  1.822  0.000   \n",
       " JUN '20   561.329  184.533  37.913  376.796  306.940  69.856  1.642  0.695   \n",
       " JUN '21   635.627  223.138  42.972  412.489  352.555  59.934 -0.939  0.000   \n",
       " JUN '22   852.651  295.633  50.218  557.018  469.925  87.093 -0.499  0.498   \n",
       " DEC '22  1001.205  336.547  55.929  664.658  571.328  93.330 -0.676    NaN   \n",
       " \n",
       "             8       9   ...          20        21        22        23  \\\n",
       " JUN '11    NaN  -0.166  ...         NaN       NaN       NaN       NaN   \n",
       " JUN '12    NaN   2.572  ...  211.923077  0.000000  0.094972  0.000000   \n",
       " JUN '13    NaN   0.015  ...   -0.988801  0.000000 -0.918367  0.000000   \n",
       " JUN '14    NaN  -6.855  ... -227.387097  0.000000 -1.000000  0.000000   \n",
       " JUN '15    NaN -13.867  ...    0.983614 -0.668712  0.000000  0.000000   \n",
       " JUN '16    NaN  -3.674  ...   -0.744990 -3.296296  0.000000  0.000000   \n",
       " JUN '17    NaN   7.369  ...   -3.055211 -1.588710  0.000000  0.000000   \n",
       " JUN '18  2.336  16.751  ...    1.506168  9.986301  0.000000  0.000000   \n",
       " JUN '19  0.423  58.046  ...    2.098004  1.271820  0.000000 -0.818921   \n",
       " JUN '20  3.685  67.118  ...    0.233181 -0.098793  0.000000  7.711584   \n",
       " JUN '21  1.891  57.104  ...   -0.142035 -1.571864 -1.000000 -0.486839   \n",
       " JUN '22  2.499  83.597  ...    0.453148 -0.468584  0.000000  0.321523   \n",
       " DEC '22  1.829  90.825  ...    0.071613  0.354709 -1.000000 -0.268107   \n",
       " \n",
       "                  24         25        26        27        28        29  \n",
       " JUN '11         NaN        NaN       NaN       NaN       NaN       NaN  \n",
       " JUN '12  -16.493976 -25.555556 -2.289406 -2.092172 -3.000000  0.949367  \n",
       " JUN '13   -0.994168  -1.680995 -3.295591 -4.180310 -3.500000 -0.242154  \n",
       " JUN '14 -458.000000  -1.423588  2.103448  4.358857  4.200000 -1.121742  \n",
       " JUN '15    1.022903  -0.588235  0.965120  0.089376  0.076923  6.788856  \n",
       " JUN '16   -0.735054   0.685714 -0.724377 -0.728632 -0.714286 -2.943336  \n",
       " JUN '17   -3.005716   2.677966 -2.744482 -2.643015 -2.500000  1.743679  \n",
       " JUN '18    1.273171 -34.559140  4.745460  4.898315  4.860000  0.711930  \n",
       " JUN '19    2.465226  -1.193299  0.394450  0.332342  0.381257  0.881143  \n",
       " JUN '20    0.156290  -0.369406  0.197536  0.229925  0.189128  0.181535  \n",
       " JUN '21   -0.149200  -6.150207  0.098736  0.066684  0.089004 -0.045124  \n",
       " JUN '22    0.463943  -0.476486  0.281817  0.279364  0.278582  0.334334  \n",
       " DEC '22    0.086462  -0.287047  0.056920  0.050235  0.056150  0.087014  \n",
       " \n",
       " [13 rows x 30 columns],\n",
       " 27:                0        1        2         3        4        5       6   \\\n",
       " DEC '11    57.206   17.574    5.287    39.632   38.176    1.456   0.108   \n",
       " DEC '12    76.810   20.418    5.523    56.392   50.337    6.055   0.687   \n",
       " DEC '13   107.601   24.573    5.503    83.028   73.711    9.317   1.859   \n",
       " DEC '14   150.929   31.856    7.162   119.073  103.373   15.700   2.521   \n",
       " DEC '15   224.653   41.211    9.421   183.442  149.007   34.435   0.517   \n",
       " DEC '16   329.141   61.900   13.632   267.241  209.270   57.971   0.308   \n",
       " DEC '17   433.047   81.833   19.395   351.214  221.504  129.710  -0.467   \n",
       " DEC '18   566.336  105.888   29.657   460.448  286.733  173.715   1.062   \n",
       " DEC '19   737.671  131.547   42.211   606.124  379.900  226.224   2.203   \n",
       " DEC '20   841.434  151.151   53.373   690.283  504.160  186.123   1.232   \n",
       " DEC '21  1055.524  265.669  135.194   789.855  536.288  253.567   0.992   \n",
       " DEC '22  1375.218  348.859  179.053  1026.359  647.680  378.679  11.876   \n",
       " \n",
       "             7      8        9   ...        20         21         22        23  \\\n",
       " DEC '11  0.134    NaN    1.430  ...       NaN        NaN        NaN       NaN   \n",
       " DEC '12  2.171  0.333    4.238  ...  3.158654   5.361111  15.201493  0.000000   \n",
       " DEC '13  2.805  0.660    7.711  ...  0.538728   1.705968   0.292031  0.981982   \n",
       " DEC '14  3.421  5.144    9.656  ...  0.685092   0.356105   0.219608  6.793939   \n",
       " DEC '15  1.427  0.000   33.525  ...  1.193312  -0.794923  -0.582871 -1.000000   \n",
       " DEC '16  1.036  0.000   57.243  ...  0.683491  -0.404255  -0.274001  0.000000   \n",
       " DEC '17  0.911  0.600  127.732  ...  1.237498  -2.516234  -0.120656  0.000000   \n",
       " DEC '18  0.766 -0.700  174.711  ...  0.339257  -3.274090  -0.159166 -2.166667   \n",
       " DEC '19  0.940  1.400  226.087  ...  0.302271   1.074388   0.227154 -3.000000   \n",
       " DEC '20  0.019  1.400  185.936  ... -0.177262  -0.440763  -0.979787  0.000000   \n",
       " DEC '21    NaN -1.403  255.962  ...  0.362363  -0.194805  -1.000000 -2.002143   \n",
       " DEC '22  2.536 -1.559  389.578  ...  0.493408  10.971774   0.000000  0.111190   \n",
       " \n",
       "                24        25        26        27        28        29  \n",
       " DEC '11       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       " DEC '12  1.963636  0.000000  1.963636 -1.234186 -1.398551  0.717040  \n",
       " DEC '13  0.819490  0.000000  0.819490 -6.094214 -3.181818  0.280014  \n",
       " DEC '14  0.252237  0.000000 -0.265595  4.425005  3.583333  0.542645  \n",
       " DEC '15  2.471935  2.150513  2.650892  0.998785  2.272727  0.918292  \n",
       " DEC '16  0.707472  0.065421  1.104329  1.066319  1.055556  0.632684  \n",
       " DEC '17  1.231399 -0.683205  1.831062  1.849435  1.831351  1.082385  \n",
       " DEC '18  0.367794  7.866227  0.111512  0.107659  0.115407  0.363952  \n",
       " DEC '19  0.294063  0.208920  0.318386  0.334555  0.322636  0.319921  \n",
       " DEC '20 -0.177591 -0.066533 -0.205225 -0.202619 -0.203753 -0.107806  \n",
       " DEC '21  0.376613  0.412377  0.366022  0.352134  0.368235  0.623246  \n",
       " DEC '22  0.522015  0.803090  0.435951  0.437982  0.436347  0.434640  \n",
       " \n",
       " [12 rows x 30 columns],\n",
       " 28:                0        1        2         3         4        5       6   \\\n",
       " JAN '16   250.481   75.820   17.620   174.661   293.965 -119.304  -3.508   \n",
       " JAN '17   381.459  105.862   28.469   275.597   391.414 -115.817   1.372   \n",
       " JAN '18   518.504  121.523   31.720   396.981   448.634  -51.653   3.135   \n",
       " JAN '19   700.969  199.442   38.027   501.527   926.050 -424.523   8.959   \n",
       " JAN '20   973.971  255.247   69.617   718.724   912.233 -193.509  19.207   \n",
       " JAN '21  1453.047  378.624   97.818  1074.423  1240.316 -165.893   8.914   \n",
       " JAN '22  2107.213  479.551  108.732  1627.662  1684.060  -56.398   1.413   \n",
       " JAN '23  2515.915  547.181  113.756  1968.734  2021.249  -52.515   4.539   \n",
       " \n",
       "              7       8        9   ...        20        21         22  \\\n",
       " JAN '16   0.780     NaN -123.592  ...       NaN       NaN        NaN   \n",
       " JAN '17   0.611     NaN -115.056  ... -0.029228 -1.391106  -0.216667   \n",
       " JAN '18   0.624     NaN  -49.142  ... -0.554012  1.284985   0.021277   \n",
       " JAN '19  10.844   1.800 -428.208  ...  7.218748  1.857735  16.378205   \n",
       " JAN '20  29.254     NaN -203.556  ... -0.544173  1.143878   1.697713   \n",
       " JAN '21  30.799  41.714 -229.492  ... -0.142712 -0.535898   0.052813   \n",
       " JAN '22   6.443   5.486  -66.914  ... -0.660034 -0.841485  -0.790805   \n",
       " JAN '23   6.389  35.516  -89.881  ... -0.068850  2.212314  -0.008381   \n",
       " \n",
       "                23        24        25        26        27        28         29  \n",
       " JAN '16       NaN       NaN       NaN       NaN       NaN       NaN        NaN  \n",
       " JAN '17  0.000000 -0.069066 -1.344627 -0.058315 -0.057281 -0.046520  -0.140986  \n",
       " JAN '18  0.000000 -0.572886  7.803371 -0.547049 -0.540190 -0.552646  -0.771798  \n",
       " JAN '19  0.000000  7.713687 -1.558392  7.157816  8.102713  8.384250  18.389756  \n",
       " JAN '20 -1.000000 -0.524633 -3.744571 -0.511420 -0.625483 -0.626607  -0.679448  \n",
       " JAN '21  0.000000  0.127415  1.867999  0.167538 -0.022690  0.110678  -0.450529  \n",
       " JAN '22 -0.868485 -0.708426 -0.777713 -0.712349 -0.708198 -0.728314  -1.768770  \n",
       " JAN '23  5.473934  0.343232  1.473220  0.392677  0.074536  0.363406   0.170195  \n",
       " \n",
       " [8 rows x 30 columns],\n",
       " 29:                  0           1          2           3          4          5   \\\n",
       " SEP '87    2.661068    1.296220   0.070516    1.364848   0.993410    0.37144   \n",
       " SEP '88    4.071373    1.990879   0.077677    2.080494   1.460156    0.62034   \n",
       " SEP '89    5.284013    2.694823   0.124800    2.589190   1.954877    0.63431   \n",
       " SEP '90    5.558435    2.606223   0.202686    2.952212   2.240200    0.71201   \n",
       " SEP '91    6.308849    3.314118   0.204433    2.994731   2.323339    0.67139   \n",
       " SEP '92    7.086542    3.991337   0.217182    3.095205   2.289397    0.80581   \n",
       " SEP '93    7.976954    5.248834   0.166113    2.728120   2.296926    0.43119   \n",
       " SEP '94    9.188748    6.844915   0.167958    2.343833   1.948414    0.39542   \n",
       " SEP '95   11.062000    8.204000   0.127000    2.858000   2.197000    0.66100   \n",
       " SEP '96    9.833000    8.865000   0.156000    0.968000   2.172000   -1.20400   \n",
       " SEP '97    7.081000    5.713000   0.118000    1.368000   1.771000   -0.40300   \n",
       " SEP '98    5.941000    4.462000   0.111000    1.479000   1.211000    0.26800   \n",
       " SEP '99    6.134000    4.438000   0.085000    1.696000   1.310000    0.38600   \n",
       " SEP '00    7.983000    5.817000   0.084000    2.166000   1.546000    0.62000   \n",
       " SEP '01    5.363000    4.128000   0.102000    1.235000   1.568000   -0.33300   \n",
       " SEP '02    5.742000    4.139000   0.118000    1.603000   1.557000    0.04600   \n",
       " SEP '03    6.207000    4.499000   0.113000    1.708000   1.683000    0.02500   \n",
       " SEP '04    8.279000    6.020000   0.150000    2.259000   1.910000    0.34900   \n",
       " SEP '05   13.931000    9.889000   0.150000    4.042000   2.399000    1.64300   \n",
       " SEP '06   19.315000   13.717000   0.192000    5.598000   3.145000    2.45300   \n",
       " SEP '07   24.006000   15.852000   0.284000    8.154000   3.745000    4.40900   \n",
       " SEP '08   32.479000   21.334000   0.409000   11.145000   4.870000    6.27500   \n",
       " SEP '09   42.603000   25.751000   0.659000   16.852000   5.482000   11.37000   \n",
       " SEP '10   65.067000   39.498000   0.884000   25.569000   7.299000   18.27000   \n",
       " SEP '11  108.598000   64.076000   1.792000   44.522000  10.028000   34.49400   \n",
       " SEP '12  155.971000   87.916000   3.205000   68.055000  13.421000   54.63400   \n",
       " SEP '13  170.866000  107.238000   6.760000   63.628000  15.305000   48.32300   \n",
       " SEP '14  183.244000  112.553000   8.000000   70.691000  18.034000   52.65700   \n",
       " SEP '15  231.283000  142.257000  10.500000   89.026000  22.396000   66.63000   \n",
       " SEP '16  214.226000  131.506000   9.800000   82.720000  24.239000   58.48100   \n",
       " SEP '17  228.572000  141.702000   9.400000   86.870000  26.842000   60.02800   \n",
       " SEP '18  265.809000  163.826000   9.300000  101.983000  30.941000   71.04200   \n",
       " SEP '19  259.968000  162.264000  11.300000   97.704000  34.462000   63.24200   \n",
       " SEP '20  274.150000  170.143000  11.056000  104.007000  38.668000   65.33900   \n",
       " SEP '21  365.817000  212.981000  11.284000  152.836000  43.887000  108.94900   \n",
       " SEP '22  394.328000  223.546000  11.104000  170.782000  51.345000  119.43700   \n",
       " \n",
       "                6         7         8           9   ...         20         21  \\\n",
       " SEP '87  0.038930  0.000000       NaN    0.410368  ...        NaN        NaN   \n",
       " SEP '88  0.035823       NaN       NaN    0.656161  ...   0.670095  -0.079810   \n",
       " SEP '89  0.110009       NaN       NaN    0.744322  ...   0.022520   2.070904   \n",
       " SEP '90  0.066505       NaN       NaN    0.778517  ...   0.122495  -0.395459   \n",
       " SEP '91  0.062150  0.009755  0.224043    0.499744  ...  -0.057050  -0.065484   \n",
       " SEP '92  0.058412  0.008778       NaN    0.855442  ...   0.200212  -0.060145   \n",
       " SEP '93 -0.279735  0.011800  0.320856    0.139659  ...  -0.464899  -5.788999   \n",
       " SEP '94  0.017664  0.039653 -0.126855    0.500286  ...  -0.082956  -1.063145   \n",
       " SEP '95  0.038000  0.048000 -0.023000    0.674000  ...   0.671640   1.151268   \n",
       " SEP '96  0.148000  0.060000  0.179000   -1.295000  ...  -2.821483   2.894737   \n",
       " SEP '97 -0.571000  0.071000  0.667000   -1.045000  ...  -0.665282  -4.858108   \n",
       " SEP '98  0.123000  0.062000       NaN    0.329000  ...  -1.665012  -1.215412   \n",
       " SEP '99  0.364000  0.047000  0.027000    0.676000  ...   0.440299   1.959350   \n",
       " SEP '00  0.591000  0.021000       NaN    1.092000  ...   0.606218   0.623626   \n",
       " SEP '01  0.308000  0.016000  0.011000   -0.052000  ...  -1.537097  -0.478849   \n",
       " SEP '02  0.081000  0.011000  0.029000    0.087000  ...  -1.138138  -0.737013   \n",
       " SEP '03  0.095000  0.008000  0.020000    0.092000  ...  -0.456522   0.172840   \n",
       " SEP '04  0.060000  0.003000  0.023000    0.383000  ...  12.960000  -0.368421   \n",
       " SEP '05  0.165000  0.000000       NaN    1.808000  ...   3.707736   1.750000   \n",
       " SEP '06  0.365000  0.000000       NaN    2.818000  ...   0.493001   1.212121   \n",
       " SEP '07  0.599000  0.000000       NaN    5.008000  ...   0.797391   0.641096   \n",
       " SEP '08  0.620000  0.000000       NaN    6.895000  ...   0.423225   0.035058   \n",
       " SEP '09  0.923000  0.000000  0.227000   12.066000  ...   0.811952   0.488710   \n",
       " SEP '10  0.567000  0.000000  0.297000   18.540000  ...   0.606860  -0.385699   \n",
       " SEP '11  0.081000  0.000000  0.370000   34.205000  ...   0.888013  -0.857143   \n",
       " SEP '12  1.784000  0.000000  0.655000   55.763000  ...   0.583870  21.024691   \n",
       " SEP '13  2.268000  0.136000  0.300000   50.155000  ...  -0.115514   0.271300   \n",
       " SEP '14  1.210000  0.384000       NaN   53.483000  ...   0.089688  -0.466490   \n",
       " SEP '15  6.618000  0.733000       NaN   72.515000  ...   0.265359   4.469421   \n",
       " SEP '16  3.799000  1.456000 -0.548000   61.372000  ...  -0.122302  -0.425960   \n",
       " SEP '17  6.384000  2.323000       NaN   64.089000  ...   0.026453   0.680442   \n",
       " SEP '18  5.101000  3.240000       NaN   72.903000  ...   0.183481  -0.200971   \n",
       " SEP '19  6.071000  3.576000       NaN   65.737000  ...  -0.109794   0.190159   \n",
       " SEP '20  4.160000  2.873000 -0.465000   67.091000  ...   0.033158  -0.314775   \n",
       " SEP '21  2.903000  2.645000  0.000000  109.207000  ...   0.667442  -0.302163   \n",
       " SEP '22  2.597000  2.931000  0.000000  119.103000  ...   0.096265  -0.105408   \n",
       " \n",
       "                22        23        24        25        26        27        28  \\\n",
       " SEP '87       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       " SEP '88  0.000000  0.000000  0.598958  0.326802  0.840301  0.864521  0.870748   \n",
       " SEP '89  0.000000  0.000000  0.134359  0.134371  0.134351  0.145215  0.145455   \n",
       " SEP '90  0.000000  0.000000  0.045941  0.045930  0.045948  0.069701  0.069841   \n",
       " SEP '91  0.000000  0.000000 -0.358082 -0.374541 -0.347559  0.027862 -0.317507   \n",
       " SEP '92 -0.100154 -1.000000  0.711760  0.711763  0.711759  0.115153  0.682609   \n",
       " SEP '93  0.344270  0.000000 -0.836741 -0.836742 -0.836739 -0.396221 -0.832041   \n",
       " SEP '94  2.360424 -1.395364  2.582197  2.582212  2.582187 -0.286272  2.584615   \n",
       " SEP '95  0.210501 -0.818691  0.347229  0.315042  0.366957  0.777978  0.321888   \n",
       " SEP '96  0.250000 -8.782609 -2.921365 -2.916000 -2.924528 -2.683931 -2.909091   \n",
       " SEP '97  0.183333  2.726257 -0.193050 -1.000000  0.280637 -0.178488  0.258503   \n",
       " SEP '98 -0.126761 -1.000000 -1.314833  0.000000 -1.295694 -1.000000 -1.254054   \n",
       " SEP '99 -0.241935  0.000000  1.054711  2.750000  0.944984  0.000000  0.712766   \n",
       " SEP '00 -0.553191 -1.000000  0.615385  3.080000  0.307820  0.172753  0.208075   \n",
       " SEP '01 -0.238095  0.000000 -1.047619 -1.049020 -1.047074 -1.022951 -1.033419   \n",
       " SEP '02 -0.312500  1.636364 -2.673077 -2.466667 -2.756757 -5.709172 -3.461538   \n",
       " SEP '03 -0.272727 -0.310345  0.057471  0.090909  0.046154 -0.042993  0.062500   \n",
       " SEP '04 -0.625000  0.150000  3.163043  3.458333  3.058824  2.342517  2.735294   \n",
       " SEP '05 -1.000000 -1.000000  3.720627  3.485981  3.811594  3.110047  3.362205   \n",
       " SEP '06  0.000000  0.000000  0.558628  0.727083  0.497741  0.462511  0.463899   \n",
       " SEP '07  0.000000  0.000000  0.777147  0.823884  0.757667  0.734416  0.731196   \n",
       " SEP '08  0.000000  0.000000  0.376797  0.363095  0.382723  0.363032  0.363248   \n",
       " SEP '09  0.000000  0.000000  0.749964  0.858806  0.703558  0.727111  0.694357   \n",
       " SEP '10  0.000000  0.308370  0.536549  0.181676  0.701639  0.661753  0.668517   \n",
       " SEP '11  0.000000  0.245791  0.844930  0.829689  0.849854  0.817566  0.827019   \n",
       " SEP '12  0.000000  0.770270  0.630259  0.693831  0.609945  0.596683  0.594983   \n",
       " SEP '13  0.000000 -0.541985 -0.100568 -0.065004 -0.112525 -0.104217 -0.099696   \n",
       " SEP '14  1.823529 -1.000000  0.066354  0.065178  0.066771  0.129879  0.135883   \n",
       " SEP '15  0.908854  0.000000  0.355851  0.368425  0.351405  0.428292  0.429457   \n",
       " SEP '16  0.986357  0.000000 -0.153665 -0.179698 -0.144342 -0.106361 -0.098698   \n",
       " SEP '17  0.595467 -1.000000  0.044271  0.003379  0.058310  0.117790  0.108303   \n",
       " SEP '18  0.394748  0.000000  0.137528 -0.150337  0.231226  0.293175  0.293160   \n",
       " SEP '19  0.103704  0.000000 -0.098295 -0.216198 -0.071811 -0.001693 -0.002049   \n",
       " SEP '20 -0.196588  0.000000  0.020597 -0.076424  0.039000  0.096024  0.102309   \n",
       " SEP '21 -0.079360 -1.000000  0.627744  0.500723  0.649161  0.723796  0.713989   \n",
       " SEP '22  0.108129  0.000000  0.090617  0.328561  0.054109  0.088917  0.088921   \n",
       " \n",
       "                29  \n",
       " SEP '87       NaN  \n",
       " SEP '88  0.579374  \n",
       " SEP '89  0.087519  \n",
       " SEP '90  0.204964  \n",
       " SEP '91 -0.042506  \n",
       " SEP '92  0.168037  \n",
       " SEP '93 -0.416123  \n",
       " SEP '94 -0.056789  \n",
       " SEP '95  0.398701  \n",
       " SEP '96 -2.329949  \n",
       " SEP '97 -0.728053  \n",
       " SEP '98 -2.329825  \n",
       " SEP '99  0.242744  \n",
       " SEP '00  0.494692  \n",
       " SEP '01 -1.328125  \n",
       " SEP '02 -1.709957  \n",
       " SEP '03 -0.158537  \n",
       " SEP '04  2.615942  \n",
       " SEP '05  2.593186  \n",
       " SEP '06  0.475181  \n",
       " SEP '07  0.774291  \n",
       " SEP '08  0.424249  \n",
       " SEP '09  0.799671  \n",
       " SEP '10  0.592319  \n",
       " SEP '11  0.894435  \n",
       " SEP '12  0.593976  \n",
       " SEP '13 -0.047650  \n",
       " SEP '14  0.101193  \n",
       " SEP '15  0.271576  \n",
       " SEP '16 -0.114728  \n",
       " SEP '17  0.016798  \n",
       " SEP '18  0.157199  \n",
       " SEP '19 -0.072191  \n",
       " SEP '20  0.024858  \n",
       " SEP '21  0.573833  \n",
       " SEP '22  0.085734  \n",
       " \n",
       " [36 rows x 30 columns],\n",
       " 30:                0         1       2         3         4        5        6   \\\n",
       " DEC '12    23.713     5.432   0.767    18.281    21.090   -2.809    0.282   \n",
       " DEC '13    50.252    14.459   1.758    35.793    41.357   -5.564   -0.568   \n",
       " DEC '14   102.836    45.688   4.672    57.148    80.058  -22.910   -0.696   \n",
       " DEC '15   205.233    95.378   7.236   109.855   128.103  -18.248   -1.034   \n",
       " DEC '16   389.330   187.168  13.967   202.162   238.852  -36.690    1.335   \n",
       " DEC '17   673.304   302.395  23.382   370.909   423.464  -52.555   12.560   \n",
       " DEC '18  1073.229   488.338  27.046   584.891   672.641  -87.750   23.197   \n",
       " DEC '19  1578.173   729.114  35.651   849.059   985.025 -135.966   40.151   \n",
       " DEC '20  2929.491  1425.835  70.060  1503.656  1374.480  129.176   21.118   \n",
       " DEC '21  4611.856  2173.854  66.308  2438.002  2110.494  327.508   38.494   \n",
       " DEC '22  5599.864  2882.999  90.520  2716.865  3381.023 -664.158  178.034   \n",
       " \n",
       "             7         8         9   ...        20        21        22  \\\n",
       " DEC '12  0.000       NaN    -2.527  ...       NaN       NaN       NaN   \n",
       " DEC '13  0.000       NaN    -6.132  ...  0.980776 -3.014184  0.000000   \n",
       " DEC '14  0.000       NaN   -23.606  ...  3.117541  0.225352  0.000000   \n",
       " DEC '15  0.000       NaN   -19.848  ... -0.203492  0.485632  0.000000   \n",
       " DEC '16  0.000       NaN   -35.355  ...  1.010631 -2.291103  0.000000   \n",
       " DEC '17  0.000       NaN   -39.995  ...  0.432407  8.408240  0.000000   \n",
       " DEC '18  0.000       NaN   -64.553  ...  0.669679  0.846895  0.000000   \n",
       " DEC '19  0.000       NaN   -95.815  ...  0.549470  0.730870  0.000000   \n",
       " DEC '20  9.085   -99.155   240.364  ... -1.950061 -0.474036  0.000000   \n",
       " DEC '21  3.493 -2778.083  3140.592  ...  1.535363  0.822805 -0.615520   \n",
       " DEC '22  3.499  3133.225 -3622.848  ... -3.027914  3.624981  0.001718   \n",
       " \n",
       "                 23         24        25        26        27        28  \\\n",
       " DEC '12        NaN        NaN       NaN       NaN       NaN       NaN   \n",
       " DEC '13   0.000000   1.426593  0.000000  2.926136  2.926245  3.000000   \n",
       " DEC '14   0.000000   2.849641  0.000000  3.612570  3.612242  3.609375   \n",
       " DEC '15   0.000000  -0.159197 -0.183012 -0.157815  0.033364  0.016949   \n",
       " DEC '16   0.000000   0.781288 -1.000000  0.881586  0.382612  0.400000   \n",
       " DEC '17   0.000000   0.131240  0.000000  0.131240 -0.007982  0.000000   \n",
       " DEC '18   0.000000   0.614027  0.000000  0.614027  0.462870  0.454762   \n",
       " DEC '19   0.000000   0.484284  0.000000  0.933946  0.808113  0.808511   \n",
       " DEC '20   0.000000  -3.508626 -3.726599 -3.559307 -2.833985 -3.342081   \n",
       " DEC '21  27.017579  12.065983 -3.854672  8.122306  2.759635  7.842349   \n",
       " DEC '22  -2.127837  -2.153556 -1.718930 -2.187246 -2.313963 -2.194197   \n",
       " \n",
       "                29  \n",
       " DEC '12       NaN  \n",
       " DEC '13  0.863859  \n",
       " DEC '14  3.791908  \n",
       " DEC '15 -0.396206  \n",
       " DEC '16  1.063476  \n",
       " DEC '17  0.283853  \n",
       " DEC '18  1.080828  \n",
       " DEC '19  0.652527  \n",
       " DEC '20 -2.986104  \n",
       " DEC '21  0.976631  \n",
       " DEC '22 -2.456614  \n",
       " \n",
       " [11 rows x 30 columns],\n",
       " 31:               0        1       2        3        4       5       6       7   \\\n",
       " DEC '10  148.922  107.615  55.668   41.307   58.069 -16.762   0.411   5.801   \n",
       " DEC '11  172.018  121.712  61.986   50.306   78.019 -27.713  -2.830   3.558   \n",
       " DEC '12  213.334  141.069  67.973   72.265  114.903 -42.638   2.848   4.393   \n",
       " DEC '13  255.575  173.560  74.837   82.015  128.332 -46.317  -2.473   3.818   \n",
       " DEC '14  304.834  200.451  81.306  104.383  161.286 -56.903   5.434   0.317   \n",
       " DEC '15  301.373  184.552  55.064  116.821  168.682 -51.861   4.542   0.247   \n",
       " DEC '16  254.090  118.501  23.787  135.589  174.552 -38.963   0.773   0.571   \n",
       " DEC '17  255.066   80.175  19.337  174.891  197.577 -22.686   5.252   0.000   \n",
       " DEC '18  321.084   79.996  23.300  241.088  245.719  -4.631   3.987  11.225   \n",
       " DEC '19  410.926   92.182  31.700  318.744  299.830  18.914  20.063  44.851   \n",
       " DEC '20  644.338  205.417  62.415  438.921  379.068  59.853   8.683  66.297   \n",
       " DEC '21  776.265  254.904  74.133  521.361  439.876  81.485 -65.472   6.896   \n",
       " DEC '22  766.897  197.396  91.607  569.501  554.744  14.757   2.882   6.040   \n",
       " \n",
       "              8        9   ...        20        21        22         23  \\\n",
       " DEC '10   5.500  -27.652  ...       NaN       NaN       NaN        NaN   \n",
       " DEC '11   3.700  -37.801  ...  0.653323 -7.885645 -0.386657  -0.327273   \n",
       " DEC '12   4.811  -49.394  ...  0.538556 -2.006360  0.234682   0.300270   \n",
       " DEC '13   2.600  -55.208  ...  0.086285 -1.868329 -0.130890  -0.459572   \n",
       " DEC '14  12.786  -64.572  ...  0.228555 -3.197331 -0.916972   3.917692   \n",
       " DEC '15  10.165  -57.731  ... -0.088607 -0.164152 -0.220820  -0.204990   \n",
       " DEC '16   1.777  -40.538  ... -0.248703 -0.829811  1.311741  -0.825184   \n",
       " DEC '17   1.047  -18.481  ... -0.417755  5.794308 -1.000000  -0.410805   \n",
       " DEC '18   1.589  -13.458  ... -0.795865 -0.240861  0.000000   0.517670   \n",
       " DEC '19   1.097   -6.971  ... -5.084215  4.032104  2.995635  -0.309629   \n",
       " DEC '20   3.100   -0.861  ...  2.164481 -0.567213  0.478161   1.825889   \n",
       " DEC '21   3.378    5.739  ...  0.361419 -8.540251 -0.895983   0.089677   \n",
       " DEC '22 -92.347  103.946  ... -0.818899 -1.044019 -0.124130 -28.337774   \n",
       " \n",
       "                 24         25          26          27          28        29  \n",
       " DEC '10        NaN        NaN         NaN         NaN         NaN       NaN  \n",
       " DEC '11   0.367026  -0.880383    0.447306    0.301321    0.189840 -0.119082  \n",
       " DEC '12   0.306685  -1.145000    0.314407   -0.828825   -0.829213 -0.260788  \n",
       " DEC '13   0.117707  21.137931    0.130041    9.566581    8.973684  0.125715  \n",
       " DEC '14   0.169613  -0.710280    0.159499   -0.910468   -0.897098 -0.144355  \n",
       " DEC '15  -0.105944   6.951613   -0.085673   -0.105384   -0.128205 -0.868746  \n",
       " DEC '16  -0.297812   0.154158   -0.286523   -0.245252   -0.308824 -5.738058  \n",
       " DEC '17  -0.544107   0.055653   -0.519872   -0.568412   -0.574468 -0.779323  \n",
       " DEC '18  -0.271793  -0.206437   -0.265986   -0.377672   -0.342500 -6.574500  \n",
       " DEC '19  -0.482018   0.841958   -0.354850   -0.390541   -0.387072  1.711125  \n",
       " DEC '20  -0.876488   1.034928   -0.352317   -0.564127   -0.384615  1.415695  \n",
       " DEC '21  -7.665505   0.342724   -0.765633   -1.198620   -0.792339  0.272761  \n",
       " DEC '22  17.112215 -23.605530 -183.879287  209.018853 -173.747573 -0.316506  \n",
       " \n",
       " [13 rows x 30 columns],\n",
       " 32:                   0        1       2        3        4       5      6   \\\n",
       " Unnamed: 12      NaN      NaN     NaN      NaN      NaN     NaN    NaN   \n",
       " Unnamed: 11      NaN      NaN     NaN      NaN      NaN     NaN    NaN   \n",
       " DEC '12       23.361    7.632   2.532   15.729   20.364  -4.635 -0.052   \n",
       " DEC '13        30.04     8.78   2.455    21.26   21.663  -0.403 -0.073   \n",
       " DEC '14       42.421   12.986   2.512   29.435   29.721  -0.286 -0.076   \n",
       " DEC '15        58.72   21.308   5.976   37.412   48.199 -10.787 -0.061   \n",
       " DEC '16       76.846   25.262   7.742   51.584    62.41 -10.826  0.022   \n",
       " DEC '17      104.352   34.447  10.207   69.905    88.07 -18.165  0.389   \n",
       " DEC '18      147.094   52.762  13.693   94.332  135.573 -41.241  1.718   \n",
       " DEC '19      200.882   73.935  19.671  126.947  173.625 -46.678  4.287   \n",
       " DEC '20      271.141  101.622  30.759  169.519  237.368 -67.849  1.086   \n",
       " DEC '21      368.433  145.876  53.168  222.557  294.706 -72.149 -2.358   \n",
       " DEC '22      431.892  169.685  78.851  262.207  328.776 -66.569  6.475   \n",
       " \n",
       "                  7      8        9   ...         20         21        22  \\\n",
       " Unnamed: 12     NaN    NaN      NaN  ...        NaN        NaN       NaN   \n",
       " Unnamed: 11     NaN    NaN      NaN  ...        NaN        NaN       NaN   \n",
       " DEC '12       0.347    NaN   -5.034  ...        NaN        NaN       NaN   \n",
       " DEC '13       0.295    NaN   -0.771  ...  -0.913053   0.403846 -0.149856   \n",
       " DEC '14        0.35    NaN   -0.712  ...  -0.290323   0.041096  0.186441   \n",
       " DEC '15       0.538    NaN  -11.386  ...  36.716783  -0.197368  0.537143   \n",
       " DEC '16       0.506    NaN   -11.31  ...   0.003615  -1.360656  -0.05948   \n",
       " DEC '17       0.691   1.12  -19.587  ...   0.677905  16.681818  0.365613   \n",
       " DEC '18       6.346   0.85  -46.719  ...   1.270355   3.416452  8.183792   \n",
       " DEC '19       7.478  1.956  -51.825  ...   0.131835   1.495343   0.17838   \n",
       " DEC '20      24.089  4.811  -95.663  ...   0.453554  -0.746676  2.221316   \n",
       " DEC '21      35.949 -3.081 -107.375  ...   0.063376  -3.171271  0.492341   \n",
       " DEC '22       5.106 -1.628  -63.572  ...   -0.07734  -3.745971 -0.857965   \n",
       " \n",
       "                    23         24        25         26         27         28  \\\n",
       " Unnamed: 12       NaN        NaN       NaN        NaN        NaN        NaN   \n",
       " Unnamed: 11       NaN        NaN       NaN        NaN        NaN        NaN   \n",
       " DEC '12           NaN        NaN       NaN        NaN        NaN        NaN   \n",
       " DEC '13           0.0  -0.846841  1.070175  -0.825378  -0.825376  -0.825354   \n",
       " DEC '14           0.0  -0.076524 -1.754237  -0.299213   -0.29923  -0.299065   \n",
       " DEC '15           0.0  14.991573  5.314607  16.373997  16.374261  16.364444   \n",
       " DEC '16           0.0  -0.006675 -0.957295   0.042683   0.733959   0.740466   \n",
       " DEC '17           0.0    0.73183 -2.958333   0.739677  -0.001342   0.036324   \n",
       " DEC '18     -0.241071   1.385204  15.93617   1.420037   1.382666   1.316447   \n",
       " DEC '19      1.301176   0.109292  -0.46608   0.099653  -0.048167  -0.034795   \n",
       " DEC '20      1.459611   0.845885 -6.334118   0.787483   0.696767   0.714141   \n",
       " DEC '21     -1.640407    0.12243  4.548743    0.01499  -0.019016  -0.075422   \n",
       " DEC '22       -0.4716  -0.407944 -0.809365  -0.354677  -0.464729  -0.296624   \n",
       " \n",
       "                    29  \n",
       " Unnamed: 12       NaN  \n",
       " Unnamed: 11       NaN  \n",
       " DEC '12           NaN  \n",
       " DEC '13     -1.975749  \n",
       " DEC '14      0.084795  \n",
       " DEC '15     -3.161276  \n",
       " DEC '16     -0.358969  \n",
       " DEC '17      1.580415  \n",
       " DEC '18      2.461674  \n",
       " DEC '19     -0.019638  \n",
       " DEC '20      0.373348  \n",
       " DEC '21     -0.488245  \n",
       " DEC '22     -1.647068  \n",
       " \n",
       " [13 rows x 30 columns],\n",
       " 33:               0        1       2        3         4        5       6       7   \\\n",
       " DEC '14   37.984    8.533   0.345   29.451    49.663  -20.212  -0.081   0.000   \n",
       " DEC '15   53.821   10.521   0.759   43.300    64.386  -21.086  -0.186   0.000   \n",
       " DEC '16   85.790   16.026   1.677   69.764    92.786  -23.022  -1.028   0.000   \n",
       " DEC '17  131.607   21.815   3.957  109.792   126.201  -16.409   0.845     NaN   \n",
       " DEC '18  253.570   23.020   5.229  230.550   200.156   30.394   3.042   7.378   \n",
       " DEC '19  417.910   39.372   8.322  378.538   340.450   38.088  10.434  21.844   \n",
       " DEC '20  495.308   42.051  20.525  453.257   455.164   -1.907  14.382  38.119   \n",
       " DEC '21  536.135   55.982  32.907  480.153   616.418 -136.265  -2.058  39.208   \n",
       " DEC '22  855.354  118.744  57.504  736.610   993.883 -257.273  -3.526   9.741   \n",
       " MAR '23  896.500  124.933  57.079  771.567  1025.531 -253.964   5.384  12.580   \n",
       " \n",
       "              8        9   ...         20        21        22         23  \\\n",
       " DEC '14     NaN  -20.293  ...        NaN       NaN       NaN        NaN   \n",
       " DEC '15     NaN  -21.272  ...   0.043242  1.296296  0.000000   0.000000   \n",
       " DEC '16     NaN  -24.050  ...   0.091814  4.526882  0.000000   0.000000   \n",
       " DEC '17   2.840  -18.404  ...  -0.287247 -1.821984  0.000000   0.000000   \n",
       " DEC '18   0.624   25.434  ...  -2.852276  2.600000  0.000000  -0.780282   \n",
       " DEC '19  20.614    6.064  ...   0.253142  2.429980  1.960694  32.035256   \n",
       " DEC '20   2.001  -27.645  ...  -1.050068  0.378378  0.745056  -0.902930   \n",
       " DEC '21   0.000 -177.531  ...  70.455165 -1.143096  0.028568  -1.000000   \n",
       " DEC '22  43.238 -313.778  ...   0.888034  0.713314 -0.751556   0.000000   \n",
       " MAR '23  34.999 -296.159  ...  -0.012862 -2.526943  0.291449  -0.190550   \n",
       " \n",
       "                24        25        26        27        28        29  \n",
       " DEC '14       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       " DEC '15  0.048243  3.944444  0.055143  0.093418  0.093408  0.023154  \n",
       " DEC '16  0.130594  0.168539  0.130909  0.276347  0.276300  0.050081  \n",
       " DEC '17 -0.234761 -5.350962 -0.278630 -0.368830 -0.297189 -0.416632  \n",
       " DEC '18 -2.381982  1.857459 -2.601234 -2.331750 -2.177687 -3.860826  \n",
       " DEC '19 -0.761579  7.151199 -0.031299  0.377566 -0.086645  0.302810  \n",
       " DEC '20 -5.558872 -0.844822 -1.897985 -1.574380 -1.933468 -0.598836  \n",
       " DEC '21  5.421812 -1.657291  6.371831  6.689406  6.247154 -6.551509  \n",
       " DEC '22  0.767455  1.195814  0.772580  0.573250  0.738426  0.932787  \n",
       " MAR '23 -0.056151  0.230248 -0.051906 -0.056139 -0.057949 -0.014437  \n",
       " \n",
       " [10 rows x 30 columns],\n",
       " 34:               0        1      2       3        4       5       6      7   \\\n",
       " DEC '16   3845.0   3319.0  320.0   526.0   3549.0 -3023.0    -3.0  334.0   \n",
       " DEC '17   7932.0   5850.0  510.0  2082.0   6105.0 -4023.0   157.0  479.0   \n",
       " DEC '18  11270.0   7357.0  426.0  3913.0   6749.0 -2836.0  3498.0  648.0   \n",
       " DEC '19  13000.0   8640.0  472.0  4360.0  12956.0 -8596.0   218.0  559.0   \n",
       " DEC '20  11139.0   7198.0  575.0  3941.0   8265.0 -4324.0   190.0  458.0   \n",
       " DEC '21  17455.0  11884.0  902.0  5571.0   9365.0 -3794.0  2150.0  483.0   \n",
       " DEC '22  31877.0  22733.0  947.0  9144.0  10194.0 -1050.0     7.0  565.0   \n",
       " \n",
       "              8       9   ...        20         21        22        23  \\\n",
       " DEC '16  -142.0 -3218.0  ...       NaN        NaN       NaN       NaN   \n",
       " DEC '17   230.0 -4575.0  ...  0.330797 -53.333333  0.434132 -2.619718   \n",
       " DEC '18 -1298.0  1312.0  ... -0.295053  21.280255  0.352818 -6.643478   \n",
       " DEC '19  -504.0 -8433.0  ...  2.031030  -0.937679 -0.137346 -0.611710   \n",
       " DEC '20  2354.0 -6946.0  ... -0.496975  -0.128440 -0.180680 -5.670635   \n",
       " DEC '21 -1102.0 -1025.0  ... -0.122572  10.315789  0.054585 -1.468139   \n",
       " DEC '22  7818.0 -9426.0  ... -0.723247  -0.996744  0.169772 -8.094374   \n",
       " \n",
       "                24         25         26         27         28        29  \n",
       " DEC '16       NaN        NaN        NaN        NaN        NaN       NaN  \n",
       " DEC '17  0.421690 -20.357143   0.242452  -0.421087  -0.387927  0.299667  \n",
       " DEC '18 -1.286776  -1.522140  -1.247211  -0.765341  -1.000000 -0.313977  \n",
       " DEC '19 -7.427591  -0.840989  -9.531595  12.140903   0.000000  2.370954  \n",
       " DEC '20 -0.176331  -5.266667  -0.204326  -0.588398  -0.433371 -0.538528  \n",
       " DEC '21 -0.852433   1.562500  -0.926714  -0.770727  -0.932114 -0.228594  \n",
       " DEC '22  8.196098  -0.632114  17.429435   1.804692  16.738649 -0.964385  \n",
       " \n",
       " [7 rows x 30 columns]}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting data to be usable\n",
    "for i in range(0,len(data)):\n",
    "    data[i]=data[i].T\n",
    "    data[i]=data[i].reindex(index=data[i].index[::-1])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e80aa84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[125.14361550857902, 110.37456211263812, 92.70086140643012,\n",
       "        81.63988093383435, 66.00307854873645],\n",
       "       [25.837072554387458, 36.31746971666901, 19.039524814557755,\n",
       "        28.788846359796132, 32.73215561633034],\n",
       "       [371.33655394524965, 119.96355768135747, 124.32824229873154,\n",
       "        113.80830390731383, 163.0714262583521],\n",
       "       [408.5367829125494, 233.539776295312, 117.55570168916198,\n",
       "        92.47823059096211, 72.75903469217538],\n",
       "       [312.3091076356946, 127.54696773617744, 88.31362397285794,\n",
       "        83.67995167824375, 75.68079376328846],\n",
       "       [77.97676282051282, 87.87452445805101, 66.14944973310406,\n",
       "        43.87653920349037, 62.91589394015339],\n",
       "       [19.81132075471698, 19.759322537513, 12.467435802009676,\n",
       "        18.27707919699978, 21.95281171313998],\n",
       "       [92.77373870896675, 89.27142857142857, 82.5949128236093,\n",
       "        64.47089947089947, 52.114665433488824],\n",
       "       [40.66245540069936, 75.12176352056056, 70.81355344184568,\n",
       "        36.000893662611894, 47.28087314723782],\n",
       "       [109.47817605462082, 86.62739939702236, 60.015842720457094,\n",
       "        55.62606461973828, 46.79051430918663],\n",
       "       [49.56150967285456, 56.51042639277932, 51.271506637924865,\n",
       "        59.241536697971334, 42.41008334544109],\n",
       "       [171.53389793019377, 53.89956791140283, 49.03904059318365,\n",
       "        34.85097678353556, 29.585403351395584],\n",
       "       [50.94113579532207, 42.41957736500344, 32.62492519449432,\n",
       "        24.150699689215024, 22.922350364930338],\n",
       "       [169.57813428401664, 97.52700022040993, 103.57294293557098,\n",
       "        71.35976788461468, 68.00941702314593],\n",
       "       [44.842840982546875, 48.53911272889558, 43.04474510282578,\n",
       "        35.63617746544203, 42.10789500851699],\n",
       "       [64.32480184535349, 66.13852219102802, 59.745804607516206,\n",
       "        52.418946444446945, 42.31768814465338],\n",
       "       [106.8933370670618, 66.33354635215267, 5.881995459620703,\n",
       "        14.645376375676229, 27.515748886716622],\n",
       "       [12.427298925858004, 14.624535402612235, 24.629899937791482,\n",
       "        34.195909938389704, 26.51844450603148],\n",
       "       [76.94326098484157, 81.85256565927962, 88.35111037868799,\n",
       "        41.87746217221008, 7.597445438050589],\n",
       "       [265.3535050928699, 143.1163133942848, 115.13023095019268,\n",
       "        55.252059669668974, 51.01449860769942],\n",
       "       [316.35934890118887, 89.91402298488912, 84.28708704728454,\n",
       "        90.12132300057539, 36.59450315225269],\n",
       "       [81.82162511418576, -11.174286519538764, 11.231514181657646,\n",
       "        30.234591557680506, 34.80703759255292],\n",
       "       [80.73057121843588, 50.44182621502209, 49.25934513228741,\n",
       "        57.01525768925403, 48.92960982285659],\n",
       "       [39.913878767803915, 31.01325757575758, 25.740874593422486,\n",
       "        19.371991090033763, 15.204959971106973],\n",
       "       [59.11476453868924, 42.81139977022571, 48.96768635103853,\n",
       "        50.183261213426164, 52.28217019015958],\n",
       "       [308.2348536260033, 152.4107055849494, 65.3241978230112,\n",
       "        40.76845834415098, 32.696567593255814],\n",
       "       [39.54006686252658, 40.28967620153914, 40.615054208606104,\n",
       "        40.49334327012431, 51.083183800704646],\n",
       "       [34.269132608467636, 40.087228225491465, 40.26728376130333,\n",
       "        48.8468087643859, 46.51084116392838],\n",
       "       [52.290592899261824, 35.926534699666284, 35.19066391001805,\n",
       "        38.94637280678602, 49.18791216576264],\n",
       "       [52.997706184133584, 29.78454688381535, 5.19343915315879,\n",
       "        13.500454714321569, 12.327018763644514],\n",
       "       [111.91751360013495, 104.64061131895247, 99.57310669415381,\n",
       "        89.70146126597574, 72.93915187630031],\n",
       "       [15.508789836290141, 24.018416677324467, 19.800406873728512,\n",
       "        19.27379438520983, -1.1353720385521342],\n",
       "       [41.69387110362256, 59.39874770071164, 53.40599137428603,\n",
       "        92.67212230352489, 64.81050597468156],\n",
       "       [106.29388816644993, 42.08270297528996, 15.350488021295474,\n",
       "        -14.315384615384616, 56.701678786246525]], dtype=object)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding input features\n",
    "\n",
    "m = 50\n",
    "x1 = data[0][15][1:6]*100\n",
    "x2 = data[1][15][1:6]*100\n",
    "x3 = data[2][15][1:6]*100\n",
    "x4 = data[3][15][1:6]*100\n",
    "x5 = data[4][15][1:6]*100\n",
    "x6 = data[5][15][1:6]*100\n",
    "x7 = data[6][15][1:6]*100\n",
    "x8 = data[7][15][1:6]*100\n",
    "x9 = data[8][15][1:6]*100\n",
    "\n",
    "x10 = data[9][15][1:6]*100\n",
    "x11 = data[10][15][1:6]*100\n",
    "x12 = data[11][15][1:6]*100\n",
    "x13 = data[12][15][1:6]*100\n",
    "x14 = data[13][15][1:6]*100\n",
    "x15 = data[14][15][1:6]*100\n",
    "x16 = data[15][15][1:6]*100\n",
    "x17 = data[16][15][1:6] *100\n",
    "x18 = data[17][15][1:6]*100\n",
    "x19 = data[18][15][1:6]*100\n",
    "\n",
    "x20 = data[19][15][1:6]*100\n",
    "x21 = data[20][15][1:6]*100\n",
    "x22 = data[21][15][1:6]*100\n",
    "x23 = data[22][15][1:6]*100\n",
    "x24 = data[23][15][1:6]*100\n",
    "x25 = data[24][15][1:6]*100\n",
    "x26 = data[25][15][1:6]*100\n",
    "x27 = data[26][15][1:6]*100\n",
    "x28 = data[27][15][1:6]*100\n",
    "x29 = data[28][15][1:6]*100\n",
    "\n",
    "x30 = data[29][15][1:6]*100\n",
    "x31 = data[30][15][1:6]*100\n",
    "x32 = data[31][15][1:6]*100\n",
    "#x33 = data[32][15][1:6]*100\n",
    "x34 = data[33][15][1:6]*100\n",
    "x35 = data[34][15][1:6]*100\n",
    "\n",
    "\n",
    "\n",
    "X = np.array((x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13, x14, x15, x16, x17, x18, x19, x20, x21, x22, x23, x24, x25, x26, x27, x28, x29, x30, x31, x32, x34, x35))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "dc0bb66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding y vector -> validate results\n",
    "X = np.array((x1, x2, x3, x4, x5, x6, x7, x8, x9, x10))\n",
    "    \n",
    "# y vector\n",
    "y = np.array((data[0][15][6]*100, data[1][15][6]*100, data[2][15][6]*100, data[3][15][6]*100, data[4][15][6]*100, data[5][15][6]*100, data[6][15][6]*100,data[7][15][6]*100,data[8][15][6]*100,data[9][15][6]*100))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5126f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f2b7107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN_model = Sequential()\n",
    "\n",
    "# # The Input Layer :\n",
    "# NN_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "# # The Hidden Layers :\n",
    "# NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "# NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "# NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# # The Output Layer :\n",
    "# NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# # Compile the network :\n",
    "# NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "# NN_model.summary()\n",
    "\n",
    "def build_model(n_hidden=2, n_neurons=300, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam',\n",
    "              metrics=[\"mean_absolute_error\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "493d68c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 14.4845 - mean_absolute_error: 3.2233\n",
      "Epoch 1: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 14.4845 - mean_absolute_error: 3.2233 - val_loss: 2794.9028 - val_mean_absolute_error: 52.8238\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.7798 - mean_absolute_error: 2.0773\n",
      "Epoch 2: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.7798 - mean_absolute_error: 2.0773 - val_loss: 2708.9590 - val_mean_absolute_error: 52.0033\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.9110 - mean_absolute_error: 2.5744\n",
      "Epoch 3: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 8.9110 - mean_absolute_error: 2.5744 - val_loss: 2839.2034 - val_mean_absolute_error: 53.2221\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.6337 - mean_absolute_error: 1.7472\n",
      "Epoch 4: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.6337 - mean_absolute_error: 1.7472 - val_loss: 3005.7559 - val_mean_absolute_error: 54.7402\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6064 - mean_absolute_error: 0.9022\n",
      "Epoch 5: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6064 - mean_absolute_error: 0.9022 - val_loss: 3126.9507 - val_mean_absolute_error: 55.8154\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2491 - mean_absolute_error: 1.3255\n",
      "Epoch 6: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2491 - mean_absolute_error: 1.3255 - val_loss: 3160.2764 - val_mean_absolute_error: 56.1017\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.0880 - mean_absolute_error: 1.4962\n",
      "Epoch 7: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0880 - mean_absolute_error: 1.4962 - val_loss: 3118.9897 - val_mean_absolute_error: 55.7309\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.9960 - mean_absolute_error: 1.3078\n",
      "Epoch 8: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.9960 - mean_absolute_error: 1.3078 - val_loss: 3036.0396 - val_mean_absolute_error: 54.9875\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6540 - mean_absolute_error: 1.0389\n",
      "Epoch 9: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6540 - mean_absolute_error: 1.0389 - val_loss: 2941.1699 - val_mean_absolute_error: 54.1265\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4623 - mean_absolute_error: 1.0374\n",
      "Epoch 10: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4623 - mean_absolute_error: 1.0374 - val_loss: 2872.0654 - val_mean_absolute_error: 53.4901\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2989 - mean_absolute_error: 1.4492\n",
      "Epoch 11: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.2989 - mean_absolute_error: 1.4492 - val_loss: 2854.2153 - val_mean_absolute_error: 53.3239\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.6310 - mean_absolute_error: 1.5567\n",
      "Epoch 12: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.6310 - mean_absolute_error: 1.5567 - val_loss: 2880.9805 - val_mean_absolute_error: 53.5714\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1052 - mean_absolute_error: 1.3937\n",
      "Epoch 13: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.1052 - mean_absolute_error: 1.3937 - val_loss: 2934.0334 - val_mean_absolute_error: 54.0585\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4400 - mean_absolute_error: 1.0725\n",
      "Epoch 14: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4400 - mean_absolute_error: 1.0725 - val_loss: 2993.8120 - val_mean_absolute_error: 54.6025\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2530 - mean_absolute_error: 0.8923\n",
      "Epoch 15: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2530 - mean_absolute_error: 0.8923 - val_loss: 3042.6001 - val_mean_absolute_error: 55.0420\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5298 - mean_absolute_error: 1.0539\n",
      "Epoch 16: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.5298 - mean_absolute_error: 1.0539 - val_loss: 3067.4199 - val_mean_absolute_error: 55.2645\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7859 - mean_absolute_error: 1.1267\n",
      "Epoch 17: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7859 - mean_absolute_error: 1.1267 - val_loss: 3066.6707 - val_mean_absolute_error: 55.2579\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7335 - mean_absolute_error: 1.1130\n",
      "Epoch 18: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.7335 - mean_absolute_error: 1.1130 - val_loss: 3046.1069 - val_mean_absolute_error: 55.0734\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4393 - mean_absolute_error: 1.0295\n",
      "Epoch 19: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4393 - mean_absolute_error: 1.0295 - val_loss: 3012.9734 - val_mean_absolute_error: 54.7750\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1673 - mean_absolute_error: 0.9091\n",
      "Epoch 20: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1673 - mean_absolute_error: 0.9091 - val_loss: 2976.8335 - val_mean_absolute_error: 54.4473\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0914 - mean_absolute_error: 0.8134\n",
      "Epoch 21: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0914 - mean_absolute_error: 0.8134 - val_loss: 2946.9746 - val_mean_absolute_error: 54.1753\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1939 - mean_absolute_error: 0.9889\n",
      "Epoch 22: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1939 - mean_absolute_error: 0.9889 - val_loss: 2931.2075 - val_mean_absolute_error: 54.0320\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3058 - mean_absolute_error: 1.0822\n",
      "Epoch 23: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3058 - mean_absolute_error: 1.0822 - val_loss: 2932.4775 - val_mean_absolute_error: 54.0453\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2768 - mean_absolute_error: 1.0724\n",
      "Epoch 24: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2768 - mean_absolute_error: 1.0724 - val_loss: 2949.0239 - val_mean_absolute_error: 54.1989\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1259 - mean_absolute_error: 0.9719\n",
      "Epoch 25: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1259 - mean_absolute_error: 0.9719 - val_loss: 2975.1418 - val_mean_absolute_error: 54.4396\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9809 - mean_absolute_error: 0.8126\n",
      "Epoch 26: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9809 - mean_absolute_error: 0.8126 - val_loss: 3003.5635 - val_mean_absolute_error: 54.6998\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9453 - mean_absolute_error: 0.7659\n",
      "Epoch 27: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9453 - mean_absolute_error: 0.7659 - val_loss: 3026.3796 - val_mean_absolute_error: 54.9075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9941 - mean_absolute_error: 0.8211\n",
      "Epoch 28: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9941 - mean_absolute_error: 0.8211 - val_loss: 3036.6965 - val_mean_absolute_error: 55.0012\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0280 - mean_absolute_error: 0.8437\n",
      "Epoch 29: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0280 - mean_absolute_error: 0.8437 - val_loss: 3033.7690 - val_mean_absolute_error: 54.9743\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9782 - mean_absolute_error: 0.8261\n",
      "Epoch 30: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9782 - mean_absolute_error: 0.8261 - val_loss: 3019.5527 - val_mean_absolute_error: 54.8448\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8733 - mean_absolute_error: 0.7732\n",
      "Epoch 31: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8733 - mean_absolute_error: 0.7732 - val_loss: 2999.2019 - val_mean_absolute_error: 54.6601\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7957 - mean_absolute_error: 0.7009\n",
      "Epoch 32: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7957 - mean_absolute_error: 0.7009 - val_loss: 2979.9229 - val_mean_absolute_error: 54.4846\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7846 - mean_absolute_error: 0.7367\n",
      "Epoch 33: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7846 - mean_absolute_error: 0.7367 - val_loss: 2969.8516 - val_mean_absolute_error: 54.3930\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7990 - mean_absolute_error: 0.7958\n",
      "Epoch 34: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7990 - mean_absolute_error: 0.7958 - val_loss: 2974.3711 - val_mean_absolute_error: 54.4350\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7654 - mean_absolute_error: 0.7715\n",
      "Epoch 35: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7654 - mean_absolute_error: 0.7715 - val_loss: 2991.3301 - val_mean_absolute_error: 54.5912\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6922 - mean_absolute_error: 0.6777\n",
      "Epoch 36: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6922 - mean_absolute_error: 0.6777 - val_loss: 3013.3557 - val_mean_absolute_error: 54.7931\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6541 - mean_absolute_error: 0.6335\n",
      "Epoch 37: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6541 - mean_absolute_error: 0.6335 - val_loss: 3029.4453 - val_mean_absolute_error: 54.9403\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6513 - mean_absolute_error: 0.6553\n",
      "Epoch 38: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6513 - mean_absolute_error: 0.6553 - val_loss: 3032.1748 - val_mean_absolute_error: 54.9657\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6265 - mean_absolute_error: 0.6434\n",
      "Epoch 39: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6265 - mean_absolute_error: 0.6434 - val_loss: 3023.0654 - val_mean_absolute_error: 54.8828\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5651 - mean_absolute_error: 0.6000\n",
      "Epoch 40: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5651 - mean_absolute_error: 0.6000 - val_loss: 3009.1399 - val_mean_absolute_error: 54.7557\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5272 - mean_absolute_error: 0.5605\n",
      "Epoch 41: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5272 - mean_absolute_error: 0.5605 - val_loss: 2999.3491 - val_mean_absolute_error: 54.6663\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5174 - mean_absolute_error: 0.6097\n",
      "Epoch 42: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5174 - mean_absolute_error: 0.6097 - val_loss: 2999.9482 - val_mean_absolute_error: 54.6725\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4900 - mean_absolute_error: 0.6024\n",
      "Epoch 43: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4900 - mean_absolute_error: 0.6024 - val_loss: 3010.9355 - val_mean_absolute_error: 54.7741\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4414 - mean_absolute_error: 0.5391\n",
      "Epoch 44: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4414 - mean_absolute_error: 0.5391 - val_loss: 3027.0620 - val_mean_absolute_error: 54.9226\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4046 - mean_absolute_error: 0.4919\n",
      "Epoch 45: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4046 - mean_absolute_error: 0.4919 - val_loss: 3040.2358 - val_mean_absolute_error: 55.0437\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3878 - mean_absolute_error: 0.4982\n",
      "Epoch 46: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3878 - mean_absolute_error: 0.4982 - val_loss: 3044.5088 - val_mean_absolute_error: 55.0833\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3647 - mean_absolute_error: 0.4852\n",
      "Epoch 47: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3647 - mean_absolute_error: 0.4852 - val_loss: 3038.2930 - val_mean_absolute_error: 55.0269\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3179 - mean_absolute_error: 0.4471\n",
      "Epoch 48: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3179 - mean_absolute_error: 0.4471 - val_loss: 3028.0796 - val_mean_absolute_error: 54.9340\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2883 - mean_absolute_error: 0.4213\n",
      "Epoch 49: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2883 - mean_absolute_error: 0.4213 - val_loss: 3022.2681 - val_mean_absolute_error: 54.8815\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2720 - mean_absolute_error: 0.4423\n",
      "Epoch 50: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2720 - mean_absolute_error: 0.4423 - val_loss: 3027.0015 - val_mean_absolute_error: 54.9262\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2415 - mean_absolute_error: 0.4135\n",
      "Epoch 51: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2415 - mean_absolute_error: 0.4135 - val_loss: 3039.9080 - val_mean_absolute_error: 55.0457\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2065 - mean_absolute_error: 0.3472\n",
      "Epoch 52: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2065 - mean_absolute_error: 0.3472 - val_loss: 3053.5715 - val_mean_absolute_error: 55.1719\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1868 - mean_absolute_error: 0.3354\n",
      "Epoch 53: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1868 - mean_absolute_error: 0.3354 - val_loss: 3060.0200 - val_mean_absolute_error: 55.2318\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1679 - mean_absolute_error: 0.3189\n",
      "Epoch 54: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1679 - mean_absolute_error: 0.3189 - val_loss: 3056.9604 - val_mean_absolute_error: 55.2046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1383 - mean_absolute_error: 0.2823\n",
      "Epoch 55: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1383 - mean_absolute_error: 0.2823 - val_loss: 3049.3789 - val_mean_absolute_error: 55.1358\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1189 - mean_absolute_error: 0.2658\n",
      "Epoch 56: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1189 - mean_absolute_error: 0.2658 - val_loss: 3045.9524 - val_mean_absolute_error: 55.1051\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1073 - mean_absolute_error: 0.2737\n",
      "Epoch 57: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1073 - mean_absolute_error: 0.2737 - val_loss: 3052.5000 - val_mean_absolute_error: 55.1660\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0877 - mean_absolute_error: 0.2360\n",
      "Epoch 58: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0877 - mean_absolute_error: 0.2360 - val_loss: 3065.0894 - val_mean_absolute_error: 55.2822\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0714 - mean_absolute_error: 0.1987\n",
      "Epoch 59: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0714 - mean_absolute_error: 0.1987 - val_loss: 3074.6074 - val_mean_absolute_error: 55.3700\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0636 - mean_absolute_error: 0.2082\n",
      "Epoch 60: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0636 - mean_absolute_error: 0.2082 - val_loss: 3074.9832 - val_mean_absolute_error: 55.3740\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0486 - mean_absolute_error: 0.1817\n",
      "Epoch 61: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0486 - mean_absolute_error: 0.1817 - val_loss: 3069.6650 - val_mean_absolute_error: 55.3260\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0382 - mean_absolute_error: 0.1515\n",
      "Epoch 62: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0382 - mean_absolute_error: 0.1515 - val_loss: 3067.1460 - val_mean_absolute_error: 55.3038\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0346 - mean_absolute_error: 0.1536\n",
      "Epoch 63: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0346 - mean_absolute_error: 0.1536 - val_loss: 3072.4763 - val_mean_absolute_error: 55.3535\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0271 - mean_absolute_error: 0.1350\n",
      "Epoch 64: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0271 - mean_absolute_error: 0.1350 - val_loss: 3082.3796 - val_mean_absolute_error: 55.4449\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0215 - mean_absolute_error: 0.1059\n",
      "Epoch 65: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0215 - mean_absolute_error: 0.1059 - val_loss: 3089.0732 - val_mean_absolute_error: 55.5067\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0203 - mean_absolute_error: 0.1117\n",
      "Epoch 66: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0203 - mean_absolute_error: 0.1117 - val_loss: 3088.2703 - val_mean_absolute_error: 55.4998\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0154 - mean_absolute_error: 0.0865\n",
      "Epoch 67: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0154 - mean_absolute_error: 0.0865 - val_loss: 3083.5894 - val_mean_absolute_error: 55.4574\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0127 - mean_absolute_error: 0.0790\n",
      "Epoch 68: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0127 - mean_absolute_error: 0.0790 - val_loss: 3082.2993 - val_mean_absolute_error: 55.4457\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0120 - mean_absolute_error: 0.0875\n",
      "Epoch 69: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0120 - mean_absolute_error: 0.0875 - val_loss: 3087.0601 - val_mean_absolute_error: 55.4891\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0087 - mean_absolute_error: 0.0670\n",
      "Epoch 70: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0087 - mean_absolute_error: 0.0670 - val_loss: 3091.0481 - val_mean_absolute_error: 55.5259\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0091 - mean_absolute_error: 0.0760\n",
      "Epoch 71: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0091 - mean_absolute_error: 0.0760 - val_loss: 3087.3667 - val_mean_absolute_error: 55.4924\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - mean_absolute_error: 0.0505\n",
      "Epoch 72: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0054 - mean_absolute_error: 0.0505 - val_loss: 3083.3552 - val_mean_absolute_error: 55.4556\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - mean_absolute_error: 0.0532\n",
      "Epoch 73: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0056 - mean_absolute_error: 0.0532 - val_loss: 3085.7810 - val_mean_absolute_error: 55.4775\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0038 - mean_absolute_error: 0.0406\n",
      "Epoch 74: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0038 - mean_absolute_error: 0.0406 - val_loss: 3091.0498 - val_mean_absolute_error: 55.5252\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0034 - mean_absolute_error: 0.0490\n",
      "Epoch 75: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0034 - mean_absolute_error: 0.0490 - val_loss: 3091.5063 - val_mean_absolute_error: 55.5289\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0032 - mean_absolute_error: 0.0500\n",
      "Epoch 76: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0032 - mean_absolute_error: 0.0500 - val_loss: 3086.7339 - val_mean_absolute_error: 55.4850\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0316\n",
      "Epoch 77: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0019 - mean_absolute_error: 0.0316 - val_loss: 3084.8384 - val_mean_absolute_error: 55.4676\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.0438\n",
      "Epoch 78: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0025 - mean_absolute_error: 0.0438 - val_loss: 3088.7583 - val_mean_absolute_error: 55.5038\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0248\n",
      "Epoch 79: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0010 - mean_absolute_error: 0.0248 - val_loss: 3091.3555 - val_mean_absolute_error: 55.5281\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0387\n",
      "Epoch 80: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0019 - mean_absolute_error: 0.0387 - val_loss: 3087.3970 - val_mean_absolute_error: 55.4923\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.3862e-04 - mean_absolute_error: 0.0174\n",
      "Epoch 81: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.3862e-04 - mean_absolute_error: 0.0174 - val_loss: 3085.5186 - val_mean_absolute_error: 55.4756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0349\n",
      "Epoch 82: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0014 - mean_absolute_error: 0.0349 - val_loss: 3090.2896 - val_mean_absolute_error: 55.5197\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.5237e-04 - mean_absolute_error: 0.0220\n",
      "Epoch 83: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.5237e-04 - mean_absolute_error: 0.0220 - val_loss: 3092.1455 - val_mean_absolute_error: 55.5367\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.7185e-04 - mean_absolute_error: 0.0225\n",
      "Epoch 84: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.7185e-04 - mean_absolute_error: 0.0225 - val_loss: 3088.4766 - val_mean_absolute_error: 55.5026\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.6892e-04 - mean_absolute_error: 0.0178\n",
      "Epoch 85: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6892e-04 - mean_absolute_error: 0.0178 - val_loss: 3089.0503 - val_mean_absolute_error: 55.5076\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.9442e-04 - mean_absolute_error: 0.0183\n",
      "Epoch 86: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.9442e-04 - mean_absolute_error: 0.0183 - val_loss: 3093.5693 - val_mean_absolute_error: 55.5493\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.1162e-04 - mean_absolute_error: 0.0200\n",
      "Epoch 87: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6.1162e-04 - mean_absolute_error: 0.0200 - val_loss: 3092.8823 - val_mean_absolute_error: 55.5435\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0800e-04 - mean_absolute_error: 0.0141\n",
      "Epoch 88: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.0800e-04 - mean_absolute_error: 0.0141 - val_loss: 3089.6567 - val_mean_absolute_error: 55.5141\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.9842e-04 - mean_absolute_error: 0.0218\n",
      "Epoch 89: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.9842e-04 - mean_absolute_error: 0.0218 - val_loss: 3091.3755 - val_mean_absolute_error: 55.5301\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1316e-04 - mean_absolute_error: 0.0142\n",
      "Epoch 90: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.1316e-04 - mean_absolute_error: 0.0142 - val_loss: 3093.3369 - val_mean_absolute_error: 55.5482\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.5821e-04 - mean_absolute_error: 0.0225\n",
      "Epoch 91: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.5821e-04 - mean_absolute_error: 0.0225 - val_loss: 3090.3452 - val_mean_absolute_error: 55.5204\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3788e-04 - mean_absolute_error: 0.0122\n",
      "Epoch 92: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3788e-04 - mean_absolute_error: 0.0122 - val_loss: 3088.7183 - val_mean_absolute_error: 55.5054\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.4504e-04 - mean_absolute_error: 0.0217\n",
      "Epoch 93: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.4504e-04 - mean_absolute_error: 0.0217 - val_loss: 3091.4082 - val_mean_absolute_error: 55.5303\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.8059e-04 - mean_absolute_error: 0.0167\n",
      "Epoch 94: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.8059e-04 - mean_absolute_error: 0.0167 - val_loss: 3091.5674 - val_mean_absolute_error: 55.5319\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.7313e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 95: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.7313e-04 - mean_absolute_error: 0.0158 - val_loss: 3089.1016 - val_mean_absolute_error: 55.5093\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.4757e-04 - mean_absolute_error: 0.0196\n",
      "Epoch 96: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.4757e-04 - mean_absolute_error: 0.0196 - val_loss: 3090.1050 - val_mean_absolute_error: 55.5184\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.8881e-04 - mean_absolute_error: 0.0125\n",
      "Epoch 97: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8881e-04 - mean_absolute_error: 0.0125 - val_loss: 3091.8809 - val_mean_absolute_error: 55.5346\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.3417e-04 - mean_absolute_error: 0.0196\n",
      "Epoch 98: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.3417e-04 - mean_absolute_error: 0.0196 - val_loss: 3089.9609 - val_mean_absolute_error: 55.5167\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3780e-04 - mean_absolute_error: 0.0122\n",
      "Epoch 99: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3780e-04 - mean_absolute_error: 0.0122 - val_loss: 3088.7856 - val_mean_absolute_error: 55.5057\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.5514e-04 - mean_absolute_error: 0.0174\n",
      "Epoch 100: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5514e-04 - mean_absolute_error: 0.0174 - val_loss: 3090.6436 - val_mean_absolute_error: 55.5230\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3493e-04 - mean_absolute_error: 0.0134\n",
      "Epoch 101: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3493e-04 - mean_absolute_error: 0.0134 - val_loss: 3090.5811 - val_mean_absolute_error: 55.5227\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.9040e-04 - mean_absolute_error: 0.0114\n",
      "Epoch 102: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.9040e-04 - mean_absolute_error: 0.0114 - val_loss: 3088.7375 - val_mean_absolute_error: 55.5058\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2134e-04 - mean_absolute_error: 0.0154\n",
      "Epoch 103: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2134e-04 - mean_absolute_error: 0.0154 - val_loss: 3089.5820 - val_mean_absolute_error: 55.5137\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9749e-04 - mean_absolute_error: 0.0102\n",
      "Epoch 104: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9749e-04 - mean_absolute_error: 0.0102 - val_loss: 3090.7336 - val_mean_absolute_error: 55.5242\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4210e-04 - mean_absolute_error: 0.0121\n",
      "Epoch 105: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4210e-04 - mean_absolute_error: 0.0121 - val_loss: 3089.3076 - val_mean_absolute_error: 55.5109\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2728e-04 - mean_absolute_error: 0.0080\n",
      "Epoch 106: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2728e-04 - mean_absolute_error: 0.0080 - val_loss: 3089.0547 - val_mean_absolute_error: 55.5085\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4291e-04 - mean_absolute_error: 0.0102\n",
      "Epoch 107: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4291e-04 - mean_absolute_error: 0.0102 - val_loss: 3090.3232 - val_mean_absolute_error: 55.5202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0986e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 108: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0986e-04 - mean_absolute_error: 0.0087 - val_loss: 3089.9609 - val_mean_absolute_error: 55.5169\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.3546e-05 - mean_absolute_error: 0.0052\n",
      "Epoch 109: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.3546e-05 - mean_absolute_error: 0.0052 - val_loss: 3088.9478 - val_mean_absolute_error: 55.5077\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.4241e-05 - mean_absolute_error: 0.0086\n",
      "Epoch 110: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.4241e-05 - mean_absolute_error: 0.0086 - val_loss: 3089.7378 - val_mean_absolute_error: 55.5150\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.7771e-05 - mean_absolute_error: 0.0037\n",
      "Epoch 111: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.7771e-05 - mean_absolute_error: 0.0037 - val_loss: 3090.1299 - val_mean_absolute_error: 55.5186\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.0318e-05 - mean_absolute_error: 0.0062\n",
      "Epoch 112: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.0318e-05 - mean_absolute_error: 0.0062 - val_loss: 3089.1152 - val_mean_absolute_error: 55.5092\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.5808e-05 - mean_absolute_error: 0.0049\n",
      "Epoch 113: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5808e-05 - mean_absolute_error: 0.0049 - val_loss: 3089.2251 - val_mean_absolute_error: 55.5103\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.5007e-05 - mean_absolute_error: 0.0033\n",
      "Epoch 114: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.5007e-05 - mean_absolute_error: 0.0033 - val_loss: 3089.9497 - val_mean_absolute_error: 55.5169\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.5535e-05 - mean_absolute_error: 0.0049\n",
      "Epoch 115: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5535e-05 - mean_absolute_error: 0.0049 - val_loss: 3089.2910 - val_mean_absolute_error: 55.5109\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0886e-05 - mean_absolute_error: 0.0027\n",
      "Epoch 116: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0886e-05 - mean_absolute_error: 0.0027 - val_loss: 3088.8652 - val_mean_absolute_error: 55.5070\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.5047e-05 - mean_absolute_error: 0.0051\n",
      "Epoch 117: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5047e-05 - mean_absolute_error: 0.0051 - val_loss: 3089.6167 - val_mean_absolute_error: 55.5138\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0559e-05 - mean_absolute_error: 0.0036\n",
      "Epoch 118: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0559e-05 - mean_absolute_error: 0.0036 - val_loss: 3089.5234 - val_mean_absolute_error: 55.5129\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3478e-05 - mean_absolute_error: 0.0031\n",
      "Epoch 119: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3478e-05 - mean_absolute_error: 0.0031 - val_loss: 3088.8540 - val_mean_absolute_error: 55.5067\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.9913e-05 - mean_absolute_error: 0.0050\n",
      "Epoch 120: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.9913e-05 - mean_absolute_error: 0.0050 - val_loss: 3089.2319 - val_mean_absolute_error: 55.5102\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.6799e-06 - mean_absolute_error: 0.0023\n",
      "Epoch 121: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.6799e-06 - mean_absolute_error: 0.0023 - val_loss: 3089.4053 - val_mean_absolute_error: 55.5118\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1226e-05 - mean_absolute_error: 0.0044\n",
      "Epoch 122: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.1226e-05 - mean_absolute_error: 0.0044 - val_loss: 3088.6892 - val_mean_absolute_error: 55.5053\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7386e-05 - mean_absolute_error: 0.0036\n",
      "Epoch 123: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7386e-05 - mean_absolute_error: 0.0036 - val_loss: 3088.7329 - val_mean_absolute_error: 55.5057\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4375e-05 - mean_absolute_error: 0.0033\n",
      "Epoch 124: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4375e-05 - mean_absolute_error: 0.0033 - val_loss: 3089.1943 - val_mean_absolute_error: 55.5099\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4263e-05 - mean_absolute_error: 0.0042\n",
      "Epoch 125: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.4263e-05 - mean_absolute_error: 0.0042 - val_loss: 3088.8120 - val_mean_absolute_error: 55.5064\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3034e-05 - mean_absolute_error: 0.0027\n",
      "Epoch 126: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3034e-05 - mean_absolute_error: 0.0027 - val_loss: 3088.6978 - val_mean_absolute_error: 55.5053\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9866e-05 - mean_absolute_error: 0.0034\n",
      "Epoch 127: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9866e-05 - mean_absolute_error: 0.0034 - val_loss: 3089.2144 - val_mean_absolute_error: 55.5100\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8836e-05 - mean_absolute_error: 0.0037\n",
      "Epoch 128: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8836e-05 - mean_absolute_error: 0.0037 - val_loss: 3089.0503 - val_mean_absolute_error: 55.5085\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1772e-05 - mean_absolute_error: 0.0025\n",
      "Epoch 129: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1772e-05 - mean_absolute_error: 0.0025 - val_loss: 3088.7708 - val_mean_absolute_error: 55.5060\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9234e-05 - mean_absolute_error: 0.0036\n",
      "Epoch 130: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9234e-05 - mean_absolute_error: 0.0036 - val_loss: 3089.1912 - val_mean_absolute_error: 55.5099\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2380e-05 - mean_absolute_error: 0.0027\n",
      "Epoch 131: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2380e-05 - mean_absolute_error: 0.0027 - val_loss: 3089.2271 - val_mean_absolute_error: 55.5102\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0559e-05 - mean_absolute_error: 0.0026\n",
      "Epoch 132: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0559e-05 - mean_absolute_error: 0.0026 - val_loss: 3088.9033 - val_mean_absolute_error: 55.5072\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3540e-05 - mean_absolute_error: 0.0029\n",
      "Epoch 133: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3540e-05 - mean_absolute_error: 0.0029 - val_loss: 3089.1763 - val_mean_absolute_error: 55.5098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.3827e-06 - mean_absolute_error: 0.0021\n",
      "Epoch 134: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.3827e-06 - mean_absolute_error: 0.0021 - val_loss: 3089.3057 - val_mean_absolute_error: 55.5110\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.0961e-06 - mean_absolute_error: 0.0026\n",
      "Epoch 135: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 9.0961e-06 - mean_absolute_error: 0.0026 - val_loss: 3088.9863 - val_mean_absolute_error: 55.5081\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.4052e-06 - mean_absolute_error: 0.0024\n",
      "Epoch 136: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 8.4052e-06 - mean_absolute_error: 0.0024 - val_loss: 3089.1553 - val_mean_absolute_error: 55.5096\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.5190e-06 - mean_absolute_error: 0.0016\n",
      "Epoch 137: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5190e-06 - mean_absolute_error: 0.0016 - val_loss: 3089.3813 - val_mean_absolute_error: 55.5117\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.5233e-06 - mean_absolute_error: 0.0024\n",
      "Epoch 138: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.5233e-06 - mean_absolute_error: 0.0024 - val_loss: 3089.1353 - val_mean_absolute_error: 55.5094\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.3329e-06 - mean_absolute_error: 0.0016\n",
      "Epoch 139: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3329e-06 - mean_absolute_error: 0.0016 - val_loss: 3089.2012 - val_mean_absolute_error: 55.5100\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.9744e-06 - mean_absolute_error: 0.0013\n",
      "Epoch 140: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.9744e-06 - mean_absolute_error: 0.0013 - val_loss: 3089.3965 - val_mean_absolute_error: 55.5118\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.4173e-06 - mean_absolute_error: 0.0020\n",
      "Epoch 141: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4173e-06 - mean_absolute_error: 0.0020 - val_loss: 3089.1475 - val_mean_absolute_error: 55.5095\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9103e-06 - mean_absolute_error: 0.0011\n",
      "Epoch 142: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9103e-06 - mean_absolute_error: 0.0011 - val_loss: 3089.1211 - val_mean_absolute_error: 55.5093\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8459e-06 - mean_absolute_error: 0.0012\n",
      "Epoch 143: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8459e-06 - mean_absolute_error: 0.0012 - val_loss: 3089.3169 - val_mean_absolute_error: 55.5111\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.8172e-06 - mean_absolute_error: 0.0014\n",
      "Epoch 144: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.8172e-06 - mean_absolute_error: 0.0014 - val_loss: 3089.1499 - val_mean_absolute_error: 55.5095\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.1353e-07 - mean_absolute_error: 8.1833e-04\n",
      "Epoch 145: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 9.1353e-07 - mean_absolute_error: 8.1833e-04 - val_loss: 3089.1294 - val_mean_absolute_error: 55.5093\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3907e-06 - mean_absolute_error: 0.0010\n",
      "Epoch 146: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3907e-06 - mean_absolute_error: 0.0010 - val_loss: 3089.3296 - val_mean_absolute_error: 55.5112\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8150e-06 - mean_absolute_error: 0.0011\n",
      "Epoch 147: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8150e-06 - mean_absolute_error: 0.0011 - val_loss: 3089.2053 - val_mean_absolute_error: 55.5100\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3401e-07 - mean_absolute_error: 3.9535e-04\n",
      "Epoch 148: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3401e-07 - mean_absolute_error: 3.9535e-04 - val_loss: 3089.1750 - val_mean_absolute_error: 55.5098\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.5629e-07 - mean_absolute_error: 7.3941e-04\n",
      "Epoch 149: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.5629e-07 - mean_absolute_error: 7.3941e-04 - val_loss: 3089.3608 - val_mean_absolute_error: 55.5115\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2576e-06 - mean_absolute_error: 9.7017e-04\n",
      "Epoch 150: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2576e-06 - mean_absolute_error: 9.7017e-04 - val_loss: 3089.2690 - val_mean_absolute_error: 55.5106\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8573e-07 - mean_absolute_error: 4.0302e-04\n",
      "Epoch 151: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8573e-07 - mean_absolute_error: 4.0302e-04 - val_loss: 3089.2393 - val_mean_absolute_error: 55.5104\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.9653e-07 - mean_absolute_error: 7.2793e-04\n",
      "Epoch 152: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.9653e-07 - mean_absolute_error: 7.2793e-04 - val_loss: 3089.3904 - val_mean_absolute_error: 55.5118\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.7065e-07 - mean_absolute_error: 9.0204e-04\n",
      "Epoch 153: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.7065e-07 - mean_absolute_error: 9.0204e-04 - val_loss: 3089.2949 - val_mean_absolute_error: 55.5109\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.8584e-07 - mean_absolute_error: 4.2281e-04\n",
      "Epoch 154: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.8584e-07 - mean_absolute_error: 4.2281e-04 - val_loss: 3089.2642 - val_mean_absolute_error: 55.5106\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.3017e-07 - mean_absolute_error: 7.4816e-04\n",
      "Epoch 155: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.3017e-07 - mean_absolute_error: 7.4816e-04 - val_loss: 3089.4009 - val_mean_absolute_error: 55.5119\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0007e-06 - mean_absolute_error: 8.9792e-04\n",
      "Epoch 156: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0007e-06 - mean_absolute_error: 8.9792e-04 - val_loss: 3089.3276 - val_mean_absolute_error: 55.5112\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.5284e-07 - mean_absolute_error: 5.6770e-04\n",
      "Epoch 157: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5284e-07 - mean_absolute_error: 5.6770e-04 - val_loss: 3089.3198 - val_mean_absolute_error: 55.5111\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.8476e-07 - mean_absolute_error: 6.9979e-04\n",
      "Epoch 158: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.8476e-07 - mean_absolute_error: 6.9979e-04 - val_loss: 3089.4287 - val_mean_absolute_error: 55.5121\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.3728e-07 - mean_absolute_error: 8.8130e-04\n",
      "Epoch 159: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.3728e-07 - mean_absolute_error: 8.8130e-04 - val_loss: 3089.3357 - val_mean_absolute_error: 55.5113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.0547e-07 - mean_absolute_error: 5.8988e-04\n",
      "Epoch 160: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.0547e-07 - mean_absolute_error: 5.8988e-04 - val_loss: 3089.3179 - val_mean_absolute_error: 55.5111\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.2263e-07 - mean_absolute_error: 5.5974e-04\n",
      "Epoch 161: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.2263e-07 - mean_absolute_error: 5.5974e-04 - val_loss: 3089.3896 - val_mean_absolute_error: 55.5118\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.1260e-07 - mean_absolute_error: 7.4542e-04\n",
      "Epoch 162: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.1260e-07 - mean_absolute_error: 7.4542e-04 - val_loss: 3089.2974 - val_mean_absolute_error: 55.5109\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.0975e-07 - mean_absolute_error: 5.2589e-04\n",
      "Epoch 163: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0975e-07 - mean_absolute_error: 5.2589e-04 - val_loss: 3089.3018 - val_mean_absolute_error: 55.5109\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3884e-07 - mean_absolute_error: 4.2967e-04\n",
      "Epoch 164: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3884e-07 - mean_absolute_error: 4.2967e-04 - val_loss: 3089.3574 - val_mean_absolute_error: 55.5115\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.1701e-07 - mean_absolute_error: 5.7744e-04\n",
      "Epoch 165: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.1701e-07 - mean_absolute_error: 5.7744e-04 - val_loss: 3089.2725 - val_mean_absolute_error: 55.5107\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.4949e-07 - mean_absolute_error: 5.4426e-04\n",
      "Epoch 166: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4949e-07 - mean_absolute_error: 5.4426e-04 - val_loss: 3089.2961 - val_mean_absolute_error: 55.5109\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1075e-07 - mean_absolute_error: 3.1098e-04\n",
      "Epoch 167: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.1075e-07 - mean_absolute_error: 3.1098e-04 - val_loss: 3089.3347 - val_mean_absolute_error: 55.5112\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3739e-07 - mean_absolute_error: 5.0143e-04\n",
      "Epoch 168: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3739e-07 - mean_absolute_error: 5.0143e-04 - val_loss: 3089.2666 - val_mean_absolute_error: 55.5106\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.9857e-07 - mean_absolute_error: 4.8780e-04\n",
      "Epoch 169: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.9857e-07 - mean_absolute_error: 4.8780e-04 - val_loss: 3089.3086 - val_mean_absolute_error: 55.5110\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4752e-07 - mean_absolute_error: 3.2969e-04\n",
      "Epoch 170: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4752e-07 - mean_absolute_error: 3.2969e-04 - val_loss: 3089.3213 - val_mean_absolute_error: 55.5111\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7632e-07 - mean_absolute_error: 3.5915e-04\n",
      "Epoch 171: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7632e-07 - mean_absolute_error: 3.5915e-04 - val_loss: 3089.2605 - val_mean_absolute_error: 55.5106\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0381e-07 - mean_absolute_error: 4.3226e-04\n",
      "Epoch 172: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0381e-07 - mean_absolute_error: 4.3226e-04 - val_loss: 3089.3059 - val_mean_absolute_error: 55.5110\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0144e-07 - mean_absolute_error: 2.5764e-04\n",
      "Epoch 173: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0144e-07 - mean_absolute_error: 2.5764e-04 - val_loss: 3089.2993 - val_mean_absolute_error: 55.5109\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.5611e-08 - mean_absolute_error: 2.0203e-04\n",
      "Epoch 174: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.5611e-08 - mean_absolute_error: 2.0203e-04 - val_loss: 3089.2661 - val_mean_absolute_error: 55.5106\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1404e-07 - mean_absolute_error: 3.2129e-04\n",
      "Epoch 175: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1404e-07 - mean_absolute_error: 3.2129e-04 - val_loss: 3089.3203 - val_mean_absolute_error: 55.5111\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.2733e-08 - mean_absolute_error: 2.4546e-04\n",
      "Epoch 176: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 8.2733e-08 - mean_absolute_error: 2.4546e-04 - val_loss: 3089.2974 - val_mean_absolute_error: 55.5109\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8334e-08 - mean_absolute_error: 1.0242e-04\n",
      "Epoch 177: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8334e-08 - mean_absolute_error: 1.0242e-04 - val_loss: 3089.2815 - val_mean_absolute_error: 55.5108\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.5244e-08 - mean_absolute_error: 1.5871e-04\n",
      "Epoch 178: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5244e-08 - mean_absolute_error: 1.5871e-04 - val_loss: 3089.3188 - val_mean_absolute_error: 55.5111\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.6525e-08 - mean_absolute_error: 2.5172e-04\n",
      "Epoch 179: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.6525e-08 - mean_absolute_error: 2.5172e-04 - val_loss: 3089.2788 - val_mean_absolute_error: 55.5107\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.8741e-08 - mean_absolute_error: 1.2579e-04\n",
      "Epoch 180: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.8741e-08 - mean_absolute_error: 1.2579e-04 - val_loss: 3089.2830 - val_mean_absolute_error: 55.5108\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.2382e-09 - mean_absolute_error: 8.7591e-05\n",
      "Epoch 181: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.2382e-09 - mean_absolute_error: 8.7591e-05 - val_loss: 3089.3027 - val_mean_absolute_error: 55.5110\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.9745e-08 - mean_absolute_error: 1.9347e-04\n",
      "Epoch 182: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.9745e-08 - mean_absolute_error: 1.9347e-04 - val_loss: 3089.2627 - val_mean_absolute_error: 55.5106\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.0405e-08 - mean_absolute_error: 1.9236e-04\n",
      "Epoch 183: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.0405e-08 - mean_absolute_error: 1.9236e-04 - val_loss: 3089.2822 - val_mean_absolute_error: 55.5108\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6358e-08 - mean_absolute_error: 1.1357e-04\n",
      "Epoch 184: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6358e-08 - mean_absolute_error: 1.1357e-04 - val_loss: 3089.2827 - val_mean_absolute_error: 55.5108\n",
      "Epoch 185/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 2.5579e-08 - mean_absolute_error: 1.2888e-04\n",
      "Epoch 185: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.5579e-08 - mean_absolute_error: 1.2888e-04 - val_loss: 3089.2573 - val_mean_absolute_error: 55.5105\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.8715e-08 - mean_absolute_error: 1.8654e-04\n",
      "Epoch 186: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.8715e-08 - mean_absolute_error: 1.8654e-04 - val_loss: 3089.2878 - val_mean_absolute_error: 55.5108\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.7728e-08 - mean_absolute_error: 1.7699e-04\n",
      "Epoch 187: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7728e-08 - mean_absolute_error: 1.7699e-04 - val_loss: 3089.2727 - val_mean_absolute_error: 55.5107\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1055e-08 - mean_absolute_error: 1.1134e-04\n",
      "Epoch 188: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.1055e-08 - mean_absolute_error: 1.1134e-04 - val_loss: 3089.2646 - val_mean_absolute_error: 55.5106\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.8008e-08 - mean_absolute_error: 1.2662e-04\n",
      "Epoch 189: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.8008e-08 - mean_absolute_error: 1.2662e-04 - val_loss: 3089.2854 - val_mean_absolute_error: 55.5108\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.8370e-08 - mean_absolute_error: 1.7920e-04\n",
      "Epoch 190: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8370e-08 - mean_absolute_error: 1.7920e-04 - val_loss: 3089.2607 - val_mean_absolute_error: 55.5106\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.8538e-08 - mean_absolute_error: 1.4586e-04\n",
      "Epoch 191: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.8538e-08 - mean_absolute_error: 1.4586e-04 - val_loss: 3089.2722 - val_mean_absolute_error: 55.5107\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5324e-08 - mean_absolute_error: 8.3023e-05\n",
      "Epoch 192: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5324e-08 - mean_absolute_error: 8.3023e-05 - val_loss: 3089.2820 - val_mean_absolute_error: 55.5108\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1623e-08 - mean_absolute_error: 1.2226e-04\n",
      "Epoch 193: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.1623e-08 - mean_absolute_error: 1.2226e-04 - val_loss: 3089.2651 - val_mean_absolute_error: 55.5106\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.9454e-08 - mean_absolute_error: 1.5433e-04\n",
      "Epoch 194: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.9454e-08 - mean_absolute_error: 1.5433e-04 - val_loss: 3089.2871 - val_mean_absolute_error: 55.5108\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9927e-08 - mean_absolute_error: 1.2704e-04\n",
      "Epoch 195: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9927e-08 - mean_absolute_error: 1.2704e-04 - val_loss: 3089.2791 - val_mean_absolute_error: 55.5107\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1303e-08 - mean_absolute_error: 6.7457e-05\n",
      "Epoch 196: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1303e-08 - mean_absolute_error: 6.7457e-05 - val_loss: 3089.2744 - val_mean_absolute_error: 55.5107\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5670e-08 - mean_absolute_error: 9.4034e-05\n",
      "Epoch 197: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5670e-08 - mean_absolute_error: 9.4034e-05 - val_loss: 3089.2913 - val_mean_absolute_error: 55.5108\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9342e-08 - mean_absolute_error: 1.2966e-04\n",
      "Epoch 198: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9342e-08 - mean_absolute_error: 1.2966e-04 - val_loss: 3089.2744 - val_mean_absolute_error: 55.5107\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4031e-08 - mean_absolute_error: 1.0062e-04\n",
      "Epoch 199: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4031e-08 - mean_absolute_error: 1.0062e-04 - val_loss: 3089.2837 - val_mean_absolute_error: 55.5108\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.6131e-09 - mean_absolute_error: 6.3332e-05\n",
      "Epoch 200: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.6131e-09 - mean_absolute_error: 6.3332e-05 - val_loss: 3089.2849 - val_mean_absolute_error: 55.5108\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.1925e-09 - mean_absolute_error: 6.3338e-05\n",
      "Epoch 201: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.1925e-09 - mean_absolute_error: 6.3338e-05 - val_loss: 3089.2727 - val_mean_absolute_error: 55.5107\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.8887e-09 - mean_absolute_error: 9.4144e-05\n",
      "Epoch 202: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.8887e-09 - mean_absolute_error: 9.4144e-05 - val_loss: 3089.2878 - val_mean_absolute_error: 55.5108\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.9265e-09 - mean_absolute_error: 7.9919e-05\n",
      "Epoch 203: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.9265e-09 - mean_absolute_error: 7.9919e-05 - val_loss: 3089.2786 - val_mean_absolute_error: 55.5107\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3476e-09 - mean_absolute_error: 4.2812e-05\n",
      "Epoch 204: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.3476e-09 - mean_absolute_error: 4.2812e-05 - val_loss: 3089.2812 - val_mean_absolute_error: 55.5107\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4851e-09 - mean_absolute_error: 3.2754e-05\n",
      "Epoch 205: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4851e-09 - mean_absolute_error: 3.2754e-05 - val_loss: 3089.2886 - val_mean_absolute_error: 55.5108\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.1075e-09 - mean_absolute_error: 5.7741e-05\n",
      "Epoch 206: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1075e-09 - mean_absolute_error: 5.7741e-05 - val_loss: 3089.2764 - val_mean_absolute_error: 55.5107\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.0943e-09 - mean_absolute_error: 6.2187e-05\n",
      "Epoch 207: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.0943e-09 - mean_absolute_error: 6.2187e-05 - val_loss: 3089.2866 - val_mean_absolute_error: 55.5108\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1215e-09 - mean_absolute_error: 4.3582e-05\n",
      "Epoch 208: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1215e-09 - mean_absolute_error: 4.3582e-05 - val_loss: 3089.2817 - val_mean_absolute_error: 55.5108\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.4639e-10 - mean_absolute_error: 2.4985e-05\n",
      "Epoch 209: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 7.4639e-10 - mean_absolute_error: 2.4985e-05 - val_loss: 3089.2812 - val_mean_absolute_error: 55.5107\n",
      "Epoch 210/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 1.3781e-09 - mean_absolute_error: 2.8501e-05\n",
      "Epoch 210: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3781e-09 - mean_absolute_error: 2.8501e-05 - val_loss: 3089.2896 - val_mean_absolute_error: 55.5108\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.4903e-09 - mean_absolute_error: 5.0721e-05\n",
      "Epoch 211: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4903e-09 - mean_absolute_error: 5.0721e-05 - val_loss: 3089.2805 - val_mean_absolute_error: 55.5107\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.4580e-09 - mean_absolute_error: 5.2314e-05\n",
      "Epoch 212: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4580e-09 - mean_absolute_error: 5.2314e-05 - val_loss: 3089.2896 - val_mean_absolute_error: 55.5108\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8522e-09 - mean_absolute_error: 4.1122e-05\n",
      "Epoch 213: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8522e-09 - mean_absolute_error: 4.1122e-05 - val_loss: 3089.2866 - val_mean_absolute_error: 55.5108\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.1489e-10 - mean_absolute_error: 2.1126e-05\n",
      "Epoch 214: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.1489e-10 - mean_absolute_error: 2.1126e-05 - val_loss: 3089.2856 - val_mean_absolute_error: 55.5108\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3648e-09 - mean_absolute_error: 2.9360e-05\n",
      "Epoch 215: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3648e-09 - mean_absolute_error: 2.9360e-05 - val_loss: 3089.2920 - val_mean_absolute_error: 55.5109\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.6884e-09 - mean_absolute_error: 4.9905e-05\n",
      "Epoch 216: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.6884e-09 - mean_absolute_error: 4.9905e-05 - val_loss: 3089.2837 - val_mean_absolute_error: 55.5108\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.8768e-09 - mean_absolute_error: 4.8836e-05\n",
      "Epoch 217: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.8768e-09 - mean_absolute_error: 4.8836e-05 - val_loss: 3089.2900 - val_mean_absolute_error: 55.5108\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8121e-09 - mean_absolute_error: 3.6841e-05\n",
      "Epoch 218: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8121e-09 - mean_absolute_error: 3.6841e-05 - val_loss: 3089.2861 - val_mean_absolute_error: 55.5108\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.8997e-10 - mean_absolute_error: 2.5255e-05\n",
      "Epoch 219: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.8997e-10 - mean_absolute_error: 2.5255e-05 - val_loss: 3089.2854 - val_mean_absolute_error: 55.5108\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0786e-09 - mean_absolute_error: 2.7778e-05\n",
      "Epoch 220: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0786e-09 - mean_absolute_error: 2.7778e-05 - val_loss: 3089.2900 - val_mean_absolute_error: 55.5108\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8139e-09 - mean_absolute_error: 3.6785e-05\n",
      "Epoch 221: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8139e-09 - mean_absolute_error: 3.6785e-05 - val_loss: 3089.2834 - val_mean_absolute_error: 55.5108\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2901e-09 - mean_absolute_error: 4.4143e-05\n",
      "Epoch 222: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2901e-09 - mean_absolute_error: 4.4143e-05 - val_loss: 3089.2896 - val_mean_absolute_error: 55.5108\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7757e-09 - mean_absolute_error: 3.6786e-05\n",
      "Epoch 223: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7757e-09 - mean_absolute_error: 3.6786e-05 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.5193e-10 - mean_absolute_error: 2.5913e-05\n",
      "Epoch 224: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.5193e-10 - mean_absolute_error: 2.5913e-05 - val_loss: 3089.2854 - val_mean_absolute_error: 55.5108\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.8065e-10 - mean_absolute_error: 1.7893e-05\n",
      "Epoch 225: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.8065e-10 - mean_absolute_error: 1.7893e-05 - val_loss: 3089.2866 - val_mean_absolute_error: 55.5108\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.0443e-10 - mean_absolute_error: 2.2228e-05\n",
      "Epoch 226: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.0443e-10 - mean_absolute_error: 2.2228e-05 - val_loss: 3089.2832 - val_mean_absolute_error: 55.5108\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.7744e-10 - mean_absolute_error: 3.0151e-05\n",
      "Epoch 227: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.7744e-10 - mean_absolute_error: 3.0151e-05 - val_loss: 3089.2871 - val_mean_absolute_error: 55.5108\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.8211e-10 - mean_absolute_error: 2.4137e-05\n",
      "Epoch 228: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.8211e-10 - mean_absolute_error: 2.4137e-05 - val_loss: 3089.2834 - val_mean_absolute_error: 55.5108\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.7550e-10 - mean_absolute_error: 2.1413e-05\n",
      "Epoch 229: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.7550e-10 - mean_absolute_error: 2.1413e-05 - val_loss: 3089.2856 - val_mean_absolute_error: 55.5108\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9173e-10 - mean_absolute_error: 9.5539e-06\n",
      "Epoch 230: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9173e-10 - mean_absolute_error: 9.5539e-06 - val_loss: 3089.2859 - val_mean_absolute_error: 55.5108\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5993e-10 - mean_absolute_error: 9.9296e-06\n",
      "Epoch 231: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5993e-10 - mean_absolute_error: 9.9296e-06 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.8945e-10 - mean_absolute_error: 1.4836e-05\n",
      "Epoch 232: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.8945e-10 - mean_absolute_error: 1.4836e-05 - val_loss: 3089.2871 - val_mean_absolute_error: 55.5108\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.4514e-10 - mean_absolute_error: 1.7903e-05\n",
      "Epoch 233: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4514e-10 - mean_absolute_error: 1.7903e-05 - val_loss: 3089.2842 - val_mean_absolute_error: 55.5108\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1979e-10 - mean_absolute_error: 1.2494e-05\n",
      "Epoch 234: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1979e-10 - mean_absolute_error: 1.2494e-05 - val_loss: 3089.2856 - val_mean_absolute_error: 55.5108\n",
      "Epoch 235/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 1.0863e-10 - mean_absolute_error: 9.1001e-06\n",
      "Epoch 235: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0863e-10 - mean_absolute_error: 9.1001e-06 - val_loss: 3089.2852 - val_mean_absolute_error: 55.5108\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.2866e-11 - mean_absolute_error: 6.1218e-06\n",
      "Epoch 236: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.2866e-11 - mean_absolute_error: 6.1218e-06 - val_loss: 3089.2842 - val_mean_absolute_error: 55.5108\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0445e-10 - mean_absolute_error: 9.1350e-06\n",
      "Epoch 237: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0445e-10 - mean_absolute_error: 9.1350e-06 - val_loss: 3089.2859 - val_mean_absolute_error: 55.5108\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8277e-10 - mean_absolute_error: 1.1466e-05\n",
      "Epoch 238: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8277e-10 - mean_absolute_error: 1.1466e-05 - val_loss: 3089.2837 - val_mean_absolute_error: 55.5108\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7927e-10 - mean_absolute_error: 1.1086e-05\n",
      "Epoch 239: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7927e-10 - mean_absolute_error: 1.1086e-05 - val_loss: 3089.2852 - val_mean_absolute_error: 55.5108\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0021e-10 - mean_absolute_error: 9.6392e-06\n",
      "Epoch 240: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0021e-10 - mean_absolute_error: 9.6392e-06 - val_loss: 3089.2842 - val_mean_absolute_error: 55.5108\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.8445e-11 - mean_absolute_error: 4.3903e-06\n",
      "Epoch 241: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8445e-11 - mean_absolute_error: 4.3903e-06 - val_loss: 3089.2839 - val_mean_absolute_error: 55.5108\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.9276e-11 - mean_absolute_error: 6.2005e-06\n",
      "Epoch 242: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.9276e-11 - mean_absolute_error: 6.2005e-06 - val_loss: 3089.2852 - val_mean_absolute_error: 55.5108\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6501e-10 - mean_absolute_error: 1.1943e-05\n",
      "Epoch 243: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6501e-10 - mean_absolute_error: 1.1943e-05 - val_loss: 3089.2827 - val_mean_absolute_error: 55.5108\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.5508e-10 - mean_absolute_error: 1.5340e-05\n",
      "Epoch 244: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.5508e-10 - mean_absolute_error: 1.5340e-05 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3507e-10 - mean_absolute_error: 1.3513e-05\n",
      "Epoch 245: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.3507e-10 - mean_absolute_error: 1.3513e-05 - val_loss: 3089.2827 - val_mean_absolute_error: 55.5108\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5511e-10 - mean_absolute_error: 1.1877e-05\n",
      "Epoch 246: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5511e-10 - mean_absolute_error: 1.1877e-05 - val_loss: 3089.2842 - val_mean_absolute_error: 55.5108\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.3885e-11 - mean_absolute_error: 6.4332e-06\n",
      "Epoch 247: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.3885e-11 - mean_absolute_error: 6.4332e-06 - val_loss: 3089.2844 - val_mean_absolute_error: 55.5108\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.1530e-11 - mean_absolute_error: 7.3135e-06\n",
      "Epoch 248: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.1530e-11 - mean_absolute_error: 7.3135e-06 - val_loss: 3089.2837 - val_mean_absolute_error: 55.5108\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6924e-10 - mean_absolute_error: 1.1663e-05\n",
      "Epoch 249: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6924e-10 - mean_absolute_error: 1.1663e-05 - val_loss: 3089.2856 - val_mean_absolute_error: 55.5108\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2259e-10 - mean_absolute_error: 1.4154e-05\n",
      "Epoch 250: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.2259e-10 - mean_absolute_error: 1.4154e-05 - val_loss: 3089.2832 - val_mean_absolute_error: 55.5108\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2060e-10 - mean_absolute_error: 1.4110e-05\n",
      "Epoch 251: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2060e-10 - mean_absolute_error: 1.4110e-05 - val_loss: 3089.2852 - val_mean_absolute_error: 55.5108\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6372e-10 - mean_absolute_error: 1.1646e-05\n",
      "Epoch 252: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6372e-10 - mean_absolute_error: 1.1646e-05 - val_loss: 3089.2837 - val_mean_absolute_error: 55.5108\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.2522e-11 - mean_absolute_error: 7.8220e-06\n",
      "Epoch 253: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.2522e-11 - mean_absolute_error: 7.8220e-06 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4168e-11 - mean_absolute_error: 3.2628e-06\n",
      "Epoch 254: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.4168e-11 - mean_absolute_error: 3.2628e-06 - val_loss: 3089.2849 - val_mean_absolute_error: 55.5108\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.0022e-11 - mean_absolute_error: 5.5309e-06\n",
      "Epoch 255: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0022e-11 - mean_absolute_error: 5.5309e-06 - val_loss: 3089.2837 - val_mean_absolute_error: 55.5108\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.2733e-11 - mean_absolute_error: 7.1398e-06\n",
      "Epoch 256: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.2733e-11 - mean_absolute_error: 7.1398e-06 - val_loss: 3089.2852 - val_mean_absolute_error: 55.5108\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.1828e-11 - mean_absolute_error: 6.6374e-06\n",
      "Epoch 257: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.1828e-11 - mean_absolute_error: 6.6374e-06 - val_loss: 3089.2842 - val_mean_absolute_error: 55.5108\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7802e-11 - mean_absolute_error: 3.3450e-06\n",
      "Epoch 258: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7802e-11 - mean_absolute_error: 3.3450e-06 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0280e-11 - mean_absolute_error: 2.6255e-06\n",
      "Epoch 259: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0280e-11 - mean_absolute_error: 2.6255e-06 - val_loss: 3089.2852 - val_mean_absolute_error: 55.5108\n",
      "Epoch 260/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 3.5809e-11 - mean_absolute_error: 5.3891e-06\n",
      "Epoch 260: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.5809e-11 - mean_absolute_error: 5.3891e-06 - val_loss: 3089.2842 - val_mean_absolute_error: 55.5108\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.7908e-11 - mean_absolute_error: 5.9786e-06\n",
      "Epoch 261: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.7908e-11 - mean_absolute_error: 5.9786e-06 - val_loss: 3089.2849 - val_mean_absolute_error: 55.5108\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2925e-11 - mean_absolute_error: 4.7511e-06\n",
      "Epoch 262: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2925e-11 - mean_absolute_error: 4.7511e-06 - val_loss: 3089.2842 - val_mean_absolute_error: 55.5108\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.4886e-12 - mean_absolute_error: 2.5244e-06\n",
      "Epoch 263: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 7.4886e-12 - mean_absolute_error: 2.5244e-06 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0992e-11 - mean_absolute_error: 2.6594e-06\n",
      "Epoch 264: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0992e-11 - mean_absolute_error: 2.6594e-06 - val_loss: 3089.2852 - val_mean_absolute_error: 55.5108\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.2208e-11 - mean_absolute_error: 5.7366e-06\n",
      "Epoch 265: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2208e-11 - mean_absolute_error: 5.7366e-06 - val_loss: 3089.2842 - val_mean_absolute_error: 55.5108\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.1265e-11 - mean_absolute_error: 7.0758e-06\n",
      "Epoch 266: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 7.1265e-11 - mean_absolute_error: 7.0758e-06 - val_loss: 3089.2856 - val_mean_absolute_error: 55.5108\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.5727e-11 - mean_absolute_error: 7.4173e-06\n",
      "Epoch 267: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.5727e-11 - mean_absolute_error: 7.4173e-06 - val_loss: 3089.2842 - val_mean_absolute_error: 55.5108\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.7258e-11 - mean_absolute_error: 5.4169e-06\n",
      "Epoch 268: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7258e-11 - mean_absolute_error: 5.4169e-06 - val_loss: 3089.2849 - val_mean_absolute_error: 55.5108\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.0714e-12 - mean_absolute_error: 2.4457e-06\n",
      "Epoch 269: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.0714e-12 - mean_absolute_error: 2.4457e-06 - val_loss: 3089.2852 - val_mean_absolute_error: 55.5108\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.6346e-12 - mean_absolute_error: 2.4396e-06\n",
      "Epoch 270: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.6346e-12 - mean_absolute_error: 2.4396e-06 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.6097e-11 - mean_absolute_error: 6.0519e-06\n",
      "Epoch 271: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6097e-11 - mean_absolute_error: 6.0519e-06 - val_loss: 3089.2856 - val_mean_absolute_error: 55.5108\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.7018e-11 - mean_absolute_error: 8.5357e-06\n",
      "Epoch 272: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 8.7018e-11 - mean_absolute_error: 8.5357e-06 - val_loss: 3089.2842 - val_mean_absolute_error: 55.5108\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0849e-10 - mean_absolute_error: 9.3390e-06\n",
      "Epoch 273: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0849e-10 - mean_absolute_error: 9.3390e-06 - val_loss: 3089.2856 - val_mean_absolute_error: 55.5108\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1155e-10 - mean_absolute_error: 9.7739e-06\n",
      "Epoch 274: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1155e-10 - mean_absolute_error: 9.7739e-06 - val_loss: 3089.2842 - val_mean_absolute_error: 55.5108\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.6228e-11 - mean_absolute_error: 8.6362e-06\n",
      "Epoch 275: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.6228e-11 - mean_absolute_error: 8.6362e-06 - val_loss: 3089.2854 - val_mean_absolute_error: 55.5108\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.9256e-11 - mean_absolute_error: 7.8566e-06\n",
      "Epoch 276: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.9256e-11 - mean_absolute_error: 7.8566e-06 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.4659e-11 - mean_absolute_error: 5.1667e-06\n",
      "Epoch 277: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4659e-11 - mean_absolute_error: 5.1667e-06 - val_loss: 3089.2849 - val_mean_absolute_error: 55.5108\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.7649e-12 - mean_absolute_error: 1.6277e-06\n",
      "Epoch 278: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.7649e-12 - mean_absolute_error: 1.6277e-06 - val_loss: 3089.2849 - val_mean_absolute_error: 55.5108\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1290e-11 - mean_absolute_error: 3.0941e-06\n",
      "Epoch 279: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1290e-11 - mean_absolute_error: 3.0941e-06 - val_loss: 3089.2842 - val_mean_absolute_error: 55.5108\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.8216e-11 - mean_absolute_error: 5.5737e-06\n",
      "Epoch 280: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8216e-11 - mean_absolute_error: 5.5737e-06 - val_loss: 3089.2854 - val_mean_absolute_error: 55.5108\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.8184e-11 - mean_absolute_error: 6.9819e-06\n",
      "Epoch 281: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.8184e-11 - mean_absolute_error: 6.9819e-06 - val_loss: 3089.2842 - val_mean_absolute_error: 55.5108\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.8175e-11 - mean_absolute_error: 7.2573e-06\n",
      "Epoch 282: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.8175e-11 - mean_absolute_error: 7.2573e-06 - val_loss: 3089.2854 - val_mean_absolute_error: 55.5108\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.4417e-11 - mean_absolute_error: 7.4263e-06\n",
      "Epoch 283: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.4417e-11 - mean_absolute_error: 7.4263e-06 - val_loss: 3089.2842 - val_mean_absolute_error: 55.5108\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.2700e-11 - mean_absolute_error: 6.2351e-06\n",
      "Epoch 284: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.2700e-11 - mean_absolute_error: 6.2351e-06 - val_loss: 3089.2852 - val_mean_absolute_error: 55.5108\n",
      "Epoch 285/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 3.4973e-11 - mean_absolute_error: 5.4590e-06\n",
      "Epoch 285: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4973e-11 - mean_absolute_error: 5.4590e-06 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7357e-11 - mean_absolute_error: 3.4980e-06\n",
      "Epoch 286: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.7357e-11 - mean_absolute_error: 3.4980e-06 - val_loss: 3089.2849 - val_mean_absolute_error: 55.5108\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5491e-12 - mean_absolute_error: 1.0144e-06\n",
      "Epoch 287: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5491e-12 - mean_absolute_error: 1.0144e-06 - val_loss: 3089.2849 - val_mean_absolute_error: 55.5108\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.3719e-12 - mean_absolute_error: 2.0624e-06\n",
      "Epoch 288: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.3719e-12 - mean_absolute_error: 2.0624e-06 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6195e-11 - mean_absolute_error: 3.4401e-06\n",
      "Epoch 289: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6195e-11 - mean_absolute_error: 3.4401e-06 - val_loss: 3089.2852 - val_mean_absolute_error: 55.5108\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9270e-11 - mean_absolute_error: 3.9484e-06\n",
      "Epoch 290: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9270e-11 - mean_absolute_error: 3.9484e-06 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4383e-11 - mean_absolute_error: 3.3174e-06\n",
      "Epoch 291: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4383e-11 - mean_absolute_error: 3.3174e-06 - val_loss: 3089.2852 - val_mean_absolute_error: 55.5108\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.8369e-12 - mean_absolute_error: 1.9999e-06\n",
      "Epoch 292: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.8369e-12 - mean_absolute_error: 1.9999e-06 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.4487e-13 - mean_absolute_error: 5.3842e-07\n",
      "Epoch 293: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4487e-13 - mean_absolute_error: 5.3842e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.5923e-13 - mean_absolute_error: 7.9182e-07\n",
      "Epoch 294: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.5923e-13 - mean_absolute_error: 7.9182e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0830e-12 - mean_absolute_error: 8.0055e-07\n",
      "Epoch 295: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0830e-12 - mean_absolute_error: 8.0055e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1133e-13 - mean_absolute_error: 2.8530e-07\n",
      "Epoch 296: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1133e-13 - mean_absolute_error: 2.8530e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.3341e-13 - mean_absolute_error: 9.2364e-07\n",
      "Epoch 297: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.3341e-13 - mean_absolute_error: 9.2364e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.2043e-13 - mean_absolute_error: 5.7719e-07\n",
      "Epoch 298: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2043e-13 - mean_absolute_error: 5.7719e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.2828e-13 - mean_absolute_error: 6.5169e-07\n",
      "Epoch 299: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.2828e-13 - mean_absolute_error: 6.5169e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.7717e-13 - mean_absolute_error: 8.7152e-07\n",
      "Epoch 300: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.7717e-13 - mean_absolute_error: 8.7152e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0040e-13 - mean_absolute_error: 4.2821e-07\n",
      "Epoch 301: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.0040e-13 - mean_absolute_error: 4.2821e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2681e-12 - mean_absolute_error: 9.5220e-07\n",
      "Epoch 302: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2681e-12 - mean_absolute_error: 9.5220e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.6163e-13 - mean_absolute_error: 8.0567e-07\n",
      "Epoch 303: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.6163e-13 - mean_absolute_error: 8.0567e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.2743e-13 - mean_absolute_error: 4.8402e-07\n",
      "Epoch 304: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2743e-13 - mean_absolute_error: 4.8402e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.2539e-13 - mean_absolute_error: 6.4913e-07\n",
      "Epoch 305: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.2539e-13 - mean_absolute_error: 6.4913e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.8462e-13 - mean_absolute_error: 4.3058e-07\n",
      "Epoch 306: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.8462e-13 - mean_absolute_error: 4.3058e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.7986e-13 - mean_absolute_error: 5.3241e-07\n",
      "Epoch 307: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.7986e-13 - mean_absolute_error: 5.3241e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1524e-13 - mean_absolute_error: 2.8898e-07\n",
      "Epoch 308: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1524e-13 - mean_absolute_error: 2.8898e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.0591e-13 - mean_absolute_error: 5.0132e-07\n",
      "Epoch 309: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0591e-13 - mean_absolute_error: 5.0132e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 310/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 1.2047e-12 - mean_absolute_error: 9.7940e-07\n",
      "Epoch 310: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2047e-12 - mean_absolute_error: 9.7940e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.9924e-13 - mean_absolute_error: 8.6260e-07\n",
      "Epoch 311: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.9924e-13 - mean_absolute_error: 8.6260e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0194e-13 - mean_absolute_error: 4.4533e-07\n",
      "Epoch 312: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.0194e-13 - mean_absolute_error: 4.4533e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.6513e-14 - mean_absolute_error: 2.1680e-07\n",
      "Epoch 313: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.6513e-14 - mean_absolute_error: 2.1680e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.9338e-14 - mean_absolute_error: 2.0931e-07\n",
      "Epoch 314: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 7.9338e-14 - mean_absolute_error: 2.0931e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.2577e-13 - mean_absolute_error: 5.9546e-07\n",
      "Epoch 315: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.2577e-13 - mean_absolute_error: 5.9546e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4255e-13 - mean_absolute_error: 4.4766e-07\n",
      "Epoch 316: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.4255e-13 - mean_absolute_error: 4.4766e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1175e-13 - mean_absolute_error: 5.1467e-07\n",
      "Epoch 317: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1175e-13 - mean_absolute_error: 5.1467e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1499e-12 - mean_absolute_error: 1.3106e-06\n",
      "Epoch 318: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.1499e-12 - mean_absolute_error: 1.3106e-06 - val_loss: 3089.2849 - val_mean_absolute_error: 55.5108\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.4118e-12 - mean_absolute_error: 1.4449e-06\n",
      "Epoch 319: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4118e-12 - mean_absolute_error: 1.4449e-06 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3472e-12 - mean_absolute_error: 1.3243e-06\n",
      "Epoch 320: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.3472e-12 - mean_absolute_error: 1.3243e-06 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.6565e-13 - mean_absolute_error: 3.2581e-07\n",
      "Epoch 321: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.6565e-13 - mean_absolute_error: 3.2581e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3200e-13 - mean_absolute_error: 3.6589e-07\n",
      "Epoch 322: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.3200e-13 - mean_absolute_error: 3.6589e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9187e-13 - mean_absolute_error: 3.0012e-07\n",
      "Epoch 323: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9187e-13 - mean_absolute_error: 3.0012e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7053e-13 - mean_absolute_error: 2.3877e-07\n",
      "Epoch 324: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7053e-13 - mean_absolute_error: 2.3877e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2513e-12 - mean_absolute_error: 6.4665e-07\n",
      "Epoch 325: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2513e-12 - mean_absolute_error: 6.4665e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.1413e-13 - mean_absolute_error: 5.8146e-07\n",
      "Epoch 326: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.1413e-13 - mean_absolute_error: 5.8146e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6373e-13 - mean_absolute_error: 2.2573e-07\n",
      "Epoch 327: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6373e-13 - mean_absolute_error: 2.2573e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.4518e-13 - mean_absolute_error: 8.7024e-07\n",
      "Epoch 328: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.4518e-13 - mean_absolute_error: 8.7024e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0261e-13 - mean_absolute_error: 3.1269e-07\n",
      "Epoch 329: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0261e-13 - mean_absolute_error: 3.1269e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0024e-13 - mean_absolute_error: 2.9282e-07\n",
      "Epoch 330: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0024e-13 - mean_absolute_error: 2.9282e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7624e-13 - mean_absolute_error: 3.4874e-07\n",
      "Epoch 331: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.7624e-13 - mean_absolute_error: 3.4874e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9711e-13 - mean_absolute_error: 3.6737e-07\n",
      "Epoch 332: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9711e-13 - mean_absolute_error: 3.6737e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.0942e-13 - mean_absolute_error: 5.3501e-07\n",
      "Epoch 333: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0942e-13 - mean_absolute_error: 5.3501e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2177e-13 - mean_absolute_error: 2.4940e-07\n",
      "Epoch 334: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2177e-13 - mean_absolute_error: 2.4940e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 335/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 1.3834e-13 - mean_absolute_error: 2.6927e-07\n",
      "Epoch 335: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3834e-13 - mean_absolute_error: 2.6927e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1020e-13 - mean_absolute_error: 3.3508e-07\n",
      "Epoch 336: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.1020e-13 - mean_absolute_error: 3.3508e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7230e-13 - mean_absolute_error: 2.5561e-07\n",
      "Epoch 337: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.7230e-13 - mean_absolute_error: 2.5561e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3682e-14 - mean_absolute_error: 1.4882e-07\n",
      "Epoch 338: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3682e-14 - mean_absolute_error: 1.4882e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0904e-13 - mean_absolute_error: 2.2705e-07\n",
      "Epoch 339: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0904e-13 - mean_absolute_error: 2.2705e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1707e-14 - mean_absolute_error: 1.4261e-07\n",
      "Epoch 340: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.1707e-14 - mean_absolute_error: 1.4261e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.1534e-14 - mean_absolute_error: 1.9849e-07\n",
      "Epoch 341: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.1534e-14 - mean_absolute_error: 1.9849e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3113e-14 - mean_absolute_error: 1.5875e-07\n",
      "Epoch 342: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3113e-14 - mean_absolute_error: 1.5875e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.9692e-14 - mean_absolute_error: 1.3888e-07\n",
      "Epoch 343: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9692e-14 - mean_absolute_error: 1.3888e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8233e-13 - mean_absolute_error: 2.9783e-07\n",
      "Epoch 344: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8233e-13 - mean_absolute_error: 2.9783e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.3842e-13 - mean_absolute_error: 4.9775e-07\n",
      "Epoch 345: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3842e-13 - mean_absolute_error: 4.9775e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1222e-12 - mean_absolute_error: 9.1169e-07\n",
      "Epoch 346: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1222e-12 - mean_absolute_error: 9.1169e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1246e-12 - mean_absolute_error: 8.2806e-07\n",
      "Epoch 347: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1246e-12 - mean_absolute_error: 8.2806e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3162e-13 - mean_absolute_error: 4.3935e-07\n",
      "Epoch 348: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3162e-13 - mean_absolute_error: 4.3935e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.8320e-13 - mean_absolute_error: 5.9830e-07\n",
      "Epoch 349: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.8320e-13 - mean_absolute_error: 5.9830e-07 - val_loss: 3089.2849 - val_mean_absolute_error: 55.5108\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6335e-12 - mean_absolute_error: 1.1745e-06\n",
      "Epoch 350: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6335e-12 - mean_absolute_error: 1.1745e-06 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.8155e-13 - mean_absolute_error: 6.8444e-07\n",
      "Epoch 351: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.8155e-13 - mean_absolute_error: 6.8444e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.5271e-14 - mean_absolute_error: 1.9969e-07\n",
      "Epoch 352: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8.5271e-14 - mean_absolute_error: 1.9969e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.3007e-13 - mean_absolute_error: 7.7090e-07\n",
      "Epoch 353: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.3007e-13 - mean_absolute_error: 7.7090e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.9879e-13 - mean_absolute_error: 6.0129e-07\n",
      "Epoch 354: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.9879e-13 - mean_absolute_error: 6.0129e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1004e-13 - mean_absolute_error: 3.3431e-07\n",
      "Epoch 355: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.1004e-13 - mean_absolute_error: 3.3431e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0677e-12 - mean_absolute_error: 8.2798e-07\n",
      "Epoch 356: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0677e-12 - mean_absolute_error: 8.2798e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8672e-12 - mean_absolute_error: 9.2542e-07\n",
      "Epoch 357: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8672e-12 - mean_absolute_error: 9.2542e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.4807e-13 - mean_absolute_error: 5.4486e-07\n",
      "Epoch 358: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4807e-13 - mean_absolute_error: 5.4486e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.8561e-13 - mean_absolute_error: 5.3990e-07\n",
      "Epoch 359: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8561e-13 - mean_absolute_error: 5.3990e-07 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 360/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 5.4004e-13 - mean_absolute_error: 5.1879e-07\n",
      "Epoch 360: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.4004e-13 - mean_absolute_error: 5.1879e-07 - val_loss: 3089.2852 - val_mean_absolute_error: 55.5108\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.4942e-12 - mean_absolute_error: 1.9406e-06\n",
      "Epoch 361: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4942e-12 - mean_absolute_error: 1.9406e-06 - val_loss: 3089.2847 - val_mean_absolute_error: 55.5108\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3241e-11 - mean_absolute_error: 3.1221e-06\n",
      "Epoch 362: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3241e-11 - mean_absolute_error: 3.1221e-06 - val_loss: 3089.2852 - val_mean_absolute_error: 55.5108\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3193e-11 - mean_absolute_error: 5.2078e-06\n",
      "Epoch 363: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3193e-11 - mean_absolute_error: 5.2078e-06 - val_loss: 3089.2837 - val_mean_absolute_error: 55.5108\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1362e-10 - mean_absolute_error: 9.4962e-06\n",
      "Epoch 364: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1362e-10 - mean_absolute_error: 9.4962e-06 - val_loss: 3089.2866 - val_mean_absolute_error: 55.5108\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.0005e-10 - mean_absolute_error: 2.0282e-05\n",
      "Epoch 365: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.0005e-10 - mean_absolute_error: 2.0282e-05 - val_loss: 3089.2798 - val_mean_absolute_error: 55.5107\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.5985e-09 - mean_absolute_error: 4.6042e-05\n",
      "Epoch 366: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5985e-09 - mean_absolute_error: 4.6042e-05 - val_loss: 3089.2959 - val_mean_absolute_error: 55.5109\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4799e-08 - mean_absolute_error: 1.0969e-04\n",
      "Epoch 367: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4799e-08 - mean_absolute_error: 1.0969e-04 - val_loss: 3089.2573 - val_mean_absolute_error: 55.5105\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.6378e-08 - mean_absolute_error: 2.6550e-04\n",
      "Epoch 368: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.6378e-08 - mean_absolute_error: 2.6550e-04 - val_loss: 3089.3506 - val_mean_absolute_error: 55.5114\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.0795e-07 - mean_absolute_error: 6.4357e-04\n",
      "Epoch 369: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.0795e-07 - mean_absolute_error: 6.4357e-04 - val_loss: 3089.1245 - val_mean_absolute_error: 55.5093\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0054e-06 - mean_absolute_error: 0.0016\n",
      "Epoch 370: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.0054e-06 - mean_absolute_error: 0.0016 - val_loss: 3089.6755 - val_mean_absolute_error: 55.5144\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7906e-05 - mean_absolute_error: 0.0038\n",
      "Epoch 371: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7906e-05 - mean_absolute_error: 0.0038 - val_loss: 3088.3257 - val_mean_absolute_error: 55.5020\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0742e-04 - mean_absolute_error: 0.0094\n",
      "Epoch 372: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0742e-04 - mean_absolute_error: 0.0094 - val_loss: 3091.5798 - val_mean_absolute_error: 55.5319\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.4691e-04 - mean_absolute_error: 0.0230\n",
      "Epoch 373: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.4691e-04 - mean_absolute_error: 0.0230 - val_loss: 3083.4668 - val_mean_absolute_error: 55.4573\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0039 - mean_absolute_error: 0.0562\n",
      "Epoch 374: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0039 - mean_absolute_error: 0.0562 - val_loss: 3102.7346 - val_mean_absolute_error: 55.6343\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0213 - mean_absolute_error: 0.1321\n",
      "Epoch 375: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0213 - mean_absolute_error: 0.1321 - val_loss: 3060.5986 - val_mean_absolute_error: 55.2470\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0818 - mean_absolute_error: 0.2621\n",
      "Epoch 376: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0818 - mean_absolute_error: 0.2621 - val_loss: 3125.5972 - val_mean_absolute_error: 55.8417\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1236 - mean_absolute_error: 0.3223\n",
      "Epoch 377: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1236 - mean_absolute_error: 0.3223 - val_loss: 3072.7180 - val_mean_absolute_error: 55.3604\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0327 - mean_absolute_error: 0.1671\n",
      "Epoch 378: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0327 - mean_absolute_error: 0.1671 - val_loss: 3077.7449 - val_mean_absolute_error: 55.4069\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0170 - mean_absolute_error: 0.1221\n",
      "Epoch 379: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0170 - mean_absolute_error: 0.1221 - val_loss: 3117.3484 - val_mean_absolute_error: 55.7674\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.2350\n",
      "Epoch 380: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0675 - mean_absolute_error: 0.2350 - val_loss: 3082.2817 - val_mean_absolute_error: 55.4476\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0064 - mean_absolute_error: 0.0754\n",
      "Epoch 381: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0064 - mean_absolute_error: 0.0754 - val_loss: 3068.3647 - val_mean_absolute_error: 55.3192\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0362 - mean_absolute_error: 0.1859\n",
      "Epoch 382: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0362 - mean_absolute_error: 0.1859 - val_loss: 3106.1406 - val_mean_absolute_error: 55.6632\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0313 - mean_absolute_error: 0.1655\n",
      "Epoch 383: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0313 - mean_absolute_error: 0.1655 - val_loss: 3095.9663 - val_mean_absolute_error: 55.5707\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0095 - mean_absolute_error: 0.0882\n",
      "Epoch 384: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0095 - mean_absolute_error: 0.0882 - val_loss: 3065.7905 - val_mean_absolute_error: 55.2953\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0393 - mean_absolute_error: 0.1934\n",
      "Epoch 385: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0393 - mean_absolute_error: 0.1934 - val_loss: 3090.3223 - val_mean_absolute_error: 55.5207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - mean_absolute_error: 0.0468\n",
      "Epoch 386: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0050 - mean_absolute_error: 0.0468 - val_loss: 3105.5356 - val_mean_absolute_error: 55.6597\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0292 - mean_absolute_error: 0.1627\n",
      "Epoch 387: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0292 - mean_absolute_error: 0.1627 - val_loss: 3077.7368 - val_mean_absolute_error: 55.4056\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0119 - mean_absolute_error: 0.1000\n",
      "Epoch 388: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0119 - mean_absolute_error: 0.1000 - val_loss: 3076.1194 - val_mean_absolute_error: 55.3904\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0145 - mean_absolute_error: 0.1144\n",
      "Epoch 389: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0145 - mean_absolute_error: 0.1144 - val_loss: 3102.6079 - val_mean_absolute_error: 55.6326\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0182 - mean_absolute_error: 0.1324\n",
      "Epoch 390: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0182 - mean_absolute_error: 0.1324 - val_loss: 3094.2744 - val_mean_absolute_error: 55.5568\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - mean_absolute_error: 0.0668\n",
      "Epoch 391: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0051 - mean_absolute_error: 0.0668 - val_loss: 3074.9443 - val_mean_absolute_error: 55.3805\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0188 - mean_absolute_error: 0.1312\n",
      "Epoch 392: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0188 - mean_absolute_error: 0.1312 - val_loss: 3091.1514 - val_mean_absolute_error: 55.5294\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0024 - mean_absolute_error: 0.0341\n",
      "Epoch 393: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0024 - mean_absolute_error: 0.0341 - val_loss: 3103.2942 - val_mean_absolute_error: 55.6405\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0142 - mean_absolute_error: 0.1166\n",
      "Epoch 394: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0142 - mean_absolute_error: 0.1166 - val_loss: 3084.5884 - val_mean_absolute_error: 55.4693\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0039 - mean_absolute_error: 0.0547\n",
      "Epoch 395: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0039 - mean_absolute_error: 0.0547 - val_loss: 3080.6797 - val_mean_absolute_error: 55.4331\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0077 - mean_absolute_error: 0.0837\n",
      "Epoch 396: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0077 - mean_absolute_error: 0.0837 - val_loss: 3098.6128 - val_mean_absolute_error: 55.5968\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - mean_absolute_error: 0.0756\n",
      "Epoch 397: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0062 - mean_absolute_error: 0.0756 - val_loss: 3095.3594 - val_mean_absolute_error: 55.5671\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0026 - mean_absolute_error: 0.0495\n",
      "Epoch 398: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0026 - mean_absolute_error: 0.0495 - val_loss: 3080.2017 - val_mean_absolute_error: 55.4287\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0072 - mean_absolute_error: 0.0819\n",
      "Epoch 399: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0072 - mean_absolute_error: 0.0819 - val_loss: 3088.6567 - val_mean_absolute_error: 55.5063\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.5302e-04 - mean_absolute_error: 0.0138\n",
      "Epoch 400: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.5302e-04 - mean_absolute_error: 0.0138 - val_loss: 3099.0171 - val_mean_absolute_error: 55.6010\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0063 - mean_absolute_error: 0.0704\n",
      "Epoch 401: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0063 - mean_absolute_error: 0.0704 - val_loss: 3087.6348 - val_mean_absolute_error: 55.4967\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.1199e-04 - mean_absolute_error: 0.0184\n",
      "Epoch 402: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1199e-04 - mean_absolute_error: 0.0184 - val_loss: 3082.1577 - val_mean_absolute_error: 55.4463\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0043 - mean_absolute_error: 0.0606\n",
      "Epoch 403: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0043 - mean_absolute_error: 0.0606 - val_loss: 3094.2988 - val_mean_absolute_error: 55.5573\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0357\n",
      "Epoch 404: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0017 - mean_absolute_error: 0.0357 - val_loss: 3095.0420 - val_mean_absolute_error: 55.5642\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0411\n",
      "Epoch 405: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0021 - mean_absolute_error: 0.0411 - val_loss: 3084.1777 - val_mean_absolute_error: 55.4651\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0027 - mean_absolute_error: 0.0480\n",
      "Epoch 406: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0027 - mean_absolute_error: 0.0480 - val_loss: 3087.8499 - val_mean_absolute_error: 55.4990\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.6950e-04 - mean_absolute_error: 0.0229\n",
      "Epoch 407: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.6950e-04 - mean_absolute_error: 0.0229 - val_loss: 3096.7869 - val_mean_absolute_error: 55.5808\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0030 - mean_absolute_error: 0.0523\n",
      "Epoch 408: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0030 - mean_absolute_error: 0.0523 - val_loss: 3090.6245 - val_mean_absolute_error: 55.5245\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2842e-04 - mean_absolute_error: 0.0075\n",
      "Epoch 409: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2842e-04 - mean_absolute_error: 0.0075 - val_loss: 3084.9670 - val_mean_absolute_error: 55.4726\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.0473\n",
      "Epoch 410: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0025 - mean_absolute_error: 0.0473 - val_loss: 3092.4937 - val_mean_absolute_error: 55.5414\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.4468e-04 - mean_absolute_error: 0.0186\n",
      "Epoch 411: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4468e-04 - mean_absolute_error: 0.0186 - val_loss: 3095.0544 - val_mean_absolute_error: 55.5649\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0387\n",
      "Epoch 412: val_loss did not improve from 0.06669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0016 - mean_absolute_error: 0.0387 - val_loss: 3087.4194 - val_mean_absolute_error: 55.4953\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.2799e-04 - mean_absolute_error: 0.0294\n",
      "Epoch 413: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.2799e-04 - mean_absolute_error: 0.0294 - val_loss: 3087.6992 - val_mean_absolute_error: 55.4980\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.9345e-04 - mean_absolute_error: 0.0270\n",
      "Epoch 414: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.9345e-04 - mean_absolute_error: 0.0270 - val_loss: 3094.4031 - val_mean_absolute_error: 55.5592\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0348\n",
      "Epoch 415: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0013 - mean_absolute_error: 0.0348 - val_loss: 3091.6670 - val_mean_absolute_error: 55.5341\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.6403e-04 - mean_absolute_error: 0.0145\n",
      "Epoch 416: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.6403e-04 - mean_absolute_error: 0.0145 - val_loss: 3086.2310 - val_mean_absolute_error: 55.4842\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0341\n",
      "Epoch 417: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0013 - mean_absolute_error: 0.0341 - val_loss: 3090.1753 - val_mean_absolute_error: 55.5202\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1638e-04 - mean_absolute_error: 0.0068\n",
      "Epoch 418: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1638e-04 - mean_absolute_error: 0.0068 - val_loss: 3093.4119 - val_mean_absolute_error: 55.5498\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.8482e-04 - mean_absolute_error: 0.0305\n",
      "Epoch 419: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.8482e-04 - mean_absolute_error: 0.0305 - val_loss: 3088.5225 - val_mean_absolute_error: 55.5052\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1332e-04 - mean_absolute_error: 0.0141\n",
      "Epoch 420: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.1332e-04 - mean_absolute_error: 0.0141 - val_loss: 3087.1714 - val_mean_absolute_error: 55.4930\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.9402e-04 - mean_absolute_error: 0.0235\n",
      "Epoch 421: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.9402e-04 - mean_absolute_error: 0.0235 - val_loss: 3091.9771 - val_mean_absolute_error: 55.5369\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.8767e-04 - mean_absolute_error: 0.0190\n",
      "Epoch 422: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.8767e-04 - mean_absolute_error: 0.0190 - val_loss: 3091.5127 - val_mean_absolute_error: 55.5327\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4749e-04 - mean_absolute_error: 0.0151\n",
      "Epoch 423: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.4749e-04 - mean_absolute_error: 0.0151 - val_loss: 3087.3120 - val_mean_absolute_error: 55.4942\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.8059e-04 - mean_absolute_error: 0.0209\n",
      "Epoch 424: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8059e-04 - mean_absolute_error: 0.0209 - val_loss: 3089.1858 - val_mean_absolute_error: 55.5113\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.1845e-05 - mean_absolute_error: 0.0069\n",
      "Epoch 425: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.1845e-05 - mean_absolute_error: 0.0069 - val_loss: 3092.4111 - val_mean_absolute_error: 55.5409\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.5614e-04 - mean_absolute_error: 0.0202\n",
      "Epoch 426: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5614e-04 - mean_absolute_error: 0.0202 - val_loss: 3089.7588 - val_mean_absolute_error: 55.5167\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0025e-05 - mean_absolute_error: 0.0029\n",
      "Epoch 427: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0025e-05 - mean_absolute_error: 0.0029 - val_loss: 3087.9443 - val_mean_absolute_error: 55.5002\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3812e-04 - mean_absolute_error: 0.0163\n",
      "Epoch 428: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3812e-04 - mean_absolute_error: 0.0163 - val_loss: 3091.1045 - val_mean_absolute_error: 55.5292\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.5437e-05 - mean_absolute_error: 0.0079\n",
      "Epoch 429: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.5437e-05 - mean_absolute_error: 0.0079 - val_loss: 3091.6892 - val_mean_absolute_error: 55.5345\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8634e-04 - mean_absolute_error: 0.0123\n",
      "Epoch 430: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8634e-04 - mean_absolute_error: 0.0123 - val_loss: 3088.6008 - val_mean_absolute_error: 55.5062\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5585e-04 - mean_absolute_error: 0.0116\n",
      "Epoch 431: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5585e-04 - mean_absolute_error: 0.0116 - val_loss: 3089.0781 - val_mean_absolute_error: 55.5105\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.5951e-05 - mean_absolute_error: 0.0077\n",
      "Epoch 432: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.5951e-05 - mean_absolute_error: 0.0077 - val_loss: 3091.5732 - val_mean_absolute_error: 55.5333\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9604e-04 - mean_absolute_error: 0.0127\n",
      "Epoch 433: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9604e-04 - mean_absolute_error: 0.0127 - val_loss: 3090.1401 - val_mean_absolute_error: 55.5203\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.0497e-06 - mean_absolute_error: 0.0027\n",
      "Epoch 434: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.0497e-06 - mean_absolute_error: 0.0027 - val_loss: 3088.2954 - val_mean_absolute_error: 55.5034\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8067e-04 - mean_absolute_error: 0.0129\n",
      "Epoch 435: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.8067e-04 - mean_absolute_error: 0.0129 - val_loss: 3090.1357 - val_mean_absolute_error: 55.5202\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6592e-05 - mean_absolute_error: 0.0037\n",
      "Epoch 436: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6592e-05 - mean_absolute_error: 0.0037 - val_loss: 3090.9976 - val_mean_absolute_error: 55.5281\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2534e-04 - mean_absolute_error: 0.0106\n",
      "Epoch 437: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2534e-04 - mean_absolute_error: 0.0106 - val_loss: 3088.8892 - val_mean_absolute_error: 55.5088\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.3891e-05 - mean_absolute_error: 0.0071\n",
      "Epoch 438: val_loss did not improve from 0.06669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 5.3891e-05 - mean_absolute_error: 0.0071 - val_loss: 3088.7864 - val_mean_absolute_error: 55.5078\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.4105e-05 - mean_absolute_error: 0.0078\n",
      "Epoch 439: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.4105e-05 - mean_absolute_error: 0.0078 - val_loss: 3090.6743 - val_mean_absolute_error: 55.5251\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.6004e-05 - mean_absolute_error: 0.0089\n",
      "Epoch 440: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.6004e-05 - mean_absolute_error: 0.0089 - val_loss: 3090.0632 - val_mean_absolute_error: 55.5195\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0902e-05 - mean_absolute_error: 0.0043\n",
      "Epoch 441: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.0902e-05 - mean_absolute_error: 0.0043 - val_loss: 3088.6294 - val_mean_absolute_error: 55.5064\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.2104e-05 - mean_absolute_error: 0.0092\n",
      "Epoch 442: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.2104e-05 - mean_absolute_error: 0.0092 - val_loss: 3089.7754 - val_mean_absolute_error: 55.5169\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.8584e-06 - mean_absolute_error: 0.0019\n",
      "Epoch 443: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 8.8584e-06 - mean_absolute_error: 0.0019 - val_loss: 3090.6707 - val_mean_absolute_error: 55.5251\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.1328e-05 - mean_absolute_error: 0.0083\n",
      "Epoch 444: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.1328e-05 - mean_absolute_error: 0.0083 - val_loss: 3089.3208 - val_mean_absolute_error: 55.5127\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9440e-05 - mean_absolute_error: 0.0040\n",
      "Epoch 445: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9440e-05 - mean_absolute_error: 0.0040 - val_loss: 3089.0706 - val_mean_absolute_error: 55.5104\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.0129e-05 - mean_absolute_error: 0.0060\n",
      "Epoch 446: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 4.0129e-05 - mean_absolute_error: 0.0060 - val_loss: 3090.4290 - val_mean_absolute_error: 55.5229\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.5462e-05 - mean_absolute_error: 0.0058\n",
      "Epoch 447: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.5462e-05 - mean_absolute_error: 0.0058 - val_loss: 3090.1648 - val_mean_absolute_error: 55.5205\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3804e-05 - mean_absolute_error: 0.0036\n",
      "Epoch 448: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3804e-05 - mean_absolute_error: 0.0036 - val_loss: 3089.0898 - val_mean_absolute_error: 55.5107\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.1970e-05 - mean_absolute_error: 0.0061\n",
      "Epoch 449: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1970e-05 - mean_absolute_error: 0.0061 - val_loss: 3089.7891 - val_mean_absolute_error: 55.5171\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.8144e-06 - mean_absolute_error: 0.0013\n",
      "Epoch 450: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.8144e-06 - mean_absolute_error: 0.0013 - val_loss: 3090.4771 - val_mean_absolute_error: 55.5233\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3954e-05 - mean_absolute_error: 0.0056\n",
      "Epoch 451: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3954e-05 - mean_absolute_error: 0.0056 - val_loss: 3089.5496 - val_mean_absolute_error: 55.5148\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.7413e-06 - mean_absolute_error: 0.0023\n",
      "Epoch 452: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.7413e-06 - mean_absolute_error: 0.0023 - val_loss: 3089.2947 - val_mean_absolute_error: 55.5125\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8786e-05 - mean_absolute_error: 0.0042\n",
      "Epoch 453: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8786e-05 - mean_absolute_error: 0.0042 - val_loss: 3090.2290 - val_mean_absolute_error: 55.5210\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3949e-05 - mean_absolute_error: 0.0035\n",
      "Epoch 454: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3949e-05 - mean_absolute_error: 0.0035 - val_loss: 3090.0684 - val_mean_absolute_error: 55.5196\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.4987e-06 - mean_absolute_error: 0.0022\n",
      "Epoch 455: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4987e-06 - mean_absolute_error: 0.0022 - val_loss: 3089.2998 - val_mean_absolute_error: 55.5126\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8656e-05 - mean_absolute_error: 0.0040\n",
      "Epoch 456: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8656e-05 - mean_absolute_error: 0.0040 - val_loss: 3089.7778 - val_mean_absolute_error: 55.5169\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2216e-07 - mean_absolute_error: 5.1456e-04\n",
      "Epoch 457: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2216e-07 - mean_absolute_error: 5.1456e-04 - val_loss: 3090.2671 - val_mean_absolute_error: 55.5214\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5781e-05 - mean_absolute_error: 0.0036\n",
      "Epoch 458: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5781e-05 - mean_absolute_error: 0.0036 - val_loss: 3089.6270 - val_mean_absolute_error: 55.5155\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.6209e-06 - mean_absolute_error: 0.0015\n",
      "Epoch 459: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.6209e-06 - mean_absolute_error: 0.0015 - val_loss: 3089.4800 - val_mean_absolute_error: 55.5142\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.5952e-06 - mean_absolute_error: 0.0027\n",
      "Epoch 460: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.5952e-06 - mean_absolute_error: 0.0027 - val_loss: 3090.1504 - val_mean_absolute_error: 55.5203\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.2674e-06 - mean_absolute_error: 0.0025\n",
      "Epoch 461: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.2674e-06 - mean_absolute_error: 0.0025 - val_loss: 3090.0227 - val_mean_absolute_error: 55.5192\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3613e-06 - mean_absolute_error: 0.0015\n",
      "Epoch 462: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.3613e-06 - mean_absolute_error: 0.0015 - val_loss: 3089.5103 - val_mean_absolute_error: 55.5145\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.6052e-06 - mean_absolute_error: 0.0029\n",
      "Epoch 463: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.6052e-06 - mean_absolute_error: 0.0029 - val_loss: 3089.8813 - val_mean_absolute_error: 55.5179\n",
      "Epoch 464/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 5.0089e-07 - mean_absolute_error: 4.7577e-04\n",
      "Epoch 464: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.0089e-07 - mean_absolute_error: 4.7577e-04 - val_loss: 3090.1865 - val_mean_absolute_error: 55.5207\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.7877e-06 - mean_absolute_error: 0.0027\n",
      "Epoch 465: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.7877e-06 - mean_absolute_error: 0.0027 - val_loss: 3089.7124 - val_mean_absolute_error: 55.5163\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3567e-06 - mean_absolute_error: 0.0015\n",
      "Epoch 466: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.3567e-06 - mean_absolute_error: 0.0015 - val_loss: 3089.6497 - val_mean_absolute_error: 55.5157\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.9097e-06 - mean_absolute_error: 0.0019\n",
      "Epoch 467: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9097e-06 - mean_absolute_error: 0.0019 - val_loss: 3090.0986 - val_mean_absolute_error: 55.5199\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.6643e-06 - mean_absolute_error: 0.0021\n",
      "Epoch 468: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6643e-06 - mean_absolute_error: 0.0021 - val_loss: 3089.9351 - val_mean_absolute_error: 55.5184\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0200e-06 - mean_absolute_error: 8.8511e-04\n",
      "Epoch 469: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0200e-06 - mean_absolute_error: 8.8511e-04 - val_loss: 3089.5898 - val_mean_absolute_error: 55.5152\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.1193e-06 - mean_absolute_error: 0.0022\n",
      "Epoch 470: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.1193e-06 - mean_absolute_error: 0.0022 - val_loss: 3089.8777 - val_mean_absolute_error: 55.5178\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.9189e-07 - mean_absolute_error: 5.8798e-04\n",
      "Epoch 471: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.9189e-07 - mean_absolute_error: 5.8798e-04 - val_loss: 3090.0256 - val_mean_absolute_error: 55.5192\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.4595e-06 - mean_absolute_error: 0.0018\n",
      "Epoch 472: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4595e-06 - mean_absolute_error: 0.0018 - val_loss: 3089.6724 - val_mean_absolute_error: 55.5159\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8089e-06 - mean_absolute_error: 0.0013\n",
      "Epoch 473: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8089e-06 - mean_absolute_error: 0.0013 - val_loss: 3089.6948 - val_mean_absolute_error: 55.5161\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3074e-06 - mean_absolute_error: 0.0011\n",
      "Epoch 474: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3074e-06 - mean_absolute_error: 0.0011 - val_loss: 3089.9990 - val_mean_absolute_error: 55.5189\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.7057e-06 - mean_absolute_error: 0.0016\n",
      "Epoch 475: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7057e-06 - mean_absolute_error: 0.0016 - val_loss: 3089.8330 - val_mean_absolute_error: 55.5174\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3387e-07 - mean_absolute_error: 2.9107e-04\n",
      "Epoch 476: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.3387e-07 - mean_absolute_error: 2.9107e-04 - val_loss: 3089.6458 - val_mean_absolute_error: 55.5157\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3259e-06 - mean_absolute_error: 0.0014\n",
      "Epoch 477: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.3259e-06 - mean_absolute_error: 0.0014 - val_loss: 3089.8926 - val_mean_absolute_error: 55.5180\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.7190e-07 - mean_absolute_error: 6.6520e-04\n",
      "Epoch 478: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.7190e-07 - mean_absolute_error: 6.6520e-04 - val_loss: 3089.9429 - val_mean_absolute_error: 55.5184\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1202e-06 - mean_absolute_error: 0.0010\n",
      "Epoch 479: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1202e-06 - mean_absolute_error: 0.0010 - val_loss: 3089.7000 - val_mean_absolute_error: 55.5162\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1797e-06 - mean_absolute_error: 0.0010\n",
      "Epoch 480: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1797e-06 - mean_absolute_error: 0.0010 - val_loss: 3089.7837 - val_mean_absolute_error: 55.5170\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7471e-07 - mean_absolute_error: 3.9691e-04\n",
      "Epoch 481: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.7471e-07 - mean_absolute_error: 3.9691e-04 - val_loss: 3089.9688 - val_mean_absolute_error: 55.5187\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3568e-06 - mean_absolute_error: 0.0011\n",
      "Epoch 482: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3568e-06 - mean_absolute_error: 0.0011 - val_loss: 3089.8047 - val_mean_absolute_error: 55.5172\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.3389e-08 - mean_absolute_error: 2.3173e-04\n",
      "Epoch 483: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 8.3389e-08 - mean_absolute_error: 2.3173e-04 - val_loss: 3089.7234 - val_mean_absolute_error: 55.5164\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.5250e-07 - mean_absolute_error: 8.3865e-04\n",
      "Epoch 484: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.5250e-07 - mean_absolute_error: 8.3865e-04 - val_loss: 3089.9087 - val_mean_absolute_error: 55.5181\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.9145e-07 - mean_absolute_error: 6.1581e-04\n",
      "Epoch 485: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.9145e-07 - mean_absolute_error: 6.1581e-04 - val_loss: 3089.8789 - val_mean_absolute_error: 55.5178\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3176e-07 - mean_absolute_error: 4.3115e-04\n",
      "Epoch 486: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.3176e-07 - mean_absolute_error: 4.3115e-04 - val_loss: 3089.7192 - val_mean_absolute_error: 55.5164\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.6476e-07 - mean_absolute_error: 8.3587e-04\n",
      "Epoch 487: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6476e-07 - mean_absolute_error: 8.3587e-04 - val_loss: 3089.8237 - val_mean_absolute_error: 55.5173\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7466e-08 - mean_absolute_error: 9.4169e-05\n",
      "Epoch 488: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.7466e-08 - mean_absolute_error: 9.4169e-05 - val_loss: 3089.9070 - val_mean_absolute_error: 55.5181\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.0404e-07 - mean_absolute_error: 7.2371e-04\n",
      "Epoch 489: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.0404e-07 - mean_absolute_error: 7.2371e-04 - val_loss: 3089.7627 - val_mean_absolute_error: 55.5168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 490/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2452e-07 - mean_absolute_error: 4.5686e-04\n",
      "Epoch 490: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.2452e-07 - mean_absolute_error: 4.5686e-04 - val_loss: 3089.7581 - val_mean_absolute_error: 55.5167\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3591e-07 - mean_absolute_error: 4.7296e-04\n",
      "Epoch 491: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.3591e-07 - mean_absolute_error: 4.7296e-04 - val_loss: 3089.8838 - val_mean_absolute_error: 55.5179\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.4542e-07 - mean_absolute_error: 6.2874e-04\n",
      "Epoch 492: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.4542e-07 - mean_absolute_error: 6.2874e-04 - val_loss: 3089.8149 - val_mean_absolute_error: 55.5173\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.2820e-08 - mean_absolute_error: 1.6233e-04\n",
      "Epoch 493: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.2820e-08 - mean_absolute_error: 1.6233e-04 - val_loss: 3089.7371 - val_mean_absolute_error: 55.5165\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.0479e-07 - mean_absolute_error: 6.2004e-04\n",
      "Epoch 494: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.0479e-07 - mean_absolute_error: 6.2004e-04 - val_loss: 3089.8438 - val_mean_absolute_error: 55.5175\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1222e-07 - mean_absolute_error: 3.2550e-04\n",
      "Epoch 495: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1222e-07 - mean_absolute_error: 3.2550e-04 - val_loss: 3089.8586 - val_mean_absolute_error: 55.5177\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8630e-07 - mean_absolute_error: 4.2315e-04\n",
      "Epoch 496: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.8630e-07 - mean_absolute_error: 4.2315e-04 - val_loss: 3089.7583 - val_mean_absolute_error: 55.5167\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.5019e-07 - mean_absolute_error: 4.8016e-04\n",
      "Epoch 497: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5019e-07 - mean_absolute_error: 4.8016e-04 - val_loss: 3089.8037 - val_mean_absolute_error: 55.5172\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.4318e-08 - mean_absolute_error: 1.4957e-04\n",
      "Epoch 498: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4318e-08 - mean_absolute_error: 1.4957e-04 - val_loss: 3089.8716 - val_mean_absolute_error: 55.5178\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.5111e-07 - mean_absolute_error: 4.8578e-04\n",
      "Epoch 499: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.5111e-07 - mean_absolute_error: 4.8578e-04 - val_loss: 3089.7944 - val_mean_absolute_error: 55.5171\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.6952e-08 - mean_absolute_error: 2.1240e-04\n",
      "Epoch 500: val_loss did not improve from 0.06669\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.6952e-08 - mean_absolute_error: 2.1240e-04 - val_loss: 3089.7793 - val_mean_absolute_error: 55.5169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x246a11f6be0>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NN_model.fit(X_train, y_train, epochs=500, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)\n",
    "keras_clf = keras.wrappers.scikit_learn.KerasClassifier(build_model)\n",
    "keras_clf.fit(X_train, y_train, epochs=500,\n",
    "              validation_data=(X_val, y_val),\n",
    "              callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "70b3e7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "[[42.548]\n",
      " [18.383]]\n",
      "[55.768 23.821]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_proba = keras_clf.predict(X_test)\n",
    "print(y_proba.round(3))\n",
    "print(y_test.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ad42c672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 881ms/step - loss: 6.4909 - mean_absolute_error: 2.1764 - val_loss: 2737.3608 - val_mean_absolute_error: 52.2884\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 20.9001 - mean_absolute_error: 4.1763 - val_loss: 2944.1995 - val_mean_absolute_error: 54.2140\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.9032 - mean_absolute_error: 2.0105 - val_loss: 3209.9258 - val_mean_absolute_error: 56.5885\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7652 - mean_absolute_error: 0.7746 - val_loss: 3364.0696 - val_mean_absolute_error: 57.9206\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.5458 - mean_absolute_error: 2.0141 - val_loss: 3370.4724 - val_mean_absolute_error: 57.9749\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.7765 - mean_absolute_error: 2.0665 - val_loss: 3288.9185 - val_mean_absolute_error: 57.2750\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5053 - mean_absolute_error: 1.3208 - val_loss: 3175.8438 - val_mean_absolute_error: 56.2905\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3077 - mean_absolute_error: 0.5435 - val_loss: 3070.8767 - val_mean_absolute_error: 55.3605\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7275 - mean_absolute_error: 0.7708 - val_loss: 3008.7683 - val_mean_absolute_error: 54.8021\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0605 - mean_absolute_error: 1.3510 - val_loss: 2996.7795 - val_mean_absolute_error: 54.6938\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.3393 - mean_absolute_error: 1.4443 - val_loss: 3027.2910 - val_mean_absolute_error: 54.9685\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 6.5350 - mean_absolute_error: 2.0886 - val_loss: 2544.8765 - val_mean_absolute_error: 50.4324\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 32.5592 - mean_absolute_error: 4.3886 - val_loss: 2833.0972 - val_mean_absolute_error: 53.1790\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.7488 - mean_absolute_error: 2.2289 - val_loss: 3171.9258 - val_mean_absolute_error: 56.2204\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.6947 - mean_absolute_error: 1.3048 - val_loss: 3336.3865 - val_mean_absolute_error: 57.6238\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.1434 - mean_absolute_error: 2.5168 - val_loss: 3294.8477 - val_mean_absolute_error: 57.2572\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6.8446 - mean_absolute_error: 2.1672 - val_loss: 3143.2476 - val_mean_absolute_error: 55.9342\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.7432 - mean_absolute_error: 1.1207 - val_loss: 2964.2512 - val_mean_absolute_error: 54.3294\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0937 - mean_absolute_error: 1.0009 - val_loss: 2848.6069 - val_mean_absolute_error: 53.2656\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8577 - mean_absolute_error: 1.6809 - val_loss: 2836.0596 - val_mean_absolute_error: 53.1455\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2404 - mean_absolute_error: 1.7338 - val_loss: 2896.0415 - val_mean_absolute_error: 53.6963\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2008 - mean_absolute_error: 1.3259 - val_loss: 2987.7466 - val_mean_absolute_error: 54.5309\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 1.7816 - mean_absolute_error: 0.9430 - val_loss: 3376.3599 - val_mean_absolute_error: 57.9419\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.1680 - mean_absolute_error: 2.3981 - val_loss: 2973.6401 - val_mean_absolute_error: 54.3980\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7100 - mean_absolute_error: 1.1859 - val_loss: 2834.6055 - val_mean_absolute_error: 53.1323\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.0172 - mean_absolute_error: 2.0731 - val_loss: 2944.2197 - val_mean_absolute_error: 54.1510\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4659 - mean_absolute_error: 1.4564 - val_loss: 3105.5454 - val_mean_absolute_error: 55.6131\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7878 - mean_absolute_error: 0.7265 - val_loss: 3221.4331 - val_mean_absolute_error: 56.6433\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.1404 - mean_absolute_error: 1.2346 - val_loss: 3247.4949 - val_mean_absolute_error: 56.8783\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.6563 - mean_absolute_error: 1.3392 - val_loss: 3205.0454 - val_mean_absolute_error: 56.5155\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6942 - mean_absolute_error: 1.0359 - val_loss: 3127.0879 - val_mean_absolute_error: 55.8324\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9071 - mean_absolute_error: 0.6173 - val_loss: 3054.4312 - val_mean_absolute_error: 55.1852\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1377 - mean_absolute_error: 0.9954 - val_loss: 3016.8154 - val_mean_absolute_error: 54.8453\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6062 - mean_absolute_error: 1.2118 - val_loss: 3018.8953 - val_mean_absolute_error: 54.8614\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5033 - mean_absolute_error: 1.1775 - val_loss: 3051.7095 - val_mean_absolute_error: 55.1540\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 8.8727 - mean_absolute_error: 2.4911 - val_loss: 2770.3337 - val_mean_absolute_error: 52.5953\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.6153 - mean_absolute_error: 1.9029 - val_loss: 2768.6416 - val_mean_absolute_error: 52.5720\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1981 - mean_absolute_error: 1.8607 - val_loss: 2949.7126 - val_mean_absolute_error: 54.2454\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2263 - mean_absolute_error: 1.0142 - val_loss: 3119.9316 - val_mean_absolute_error: 55.7658\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3319 - mean_absolute_error: 0.8738 - val_loss: 3198.5425 - val_mean_absolute_error: 56.4465\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.6155 - mean_absolute_error: 1.2531 - val_loss: 3181.9729 - val_mean_absolute_error: 56.2955\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.2065 - mean_absolute_error: 1.1201 - val_loss: 3097.9536 - val_mean_absolute_error: 55.5489\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9772 - mean_absolute_error: 0.7973 - val_loss: 2994.7969 - val_mean_absolute_error: 54.6198\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6328 - mean_absolute_error: 0.7388 - val_loss: 2925.9443 - val_mean_absolute_error: 53.9911\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2226 - mean_absolute_error: 1.0632 - val_loss: 2917.0498 - val_mean_absolute_error: 53.9118\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3500 - mean_absolute_error: 1.0978 - val_loss: 2957.5454 - val_mean_absolute_error: 54.2867\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8274 - mean_absolute_error: 0.8941 - val_loss: 3022.0459 - val_mean_absolute_error: 54.8758\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 539ms/step - loss: 12.1540 - mean_absolute_error: 2.8550 - val_loss: 2897.4729 - val_mean_absolute_error: 53.7747\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 2.4478 - mean_absolute_error: 1.3502 - val_loss: 2754.4517 - val_mean_absolute_error: 52.4352\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.7378 - mean_absolute_error: 1.9572 - val_loss: 2842.3047 - val_mean_absolute_error: 53.2561\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.0363 - mean_absolute_error: 1.5220 - val_loss: 2995.8547 - val_mean_absolute_error: 54.6606\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0869 - mean_absolute_error: 0.8635 - val_loss: 3130.6428 - val_mean_absolute_error: 55.8603\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4812 - mean_absolute_error: 0.8968 - val_loss: 3196.9468 - val_mean_absolute_error: 56.4378\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.3633 - mean_absolute_error: 1.1761 - val_loss: 3191.4780 - val_mean_absolute_error: 56.3863\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2071 - mean_absolute_error: 1.1233 - val_loss: 3133.7163 - val_mean_absolute_error: 55.8766\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3522 - mean_absolute_error: 0.8675 - val_loss: 3050.5674 - val_mean_absolute_error: 55.1370\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7875 - mean_absolute_error: 0.6412 - val_loss: 2970.7715 - val_mean_absolute_error: 54.4149\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9562 - mean_absolute_error: 0.9370 - val_loss: 2925.5283 - val_mean_absolute_error: 53.9989\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3597 - mean_absolute_error: 1.1237 - val_loss: 2924.3330 - val_mean_absolute_error: 53.9840\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 631ms/step - loss: 3.4143 - mean_absolute_error: 1.4913 - val_loss: 3100.6423 - val_mean_absolute_error: 55.6229\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4894 - mean_absolute_error: 0.5578 - val_loss: 3102.8208 - val_mean_absolute_error: 55.6445\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4160 - mean_absolute_error: 0.4863 - val_loss: 3164.5940 - val_mean_absolute_error: 56.1914\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3110 - mean_absolute_error: 0.4686 - val_loss: 3155.4131 - val_mean_absolute_error: 56.1110\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2309 - mean_absolute_error: 0.3928 - val_loss: 3115.5869 - val_mean_absolute_error: 55.7603\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2549 - mean_absolute_error: 0.3705 - val_loss: 3131.1689 - val_mean_absolute_error: 55.8977\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1783 - mean_absolute_error: 0.3275 - val_loss: 3161.3320 - val_mean_absolute_error: 56.1626\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1996 - mean_absolute_error: 0.4091 - val_loss: 3152.4644 - val_mean_absolute_error: 56.0858\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1480 - mean_absolute_error: 0.3247 - val_loss: 3126.5627 - val_mean_absolute_error: 55.8590\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1667 - mean_absolute_error: 0.3225 - val_loss: 3139.4712 - val_mean_absolute_error: 55.9745\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1236 - mean_absolute_error: 0.2369 - val_loss: 3163.7488 - val_mean_absolute_error: 56.1891\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 621ms/step - loss: 6.4788 - mean_absolute_error: 2.1034 - val_loss: 3141.5693 - val_mean_absolute_error: 55.9827\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.1452 - mean_absolute_error: 0.9118 - val_loss: 2942.1382 - val_mean_absolute_error: 54.1888\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9940 - mean_absolute_error: 1.7672 - val_loss: 3038.3442 - val_mean_absolute_error: 55.0528\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8194 - mean_absolute_error: 1.0912 - val_loss: 3141.6636 - val_mean_absolute_error: 55.9679\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8492 - mean_absolute_error: 0.8488 - val_loss: 3159.2209 - val_mean_absolute_error: 56.1200\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0465 - mean_absolute_error: 0.9926 - val_loss: 3119.7544 - val_mean_absolute_error: 55.7670\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5263 - mean_absolute_error: 0.8299 - val_loss: 3049.4331 - val_mean_absolute_error: 55.1342\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2664 - mean_absolute_error: 0.8719 - val_loss: 2998.1836 - val_mean_absolute_error: 54.6643\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4830 - mean_absolute_error: 1.1254 - val_loss: 3006.9224 - val_mean_absolute_error: 54.7338\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1653 - mean_absolute_error: 0.9905 - val_loss: 3043.9351 - val_mean_absolute_error: 55.0590\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8614 - mean_absolute_error: 0.7912 - val_loss: 3073.3794 - val_mean_absolute_error: 55.3143\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8727 - mean_absolute_error: 0.7808 - val_loss: 3073.3584 - val_mean_absolute_error: 55.3029\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 653ms/step - loss: 7.2262 - mean_absolute_error: 2.2356 - val_loss: 3137.5112 - val_mean_absolute_error: 55.9484\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.1416 - mean_absolute_error: 0.9095 - val_loss: 2976.5059 - val_mean_absolute_error: 54.5037\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.0816 - mean_absolute_error: 1.5615 - val_loss: 3057.1492 - val_mean_absolute_error: 55.2258\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7404 - mean_absolute_error: 1.0463 - val_loss: 3143.6655 - val_mean_absolute_error: 55.9889\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.7692 - mean_absolute_error: 0.8779 - val_loss: 3137.6406 - val_mean_absolute_error: 55.9290\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6154 - mean_absolute_error: 0.8858 - val_loss: 3073.8020 - val_mean_absolute_error: 55.3543\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2158 - mean_absolute_error: 0.8227 - val_loss: 3016.9238 - val_mean_absolute_error: 54.8326\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4324 - mean_absolute_error: 1.1309 - val_loss: 3041.5098 - val_mean_absolute_error: 55.0448\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0915 - mean_absolute_error: 0.9103 - val_loss: 3092.7222 - val_mean_absolute_error: 55.4971\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0572 - mean_absolute_error: 0.8726 - val_loss: 3105.9016 - val_mean_absolute_error: 55.6100\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1391 - mean_absolute_error: 0.9744 - val_loss: 3077.2251 - val_mean_absolute_error: 55.3474\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9757 - mean_absolute_error: 0.8630 - val_loss: 3036.6677 - val_mean_absolute_error: 54.9785\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.4592 - mean_absolute_error: 2.0852 - val_loss: 3092.7329 - val_mean_absolute_error: 55.5501\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.9215 - mean_absolute_error: 0.8603 - val_loss: 2881.4409 - val_mean_absolute_error: 53.6320\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 3.0926 - mean_absolute_error: 1.4539 - val_loss: 2982.8232 - val_mean_absolute_error: 54.5537\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4570 - mean_absolute_error: 0.9546 - val_loss: 3073.8821 - val_mean_absolute_error: 55.3670\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3334 - mean_absolute_error: 0.7599 - val_loss: 3099.9622 - val_mean_absolute_error: 55.5946\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4355 - mean_absolute_error: 0.8553 - val_loss: 3072.1025 - val_mean_absolute_error: 55.3400\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1322 - mean_absolute_error: 0.7511 - val_loss: 3007.0530 - val_mean_absolute_error: 54.7469\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8961 - mean_absolute_error: 0.7797 - val_loss: 2950.0566 - val_mean_absolute_error: 54.2191\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0682 - mean_absolute_error: 1.0047 - val_loss: 2961.7212 - val_mean_absolute_error: 54.3171\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9457 - mean_absolute_error: 0.9285 - val_loss: 3014.8506 - val_mean_absolute_error: 54.7972\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7571 - mean_absolute_error: 0.7906 - val_loss: 3060.6597 - val_mean_absolute_error: 55.2140\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8140 - mean_absolute_error: 0.7936 - val_loss: 3068.8892 - val_mean_absolute_error: 55.2916\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 624ms/step - loss: 6.2925 - mean_absolute_error: 2.0554 - val_loss: 3122.7402 - val_mean_absolute_error: 55.8196\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2553 - mean_absolute_error: 1.0042 - val_loss: 2932.7090 - val_mean_absolute_error: 54.1097\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0577 - mean_absolute_error: 1.1536 - val_loss: 2931.4216 - val_mean_absolute_error: 54.0941\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9121 - mean_absolute_error: 1.1341 - val_loss: 3011.6143 - val_mean_absolute_error: 54.8207\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4231 - mean_absolute_error: 0.9150 - val_loss: 3068.4485 - val_mean_absolute_error: 55.3285\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4878 - mean_absolute_error: 0.7914 - val_loss: 3064.0698 - val_mean_absolute_error: 55.2843\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3461 - mean_absolute_error: 0.7718 - val_loss: 3011.1523 - val_mean_absolute_error: 54.8021\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0734 - mean_absolute_error: 0.7636 - val_loss: 2954.0281 - val_mean_absolute_error: 54.2747\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1441 - mean_absolute_error: 0.9898 - val_loss: 2973.5430 - val_mean_absolute_error: 54.4455\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9363 - mean_absolute_error: 0.8859 - val_loss: 3027.5017 - val_mean_absolute_error: 54.9308\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8113 - mean_absolute_error: 0.7154 - val_loss: 3052.7981 - val_mean_absolute_error: 55.1552\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8383 - mean_absolute_error: 0.7550 - val_loss: 3030.7561 - val_mean_absolute_error: 54.9504\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7211 - mean_absolute_error: 0.7650 - val_loss: 2989.0994 - val_mean_absolute_error: 54.5669\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 5.8618 - mean_absolute_error: 2.0724 - val_loss: 2747.2122 - val_mean_absolute_error: 52.3983\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 19.4558 - mean_absolute_error: 3.9278 - val_loss: 2944.8562 - val_mean_absolute_error: 54.2311\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.8433 - mean_absolute_error: 1.9496 - val_loss: 3187.6077 - val_mean_absolute_error: 56.3953\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5646 - mean_absolute_error: 0.6442 - val_loss: 3336.6353 - val_mean_absolute_error: 57.6820\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.9875 - mean_absolute_error: 1.8686 - val_loss: 3346.1401 - val_mean_absolute_error: 57.7617\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.4938 - mean_absolute_error: 1.9634 - val_loss: 3274.0684 - val_mean_absolute_error: 57.1448\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.5599 - mean_absolute_error: 1.3197 - val_loss: 3174.8755 - val_mean_absolute_error: 56.2831\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3726 - mean_absolute_error: 0.5855 - val_loss: 3082.0398 - val_mean_absolute_error: 55.4629\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5320 - mean_absolute_error: 0.6265 - val_loss: 3021.3818 - val_mean_absolute_error: 54.9209\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8251 - mean_absolute_error: 1.2366 - val_loss: 3006.0376 - val_mean_absolute_error: 54.7828\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.3135 - mean_absolute_error: 1.3944 - val_loss: 3028.2671 - val_mean_absolute_error: 54.9830\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 2.5563 - mean_absolute_error: 1.0833 - val_loss: 2586.3752 - val_mean_absolute_error: 50.8285\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 26.1188 - mean_absolute_error: 3.9788 - val_loss: 2920.4541 - val_mean_absolute_error: 53.9772\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4801 - mean_absolute_error: 1.7080 - val_loss: 3250.3787 - val_mean_absolute_error: 56.9071\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5173 - mean_absolute_error: 1.7668 - val_loss: 3368.6211 - val_mean_absolute_error: 57.9135\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.6243 - mean_absolute_error: 2.6129 - val_loss: 3312.7993 - val_mean_absolute_error: 57.4327\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.0639 - mean_absolute_error: 2.2330 - val_loss: 3187.8494 - val_mean_absolute_error: 56.3443\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.6863 - mean_absolute_error: 1.3222 - val_loss: 3052.9956 - val_mean_absolute_error: 55.1463\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9275 - mean_absolute_error: 0.7242 - val_loss: 2937.3770 - val_mean_absolute_error: 54.0973\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.9706 - mean_absolute_error: 1.3482 - val_loss: 2884.8550 - val_mean_absolute_error: 53.6128\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2747 - mean_absolute_error: 1.6614 - val_loss: 2893.2119 - val_mean_absolute_error: 53.6892\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.9789 - mean_absolute_error: 1.5947 - val_loss: 2941.9019 - val_mean_absolute_error: 54.1364\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 586ms/step - loss: 3.1360 - mean_absolute_error: 1.2524 - val_loss: 2618.4829 - val_mean_absolute_error: 51.1437\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.6419 - mean_absolute_error: 3.7462 - val_loss: 2928.3613 - val_mean_absolute_error: 54.0547\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8464 - mean_absolute_error: 1.7597 - val_loss: 3230.0815 - val_mean_absolute_error: 56.7349\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7643 - mean_absolute_error: 1.5019 - val_loss: 3360.8647 - val_mean_absolute_error: 57.8522\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 8.9371 - mean_absolute_error: 2.4388 - val_loss: 3334.9043 - val_mean_absolute_error: 57.6279\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.5263 - mean_absolute_error: 2.2202 - val_loss: 3228.6963 - val_mean_absolute_error: 56.7115\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4441 - mean_absolute_error: 1.4681 - val_loss: 3100.2827 - val_mean_absolute_error: 55.5842\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2591 - mean_absolute_error: 0.7710 - val_loss: 2983.0923 - val_mean_absolute_error: 54.5343\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9356 - mean_absolute_error: 1.3174 - val_loss: 2914.7009 - val_mean_absolute_error: 53.9115\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4375 - mean_absolute_error: 1.7190 - val_loss: 2905.2896 - val_mean_absolute_error: 53.8243\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.7373 - mean_absolute_error: 1.7770 - val_loss: 2938.8806 - val_mean_absolute_error: 54.1308\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 545ms/step - loss: 10.7317 - mean_absolute_error: 2.8125 - val_loss: 2791.1084 - val_mean_absolute_error: 52.8072\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.2422 - mean_absolute_error: 2.0671 - val_loss: 2812.6990 - val_mean_absolute_error: 52.9988\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.4972 - mean_absolute_error: 1.9410 - val_loss: 2994.8760 - val_mean_absolute_error: 54.6605\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8300 - mean_absolute_error: 1.0557 - val_loss: 3169.1875 - val_mean_absolute_error: 56.1981\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9829 - mean_absolute_error: 1.0185 - val_loss: 3234.8545 - val_mean_absolute_error: 56.7546\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.9523 - mean_absolute_error: 1.3112 - val_loss: 3182.4204 - val_mean_absolute_error: 56.2867\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9024 - mean_absolute_error: 1.0287 - val_loss: 3068.3027 - val_mean_absolute_error: 55.2744\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8557 - mean_absolute_error: 0.7178 - val_loss: 2959.2107 - val_mean_absolute_error: 54.2912\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3638 - mean_absolute_error: 1.1312 - val_loss: 2921.6807 - val_mean_absolute_error: 53.9449\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.8552 - mean_absolute_error: 1.2879 - val_loss: 2960.6631 - val_mean_absolute_error: 54.2952\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2477 - mean_absolute_error: 1.0910 - val_loss: 3041.4897 - val_mean_absolute_error: 55.0192\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 5.4526 - mean_absolute_error: 1.9095 - val_loss: 2776.7734 - val_mean_absolute_error: 52.6530\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.5495 - mean_absolute_error: 1.8780 - val_loss: 2833.1929 - val_mean_absolute_error: 53.1716\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.0958 - mean_absolute_error: 1.5232 - val_loss: 3003.7241 - val_mean_absolute_error: 54.7246\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8438 - mean_absolute_error: 0.7414 - val_loss: 3144.5474 - val_mean_absolute_error: 55.9722\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6742 - mean_absolute_error: 0.9565 - val_loss: 3180.2720 - val_mean_absolute_error: 56.2795\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2079 - mean_absolute_error: 1.0716 - val_loss: 3139.3730 - val_mean_absolute_error: 55.9121\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.4423 - mean_absolute_error: 0.8964 - val_loss: 3056.5869 - val_mean_absolute_error: 55.1718\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6890 - mean_absolute_error: 0.7478 - val_loss: 2975.2019 - val_mean_absolute_error: 54.4362\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8455 - mean_absolute_error: 0.8889 - val_loss: 2936.4917 - val_mean_absolute_error: 54.0841\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2605 - mean_absolute_error: 1.0717 - val_loss: 2950.2251 - val_mean_absolute_error: 54.2124\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0898 - mean_absolute_error: 1.0087 - val_loss: 3001.1567 - val_mean_absolute_error: 54.6787\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 11.2742 - mean_absolute_error: 2.9048 - val_loss: 2866.1411 - val_mean_absolute_error: 53.4869\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 10.2664 - mean_absolute_error: 3.0259 - val_loss: 2925.8608 - val_mean_absolute_error: 54.0437\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6.6445 - mean_absolute_error: 2.4133 - val_loss: 3102.5078 - val_mean_absolute_error: 55.6436\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5884 - mean_absolute_error: 0.6601 - val_loss: 3268.2749 - val_mean_absolute_error: 57.1029\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4291 - mean_absolute_error: 1.0222 - val_loss: 3335.2014 - val_mean_absolute_error: 57.6821\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.4347 - mean_absolute_error: 1.6255 - val_loss: 3315.9866 - val_mean_absolute_error: 57.5162\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.8014 - mean_absolute_error: 1.4488 - val_loss: 3246.7788 - val_mean_absolute_error: 56.9163\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1403 - mean_absolute_error: 0.9616 - val_loss: 3160.3428 - val_mean_absolute_error: 56.1579\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2459 - mean_absolute_error: 0.4295 - val_loss: 3086.8884 - val_mean_absolute_error: 55.5065\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6673 - mean_absolute_error: 0.6403 - val_loss: 3044.2358 - val_mean_absolute_error: 55.1253\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3917 - mean_absolute_error: 1.0316 - val_loss: 3037.6748 - val_mean_absolute_error: 55.0670\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 12.6376 - mean_absolute_error: 2.9433 - val_loss: 2708.3564 - val_mean_absolute_error: 52.0107\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 15.4603 - mean_absolute_error: 3.1580 - val_loss: 2812.4927 - val_mean_absolute_error: 52.9870\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.0085 - mean_absolute_error: 2.3918 - val_loss: 3019.4626 - val_mean_absolute_error: 54.8766\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7492 - mean_absolute_error: 1.0217 - val_loss: 3200.0244 - val_mean_absolute_error: 56.4653\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2032 - mean_absolute_error: 1.4092 - val_loss: 3264.6694 - val_mean_absolute_error: 57.0152\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.9994 - mean_absolute_error: 1.8494 - val_loss: 3219.1462 - val_mean_absolute_error: 56.6119\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5078 - mean_absolute_error: 1.5363 - val_loss: 3116.1704 - val_mean_absolute_error: 55.7027\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step - loss: 1.3346 - mean_absolute_error: 0.9780 - val_loss: 3002.3020 - val_mean_absolute_error: 54.6814\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8305 - mean_absolute_error: 0.8384 - val_loss: 2919.9961 - val_mean_absolute_error: 53.9296\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8386 - mean_absolute_error: 1.3008 - val_loss: 2897.4758 - val_mean_absolute_error: 53.7178\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2622 - mean_absolute_error: 1.4046 - val_loss: 2924.0342 - val_mean_absolute_error: 53.9548\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 17.9339 - mean_absolute_error: 3.4363 - val_loss: 2815.1042 - val_mean_absolute_error: 53.0042\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 8.7853 - mean_absolute_error: 2.4177 - val_loss: 2773.2915 - val_mean_absolute_error: 52.6132\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 10.2166 - mean_absolute_error: 2.6571 - val_loss: 2940.6458 - val_mean_absolute_error: 54.1586\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.1084 - mean_absolute_error: 1.6063 - val_loss: 3131.5576 - val_mean_absolute_error: 55.8638\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5809 - mean_absolute_error: 0.9836 - val_loss: 3252.2832 - val_mean_absolute_error: 56.9114\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9716 - mean_absolute_error: 1.6374 - val_loss: 3271.3840 - val_mean_absolute_error: 57.0705\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.6912 - mean_absolute_error: 1.7761 - val_loss: 3217.9866 - val_mean_absolute_error: 56.6038\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.0668 - mean_absolute_error: 1.5196 - val_loss: 3126.3989 - val_mean_absolute_error: 55.7986\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3170 - mean_absolute_error: 1.0451 - val_loss: 3026.6375 - val_mean_absolute_error: 54.9076\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1347 - mean_absolute_error: 0.9677 - val_loss: 2955.6858 - val_mean_absolute_error: 54.2649\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.1115 - mean_absolute_error: 1.3992 - val_loss: 2937.9221 - val_mean_absolute_error: 54.1047\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.4745 - mean_absolute_error: 1.4983 - val_loss: 2964.5486 - val_mean_absolute_error: 54.3486\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 6.3391 - mean_absolute_error: 2.0712 - val_loss: 2659.3242 - val_mean_absolute_error: 51.5567\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 12.7634 - mean_absolute_error: 2.5536 - val_loss: 2834.9595 - val_mean_absolute_error: 53.2118\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4402 - mean_absolute_error: 1.6545 - val_loss: 3075.3748 - val_mean_absolute_error: 55.3894\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4935 - mean_absolute_error: 0.8188 - val_loss: 3219.0894 - val_mean_absolute_error: 56.6419\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.6476 - mean_absolute_error: 1.5079 - val_loss: 3224.1025 - val_mean_absolute_error: 56.6752\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.6679 - mean_absolute_error: 1.4890 - val_loss: 3135.7368 - val_mean_absolute_error: 55.8937\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8081 - mean_absolute_error: 1.0373 - val_loss: 3012.2036 - val_mean_absolute_error: 54.7876\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7965 - mean_absolute_error: 0.7120 - val_loss: 2907.4375 - val_mean_absolute_error: 53.8333\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5787 - mean_absolute_error: 1.1978 - val_loss: 2874.8818 - val_mean_absolute_error: 53.5311\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.1424 - mean_absolute_error: 1.3497 - val_loss: 2909.1689 - val_mean_absolute_error: 53.8436\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5227 - mean_absolute_error: 1.1803 - val_loss: 2978.7207 - val_mean_absolute_error: 54.4777\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 5.3035 - mean_absolute_error: 1.9619 - val_loss: 2687.8291 - val_mean_absolute_error: 51.7930\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 14.7251 - mean_absolute_error: 2.7210 - val_loss: 2911.0259 - val_mean_absolute_error: 53.8860\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8320 - mean_absolute_error: 1.5439 - val_loss: 3216.7158 - val_mean_absolute_error: 56.6143\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6699 - mean_absolute_error: 1.0362 - val_loss: 3368.5669 - val_mean_absolute_error: 57.9121\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.1289 - mean_absolute_error: 1.8945 - val_loss: 3336.1680 - val_mean_absolute_error: 57.6264\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1738 - mean_absolute_error: 1.6791 - val_loss: 3212.3574 - val_mean_absolute_error: 56.5450\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4883 - mean_absolute_error: 0.9268 - val_loss: 3056.9670 - val_mean_absolute_error: 55.1648\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5804 - mean_absolute_error: 0.7273 - val_loss: 2933.4448 - val_mean_absolute_error: 54.0424\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.9126 - mean_absolute_error: 1.2520 - val_loss: 2895.6157 - val_mean_absolute_error: 53.6941\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.6293 - mean_absolute_error: 1.3981 - val_loss: 2932.6179 - val_mean_absolute_error: 54.0337\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8293 - mean_absolute_error: 1.2208 - val_loss: 3012.6567 - val_mean_absolute_error: 54.7617\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 5.5884 - mean_absolute_error: 1.9751 - val_loss: 3127.0015 - val_mean_absolute_error: 55.8636\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3525 - mean_absolute_error: 0.5438 - val_loss: 3085.4780 - val_mean_absolute_error: 55.4936\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6277 - mean_absolute_error: 0.6619 - val_loss: 3178.2588 - val_mean_absolute_error: 56.3115\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3461 - mean_absolute_error: 0.5309 - val_loss: 3169.8157 - val_mean_absolute_error: 56.2392\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2705 - mean_absolute_error: 0.4707 - val_loss: 3113.4126 - val_mean_absolute_error: 55.7433\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2691 - mean_absolute_error: 0.4105 - val_loss: 3118.8833 - val_mean_absolute_error: 55.7925\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2069 - mean_absolute_error: 0.3648 - val_loss: 3166.0771 - val_mean_absolute_error: 56.2089\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1906 - mean_absolute_error: 0.4271 - val_loss: 3168.0212 - val_mean_absolute_error: 56.2272\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1791 - mean_absolute_error: 0.4186 - val_loss: 3129.8132 - val_mean_absolute_error: 55.8915\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1507 - mean_absolute_error: 0.3261 - val_loss: 3124.3140 - val_mean_absolute_error: 55.8435\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1783 - mean_absolute_error: 0.3740 - val_loss: 3158.6353 - val_mean_absolute_error: 56.1463\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1235 - mean_absolute_error: 0.3174 - val_loss: 3172.1138 - val_mean_absolute_error: 56.2647\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 618ms/step - loss: 7.0376 - mean_absolute_error: 2.2069 - val_loss: 3176.1982 - val_mean_absolute_error: 56.2899\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6210 - mean_absolute_error: 1.0264 - val_loss: 3004.0659 - val_mean_absolute_error: 54.7572\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.9770 - mean_absolute_error: 1.4430 - val_loss: 3040.7349 - val_mean_absolute_error: 55.0841\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.1406 - mean_absolute_error: 1.1565 - val_loss: 3105.5596 - val_mean_absolute_error: 55.6601\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7333 - mean_absolute_error: 0.8431 - val_loss: 3138.7742 - val_mean_absolute_error: 55.9502\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7866 - mean_absolute_error: 0.8184 - val_loss: 3122.7080 - val_mean_absolute_error: 55.8020\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5037 - mean_absolute_error: 0.7643 - val_loss: 3070.8232 - val_mean_absolute_error: 55.3326\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1813 - mean_absolute_error: 0.7730 - val_loss: 3023.2791 - val_mean_absolute_error: 54.8951\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1504 - mean_absolute_error: 0.9750 - val_loss: 3032.1479 - val_mean_absolute_error: 54.9606\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7878 - mean_absolute_error: 0.7906 - val_loss: 3065.4167 - val_mean_absolute_error: 55.2451\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6064 - mean_absolute_error: 0.6508 - val_loss: 3068.6055 - val_mean_absolute_error: 55.2590\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5522 - mean_absolute_error: 0.7083 - val_loss: 3030.4141 - val_mean_absolute_error: 54.8984\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 630ms/step - loss: 6.0364 - mean_absolute_error: 2.0084 - val_loss: 3119.6465 - val_mean_absolute_error: 55.7944\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1371 - mean_absolute_error: 0.8963 - val_loss: 2965.2903 - val_mean_absolute_error: 54.4044\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5126 - mean_absolute_error: 1.6566 - val_loss: 3045.7041 - val_mean_absolute_error: 55.1260\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9634 - mean_absolute_error: 1.1216 - val_loss: 3128.8857 - val_mean_absolute_error: 55.8624\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8136 - mean_absolute_error: 0.8464 - val_loss: 3155.9182 - val_mean_absolute_error: 56.0974\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0290 - mean_absolute_error: 0.9355 - val_loss: 3126.9526 - val_mean_absolute_error: 55.8384\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7149 - mean_absolute_error: 0.8530 - val_loss: 3072.1052 - val_mean_absolute_error: 55.3476\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4680 - mean_absolute_error: 0.8714 - val_loss: 3026.3872 - val_mean_absolute_error: 54.9318\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5914 - mean_absolute_error: 1.1146 - val_loss: 3030.5156 - val_mean_absolute_error: 54.9623\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4143 - mean_absolute_error: 1.0410 - val_loss: 3060.0542 - val_mean_absolute_error: 55.2225\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1935 - mean_absolute_error: 0.8619 - val_loss: 3084.9248 - val_mean_absolute_error: 55.4396\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1788 - mean_absolute_error: 0.8441 - val_loss: 3087.5146 - val_mean_absolute_error: 55.4561\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 6.7813 - mean_absolute_error: 2.1359 - val_loss: 3108.4233 - val_mean_absolute_error: 55.6932\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.1340 - mean_absolute_error: 0.8848 - val_loss: 2885.0586 - val_mean_absolute_error: 53.6721\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3520 - mean_absolute_error: 1.4559 - val_loss: 2976.3408 - val_mean_absolute_error: 54.5029\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8415 - mean_absolute_error: 1.0795 - val_loss: 3077.8008 - val_mean_absolute_error: 55.4136\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6405 - mean_absolute_error: 0.8232 - val_loss: 3111.0488 - val_mean_absolute_error: 55.7066\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8089 - mean_absolute_error: 0.8950 - val_loss: 3092.1455 - val_mean_absolute_error: 55.5356\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5607 - mean_absolute_error: 0.8220 - val_loss: 3039.2153 - val_mean_absolute_error: 55.0583\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2409 - mean_absolute_error: 0.8094 - val_loss: 2979.2539 - val_mean_absolute_error: 54.5110\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2213 - mean_absolute_error: 0.9472 - val_loss: 2958.5386 - val_mean_absolute_error: 54.3151\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2000 - mean_absolute_error: 1.0141 - val_loss: 2985.1055 - val_mean_absolute_error: 54.5499\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9356 - mean_absolute_error: 0.8728 - val_loss: 3028.8022 - val_mean_absolute_error: 54.9401\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8127 - mean_absolute_error: 0.7050 - val_loss: 3053.7065 - val_mean_absolute_error: 55.1600\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 5.8187 - mean_absolute_error: 1.9637 - val_loss: 3077.6404 - val_mean_absolute_error: 55.4243\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0028 - mean_absolute_error: 0.8536 - val_loss: 2827.9028 - val_mean_absolute_error: 53.1494\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6053 - mean_absolute_error: 1.5315 - val_loss: 2925.3965 - val_mean_absolute_error: 54.0424\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.8651 - mean_absolute_error: 1.1028 - val_loss: 3032.6738 - val_mean_absolute_error: 55.0088\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3918 - mean_absolute_error: 0.7736 - val_loss: 3081.5405 - val_mean_absolute_error: 55.4387\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5440 - mean_absolute_error: 0.8604 - val_loss: 3072.9565 - val_mean_absolute_error: 55.3541\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3594 - mean_absolute_error: 0.8272 - val_loss: 3021.3098 - val_mean_absolute_error: 54.8823\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9992 - mean_absolute_error: 0.7279 - val_loss: 2945.9397 - val_mean_absolute_error: 54.1911\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0202 - mean_absolute_error: 0.9414 - val_loss: 2927.5713 - val_mean_absolute_error: 54.0166\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0990 - mean_absolute_error: 1.0060 - val_loss: 2974.1294 - val_mean_absolute_error: 54.4383\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8469 - mean_absolute_error: 0.8101 - val_loss: 3027.9150 - val_mean_absolute_error: 54.9276\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8043 - mean_absolute_error: 0.7762 - val_loss: 3055.3979 - val_mean_absolute_error: 55.1784\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.5211 - mean_absolute_error: 1.3054 - val_loss: 3081.3076 - val_mean_absolute_error: 55.4508\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7084 - mean_absolute_error: 0.6957 - val_loss: 3137.6399 - val_mean_absolute_error: 55.9513\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2805 - mean_absolute_error: 0.4562 - val_loss: 3186.2620 - val_mean_absolute_error: 56.3797\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4486 - mean_absolute_error: 0.6144 - val_loss: 3131.9175 - val_mean_absolute_error: 55.9039\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2159 - mean_absolute_error: 0.3776 - val_loss: 3109.0461 - val_mean_absolute_error: 55.7033\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3264 - mean_absolute_error: 0.4653 - val_loss: 3155.7129 - val_mean_absolute_error: 56.1158\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1587 - mean_absolute_error: 0.3341 - val_loss: 3182.1443 - val_mean_absolute_error: 56.3480\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2573 - mean_absolute_error: 0.5014 - val_loss: 3156.6304 - val_mean_absolute_error: 56.1244\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1422 - mean_absolute_error: 0.3100 - val_loss: 3124.5713 - val_mean_absolute_error: 55.8423\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2123 - mean_absolute_error: 0.3946 - val_loss: 3137.2651 - val_mean_absolute_error: 55.9548\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1492 - mean_absolute_error: 0.3073 - val_loss: 3168.2979 - val_mean_absolute_error: 56.2280\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 629ms/step - loss: 6.2442 - mean_absolute_error: 2.0578 - val_loss: 3116.1221 - val_mean_absolute_error: 55.7649\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.1771 - mean_absolute_error: 0.9288 - val_loss: 2981.1748 - val_mean_absolute_error: 54.5496\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2117 - mean_absolute_error: 1.5610 - val_loss: 3092.1243 - val_mean_absolute_error: 55.5390\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6929 - mean_absolute_error: 0.8612 - val_loss: 3157.2512 - val_mean_absolute_error: 56.1097\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9118 - mean_absolute_error: 0.9053 - val_loss: 3131.6824 - val_mean_absolute_error: 55.8776\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5256 - mean_absolute_error: 0.7665 - val_loss: 3058.4995 - val_mean_absolute_error: 55.2178\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1320 - mean_absolute_error: 0.8296 - val_loss: 3001.0205 - val_mean_absolute_error: 54.6878\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2725 - mean_absolute_error: 1.0820 - val_loss: 3025.1384 - val_mean_absolute_error: 54.8913\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7854 - mean_absolute_error: 0.8180 - val_loss: 3068.2524 - val_mean_absolute_error: 55.2641\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6270 - mean_absolute_error: 0.6914 - val_loss: 3073.4956 - val_mean_absolute_error: 55.2953\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6580 - mean_absolute_error: 0.7928 - val_loss: 3042.0442 - val_mean_absolute_error: 54.9952\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5332 - mean_absolute_error: 0.6956 - val_loss: 3000.6396 - val_mean_absolute_error: 54.6109\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 633ms/step - loss: 7.8716 - mean_absolute_error: 2.3495 - val_loss: 3190.1887 - val_mean_absolute_error: 56.4158\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8826 - mean_absolute_error: 1.1458 - val_loss: 3051.2168 - val_mean_absolute_error: 55.1850\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.3532 - mean_absolute_error: 1.1641 - val_loss: 3029.1499 - val_mean_absolute_error: 54.9831\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.3980 - mean_absolute_error: 1.2762 - val_loss: 3090.6599 - val_mean_absolute_error: 55.5310\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8490 - mean_absolute_error: 0.8782 - val_loss: 3137.4062 - val_mean_absolute_error: 55.9443\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9553 - mean_absolute_error: 0.8486 - val_loss: 3132.7087 - val_mean_absolute_error: 55.9003\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8497 - mean_absolute_error: 0.8393 - val_loss: 3089.6987 - val_mean_absolute_error: 55.5153\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5976 - mean_absolute_error: 0.8444 - val_loss: 3044.5840 - val_mean_absolute_error: 55.1067\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6185 - mean_absolute_error: 1.0747 - val_loss: 3053.7583 - val_mean_absolute_error: 55.1833\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4078 - mean_absolute_error: 0.9904 - val_loss: 3097.7048 - val_mean_absolute_error: 55.5709\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2372 - mean_absolute_error: 0.7915 - val_loss: 3113.9917 - val_mean_absolute_error: 55.7085\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2076 - mean_absolute_error: 0.8038 - val_loss: 3082.1074 - val_mean_absolute_error: 55.4126\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9974 - mean_absolute_error: 0.7698 - val_loss: 3035.8147 - val_mean_absolute_error: 54.9837\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 636ms/step - loss: 6.2276 - mean_absolute_error: 2.0488 - val_loss: 3126.2026 - val_mean_absolute_error: 55.8525\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2910 - mean_absolute_error: 0.9807 - val_loss: 2938.3762 - val_mean_absolute_error: 54.1628\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.5747 - mean_absolute_error: 1.2559 - val_loss: 2964.7734 - val_mean_absolute_error: 54.3987\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9415 - mean_absolute_error: 1.1062 - val_loss: 3040.4023 - val_mean_absolute_error: 55.0777\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4395 - mean_absolute_error: 0.8737 - val_loss: 3084.3394 - val_mean_absolute_error: 55.4656\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4322 - mean_absolute_error: 0.7622 - val_loss: 3067.5320 - val_mean_absolute_error: 55.3101\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2053 - mean_absolute_error: 0.7043 - val_loss: 3010.6592 - val_mean_absolute_error: 54.7912\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9664 - mean_absolute_error: 0.7863 - val_loss: 2965.6799 - val_mean_absolute_error: 54.3744\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9997 - mean_absolute_error: 0.9481 - val_loss: 2990.6621 - val_mean_absolute_error: 54.5928\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7839 - mean_absolute_error: 0.8144 - val_loss: 3041.6348 - val_mean_absolute_error: 55.0472\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7083 - mean_absolute_error: 0.7385 - val_loss: 3063.7173 - val_mean_absolute_error: 55.2412\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7428 - mean_absolute_error: 0.7748 - val_loss: 3042.6733 - val_mean_absolute_error: 55.0460\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 625ms/step - loss: 5.2412 - mean_absolute_error: 1.8434 - val_loss: 3022.4993 - val_mean_absolute_error: 54.9262\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8031 - mean_absolute_error: 0.9961 - val_loss: 2888.9937 - val_mean_absolute_error: 53.7050\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.5351 - mean_absolute_error: 1.3302 - val_loss: 3020.8662 - val_mean_absolute_error: 54.9041\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5047 - mean_absolute_error: 0.8995 - val_loss: 3100.5183 - val_mean_absolute_error: 55.6134\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7924 - mean_absolute_error: 0.9044 - val_loss: 3048.9756 - val_mean_absolute_error: 55.1504\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4061 - mean_absolute_error: 0.7823 - val_loss: 2957.9180 - val_mean_absolute_error: 54.3236\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4028 - mean_absolute_error: 1.0013 - val_loss: 2947.9800 - val_mean_absolute_error: 54.2281\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3370 - mean_absolute_error: 1.0257 - val_loss: 3009.3501 - val_mean_absolute_error: 54.7809\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0551 - mean_absolute_error: 0.7524 - val_loss: 3056.0774 - val_mean_absolute_error: 55.1974\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1294 - mean_absolute_error: 0.7608 - val_loss: 3040.4805 - val_mean_absolute_error: 55.0514\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9992 - mean_absolute_error: 0.7428 - val_loss: 2985.5308 - val_mean_absolute_error: 54.5481\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9026 - mean_absolute_error: 0.8197 - val_loss: 2959.3281 - val_mean_absolute_error: 54.3032\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 546ms/step - loss: 18.4996 - mean_absolute_error: 3.7078 - val_loss: 3060.1760 - val_mean_absolute_error: 55.2485\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9619 - mean_absolute_error: 0.8269 - val_loss: 2945.1802 - val_mean_absolute_error: 54.2154\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5012 - mean_absolute_error: 2.0060 - val_loss: 2998.9932 - val_mean_absolute_error: 54.7095\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.4475 - mean_absolute_error: 1.4614 - val_loss: 3106.7905 - val_mean_absolute_error: 55.6759\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4116 - mean_absolute_error: 0.4978 - val_loss: 3203.0083 - val_mean_absolute_error: 56.5233\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7473 - mean_absolute_error: 0.7558 - val_loss: 3241.6030 - val_mean_absolute_error: 56.8605\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4366 - mean_absolute_error: 1.0199 - val_loss: 3230.7163 - val_mean_absolute_error: 56.7679\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1302 - mean_absolute_error: 0.9152 - val_loss: 3191.4373 - val_mean_absolute_error: 56.4277\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5026 - mean_absolute_error: 0.6322 - val_loss: 3145.9478 - val_mean_absolute_error: 56.0284\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2270 - mean_absolute_error: 0.4272 - val_loss: 3108.9170 - val_mean_absolute_error: 55.7014\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3754 - mean_absolute_error: 0.4646 - val_loss: 3091.8804 - val_mean_absolute_error: 55.5503\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5344 - mean_absolute_error: 0.5993 - val_loss: 3096.5146 - val_mean_absolute_error: 55.5919\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 565ms/step - loss: 9.9651 - mean_absolute_error: 2.6307 - val_loss: 2932.6465 - val_mean_absolute_error: 54.0996\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0092 - mean_absolute_error: 1.7869 - val_loss: 2920.2510 - val_mean_absolute_error: 53.9804\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0191 - mean_absolute_error: 1.7880 - val_loss: 3022.5823 - val_mean_absolute_error: 54.9012\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5096 - mean_absolute_error: 1.0773 - val_loss: 3121.7578 - val_mean_absolute_error: 55.7785\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2170 - mean_absolute_error: 0.7521 - val_loss: 3159.3716 - val_mean_absolute_error: 56.1006\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5953 - mean_absolute_error: 0.9932 - val_loss: 3136.0693 - val_mean_absolute_error: 55.8857\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1895 - mean_absolute_error: 0.9087 - val_loss: 3073.1477 - val_mean_absolute_error: 55.3184\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6515 - mean_absolute_error: 0.6522 - val_loss: 3007.2603 - val_mean_absolute_error: 54.7208\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8753 - mean_absolute_error: 0.9165 - val_loss: 2989.1841 - val_mean_absolute_error: 54.5518\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9604 - mean_absolute_error: 0.9630 - val_loss: 3015.3916 - val_mean_absolute_error: 54.7849\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5986 - mean_absolute_error: 0.7313 - val_loss: 3060.3633 - val_mean_absolute_error: 55.1874\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4520 - mean_absolute_error: 0.5960 - val_loss: 3095.0771 - val_mean_absolute_error: 55.4974\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 3.1690 - mean_absolute_error: 1.1867 - val_loss: 2681.7451 - val_mean_absolute_error: 51.7644\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 19.6593 - mean_absolute_error: 3.5082 - val_loss: 2981.0273 - val_mean_absolute_error: 54.5474\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.1099 - mean_absolute_error: 1.5367 - val_loss: 3212.1672 - val_mean_absolute_error: 56.5994\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.1110 - mean_absolute_error: 1.2838 - val_loss: 3271.9321 - val_mean_absolute_error: 57.1154\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7040 - mean_absolute_error: 1.7321 - val_loss: 3229.5889 - val_mean_absolute_error: 56.7456\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4822 - mean_absolute_error: 1.4306 - val_loss: 3135.7310 - val_mean_absolute_error: 55.9216\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8477 - mean_absolute_error: 0.8669 - val_loss: 3033.9880 - val_mean_absolute_error: 55.0137\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8832 - mean_absolute_error: 1.1470 - val_loss: 2979.1536 - val_mean_absolute_error: 54.5166\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.6357 - mean_absolute_error: 1.4686 - val_loss: 2985.7676 - val_mean_absolute_error: 54.5736\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.3815 - mean_absolute_error: 1.4023 - val_loss: 3030.2612 - val_mean_absolute_error: 54.9725\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6672 - mean_absolute_error: 1.1068 - val_loss: 3086.2119 - val_mean_absolute_error: 55.4702\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 9.0078 - mean_absolute_error: 2.5020 - val_loss: 2908.5459 - val_mean_absolute_error: 53.8869\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3126 - mean_absolute_error: 1.4216 - val_loss: 2891.2163 - val_mean_absolute_error: 53.7227\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3286 - mean_absolute_error: 1.4745 - val_loss: 3002.3865 - val_mean_absolute_error: 54.7317\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6263 - mean_absolute_error: 1.0189 - val_loss: 3114.8145 - val_mean_absolute_error: 55.7323\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6722 - mean_absolute_error: 0.8874 - val_loss: 3145.0400 - val_mean_absolute_error: 55.9946\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9368 - mean_absolute_error: 1.0087 - val_loss: 3107.8413 - val_mean_absolute_error: 55.6612\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4623 - mean_absolute_error: 0.8672 - val_loss: 3036.4058 - val_mean_absolute_error: 55.0203\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1236 - mean_absolute_error: 0.7845 - val_loss: 2979.7971 - val_mean_absolute_error: 54.5064\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3027 - mean_absolute_error: 1.0192 - val_loss: 2969.7163 - val_mean_absolute_error: 54.4096\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2796 - mean_absolute_error: 1.0485 - val_loss: 3003.4421 - val_mean_absolute_error: 54.7084\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9516 - mean_absolute_error: 0.8726 - val_loss: 3053.4937 - val_mean_absolute_error: 55.1520\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8516 - mean_absolute_error: 0.7310 - val_loss: 3084.1655 - val_mean_absolute_error: 55.4209\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 534ms/step - loss: 5.3492 - mean_absolute_error: 1.8957 - val_loss: 2969.7861 - val_mean_absolute_error: 54.4340\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7334 - mean_absolute_error: 1.0735 - val_loss: 2917.0698 - val_mean_absolute_error: 53.9406\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8535 - mean_absolute_error: 1.2450 - val_loss: 3000.1267 - val_mean_absolute_error: 54.6896\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9442 - mean_absolute_error: 0.8566 - val_loss: 3085.8027 - val_mean_absolute_error: 55.4530\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9602 - mean_absolute_error: 0.7241 - val_loss: 3105.6721 - val_mean_absolute_error: 55.6244\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9988 - mean_absolute_error: 0.7684 - val_loss: 3068.1895 - val_mean_absolute_error: 55.2838\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6855 - mean_absolute_error: 0.7151 - val_loss: 3010.4150 - val_mean_absolute_error: 54.7564\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6258 - mean_absolute_error: 0.7270 - val_loss: 2985.6367 - val_mean_absolute_error: 54.5281\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7222 - mean_absolute_error: 0.8219 - val_loss: 3012.9233 - val_mean_absolute_error: 54.7806\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5392 - mean_absolute_error: 0.6918 - val_loss: 3062.8796 - val_mean_absolute_error: 55.2405\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4164 - mean_absolute_error: 0.5823 - val_loss: 3097.8689 - val_mean_absolute_error: 55.5609\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4720 - mean_absolute_error: 0.5489 - val_loss: 3097.5203 - val_mean_absolute_error: 55.5613\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 5.9851 - mean_absolute_error: 2.1742 - val_loss: 2825.6875 - val_mean_absolute_error: 53.1270\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.2003 - mean_absolute_error: 3.3157 - val_loss: 3003.8682 - val_mean_absolute_error: 54.7619\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.7697 - mean_absolute_error: 1.5010 - val_loss: 3225.5662 - val_mean_absolute_error: 56.7295\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9253 - mean_absolute_error: 0.8560 - val_loss: 3321.1497 - val_mean_absolute_error: 57.5555\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.6062 - mean_absolute_error: 1.5886 - val_loss: 3302.7664 - val_mean_absolute_error: 57.3958\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.9257 - mean_absolute_error: 1.4078 - val_loss: 3228.3579 - val_mean_absolute_error: 56.7517\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9567 - mean_absolute_error: 0.8754 - val_loss: 3140.2192 - val_mean_absolute_error: 55.9794\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2235 - mean_absolute_error: 0.4147 - val_loss: 3074.4062 - val_mean_absolute_error: 55.3954\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8992 - mean_absolute_error: 0.8315 - val_loss: 3057.9106 - val_mean_absolute_error: 55.2482\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2369 - mean_absolute_error: 0.9982 - val_loss: 3077.6089 - val_mean_absolute_error: 55.4242\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8271 - mean_absolute_error: 0.8014 - val_loss: 3120.2817 - val_mean_absolute_error: 55.8032\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 8.3490 - mean_absolute_error: 2.4218 - val_loss: 2934.5967 - val_mean_absolute_error: 54.1255\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3894 - mean_absolute_error: 1.7791 - val_loss: 2930.6792 - val_mean_absolute_error: 54.0800\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.0245 - mean_absolute_error: 1.7417 - val_loss: 3025.1177 - val_mean_absolute_error: 54.9302\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8091 - mean_absolute_error: 1.0834 - val_loss: 3128.5391 - val_mean_absolute_error: 55.8426\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6965 - mean_absolute_error: 0.8774 - val_loss: 3153.7188 - val_mean_absolute_error: 56.0546\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.0095 - mean_absolute_error: 1.0727 - val_loss: 3115.3022 - val_mean_absolute_error: 55.7043\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4285 - mean_absolute_error: 0.9389 - val_loss: 3043.9424 - val_mean_absolute_error: 55.0603\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9577 - mean_absolute_error: 0.8029 - val_loss: 2981.5264 - val_mean_absolute_error: 54.4917\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2182 - mean_absolute_error: 1.0312 - val_loss: 2966.8384 - val_mean_absolute_error: 54.3479\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1493 - mean_absolute_error: 1.0172 - val_loss: 2990.8545 - val_mean_absolute_error: 54.5559\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7646 - mean_absolute_error: 0.7828 - val_loss: 3027.1309 - val_mean_absolute_error: 54.8759\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6203 - mean_absolute_error: 0.6655 - val_loss: 3053.2646 - val_mean_absolute_error: 55.1049\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 639ms/step - loss: 4.7826 - mean_absolute_error: 1.6975 - val_loss: 2813.0889 - val_mean_absolute_error: 53.0013\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 10.1461 - mean_absolute_error: 2.6373 - val_loss: 2987.7878 - val_mean_absolute_error: 54.6027\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.9903 - mean_absolute_error: 1.4944 - val_loss: 3158.9956 - val_mean_absolute_error: 56.1260\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.1018 - mean_absolute_error: 0.9067 - val_loss: 3237.6399 - val_mean_absolute_error: 56.8111\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4611 - mean_absolute_error: 1.4453 - val_loss: 3232.4619 - val_mean_absolute_error: 56.7634\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1889 - mean_absolute_error: 1.3801 - val_loss: 3176.4326 - val_mean_absolute_error: 56.2712\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0318 - mean_absolute_error: 1.0199 - val_loss: 3097.3723 - val_mean_absolute_error: 55.5715\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3652 - mean_absolute_error: 0.8062 - val_loss: 3025.8643 - val_mean_absolute_error: 54.9313\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6259 - mean_absolute_error: 1.1461 - val_loss: 2990.4072 - val_mean_absolute_error: 54.6082\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9784 - mean_absolute_error: 1.3231 - val_loss: 2998.7603 - val_mean_absolute_error: 54.6793\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7271 - mean_absolute_error: 1.2387 - val_loss: 3034.8108 - val_mean_absolute_error: 55.0002\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 10.0355 - mean_absolute_error: 2.6219 - val_loss: 2828.4810 - val_mean_absolute_error: 53.1422\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3416 - mean_absolute_error: 1.7003 - val_loss: 2829.1460 - val_mean_absolute_error: 53.1441\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8409 - mean_absolute_error: 1.6568 - val_loss: 2969.3506 - val_mean_absolute_error: 54.4260\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4985 - mean_absolute_error: 0.9838 - val_loss: 3093.0562 - val_mean_absolute_error: 55.5306\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6708 - mean_absolute_error: 0.9197 - val_loss: 3133.8184 - val_mean_absolute_error: 55.8831\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1000 - mean_absolute_error: 1.0631 - val_loss: 3097.9949 - val_mean_absolute_error: 55.5576\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5664 - mean_absolute_error: 0.9309 - val_loss: 3018.1455 - val_mean_absolute_error: 54.8399\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0223 - mean_absolute_error: 0.7792 - val_loss: 2938.7859 - val_mean_absolute_error: 54.1188\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.2272 - mean_absolute_error: 1.0630 - val_loss: 2908.3911 - val_mean_absolute_error: 53.8379\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4659 - mean_absolute_error: 1.1818 - val_loss: 2934.0874 - val_mean_absolute_error: 54.0697\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1836 - mean_absolute_error: 1.0555 - val_loss: 2992.4204 - val_mean_absolute_error: 54.5972\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 7.4792 - mean_absolute_error: 2.2916 - val_loss: 2937.4419 - val_mean_absolute_error: 54.1519\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.4030 - mean_absolute_error: 1.2147 - val_loss: 2866.3354 - val_mean_absolute_error: 53.4836\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.7126 - mean_absolute_error: 1.4523 - val_loss: 2945.4226 - val_mean_absolute_error: 54.2033\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.3856 - mean_absolute_error: 1.0415 - val_loss: 3035.4697 - val_mean_absolute_error: 55.0150\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1210 - mean_absolute_error: 0.6922 - val_loss: 3068.6814 - val_mean_absolute_error: 55.3067\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2390 - mean_absolute_error: 0.7839 - val_loss: 3048.2412 - val_mean_absolute_error: 55.1170\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0248 - mean_absolute_error: 0.7761 - val_loss: 2996.5200 - val_mean_absolute_error: 54.6460\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8477 - mean_absolute_error: 0.7424 - val_loss: 2952.8313 - val_mean_absolute_error: 54.2452\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9430 - mean_absolute_error: 0.9160 - val_loss: 2956.0010 - val_mean_absolute_error: 54.2717\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8844 - mean_absolute_error: 0.8830 - val_loss: 2996.2061 - val_mean_absolute_error: 54.6374\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7230 - mean_absolute_error: 0.7395 - val_loss: 3041.0552 - val_mean_absolute_error: 55.0452\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7375 - mean_absolute_error: 0.7529 - val_loss: 3054.3650 - val_mean_absolute_error: 55.1677\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 5.7209 - mean_absolute_error: 1.9047 - val_loss: 2895.4536 - val_mean_absolute_error: 53.7703\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.5466 - mean_absolute_error: 2.5447 - val_loss: 3006.8699 - val_mean_absolute_error: 54.7870\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.2698 - mean_absolute_error: 1.3892 - val_loss: 3151.6826 - val_mean_absolute_error: 56.0754\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2757 - mean_absolute_error: 0.4343 - val_loss: 3232.1775 - val_mean_absolute_error: 56.7806\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2130 - mean_absolute_error: 0.9615 - val_loss: 3245.2656 - val_mean_absolute_error: 56.8960\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4684 - mean_absolute_error: 1.0458 - val_loss: 3218.0305 - val_mean_absolute_error: 56.6610\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8761 - mean_absolute_error: 0.8434 - val_loss: 3172.5840 - val_mean_absolute_error: 56.2645\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3196 - mean_absolute_error: 0.5223 - val_loss: 3126.4307 - val_mean_absolute_error: 55.8577\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2263 - mean_absolute_error: 0.3989 - val_loss: 3093.9470 - val_mean_absolute_error: 55.5692\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4152 - mean_absolute_error: 0.5082 - val_loss: 3084.7285 - val_mean_absolute_error: 55.4871\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5210 - mean_absolute_error: 0.6046 - val_loss: 3095.5522 - val_mean_absolute_error: 55.5838\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 586ms/step - loss: 6.2032 - mean_absolute_error: 2.0432 - val_loss: 2891.7461 - val_mean_absolute_error: 53.7356\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.7682 - mean_absolute_error: 2.1683 - val_loss: 3006.4829 - val_mean_absolute_error: 54.7732\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.6357 - mean_absolute_error: 1.3526 - val_loss: 3141.6143 - val_mean_absolute_error: 55.9744\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step - loss: 1.9020 - mean_absolute_error: 0.8617 - val_loss: 3194.5669 - val_mean_absolute_error: 56.4323\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5618 - mean_absolute_error: 1.2116 - val_loss: 3148.9116 - val_mean_absolute_error: 56.0281\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.7734 - mean_absolute_error: 0.8804 - val_loss: 3056.8889 - val_mean_absolute_error: 55.2084\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3033 - mean_absolute_error: 0.8551 - val_loss: 2994.5789 - val_mean_absolute_error: 54.6424\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.7057 - mean_absolute_error: 1.1833 - val_loss: 3007.1035 - val_mean_absolute_error: 54.7469\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.3460 - mean_absolute_error: 1.0524 - val_loss: 3058.8896 - val_mean_absolute_error: 55.2002\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8622 - mean_absolute_error: 0.7332 - val_loss: 3101.0977 - val_mean_absolute_error: 55.5633\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9771 - mean_absolute_error: 0.8385 - val_loss: 3100.2725 - val_mean_absolute_error: 55.5448\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.9083 - mean_absolute_error: 1.7217 - val_loss: 2831.9663 - val_mean_absolute_error: 53.1843\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.5881 - mean_absolute_error: 2.4706 - val_loss: 2969.1079 - val_mean_absolute_error: 54.4416\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.1392 - mean_absolute_error: 1.5494 - val_loss: 3128.2935 - val_mean_absolute_error: 55.8627\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8845 - mean_absolute_error: 0.7883 - val_loss: 3209.8945 - val_mean_absolute_error: 56.5726\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.8450 - mean_absolute_error: 1.2879 - val_loss: 3194.1675 - val_mean_absolute_error: 56.4314\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.4146 - mean_absolute_error: 1.1516 - val_loss: 3128.6106 - val_mean_absolute_error: 55.8517\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5427 - mean_absolute_error: 0.8118 - val_loss: 3056.3770 - val_mean_absolute_error: 55.2073\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3816 - mean_absolute_error: 0.9502 - val_loss: 3011.4600 - val_mean_absolute_error: 54.8017\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6807 - mean_absolute_error: 1.2015 - val_loss: 3007.8457 - val_mean_absolute_error: 54.7656\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5994 - mean_absolute_error: 1.1824 - val_loss: 3033.7622 - val_mean_absolute_error: 54.9949\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2529 - mean_absolute_error: 0.9802 - val_loss: 3072.3208 - val_mean_absolute_error: 55.3357\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 7.2747 - mean_absolute_error: 2.2414 - val_loss: 2832.8027 - val_mean_absolute_error: 53.1799\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4119 - mean_absolute_error: 1.7018 - val_loss: 2860.8813 - val_mean_absolute_error: 53.4350\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4042 - mean_absolute_error: 1.5503 - val_loss: 2979.4380 - val_mean_absolute_error: 54.5192\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4265 - mean_absolute_error: 0.9899 - val_loss: 3083.7866 - val_mean_absolute_error: 55.4523\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.2106 - mean_absolute_error: 0.7502 - val_loss: 3132.6626 - val_mean_absolute_error: 55.8767\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5899 - mean_absolute_error: 0.9488 - val_loss: 3114.6204 - val_mean_absolute_error: 55.7050\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2908 - mean_absolute_error: 0.8729 - val_loss: 3054.7183 - val_mean_absolute_error: 55.1594\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8026 - mean_absolute_error: 0.7853 - val_loss: 2982.8403 - val_mean_absolute_error: 54.5007\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8185 - mean_absolute_error: 0.8358 - val_loss: 2942.0850 - val_mean_absolute_error: 54.1238\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1272 - mean_absolute_error: 1.0141 - val_loss: 2951.4434 - val_mean_absolute_error: 54.2110\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0049 - mean_absolute_error: 0.9568 - val_loss: 2991.0232 - val_mean_absolute_error: 54.5771\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 7.5287 - mean_absolute_error: 2.2997 - val_loss: 2796.4868 - val_mean_absolute_error: 52.8517\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2969 - mean_absolute_error: 1.6846 - val_loss: 2836.4807 - val_mean_absolute_error: 53.2162\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.9627 - mean_absolute_error: 1.4817 - val_loss: 3004.7200 - val_mean_absolute_error: 54.7460\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0660 - mean_absolute_error: 0.7594 - val_loss: 3134.8032 - val_mean_absolute_error: 55.8984\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6296 - mean_absolute_error: 0.9478 - val_loss: 3133.5771 - val_mean_absolute_error: 55.8814\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5408 - mean_absolute_error: 0.9355 - val_loss: 3052.5923 - val_mean_absolute_error: 55.1573\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8860 - mean_absolute_error: 0.6903 - val_loss: 2956.1523 - val_mean_absolute_error: 54.2833\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0332 - mean_absolute_error: 0.9771 - val_loss: 2925.3669 - val_mean_absolute_error: 53.9974\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2361 - mean_absolute_error: 1.0838 - val_loss: 2965.6436 - val_mean_absolute_error: 54.3602\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8749 - mean_absolute_error: 0.8990 - val_loss: 3035.1001 - val_mean_absolute_error: 54.9851\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6962 - mean_absolute_error: 0.7448 - val_loss: 3088.7856 - val_mean_absolute_error: 55.4640\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 1.3492 - mean_absolute_error: 0.9417 - val_loss: 2776.3486 - val_mean_absolute_error: 52.6543\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.7620 - mean_absolute_error: 3.8009 - val_loss: 3042.5498 - val_mean_absolute_error: 55.1051\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6476 - mean_absolute_error: 1.1396 - val_loss: 3272.0303 - val_mean_absolute_error: 57.1304\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9423 - mean_absolute_error: 1.1500 - val_loss: 3335.2168 - val_mean_absolute_error: 57.6755\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1242 - mean_absolute_error: 1.7297 - val_loss: 3310.1404 - val_mean_absolute_error: 57.4604\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.1016 - mean_absolute_error: 1.4870 - val_loss: 3247.3267 - val_mean_absolute_error: 56.9181\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1794 - mean_absolute_error: 0.9581 - val_loss: 3160.4500 - val_mean_absolute_error: 56.1599\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1533 - mean_absolute_error: 0.3449 - val_loss: 3077.1421 - val_mean_absolute_error: 55.4232\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8438 - mean_absolute_error: 0.7964 - val_loss: 3053.3457 - val_mean_absolute_error: 55.2094\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3126 - mean_absolute_error: 1.0225 - val_loss: 3073.9824 - val_mean_absolute_error: 55.3929\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8307 - mean_absolute_error: 0.8009 - val_loss: 3112.2729 - val_mean_absolute_error: 55.7324\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 17.5488 - mean_absolute_error: 3.6019 - val_loss: 3031.9092 - val_mean_absolute_error: 55.0036\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.2178 - mean_absolute_error: 1.1918 - val_loss: 2921.5601 - val_mean_absolute_error: 53.9955\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2627 - mean_absolute_error: 1.8269 - val_loss: 2990.4663 - val_mean_absolute_error: 54.6189\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4250 - mean_absolute_error: 1.3770 - val_loss: 3088.0117 - val_mean_absolute_error: 55.4920\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4923 - mean_absolute_error: 0.8523 - val_loss: 3149.7498 - val_mean_absolute_error: 56.0363\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8069 - mean_absolute_error: 0.8987 - val_loss: 3148.1006 - val_mean_absolute_error: 56.0181\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7152 - mean_absolute_error: 0.8851 - val_loss: 3097.7871 - val_mean_absolute_error: 55.5691\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2496 - mean_absolute_error: 0.7854 - val_loss: 3036.3267 - val_mean_absolute_error: 55.0163\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2695 - mean_absolute_error: 0.9622 - val_loss: 3019.0513 - val_mean_absolute_error: 54.8538\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2390 - mean_absolute_error: 1.0200 - val_loss: 3045.4697 - val_mean_absolute_error: 55.0833\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8985 - mean_absolute_error: 0.8016 - val_loss: 3087.0791 - val_mean_absolute_error: 55.4454\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8396 - mean_absolute_error: 0.7089 - val_loss: 3096.6909 - val_mean_absolute_error: 55.5209\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 8.4973 - mean_absolute_error: 2.4580 - val_loss: 2909.8289 - val_mean_absolute_error: 53.8943\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.3478 - mean_absolute_error: 2.0207 - val_loss: 2952.3989 - val_mean_absolute_error: 54.2780\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4659 - mean_absolute_error: 1.6831 - val_loss: 3087.0056 - val_mean_absolute_error: 55.4866\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6366 - mean_absolute_error: 0.8602 - val_loss: 3181.2297 - val_mean_absolute_error: 56.3125\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4755 - mean_absolute_error: 1.1654 - val_loss: 3170.3259 - val_mean_absolute_error: 56.2136\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.1211 - mean_absolute_error: 1.0925 - val_loss: 3107.6929 - val_mean_absolute_error: 55.6582\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3559 - mean_absolute_error: 0.7676 - val_loss: 3037.5200 - val_mean_absolute_error: 55.0291\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3869 - mean_absolute_error: 1.0386 - val_loss: 3004.7354 - val_mean_absolute_error: 54.7311\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6576 - mean_absolute_error: 1.2182 - val_loss: 3025.6758 - val_mean_absolute_error: 54.9148\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3021 - mean_absolute_error: 1.0484 - val_loss: 3075.6455 - val_mean_absolute_error: 55.3555\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0428 - mean_absolute_error: 0.7231 - val_loss: 3116.8096 - val_mean_absolute_error: 55.7165\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 6.5408 - mean_absolute_error: 2.0835 - val_loss: 2798.1909 - val_mean_absolute_error: 52.8650\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.9423 - mean_absolute_error: 1.8962 - val_loss: 2885.3574 - val_mean_absolute_error: 53.6722\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4287 - mean_absolute_error: 1.4797 - val_loss: 3036.1260 - val_mean_absolute_error: 55.0424\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5588 - mean_absolute_error: 0.9545 - val_loss: 3128.4727 - val_mean_absolute_error: 55.8594\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8638 - mean_absolute_error: 0.9361 - val_loss: 3150.3491 - val_mean_absolute_error: 56.0472\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0351 - mean_absolute_error: 1.0398 - val_loss: 3117.3682 - val_mean_absolute_error: 55.7503\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5234 - mean_absolute_error: 0.8948 - val_loss: 3048.6631 - val_mean_absolute_error: 55.1340\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0666 - mean_absolute_error: 0.7116 - val_loss: 2981.5576 - val_mean_absolute_error: 54.5263\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1885 - mean_absolute_error: 0.9613 - val_loss: 2949.0305 - val_mean_absolute_error: 54.2267\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3853 - mean_absolute_error: 1.0963 - val_loss: 2964.0596 - val_mean_absolute_error: 54.3600\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1553 - mean_absolute_error: 1.0101 - val_loss: 3008.0405 - val_mean_absolute_error: 54.7555\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 4.0702 - mean_absolute_error: 1.5803 - val_loss: 2788.5601 - val_mean_absolute_error: 52.7762\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.2009 - mean_absolute_error: 1.8098 - val_loss: 2902.1597 - val_mean_absolute_error: 53.8222\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.1724 - mean_absolute_error: 1.2550 - val_loss: 3055.2095 - val_mean_absolute_error: 55.2011\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2943 - mean_absolute_error: 0.7380 - val_loss: 3132.1572 - val_mean_absolute_error: 55.8743\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8254 - mean_absolute_error: 0.9945 - val_loss: 3118.9395 - val_mean_absolute_error: 55.7503\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5451 - mean_absolute_error: 0.9316 - val_loss: 3048.2988 - val_mean_absolute_error: 55.1169\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9176 - mean_absolute_error: 0.7070 - val_loss: 2962.8115 - val_mean_absolute_error: 54.3422\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0185 - mean_absolute_error: 0.9619 - val_loss: 2933.2842 - val_mean_absolute_error: 54.0688\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2437 - mean_absolute_error: 1.0784 - val_loss: 2971.7271 - val_mean_absolute_error: 54.4140\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8906 - mean_absolute_error: 0.8977 - val_loss: 3033.3394 - val_mean_absolute_error: 54.9678\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7234 - mean_absolute_error: 0.7418 - val_loss: 3076.4636 - val_mean_absolute_error: 55.3541\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 1.7745 - mean_absolute_error: 1.0993 - val_loss: 2776.7275 - val_mean_absolute_error: 52.6580\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 17.4125 - mean_absolute_error: 3.8458 - val_loss: 3031.3286 - val_mean_absolute_error: 54.9990\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.9117 - mean_absolute_error: 1.2672 - val_loss: 3244.7346 - val_mean_absolute_error: 56.8860\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2940 - mean_absolute_error: 0.9856 - val_loss: 3323.9827 - val_mean_absolute_error: 57.5683\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.7953 - mean_absolute_error: 1.6064 - val_loss: 3310.1575 - val_mean_absolute_error: 57.4488\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.2472 - mean_absolute_error: 1.4652 - val_loss: 3255.5498 - val_mean_absolute_error: 56.9774\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6123 - mean_absolute_error: 1.0870 - val_loss: 3185.3545 - val_mean_absolute_error: 56.3684\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4978 - mean_absolute_error: 0.6382 - val_loss: 3124.9619 - val_mean_absolute_error: 55.8384\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3044 - mean_absolute_error: 0.4568 - val_loss: 3082.7778 - val_mean_absolute_error: 55.4649\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6760 - mean_absolute_error: 0.6720 - val_loss: 3064.3428 - val_mean_absolute_error: 55.3008\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9414 - mean_absolute_error: 0.8524 - val_loss: 3069.2979 - val_mean_absolute_error: 55.3451\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.0154 - mean_absolute_error: 2.6367 - val_loss: 2861.5403 - val_mean_absolute_error: 53.4391\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.4203 - mean_absolute_error: 2.1757 - val_loss: 2918.8101 - val_mean_absolute_error: 53.9653\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0737 - mean_absolute_error: 1.7757 - val_loss: 3073.2998 - val_mean_absolute_error: 55.3606\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5295 - mean_absolute_error: 0.9396 - val_loss: 3189.2708 - val_mean_absolute_error: 56.3805\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.4321 - mean_absolute_error: 1.1707 - val_loss: 3194.1353 - val_mean_absolute_error: 56.4182\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.4384 - mean_absolute_error: 1.2118 - val_loss: 3132.4175 - val_mean_absolute_error: 55.8704\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4059 - mean_absolute_error: 0.8509 - val_loss: 3043.4219 - val_mean_absolute_error: 55.0750\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0715 - mean_absolute_error: 0.8661 - val_loss: 2983.5938 - val_mean_absolute_error: 54.5316\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6092 - mean_absolute_error: 1.2154 - val_loss: 2979.3381 - val_mean_absolute_error: 54.4879\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5297 - mean_absolute_error: 1.1972 - val_loss: 3015.6548 - val_mean_absolute_error: 54.8115\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9899 - mean_absolute_error: 0.9327 - val_loss: 3066.9219 - val_mean_absolute_error: 55.2673\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 1.9636 - mean_absolute_error: 0.8039 - val_loss: 2497.7881 - val_mean_absolute_error: 49.9608\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 40.1229 - mean_absolute_error: 4.8219 - val_loss: 2946.0200 - val_mean_absolute_error: 54.2211\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5239 - mean_absolute_error: 1.6953 - val_loss: 3326.5740 - val_mean_absolute_error: 57.5810\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.4806 - mean_absolute_error: 2.1119 - val_loss: 3420.7173 - val_mean_absolute_error: 58.3813\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.1744 - mean_absolute_error: 2.8232 - val_loss: 3353.4639 - val_mean_absolute_error: 57.8108\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.7046 - mean_absolute_error: 2.3107 - val_loss: 3237.4766 - val_mean_absolute_error: 56.8094\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6744 - mean_absolute_error: 1.4987 - val_loss: 3114.9961 - val_mean_absolute_error: 55.7321\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.7027 - mean_absolute_error: 0.9042 - val_loss: 3019.2388 - val_mean_absolute_error: 54.8782\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.0579 - mean_absolute_error: 1.2308 - val_loss: 2974.9624 - val_mean_absolute_error: 54.4767\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.8330 - mean_absolute_error: 1.5221 - val_loss: 2978.0942 - val_mean_absolute_error: 54.5037\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.6918 - mean_absolute_error: 1.4941 - val_loss: 3011.0557 - val_mean_absolute_error: 54.7995\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 8.7836 - mean_absolute_error: 2.4327 - val_loss: 2901.0461 - val_mean_absolute_error: 53.8216\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.9293 - mean_absolute_error: 1.3482 - val_loss: 2860.3730 - val_mean_absolute_error: 53.4413\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7166 - mean_absolute_error: 1.5522 - val_loss: 2956.1025 - val_mean_absolute_error: 54.3151\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8275 - mean_absolute_error: 1.0880 - val_loss: 3068.1650 - val_mean_absolute_error: 55.3198\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3029 - mean_absolute_error: 0.7233 - val_loss: 3134.8008 - val_mean_absolute_error: 55.9061\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.7540 - mean_absolute_error: 0.9449 - val_loss: 3129.9707 - val_mean_absolute_error: 55.8584\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6156 - mean_absolute_error: 0.9199 - val_loss: 3078.9375 - val_mean_absolute_error: 55.3999\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0981 - mean_absolute_error: 0.7293 - val_loss: 3003.5298 - val_mean_absolute_error: 54.7186\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9425 - mean_absolute_error: 0.8313 - val_loss: 2952.5132 - val_mean_absolute_error: 54.2519\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2110 - mean_absolute_error: 1.0537 - val_loss: 2954.5034 - val_mean_absolute_error: 54.2664\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1103 - mean_absolute_error: 1.0218 - val_loss: 2996.3911 - val_mean_absolute_error: 54.6426\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7980 - mean_absolute_error: 0.8139 - val_loss: 3045.6638 - val_mean_absolute_error: 55.0830\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 597ms/step - loss: 14.2154 - mean_absolute_error: 3.2302 - val_loss: 3138.6304 - val_mean_absolute_error: 55.9668\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8491 - mean_absolute_error: 1.2037 - val_loss: 2876.9038 - val_mean_absolute_error: 53.5995\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 2.7845 - mean_absolute_error: 1.3558 - val_loss: 2846.3152 - val_mean_absolute_error: 53.3089\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8112 - mean_absolute_error: 1.4393 - val_loss: 2926.3228 - val_mean_absolute_error: 54.0431\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6512 - mean_absolute_error: 1.0887 - val_loss: 3028.2769 - val_mean_absolute_error: 54.9648\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3040 - mean_absolute_error: 0.7728 - val_loss: 3097.2388 - val_mean_absolute_error: 55.5780\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6393 - mean_absolute_error: 0.9023 - val_loss: 3099.7810 - val_mean_absolute_error: 55.5975\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6255 - mean_absolute_error: 0.9097 - val_loss: 3057.2961 - val_mean_absolute_error: 55.2153\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2384 - mean_absolute_error: 0.7710 - val_loss: 2993.0957 - val_mean_absolute_error: 54.6330\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9944 - mean_absolute_error: 0.7684 - val_loss: 2935.7695 - val_mean_absolute_error: 54.1065\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1361 - mean_absolute_error: 0.9996 - val_loss: 2918.1357 - val_mean_absolute_error: 53.9406\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2118 - mean_absolute_error: 1.0604 - val_loss: 2944.7659 - val_mean_absolute_error: 54.1816\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9919 - mean_absolute_error: 0.9409 - val_loss: 2993.0146 - val_mean_absolute_error: 54.6180\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 659ms/step - loss: 4.8702 - mean_absolute_error: 1.8541 - val_loss: 3110.7202 - val_mean_absolute_error: 55.7179\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4440 - mean_absolute_error: 0.5447 - val_loss: 3117.3745 - val_mean_absolute_error: 55.7759\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3731 - mean_absolute_error: 0.5107 - val_loss: 3168.3518 - val_mean_absolute_error: 56.2242\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3533 - mean_absolute_error: 0.5000 - val_loss: 3135.2910 - val_mean_absolute_error: 55.9353\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2256 - mean_absolute_error: 0.4194 - val_loss: 3119.1924 - val_mean_absolute_error: 55.7945\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2533 - mean_absolute_error: 0.3954 - val_loss: 3160.4150 - val_mean_absolute_error: 56.1583\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1902 - mean_absolute_error: 0.3935 - val_loss: 3159.6016 - val_mean_absolute_error: 56.1524\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1654 - mean_absolute_error: 0.3687 - val_loss: 3127.8159 - val_mean_absolute_error: 55.8738\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1864 - mean_absolute_error: 0.3772 - val_loss: 3147.2590 - val_mean_absolute_error: 56.0453\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1242 - mean_absolute_error: 0.2453 - val_loss: 3169.2627 - val_mean_absolute_error: 56.2382\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1645 - mean_absolute_error: 0.3964 - val_loss: 3144.6665 - val_mean_absolute_error: 56.0224\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 673ms/step - loss: 5.9408 - mean_absolute_error: 1.9702 - val_loss: 3078.8096 - val_mean_absolute_error: 55.4325\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2544 - mean_absolute_error: 1.0047 - val_loss: 3019.9871 - val_mean_absolute_error: 54.8968\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.3591 - mean_absolute_error: 1.2798 - val_loss: 3081.9648 - val_mean_absolute_error: 55.4468\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.5966 - mean_absolute_error: 0.8234 - val_loss: 3123.7280 - val_mean_absolute_error: 55.8092\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.5371 - mean_absolute_error: 0.7449 - val_loss: 3092.2466 - val_mean_absolute_error: 55.5182\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1412 - mean_absolute_error: 0.7008 - val_loss: 3011.8574 - val_mean_absolute_error: 54.7838\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1566 - mean_absolute_error: 1.0114 - val_loss: 3040.3032 - val_mean_absolute_error: 55.0248\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7191 - mean_absolute_error: 0.7135 - val_loss: 3081.5862 - val_mean_absolute_error: 55.3810\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7027 - mean_absolute_error: 0.7533 - val_loss: 3053.2266 - val_mean_absolute_error: 55.1064\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5303 - mean_absolute_error: 0.6899 - val_loss: 2990.2012 - val_mean_absolute_error: 54.5132\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5909 - mean_absolute_error: 0.5967 - val_loss: 3004.1641 - val_mean_absolute_error: 54.6425\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4645 - mean_absolute_error: 0.4770 - val_loss: 3057.7339 - val_mean_absolute_error: 55.1501\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3812 - mean_absolute_error: 0.6035 - val_loss: 3069.7334 - val_mean_absolute_error: 55.2763\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3437 - mean_absolute_error: 0.5440 - val_loss: 3037.5674 - val_mean_absolute_error: 54.9950\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2846 - mean_absolute_error: 0.4720 - val_loss: 3020.1035 - val_mean_absolute_error: 54.8385\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3199 - mean_absolute_error: 0.5468 - val_loss: 3048.9111 - val_mean_absolute_error: 55.0996\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2022 - mean_absolute_error: 0.3612 - val_loss: 3075.2856 - val_mean_absolute_error: 55.3340\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2020 - mean_absolute_error: 0.4141 - val_loss: 3064.4326 - val_mean_absolute_error: 55.2282\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1682 - mean_absolute_error: 0.3495 - val_loss: 3040.5415 - val_mean_absolute_error: 55.0073\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1603 - mean_absolute_error: 0.2973 - val_loss: 3047.9111 - val_mean_absolute_error: 55.0860\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 9.6930 - mean_absolute_error: 2.6437 - val_loss: 3213.8984 - val_mean_absolute_error: 56.6222\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3654 - mean_absolute_error: 1.3269 - val_loss: 3099.6960 - val_mean_absolute_error: 55.6182\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.1801 - mean_absolute_error: 0.9270 - val_loss: 3012.5127 - val_mean_absolute_error: 54.8360\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.8480 - mean_absolute_error: 1.4016 - val_loss: 3050.8040 - val_mean_absolute_error: 55.1780\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2189 - mean_absolute_error: 1.1460 - val_loss: 3115.7002 - val_mean_absolute_error: 55.7546\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9687 - mean_absolute_error: 0.8790 - val_loss: 3153.4131 - val_mean_absolute_error: 56.0849\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.1559 - mean_absolute_error: 0.8948 - val_loss: 3139.1746 - val_mean_absolute_error: 55.9565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9419 - mean_absolute_error: 0.8529 - val_loss: 3088.4543 - val_mean_absolute_error: 55.5045\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6889 - mean_absolute_error: 0.8695 - val_loss: 3046.3081 - val_mean_absolute_error: 55.1248\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7954 - mean_absolute_error: 1.1143 - val_loss: 3058.6660 - val_mean_absolute_error: 55.2312\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5898 - mean_absolute_error: 1.0234 - val_loss: 3098.3384 - val_mean_absolute_error: 55.5813\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4080 - mean_absolute_error: 0.7976 - val_loss: 3122.5176 - val_mean_absolute_error: 55.7919\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4306 - mean_absolute_error: 0.7830 - val_loss: 3111.5039 - val_mean_absolute_error: 55.6883\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 626ms/step - loss: 6.7820 - mean_absolute_error: 2.1447 - val_loss: 3158.8242 - val_mean_absolute_error: 56.1394\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7408 - mean_absolute_error: 1.1920 - val_loss: 2974.9604 - val_mean_absolute_error: 54.4938\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9145 - mean_absolute_error: 1.0893 - val_loss: 2911.4541 - val_mean_absolute_error: 53.9063\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2621 - mean_absolute_error: 1.2715 - val_loss: 2984.0005 - val_mean_absolute_error: 54.5636\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4287 - mean_absolute_error: 0.9324 - val_loss: 3054.9058 - val_mean_absolute_error: 55.1998\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3391 - mean_absolute_error: 0.7391 - val_loss: 3081.3054 - val_mean_absolute_error: 55.4295\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3751 - mean_absolute_error: 0.8077 - val_loss: 3047.3796 - val_mean_absolute_error: 55.1186\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0836 - mean_absolute_error: 0.6841 - val_loss: 2975.0237 - val_mean_absolute_error: 54.4559\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0014 - mean_absolute_error: 0.9149 - val_loss: 2948.8047 - val_mean_absolute_error: 54.2063\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0690 - mean_absolute_error: 1.0018 - val_loss: 2991.8440 - val_mean_absolute_error: 54.5919\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8471 - mean_absolute_error: 0.7988 - val_loss: 3044.0144 - val_mean_absolute_error: 55.0618\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8682 - mean_absolute_error: 0.8326 - val_loss: 3060.4224 - val_mean_absolute_error: 55.2091\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8979 - mean_absolute_error: 0.8334 - val_loss: 3041.0283 - val_mean_absolute_error: 55.0323\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.3978 - mean_absolute_error: 1.6683 - val_loss: 2982.3296 - val_mean_absolute_error: 54.5621\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7967 - mean_absolute_error: 1.0594 - val_loss: 2937.5149 - val_mean_absolute_error: 54.1498\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8237 - mean_absolute_error: 1.0909 - val_loss: 3027.4556 - val_mean_absolute_error: 54.9646\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4755 - mean_absolute_error: 0.8676 - val_loss: 3049.7661 - val_mean_absolute_error: 55.1611\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4239 - mean_absolute_error: 0.7743 - val_loss: 3002.0171 - val_mean_absolute_error: 54.7243\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1699 - mean_absolute_error: 0.7890 - val_loss: 2953.5679 - val_mean_absolute_error: 54.2763\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1273 - mean_absolute_error: 0.9443 - val_loss: 3017.4175 - val_mean_absolute_error: 54.8488\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9409 - mean_absolute_error: 0.6894 - val_loss: 3034.5771 - val_mean_absolute_error: 54.9970\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9119 - mean_absolute_error: 0.7431 - val_loss: 2975.0820 - val_mean_absolute_error: 54.4496\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8311 - mean_absolute_error: 0.8011 - val_loss: 2985.8071 - val_mean_absolute_error: 54.5426\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7681 - mean_absolute_error: 0.7475 - val_loss: 3041.6587 - val_mean_absolute_error: 55.0517\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7481 - mean_absolute_error: 0.7510 - val_loss: 3027.4619 - val_mean_absolute_error: 54.9260\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 3.9509 - mean_absolute_error: 1.5814 - val_loss: 2886.7546 - val_mean_absolute_error: 53.6912\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 8.3789 - mean_absolute_error: 2.6409 - val_loss: 3074.4075 - val_mean_absolute_error: 55.3897\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8550 - mean_absolute_error: 0.7650 - val_loss: 3236.2192 - val_mean_absolute_error: 56.8119\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.4780 - mean_absolute_error: 1.0347 - val_loss: 3260.6499 - val_mean_absolute_error: 57.0259\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0476 - mean_absolute_error: 1.1911 - val_loss: 3212.7559 - val_mean_absolute_error: 56.6117\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9135 - mean_absolute_error: 0.8386 - val_loss: 3145.0159 - val_mean_absolute_error: 56.0204\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2759 - mean_absolute_error: 0.4823 - val_loss: 3093.1335 - val_mean_absolute_error: 55.5622\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5646 - mean_absolute_error: 0.5880 - val_loss: 3080.8857 - val_mean_absolute_error: 55.4540\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7119 - mean_absolute_error: 0.7039 - val_loss: 3104.2324 - val_mean_absolute_error: 55.6626\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3981 - mean_absolute_error: 0.5180 - val_loss: 3141.9497 - val_mean_absolute_error: 55.9965\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1825 - mean_absolute_error: 0.3805 - val_loss: 3176.6409 - val_mean_absolute_error: 56.3017\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 3.9510 - mean_absolute_error: 1.4845 - val_loss: 2911.5581 - val_mean_absolute_error: 53.9200\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.7007 - mean_absolute_error: 2.0422 - val_loss: 3036.0674 - val_mean_absolute_error: 55.0439\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.2443 - mean_absolute_error: 1.2018 - val_loss: 3140.4087 - val_mean_absolute_error: 55.9678\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9509 - mean_absolute_error: 0.8559 - val_loss: 3167.6772 - val_mean_absolute_error: 56.2026\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.1640 - mean_absolute_error: 0.9721 - val_loss: 3128.0884 - val_mean_absolute_error: 55.8508\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.7011 - mean_absolute_error: 0.7931 - val_loss: 3063.7292 - val_mean_absolute_error: 55.2756\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4802 - mean_absolute_error: 0.9058 - val_loss: 3022.6597 - val_mean_absolute_error: 54.9022\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5856 - mean_absolute_error: 1.1051 - val_loss: 3033.3567 - val_mean_absolute_error: 54.9912\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3141 - mean_absolute_error: 0.9953 - val_loss: 3068.4497 - val_mean_absolute_error: 55.2978\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0330 - mean_absolute_error: 0.7384 - val_loss: 3094.5369 - val_mean_absolute_error: 55.5212\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9769 - mean_absolute_error: 0.7033 - val_loss: 3088.2432 - val_mean_absolute_error: 55.4538\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 663ms/step - loss: 6.4519 - mean_absolute_error: 2.0979 - val_loss: 2915.4746 - val_mean_absolute_error: 53.9465\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9022 - mean_absolute_error: 1.9570 - val_loss: 3038.2358 - val_mean_absolute_error: 55.0559\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.9563 - mean_absolute_error: 1.1561 - val_loss: 3162.1069 - val_mean_absolute_error: 56.1521\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.2222 - mean_absolute_error: 0.9766 - val_loss: 3156.1541 - val_mean_absolute_error: 56.0968\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0600 - mean_absolute_error: 0.9625 - val_loss: 3089.2993 - val_mean_absolute_error: 55.5037\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5303 - mean_absolute_error: 0.8311 - val_loss: 3023.7051 - val_mean_absolute_error: 54.9138\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7974 - mean_absolute_error: 1.1902 - val_loss: 3028.3872 - val_mean_absolute_error: 54.9509\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6099 - mean_absolute_error: 1.1311 - val_loss: 3075.1731 - val_mean_absolute_error: 55.3650\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2809 - mean_absolute_error: 0.8135 - val_loss: 3116.4539 - val_mean_absolute_error: 55.7275\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3846 - mean_absolute_error: 0.8790 - val_loss: 3113.8018 - val_mean_absolute_error: 55.6987\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3115 - mean_absolute_error: 0.8868 - val_loss: 3073.8784 - val_mean_absolute_error: 55.3380\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 9.0212 - mean_absolute_error: 2.4956 - val_loss: 3131.6719 - val_mean_absolute_error: 55.8951\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.1960 - mean_absolute_error: 1.0037 - val_loss: 2940.4980 - val_mean_absolute_error: 54.1737\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1668 - mean_absolute_error: 1.1984 - val_loss: 2939.8518 - val_mean_absolute_error: 54.1605\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.8079 - mean_absolute_error: 1.1560 - val_loss: 3017.2571 - val_mean_absolute_error: 54.8567\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0751 - mean_absolute_error: 0.7812 - val_loss: 3081.7163 - val_mean_absolute_error: 55.4265\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0887 - mean_absolute_error: 0.7331 - val_loss: 3077.8472 - val_mean_absolute_error: 55.3839\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9621 - mean_absolute_error: 0.7086 - val_loss: 3025.3672 - val_mean_absolute_error: 54.9028\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7076 - mean_absolute_error: 0.6855 - val_loss: 2973.5605 - val_mean_absolute_error: 54.4241\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8102 - mean_absolute_error: 0.8763 - val_loss: 2982.3423 - val_mean_absolute_error: 54.4986\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7421 - mean_absolute_error: 0.8147 - val_loss: 3029.9976 - val_mean_absolute_error: 54.9313\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5979 - mean_absolute_error: 0.7352 - val_loss: 3066.7893 - val_mean_absolute_error: 55.2689\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6439 - mean_absolute_error: 0.7278 - val_loss: 3067.0315 - val_mean_absolute_error: 55.2751\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5862 - mean_absolute_error: 0.6847 - val_loss: 3037.0142 - val_mean_absolute_error: 55.0060\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 6.0545 - mean_absolute_error: 2.0271 - val_loss: 2917.8118 - val_mean_absolute_error: 53.9727\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.5704 - mean_absolute_error: 1.2749 - val_loss: 2923.4937 - val_mean_absolute_error: 54.0159\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9692 - mean_absolute_error: 1.1938 - val_loss: 3017.5625 - val_mean_absolute_error: 54.8651\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1791 - mean_absolute_error: 0.7987 - val_loss: 3077.2754 - val_mean_absolute_error: 55.3941\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2960 - mean_absolute_error: 0.8070 - val_loss: 3059.0732 - val_mean_absolute_error: 55.2249\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0793 - mean_absolute_error: 0.7347 - val_loss: 2992.3740 - val_mean_absolute_error: 54.6183\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8796 - mean_absolute_error: 0.7838 - val_loss: 2946.7085 - val_mean_absolute_error: 54.1962\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9994 - mean_absolute_error: 0.9571 - val_loss: 2969.8062 - val_mean_absolute_error: 54.4022\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8209 - mean_absolute_error: 0.8309 - val_loss: 3024.6816 - val_mean_absolute_error: 54.8992\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7331 - mean_absolute_error: 0.7449 - val_loss: 3056.5083 - val_mean_absolute_error: 55.1864\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7752 - mean_absolute_error: 0.7406 - val_loss: 3042.1587 - val_mean_absolute_error: 55.0581\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 2.9450 - mean_absolute_error: 1.3876 - val_loss: 2858.2104 - val_mean_absolute_error: 53.4206\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.8475 - mean_absolute_error: 2.9201 - val_loss: 3023.8960 - val_mean_absolute_error: 54.9353\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9635 - mean_absolute_error: 1.2827 - val_loss: 3191.3860 - val_mean_absolute_error: 56.4265\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4960 - mean_absolute_error: 0.6430 - val_loss: 3276.6851 - val_mean_absolute_error: 57.1715\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1279 - mean_absolute_error: 1.2227 - val_loss: 3280.6453 - val_mean_absolute_error: 57.2065\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1896 - mean_absolute_error: 1.2404 - val_loss: 3241.3420 - val_mean_absolute_error: 56.8668\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1947 - mean_absolute_error: 0.9630 - val_loss: 3182.1738 - val_mean_absolute_error: 56.3509\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3435 - mean_absolute_error: 0.5654 - val_loss: 3123.2314 - val_mean_absolute_error: 55.8317\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1949 - mean_absolute_error: 0.3513 - val_loss: 3083.1543 - val_mean_absolute_error: 55.4755\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5304 - mean_absolute_error: 0.6137 - val_loss: 3070.4751 - val_mean_absolute_error: 55.3634\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7042 - mean_absolute_error: 0.7315 - val_loss: 3084.2754 - val_mean_absolute_error: 55.4878\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 11.3531 - mean_absolute_error: 2.8627 - val_loss: 2945.8105 - val_mean_absolute_error: 54.2324\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5910 - mean_absolute_error: 1.8296 - val_loss: 2920.0520 - val_mean_absolute_error: 53.9914\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.9230 - mean_absolute_error: 1.9030 - val_loss: 3037.5203 - val_mean_absolute_error: 55.0548\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.1445 - mean_absolute_error: 1.1476 - val_loss: 3138.4561 - val_mean_absolute_error: 55.9463\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9059 - mean_absolute_error: 0.9030 - val_loss: 3181.8120 - val_mean_absolute_error: 56.3200\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.3965 - mean_absolute_error: 1.1448 - val_loss: 3161.1357 - val_mean_absolute_error: 56.1327\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9952 - mean_absolute_error: 0.9976 - val_loss: 3099.1873 - val_mean_absolute_error: 55.5822\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3524 - mean_absolute_error: 0.7977 - val_loss: 3033.1865 - val_mean_absolute_error: 54.9887\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3136 - mean_absolute_error: 0.9601 - val_loss: 2996.1069 - val_mean_absolute_error: 54.6486\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5341 - mean_absolute_error: 1.1501 - val_loss: 3000.8152 - val_mean_absolute_error: 54.6839\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2799 - mean_absolute_error: 1.0554 - val_loss: 3032.1855 - val_mean_absolute_error: 54.9583\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9077 - mean_absolute_error: 0.8011 - val_loss: 3070.0317 - val_mean_absolute_error: 55.2891\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 3.7796 - mean_absolute_error: 1.3933 - val_loss: 2735.2310 - val_mean_absolute_error: 52.2769\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 16.4692 - mean_absolute_error: 3.2555 - val_loss: 2982.7002 - val_mean_absolute_error: 54.5606\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.9836 - mean_absolute_error: 1.5431 - val_loss: 3200.7925 - val_mean_absolute_error: 56.4888\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5382 - mean_absolute_error: 1.1974 - val_loss: 3265.4404 - val_mean_absolute_error: 57.0459\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2464 - mean_absolute_error: 1.6690 - val_loss: 3234.2700 - val_mean_absolute_error: 56.7724\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3709 - mean_absolute_error: 1.4536 - val_loss: 3151.6255 - val_mean_absolute_error: 56.0487\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.7110 - mean_absolute_error: 0.9825 - val_loss: 3054.9487 - val_mean_absolute_error: 55.1916\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3153 - mean_absolute_error: 0.9597 - val_loss: 2990.1909 - val_mean_absolute_error: 54.6081\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0417 - mean_absolute_error: 1.3619 - val_loss: 2983.6360 - val_mean_absolute_error: 54.5464\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0454 - mean_absolute_error: 1.3737 - val_loss: 3019.5535 - val_mean_absolute_error: 54.8676\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4345 - mean_absolute_error: 1.1390 - val_loss: 3071.2402 - val_mean_absolute_error: 55.3279\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.8729 - mean_absolute_error: 0.8680 - val_loss: 2556.5547 - val_mean_absolute_error: 50.5470\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 19.8247 - mean_absolute_error: 3.1067 - val_loss: 2933.1069 - val_mean_absolute_error: 54.1090\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2168 - mean_absolute_error: 1.1892 - val_loss: 3260.5244 - val_mean_absolute_error: 57.0078\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4683 - mean_absolute_error: 1.6901 - val_loss: 3327.7910 - val_mean_absolute_error: 57.5764\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.5690 - mean_absolute_error: 2.0468 - val_loss: 3253.6396 - val_mean_absolute_error: 56.9302\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1101 - mean_absolute_error: 1.5802 - val_loss: 3134.0369 - val_mean_absolute_error: 55.8829\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5954 - mean_absolute_error: 0.9318 - val_loss: 3010.6445 - val_mean_absolute_error: 54.7827\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9744 - mean_absolute_error: 0.8184 - val_loss: 2924.1675 - val_mean_absolute_error: 53.9975\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7825 - mean_absolute_error: 1.2264 - val_loss: 2898.7219 - val_mean_absolute_error: 53.7641\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2218 - mean_absolute_error: 1.3465 - val_loss: 2924.6443 - val_mean_absolute_error: 54.0008\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7317 - mean_absolute_error: 1.2144 - val_loss: 2980.8687 - val_mean_absolute_error: 54.5120\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 8.6727 - mean_absolute_error: 2.5043 - val_loss: 2838.3779 - val_mean_absolute_error: 53.2434\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3094 - mean_absolute_error: 1.6367 - val_loss: 2844.3323 - val_mean_absolute_error: 53.2905\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5025 - mean_absolute_error: 1.5539 - val_loss: 2994.5225 - val_mean_absolute_error: 54.6600\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3593 - mean_absolute_error: 0.9108 - val_loss: 3119.9263 - val_mean_absolute_error: 55.7771\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6706 - mean_absolute_error: 0.9222 - val_loss: 3142.0630 - val_mean_absolute_error: 55.9659\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8445 - mean_absolute_error: 0.9982 - val_loss: 3078.1606 - val_mean_absolute_error: 55.3927\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1423 - mean_absolute_error: 0.7729 - val_loss: 2978.7964 - val_mean_absolute_error: 54.4946\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0113 - mean_absolute_error: 0.9013 - val_loss: 2924.0703 - val_mean_absolute_error: 53.9911\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3875 - mean_absolute_error: 1.1337 - val_loss: 2945.9858 - val_mean_absolute_error: 54.1868\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1370 - mean_absolute_error: 1.0307 - val_loss: 3005.0762 - val_mean_absolute_error: 54.7191\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8139 - mean_absolute_error: 0.7631 - val_loss: 3063.6914 - val_mean_absolute_error: 55.2420\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 585ms/step - loss: 1.4679 - mean_absolute_error: 0.9641 - val_loss: 2874.4360 - val_mean_absolute_error: 53.5758\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.4174 - mean_absolute_error: 2.7591 - val_loss: 3069.2192 - val_mean_absolute_error: 55.3494\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0863 - mean_absolute_error: 0.7972 - val_loss: 3236.4517 - val_mean_absolute_error: 56.8243\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2967 - mean_absolute_error: 0.9694 - val_loss: 3286.1096 - val_mean_absolute_error: 57.2556\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.5476 - mean_absolute_error: 1.3082 - val_loss: 3261.7769 - val_mean_absolute_error: 57.0460\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8344 - mean_absolute_error: 1.1342 - val_loss: 3200.9521 - val_mean_absolute_error: 56.5168\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6659 - mean_absolute_error: 0.7193 - val_loss: 3130.3506 - val_mean_absolute_error: 55.8956\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2990 - mean_absolute_error: 0.5116 - val_loss: 3076.8164 - val_mean_absolute_error: 55.4194\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7681 - mean_absolute_error: 0.6982 - val_loss: 3063.4912 - val_mean_absolute_error: 55.3001\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9697 - mean_absolute_error: 0.8265 - val_loss: 3083.4570 - val_mean_absolute_error: 55.4780\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6224 - mean_absolute_error: 0.6243 - val_loss: 3120.4678 - val_mean_absolute_error: 55.8063\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 3.3686 - mean_absolute_error: 1.2633 - val_loss: 2633.2466 - val_mean_absolute_error: 51.2986\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 24.8791 - mean_absolute_error: 3.8988 - val_loss: 3031.6785 - val_mean_absolute_error: 54.9890\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7229 - mean_absolute_error: 1.0895 - val_loss: 3333.5891 - val_mean_absolute_error: 57.6099\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.7155 - mean_absolute_error: 2.3465 - val_loss: 3339.5840 - val_mean_absolute_error: 57.6547\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.1060 - mean_absolute_error: 2.3934 - val_loss: 3218.9067 - val_mean_absolute_error: 56.6169\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4239 - mean_absolute_error: 1.5109 - val_loss: 3065.1831 - val_mean_absolute_error: 55.2720\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1849 - mean_absolute_error: 0.7791 - val_loss: 2937.5859 - val_mean_absolute_error: 54.1242\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7667 - mean_absolute_error: 1.5326 - val_loss: 2905.1873 - val_mean_absolute_error: 53.8260\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6079 - mean_absolute_error: 1.7167 - val_loss: 2941.4172 - val_mean_absolute_error: 54.1539\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.3748 - mean_absolute_error: 1.4298 - val_loss: 3007.9658 - val_mean_absolute_error: 54.7519\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2333 - mean_absolute_error: 0.9797 - val_loss: 3073.1978 - val_mean_absolute_error: 55.3292\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 600ms/step - loss: 2.9966 - mean_absolute_error: 1.1818 - val_loss: 2755.9016 - val_mean_absolute_error: 52.4715\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.7636 - mean_absolute_error: 3.0235 - val_loss: 2987.7036 - val_mean_absolute_error: 54.6057\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.5666 - mean_absolute_error: 1.4339 - val_loss: 3196.6274 - val_mean_absolute_error: 56.4511\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.5668 - mean_absolute_error: 1.2048 - val_loss: 3269.7036 - val_mean_absolute_error: 57.0797\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3804 - mean_absolute_error: 1.7005 - val_loss: 3239.0908 - val_mean_absolute_error: 56.8141\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4312 - mean_absolute_error: 1.4718 - val_loss: 3176.2490 - val_mean_absolute_error: 56.2641\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9875 - mean_absolute_error: 1.0725 - val_loss: 3102.6528 - val_mean_absolute_error: 55.6126\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1868 - mean_absolute_error: 0.7786 - val_loss: 3030.2822 - val_mean_absolute_error: 54.9630\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3378 - mean_absolute_error: 1.0544 - val_loss: 2992.7639 - val_mean_absolute_error: 54.6197\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.7131 - mean_absolute_error: 1.2497 - val_loss: 3001.4238 - val_mean_absolute_error: 54.6938\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4513 - mean_absolute_error: 1.1560 - val_loss: 3038.4771 - val_mean_absolute_error: 55.0256\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 2.6403 - mean_absolute_error: 1.1900 - val_loss: 2538.4937 - val_mean_absolute_error: 50.3620\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 16.3275 - mean_absolute_error: 2.9588 - val_loss: 2873.1802 - val_mean_absolute_error: 53.5545\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.6891 - mean_absolute_error: 1.4067 - val_loss: 3169.6294 - val_mean_absolute_error: 56.2264\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.7393 - mean_absolute_error: 1.2728 - val_loss: 3284.9956 - val_mean_absolute_error: 57.2249\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.2832 - mean_absolute_error: 1.8689 - val_loss: 3258.5098 - val_mean_absolute_error: 56.9925\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5932 - mean_absolute_error: 1.7244 - val_loss: 3160.3950 - val_mean_absolute_error: 56.1350\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4232 - mean_absolute_error: 1.1656 - val_loss: 3040.4807 - val_mean_absolute_error: 55.0686\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2018 - mean_absolute_error: 0.7491 - val_loss: 2929.5615 - val_mean_absolute_error: 54.0630\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6601 - mean_absolute_error: 1.1483 - val_loss: 2882.5850 - val_mean_absolute_error: 53.6297\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2823 - mean_absolute_error: 1.3538 - val_loss: 2894.5205 - val_mean_absolute_error: 53.7396\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0798 - mean_absolute_error: 1.2986 - val_loss: 2944.0891 - val_mean_absolute_error: 54.1943\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 2.7789 - mean_absolute_error: 1.1676 - val_loss: 2649.5073 - val_mean_absolute_error: 51.4473\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.4760 - mean_absolute_error: 2.4523 - val_loss: 2893.8772 - val_mean_absolute_error: 53.7425\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2589 - mean_absolute_error: 1.3015 - val_loss: 3101.0728 - val_mean_absolute_error: 55.6118\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6144 - mean_absolute_error: 0.8857 - val_loss: 3185.5376 - val_mean_absolute_error: 56.3525\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 2.8283 - mean_absolute_error: 1.2998 - val_loss: 3176.3979 - val_mean_absolute_error: 56.2679\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.6622 - mean_absolute_error: 1.2407 - val_loss: 3121.3257 - val_mean_absolute_error: 55.7777\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.7778 - mean_absolute_error: 0.9937 - val_loss: 3049.8584 - val_mean_absolute_error: 55.1353\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0579 - mean_absolute_error: 0.7441 - val_loss: 2971.5190 - val_mean_absolute_error: 54.4244\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9550 - mean_absolute_error: 0.8759 - val_loss: 2915.2949 - val_mean_absolute_error: 53.9072\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2991 - mean_absolute_error: 1.1057 - val_loss: 2906.3730 - val_mean_absolute_error: 53.8219\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3698 - mean_absolute_error: 1.1360 - val_loss: 2937.4084 - val_mean_absolute_error: 54.1037\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 3.6437 - mean_absolute_error: 1.5267 - val_loss: 2760.9697 - val_mean_absolute_error: 52.5160\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 19.7297 - mean_absolute_error: 4.0337 - val_loss: 3008.1040 - val_mean_absolute_error: 54.8001\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.9098 - mean_absolute_error: 1.4939 - val_loss: 3262.6841 - val_mean_absolute_error: 57.0502\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5796 - mean_absolute_error: 1.0383 - val_loss: 3385.5496 - val_mean_absolute_error: 58.1058\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.2634 - mean_absolute_error: 2.1642 - val_loss: 3375.7356 - val_mean_absolute_error: 58.0253\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.6891 - mean_absolute_error: 2.0768 - val_loss: 3296.3572 - val_mean_absolute_error: 57.3479\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.3807 - mean_absolute_error: 1.3222 - val_loss: 3196.2339 - val_mean_absolute_error: 56.4803\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2943 - mean_absolute_error: 0.5164 - val_loss: 3103.4849 - val_mean_absolute_error: 55.6640\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5752 - mean_absolute_error: 0.6915 - val_loss: 3045.7681 - val_mean_absolute_error: 55.1494\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.8241 - mean_absolute_error: 1.1574 - val_loss: 3032.8394 - val_mean_absolute_error: 55.0324\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0626 - mean_absolute_error: 1.2532 - val_loss: 3053.3896 - val_mean_absolute_error: 55.2153\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 2.2335 - mean_absolute_error: 0.9600 - val_loss: 2582.8315 - val_mean_absolute_error: 50.7994\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 28.4045 - mean_absolute_error: 4.1188 - val_loss: 2937.3921 - val_mean_absolute_error: 54.1411\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.5412 - mean_absolute_error: 1.6915 - val_loss: 3297.1851 - val_mean_absolute_error: 57.3195\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5174 - mean_absolute_error: 1.9772 - val_loss: 3409.4688 - val_mean_absolute_error: 58.2697\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 10.7723 - mean_absolute_error: 2.7602 - val_loss: 3344.3635 - val_mean_absolute_error: 57.7175\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.2331 - mean_absolute_error: 2.2669 - val_loss: 3204.4453 - val_mean_absolute_error: 56.5133\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.4992 - mean_absolute_error: 1.2680 - val_loss: 3056.6382 - val_mean_absolute_error: 55.2073\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1311 - mean_absolute_error: 0.8417 - val_loss: 2942.5391 - val_mean_absolute_error: 54.1759\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.6363 - mean_absolute_error: 1.5092 - val_loss: 2898.3696 - val_mean_absolute_error: 53.7690\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7432 - mean_absolute_error: 1.7524 - val_loss: 2914.1470 - val_mean_absolute_error: 53.9121\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.0301 - mean_absolute_error: 1.6022 - val_loss: 2967.1829 - val_mean_absolute_error: 54.3935\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.0040 - mean_absolute_error: 1.2567 - val_loss: 2432.8027 - val_mean_absolute_error: 49.3141\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 49.5475 - mean_absolute_error: 5.3462 - val_loss: 2865.6992 - val_mean_absolute_error: 53.4911\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.8316 - mean_absolute_error: 2.2459 - val_loss: 3306.8589 - val_mean_absolute_error: 57.4105\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.3289 - mean_absolute_error: 2.0513 - val_loss: 3499.8721 - val_mean_absolute_error: 59.0355\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 17.4258 - mean_absolute_error: 3.5204 - val_loss: 3469.4880 - val_mean_absolute_error: 58.7791\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 15.1689 - mean_absolute_error: 3.2678 - val_loss: 3340.3350 - val_mean_absolute_error: 57.6822\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 7.4712 - mean_absolute_error: 2.2444 - val_loss: 3178.4229 - val_mean_absolute_error: 56.2791\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.2605 - mean_absolute_error: 1.1439 - val_loss: 3025.4343 - val_mean_absolute_error: 54.9215\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5795 - mean_absolute_error: 1.1038 - val_loss: 2916.9316 - val_mean_absolute_error: 53.9371\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.7612 - mean_absolute_error: 1.7814 - val_loss: 2869.1396 - val_mean_absolute_error: 53.4972\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4223 - mean_absolute_error: 2.0752 - val_loss: 2874.1968 - val_mean_absolute_error: 53.5426\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 2.2006 - mean_absolute_error: 0.9466 - val_loss: 2550.3159 - val_mean_absolute_error: 50.4836\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 19.3074 - mean_absolute_error: 3.0882 - val_loss: 2892.4648 - val_mean_absolute_error: 53.7303\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.7561 - mean_absolute_error: 1.3878 - val_loss: 3215.9556 - val_mean_absolute_error: 56.6171\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.9989 - mean_absolute_error: 1.3515 - val_loss: 3354.1484 - val_mean_absolute_error: 57.7992\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.7634 - mean_absolute_error: 2.0894 - val_loss: 3328.2695 - val_mean_absolute_error: 57.5723\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.8027 - mean_absolute_error: 1.9205 - val_loss: 3219.8062 - val_mean_absolute_error: 56.6346\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.9033 - mean_absolute_error: 1.3090 - val_loss: 3082.5986 - val_mean_absolute_error: 55.4277\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0445 - mean_absolute_error: 0.6938 - val_loss: 2957.8333 - val_mean_absolute_error: 54.3067\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4138 - mean_absolute_error: 1.0882 - val_loss: 2878.9980 - val_mean_absolute_error: 53.5836\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.6578 - mean_absolute_error: 1.4419 - val_loss: 2860.5952 - val_mean_absolute_error: 53.4110\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.9490 - mean_absolute_error: 1.5071 - val_loss: 2891.9724 - val_mean_absolute_error: 53.6976\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 18.9423 - mean_absolute_error: 3.7415 - val_loss: 2913.9780 - val_mean_absolute_error: 53.9360\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.3648 - mean_absolute_error: 1.2491 - val_loss: 2668.8887 - val_mean_absolute_error: 51.6255\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8.7388 - mean_absolute_error: 2.2955 - val_loss: 2737.2163 - val_mean_absolute_error: 52.2715\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.6177 - mean_absolute_error: 1.9457 - val_loss: 2896.8140 - val_mean_absolute_error: 53.7588\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6430 - mean_absolute_error: 1.1950 - val_loss: 3070.3865 - val_mean_absolute_error: 55.3282\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0994 - mean_absolute_error: 0.7816 - val_loss: 3190.3574 - val_mean_absolute_error: 56.3839\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.6377 - mean_absolute_error: 1.2266 - val_loss: 3227.7422 - val_mean_absolute_error: 56.7052\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4054 - mean_absolute_error: 1.4086 - val_loss: 3195.7666 - val_mean_absolute_error: 56.4218\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.6596 - mean_absolute_error: 1.2064 - val_loss: 3122.3696 - val_mean_absolute_error: 55.7713\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4646 - mean_absolute_error: 0.9441 - val_loss: 3035.2971 - val_mean_absolute_error: 54.9914\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7875 - mean_absolute_error: 0.7810 - val_loss: 2953.1216 - val_mean_absolute_error: 54.2464\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9476 - mean_absolute_error: 0.9248 - val_loss: 2898.0706 - val_mean_absolute_error: 53.7427\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 589ms/step - loss: 23.3806 - mean_absolute_error: 4.2585 - val_loss: 2901.7412 - val_mean_absolute_error: 53.8296\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8.6323 - mean_absolute_error: 2.5063 - val_loss: 2816.3647 - val_mean_absolute_error: 53.0391\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 13.8215 - mean_absolute_error: 3.3223 - val_loss: 2965.8164 - val_mean_absolute_error: 54.4177\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.7437 - mean_absolute_error: 1.9016 - val_loss: 3159.8218 - val_mean_absolute_error: 56.1539\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3722 - mean_absolute_error: 0.5955 - val_loss: 3313.4834 - val_mean_absolute_error: 57.4903\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.0383 - mean_absolute_error: 1.4600 - val_loss: 3372.1377 - val_mean_absolute_error: 57.9913\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.4907 - mean_absolute_error: 2.0221 - val_loss: 3350.9524 - val_mean_absolute_error: 57.8099\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.5560 - mean_absolute_error: 1.8223 - val_loss: 3277.6367 - val_mean_absolute_error: 57.1787\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0402 - mean_absolute_error: 1.2018 - val_loss: 3183.4985 - val_mean_absolute_error: 56.3582\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4126 - mean_absolute_error: 0.5683 - val_loss: 3094.9832 - val_mean_absolute_error: 55.5755\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5465 - mean_absolute_error: 0.5682 - val_loss: 3034.1870 - val_mean_absolute_error: 55.0325\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.6496 - mean_absolute_error: 1.1577 - val_loss: 3010.2256 - val_mean_absolute_error: 54.8179\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 11.1439 - mean_absolute_error: 2.8480 - val_loss: 2895.0916 - val_mean_absolute_error: 53.7584\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.7471 - mean_absolute_error: 2.0898 - val_loss: 2848.3462 - val_mean_absolute_error: 53.3154\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.9676 - mean_absolute_error: 2.2708 - val_loss: 2975.8740 - val_mean_absolute_error: 54.4797\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.2632 - mean_absolute_error: 1.3957 - val_loss: 3116.9458 - val_mean_absolute_error: 55.7363\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3101 - mean_absolute_error: 0.7919 - val_loss: 3198.3777 - val_mean_absolute_error: 56.4421\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.6040 - mean_absolute_error: 1.3330 - val_loss: 3206.1492 - val_mean_absolute_error: 56.4979\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.7832 - mean_absolute_error: 1.3944 - val_loss: 3157.0518 - val_mean_absolute_error: 56.0549\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7012 - mean_absolute_error: 1.1473 - val_loss: 3076.8035 - val_mean_absolute_error: 55.3320\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7202 - mean_absolute_error: 0.7493 - val_loss: 2993.5410 - val_mean_absolute_error: 54.5754\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9230 - mean_absolute_error: 0.9333 - val_loss: 2945.9043 - val_mean_absolute_error: 54.1364\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.5227 - mean_absolute_error: 1.1641 - val_loss: 2946.9277 - val_mean_absolute_error: 54.1420\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4157 - mean_absolute_error: 1.1134 - val_loss: 2980.5107 - val_mean_absolute_error: 54.4473\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 575ms/step - loss: 21.1151 - mean_absolute_error: 3.9216 - val_loss: 2931.8728 - val_mean_absolute_error: 54.0984\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.8065 - mean_absolute_error: 1.7700 - val_loss: 2767.2520 - val_mean_absolute_error: 52.5656\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 11.4979 - mean_absolute_error: 2.8358 - val_loss: 2849.2988 - val_mean_absolute_error: 53.3274\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.4499 - mean_absolute_error: 2.2438 - val_loss: 3005.6819 - val_mean_absolute_error: 54.7518\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7514 - mean_absolute_error: 1.2080 - val_loss: 3156.3950 - val_mean_absolute_error: 56.0857\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0941 - mean_absolute_error: 1.1566 - val_loss: 3235.6831 - val_mean_absolute_error: 56.7700\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9776 - mean_absolute_error: 1.6039 - val_loss: 3236.2515 - val_mean_absolute_error: 56.7684\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8837 - mean_absolute_error: 1.6136 - val_loss: 3180.7744 - val_mean_absolute_error: 56.2793\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.3511 - mean_absolute_error: 1.3300 - val_loss: 3092.2407 - val_mean_absolute_error: 55.4954\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1032 - mean_absolute_error: 0.8690 - val_loss: 3004.6934 - val_mean_absolute_error: 54.7100\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2812 - mean_absolute_error: 1.0513 - val_loss: 2951.3325 - val_mean_absolute_error: 54.2271\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1637 - mean_absolute_error: 1.3833 - val_loss: 2949.7961 - val_mean_absolute_error: 54.2139\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 7.4104 - mean_absolute_error: 2.2158 - val_loss: 2721.4236 - val_mean_absolute_error: 52.1346\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.7451 - mean_absolute_error: 2.2673 - val_loss: 2798.9978 - val_mean_absolute_error: 52.8559\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8778 - mean_absolute_error: 1.8164 - val_loss: 2994.5752 - val_mean_absolute_error: 54.6427\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1355 - mean_absolute_error: 0.9124 - val_loss: 3160.7830 - val_mean_absolute_error: 56.1099\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.8558 - mean_absolute_error: 1.0381 - val_loss: 3230.7412 - val_mean_absolute_error: 56.7087\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2065 - mean_absolute_error: 1.3457 - val_loss: 3203.4409 - val_mean_absolute_error: 56.4631\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.6346 - mean_absolute_error: 1.1725 - val_loss: 3117.5410 - val_mean_absolute_error: 55.7050\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2240 - mean_absolute_error: 0.9082 - val_loss: 3012.1680 - val_mean_absolute_error: 54.7634\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7253 - mean_absolute_error: 0.7540 - val_loss: 2925.5486 - val_mean_absolute_error: 53.9784\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3670 - mean_absolute_error: 1.1343 - val_loss: 2893.0376 - val_mean_absolute_error: 53.6810\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8579 - mean_absolute_error: 1.2837 - val_loss: 2911.0447 - val_mean_absolute_error: 53.8464\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 1.9810 - mean_absolute_error: 1.1652 - val_loss: 3539.2476 - val_mean_absolute_error: 59.3451\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 15.7368 - mean_absolute_error: 3.1481 - val_loss: 3089.5918 - val_mean_absolute_error: 55.4884\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.2534 - mean_absolute_error: 0.8902 - val_loss: 2707.4360 - val_mean_absolute_error: 51.9772\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.1856 - mean_absolute_error: 2.0333 - val_loss: 2675.1782 - val_mean_absolute_error: 51.6738\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.2767 - mean_absolute_error: 2.1600 - val_loss: 2803.1719 - val_mean_absolute_error: 52.8889\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1927 - mean_absolute_error: 1.5741 - val_loss: 2980.8257 - val_mean_absolute_error: 54.5222\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8617 - mean_absolute_error: 0.7861 - val_loss: 3131.9941 - val_mean_absolute_error: 55.8710\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7707 - mean_absolute_error: 1.0470 - val_loss: 3207.7703 - val_mean_absolute_error: 56.5355\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.0610 - mean_absolute_error: 1.3468 - val_loss: 3208.9175 - val_mean_absolute_error: 56.5466\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.0542 - mean_absolute_error: 1.3520 - val_loss: 3155.4624 - val_mean_absolute_error: 56.0786\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9611 - mean_absolute_error: 1.0750 - val_loss: 3071.8691 - val_mean_absolute_error: 55.3382\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9520 - mean_absolute_error: 0.7789 - val_loss: 2981.7393 - val_mean_absolute_error: 54.5279\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7555 - mean_absolute_error: 0.7720 - val_loss: 2911.5400 - val_mean_absolute_error: 53.8872\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2743 - mean_absolute_error: 1.0820 - val_loss: 2879.1782 - val_mean_absolute_error: 53.5887\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 3.5850 - mean_absolute_error: 1.5137 - val_loss: 3116.1421 - val_mean_absolute_error: 55.7630\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4867 - mean_absolute_error: 0.5922 - val_loss: 3106.2549 - val_mean_absolute_error: 55.6750\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4123 - mean_absolute_error: 0.5001 - val_loss: 3163.5835 - val_mean_absolute_error: 56.1815\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3382 - mean_absolute_error: 0.4836 - val_loss: 3137.4985 - val_mean_absolute_error: 55.9529\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2154 - mean_absolute_error: 0.3875 - val_loss: 3106.5459 - val_mean_absolute_error: 55.6797\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2868 - mean_absolute_error: 0.3958 - val_loss: 3156.5742 - val_mean_absolute_error: 56.1220\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2236 - mean_absolute_error: 0.4404 - val_loss: 3151.1685 - val_mean_absolute_error: 56.0750\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1811 - mean_absolute_error: 0.3844 - val_loss: 3116.1558 - val_mean_absolute_error: 55.7667\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2031 - mean_absolute_error: 0.3452 - val_loss: 3136.2119 - val_mean_absolute_error: 55.9450\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1407 - mean_absolute_error: 0.2442 - val_loss: 3164.0906 - val_mean_absolute_error: 56.1910\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1813 - mean_absolute_error: 0.4161 - val_loss: 3145.2781 - val_mean_absolute_error: 56.0262\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1263 - mean_absolute_error: 0.2645 - val_loss: 3126.6934 - val_mean_absolute_error: 55.8628\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.0211 - mean_absolute_error: 1.9905 - val_loss: 3054.1772 - val_mean_absolute_error: 55.2165\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.5950 - mean_absolute_error: 1.1751 - val_loss: 3046.4844 - val_mean_absolute_error: 55.1403\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.2193 - mean_absolute_error: 1.1598 - val_loss: 3112.0271 - val_mean_absolute_error: 55.7164\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.7398 - mean_absolute_error: 0.8191 - val_loss: 3111.8506 - val_mean_absolute_error: 55.7054\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5078 - mean_absolute_error: 0.7739 - val_loss: 3053.6702 - val_mean_absolute_error: 55.1751\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2226 - mean_absolute_error: 0.8997 - val_loss: 3039.1763 - val_mean_absolute_error: 55.0288\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9792 - mean_absolute_error: 0.8732 - val_loss: 3076.0774 - val_mean_absolute_error: 55.3425\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7611 - mean_absolute_error: 0.6879 - val_loss: 3064.1055 - val_mean_absolute_error: 55.2153\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6396 - mean_absolute_error: 0.6914 - val_loss: 3010.8811 - val_mean_absolute_error: 54.7136\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7061 - mean_absolute_error: 0.7207 - val_loss: 3066.3286 - val_mean_absolute_error: 55.2150\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6346 - mean_absolute_error: 0.7836 - val_loss: 3050.1477 - val_mean_absolute_error: 55.0742\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5194 - mean_absolute_error: 0.6736 - val_loss: 3005.0933 - val_mean_absolute_error: 54.6725\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5303 - mean_absolute_error: 0.6063 - val_loss: 3043.8940 - val_mean_absolute_error: 55.0428\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3906 - mean_absolute_error: 0.5646 - val_loss: 3076.6750 - val_mean_absolute_error: 55.3510\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4335 - mean_absolute_error: 0.5682 - val_loss: 3055.1221 - val_mean_absolute_error: 55.1586\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3480 - mean_absolute_error: 0.5182 - val_loss: 3035.5063 - val_mean_absolute_error: 54.9758\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3391 - mean_absolute_error: 0.5231 - val_loss: 3062.7847 - val_mean_absolute_error: 55.2164\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2586 - mean_absolute_error: 0.4110 - val_loss: 3080.8235 - val_mean_absolute_error: 55.3741\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2783 - mean_absolute_error: 0.4764 - val_loss: 3062.6528 - val_mean_absolute_error: 55.2081\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2356 - mean_absolute_error: 0.3431 - val_loss: 3060.3281 - val_mean_absolute_error: 55.1950\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2028 - mean_absolute_error: 0.2984 - val_loss: 3087.2104 - val_mean_absolute_error: 55.4534\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1630 - mean_absolute_error: 0.3221 - val_loss: 3094.1716 - val_mean_absolute_error: 55.5266\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 665ms/step - loss: 4.1398 - mean_absolute_error: 1.5921 - val_loss: 2983.4189 - val_mean_absolute_error: 54.5777\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.5533 - mean_absolute_error: 1.5934 - val_loss: 3083.4111 - val_mean_absolute_error: 55.4660\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.9169 - mean_absolute_error: 0.9117 - val_loss: 3141.6589 - val_mean_absolute_error: 55.9758\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9994 - mean_absolute_error: 0.8557 - val_loss: 3105.6133 - val_mean_absolute_error: 55.6531\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6862 - mean_absolute_error: 0.8583 - val_loss: 3039.8062 - val_mean_absolute_error: 55.0603\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.7214 - mean_absolute_error: 1.1043 - val_loss: 3055.5657 - val_mean_absolute_error: 55.1940\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4471 - mean_absolute_error: 0.9708 - val_loss: 3103.7656 - val_mean_absolute_error: 55.6166\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3276 - mean_absolute_error: 0.8275 - val_loss: 3103.8342 - val_mean_absolute_error: 55.6070\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2435 - mean_absolute_error: 0.8514 - val_loss: 3050.8955 - val_mean_absolute_error: 55.1224\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1037 - mean_absolute_error: 0.8560 - val_loss: 3029.6892 - val_mean_absolute_error: 54.9197\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1294 - mean_absolute_error: 0.9198 - val_loss: 3076.7588 - val_mean_absolute_error: 55.3354\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 675ms/step - loss: 4.1689 - mean_absolute_error: 1.6162 - val_loss: 2991.4036 - val_mean_absolute_error: 54.6378\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9550 - mean_absolute_error: 1.1126 - val_loss: 2978.2131 - val_mean_absolute_error: 54.5105\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6896 - mean_absolute_error: 1.0420 - val_loss: 3048.2100 - val_mean_absolute_error: 55.1364\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2773 - mean_absolute_error: 0.7947 - val_loss: 3061.3467 - val_mean_absolute_error: 55.2447\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1578 - mean_absolute_error: 0.6903 - val_loss: 3022.5054 - val_mean_absolute_error: 54.8823\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9630 - mean_absolute_error: 0.7959 - val_loss: 3003.1670 - val_mean_absolute_error: 54.6930\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9048 - mean_absolute_error: 0.8629 - val_loss: 3046.2275 - val_mean_absolute_error: 55.0746\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8153 - mean_absolute_error: 0.7973 - val_loss: 3056.3843 - val_mean_absolute_error: 55.1627\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7847 - mean_absolute_error: 0.8083 - val_loss: 3026.7759 - val_mean_absolute_error: 54.8930\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7054 - mean_absolute_error: 0.7621 - val_loss: 3025.6387 - val_mean_absolute_error: 54.8893\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6468 - mean_absolute_error: 0.7095 - val_loss: 3057.5681 - val_mean_absolute_error: 55.1878\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6079 - mean_absolute_error: 0.6688 - val_loss: 3053.3848 - val_mean_absolute_error: 55.1518\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 646ms/step - loss: 6.7780 - mean_absolute_error: 2.1573 - val_loss: 3075.8010 - val_mean_absolute_error: 55.4045\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9563 - mean_absolute_error: 0.9100 - val_loss: 2894.0623 - val_mean_absolute_error: 53.7514\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.5744 - mean_absolute_error: 1.3304 - val_loss: 2968.8330 - val_mean_absolute_error: 54.4308\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6000 - mean_absolute_error: 1.0067 - val_loss: 3069.6543 - val_mean_absolute_error: 55.3365\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4857 - mean_absolute_error: 0.7775 - val_loss: 3090.1045 - val_mean_absolute_error: 55.5146\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5094 - mean_absolute_error: 0.8348 - val_loss: 3043.9485 - val_mean_absolute_error: 55.0957\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1738 - mean_absolute_error: 0.7350 - val_loss: 2975.1230 - val_mean_absolute_error: 54.4667\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1619 - mean_absolute_error: 0.9524 - val_loss: 2968.8940 - val_mean_absolute_error: 54.4001\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0787 - mean_absolute_error: 0.9691 - val_loss: 3020.9878 - val_mean_absolute_error: 54.8661\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8308 - mean_absolute_error: 0.7081 - val_loss: 3063.9121 - val_mean_absolute_error: 55.2470\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9002 - mean_absolute_error: 0.7827 - val_loss: 3050.9990 - val_mean_absolute_error: 55.1247\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7954 - mean_absolute_error: 0.7975 - val_loss: 3006.6597 - val_mean_absolute_error: 54.7165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 94ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 627ms/step - loss: 6.1989 - mean_absolute_error: 2.1544 - val_loss: 3003.3042 - val_mean_absolute_error: 54.7688\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.9253 - mean_absolute_error: 1.4512 - val_loss: 3070.5557 - val_mean_absolute_error: 55.3699\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9868 - mean_absolute_error: 0.8303 - val_loss: 3168.4351 - val_mean_absolute_error: 56.2321\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3269 - mean_absolute_error: 0.4822 - val_loss: 3215.3833 - val_mean_absolute_error: 56.6401\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8215 - mean_absolute_error: 0.8060 - val_loss: 3202.5415 - val_mean_absolute_error: 56.5284\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6031 - mean_absolute_error: 0.7098 - val_loss: 3162.4895 - val_mean_absolute_error: 56.1788\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2212 - mean_absolute_error: 0.4225 - val_loss: 3118.3584 - val_mean_absolute_error: 55.7902\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2450 - mean_absolute_error: 0.3967 - val_loss: 3102.0681 - val_mean_absolute_error: 55.6451\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3753 - mean_absolute_error: 0.5273 - val_loss: 3117.0317 - val_mean_absolute_error: 55.7759\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2367 - mean_absolute_error: 0.3975 - val_loss: 3144.7832 - val_mean_absolute_error: 56.0193\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1519 - mean_absolute_error: 0.3151 - val_loss: 3166.3267 - val_mean_absolute_error: 56.2083\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 597ms/step - loss: 5.3884 - mean_absolute_error: 1.8939 - val_loss: 2964.1348 - val_mean_absolute_error: 54.3873\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.0460 - mean_absolute_error: 1.5436 - val_loss: 3023.8076 - val_mean_absolute_error: 54.9152\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6861 - mean_absolute_error: 1.0856 - val_loss: 3119.0962 - val_mean_absolute_error: 55.7570\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5602 - mean_absolute_error: 0.8278 - val_loss: 3117.3086 - val_mean_absolute_error: 55.7352\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4111 - mean_absolute_error: 0.8243 - val_loss: 3057.1748 - val_mean_absolute_error: 55.1924\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0228 - mean_absolute_error: 0.7794 - val_loss: 3001.6687 - val_mean_absolute_error: 54.6824\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0949 - mean_absolute_error: 0.9883 - val_loss: 3015.3647 - val_mean_absolute_error: 54.7926\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7731 - mean_absolute_error: 0.7992 - val_loss: 3052.0269 - val_mean_absolute_error: 55.1112\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6532 - mean_absolute_error: 0.6932 - val_loss: 3059.1035 - val_mean_absolute_error: 55.1645\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6597 - mean_absolute_error: 0.7669 - val_loss: 3028.2393 - val_mean_absolute_error: 54.8760\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5168 - mean_absolute_error: 0.6416 - val_loss: 2991.0198 - val_mean_absolute_error: 54.5322\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 638ms/step - loss: 4.3207 - mean_absolute_error: 1.6067 - val_loss: 2891.0410 - val_mean_absolute_error: 53.7307\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.8461 - mean_absolute_error: 2.1702 - val_loss: 3047.9832 - val_mean_absolute_error: 55.1500\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.1478 - mean_absolute_error: 1.1253 - val_loss: 3160.3521 - val_mean_absolute_error: 56.1405\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.0492 - mean_absolute_error: 0.9109 - val_loss: 3180.0012 - val_mean_absolute_error: 56.3063\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.2295 - mean_absolute_error: 1.0592 - val_loss: 3142.9380 - val_mean_absolute_error: 55.9734\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6535 - mean_absolute_error: 0.8989 - val_loss: 3079.2959 - val_mean_absolute_error: 55.4027\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2588 - mean_absolute_error: 0.8461 - val_loss: 3024.3259 - val_mean_absolute_error: 54.9025\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4660 - mean_absolute_error: 1.1245 - val_loss: 3021.4858 - val_mean_absolute_error: 54.8710\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3756 - mean_absolute_error: 1.1093 - val_loss: 3059.0688 - val_mean_absolute_error: 55.2054\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0081 - mean_absolute_error: 0.8405 - val_loss: 3102.3818 - val_mean_absolute_error: 55.5905\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9975 - mean_absolute_error: 0.8090 - val_loss: 3121.2427 - val_mean_absolute_error: 55.7550\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 633ms/step - loss: 7.2300 - mean_absolute_error: 2.2177 - val_loss: 3097.4453 - val_mean_absolute_error: 55.5974\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0589 - mean_absolute_error: 0.8981 - val_loss: 2929.6748 - val_mean_absolute_error: 54.0785\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4181 - mean_absolute_error: 1.2450 - val_loss: 2942.8149 - val_mean_absolute_error: 54.1901\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.8219 - mean_absolute_error: 1.1383 - val_loss: 3019.4473 - val_mean_absolute_error: 54.8777\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1354 - mean_absolute_error: 0.7887 - val_loss: 3076.6167 - val_mean_absolute_error: 55.3827\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1710 - mean_absolute_error: 0.7662 - val_loss: 3070.6641 - val_mean_absolute_error: 55.3191\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0148 - mean_absolute_error: 0.7381 - val_loss: 3019.5667 - val_mean_absolute_error: 54.8484\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7695 - mean_absolute_error: 0.7311 - val_loss: 2966.4612 - val_mean_absolute_error: 54.3562\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9109 - mean_absolute_error: 0.9182 - val_loss: 2975.8555 - val_mean_absolute_error: 54.4358\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8437 - mean_absolute_error: 0.8571 - val_loss: 3023.6040 - val_mean_absolute_error: 54.8692\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6775 - mean_absolute_error: 0.7845 - val_loss: 3065.9014 - val_mean_absolute_error: 55.2563\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6847 - mean_absolute_error: 0.7647 - val_loss: 3076.5786 - val_mean_absolute_error: 55.3602\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.6472 - mean_absolute_error: 1.9360 - val_loss: 2975.1360 - val_mean_absolute_error: 54.5012\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9756 - mean_absolute_error: 1.1184 - val_loss: 2947.7454 - val_mean_absolute_error: 54.2403\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.7398 - mean_absolute_error: 1.0689 - val_loss: 3043.0466 - val_mean_absolute_error: 55.0905\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2829 - mean_absolute_error: 0.7287 - val_loss: 3040.6929 - val_mean_absolute_error: 55.0553\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0631 - mean_absolute_error: 0.7236 - val_loss: 2945.9019 - val_mean_absolute_error: 54.1859\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1060 - mean_absolute_error: 1.0142 - val_loss: 3009.7173 - val_mean_absolute_error: 54.7545\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8352 - mean_absolute_error: 0.8007 - val_loss: 3069.9011 - val_mean_absolute_error: 55.2899\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9693 - mean_absolute_error: 0.8790 - val_loss: 3007.2559 - val_mean_absolute_error: 54.7267\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7391 - mean_absolute_error: 0.7837 - val_loss: 2969.3120 - val_mean_absolute_error: 54.3870\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8104 - mean_absolute_error: 0.8688 - val_loss: 3037.1616 - val_mean_absolute_error: 55.0078\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6288 - mean_absolute_error: 0.7023 - val_loss: 3072.7422 - val_mean_absolute_error: 55.3324\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6792 - mean_absolute_error: 0.6876 - val_loss: 3019.6167 - val_mean_absolute_error: 54.8568\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5326 - mean_absolute_error: 0.6491 - val_loss: 2994.7939 - val_mean_absolute_error: 54.6304\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5546 - mean_absolute_error: 0.7306 - val_loss: 3052.5642 - val_mean_absolute_error: 55.1503\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4163 - mean_absolute_error: 0.5891 - val_loss: 3084.8682 - val_mean_absolute_error: 55.4383\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 644ms/step - loss: 2.7192 - mean_absolute_error: 1.3463 - val_loss: 3084.2622 - val_mean_absolute_error: 55.4825\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7146 - mean_absolute_error: 0.6414 - val_loss: 3140.8589 - val_mean_absolute_error: 55.9875\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2750 - mean_absolute_error: 0.4983 - val_loss: 3203.5103 - val_mean_absolute_error: 56.5377\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6207 - mean_absolute_error: 0.7163 - val_loss: 3124.6870 - val_mean_absolute_error: 55.8459\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2452 - mean_absolute_error: 0.4146 - val_loss: 3096.5205 - val_mean_absolute_error: 55.5959\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4649 - mean_absolute_error: 0.5802 - val_loss: 3142.4951 - val_mean_absolute_error: 56.0020\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1737 - mean_absolute_error: 0.3711 - val_loss: 3181.2471 - val_mean_absolute_error: 56.3421\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3194 - mean_absolute_error: 0.5418 - val_loss: 3174.0020 - val_mean_absolute_error: 56.2787\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2520 - mean_absolute_error: 0.4815 - val_loss: 3139.6030 - val_mean_absolute_error: 55.9763\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1563 - mean_absolute_error: 0.3286 - val_loss: 3115.1001 - val_mean_absolute_error: 55.7602\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2591 - mean_absolute_error: 0.4427 - val_loss: 3129.8677 - val_mean_absolute_error: 55.8915\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 654ms/step - loss: 5.0142 - mean_absolute_error: 1.7755 - val_loss: 3028.2417 - val_mean_absolute_error: 54.9735\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.4505 - mean_absolute_error: 1.2486 - val_loss: 3070.1680 - val_mean_absolute_error: 55.3409\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7959 - mean_absolute_error: 0.9331 - val_loss: 3117.0173 - val_mean_absolute_error: 55.7505\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6874 - mean_absolute_error: 0.8200 - val_loss: 3076.5835 - val_mean_absolute_error: 55.3795\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2987 - mean_absolute_error: 0.7650 - val_loss: 3021.6597 - val_mean_absolute_error: 54.8701\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2369 - mean_absolute_error: 1.0111 - val_loss: 3050.8154 - val_mean_absolute_error: 55.1137\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8894 - mean_absolute_error: 0.7071 - val_loss: 3077.8188 - val_mean_absolute_error: 55.3396\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9258 - mean_absolute_error: 0.8534 - val_loss: 3018.5742 - val_mean_absolute_error: 54.7874\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7427 - mean_absolute_error: 0.7120 - val_loss: 2988.8279 - val_mean_absolute_error: 54.5053\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7892 - mean_absolute_error: 0.7538 - val_loss: 3041.6208 - val_mean_absolute_error: 54.9893\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6842 - mean_absolute_error: 0.7742 - val_loss: 3044.8079 - val_mean_absolute_error: 55.0253\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6386 - mean_absolute_error: 0.7439 - val_loss: 3006.6418 - val_mean_absolute_error: 54.6826\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5584 - mean_absolute_error: 0.6288 - val_loss: 3002.5068 - val_mean_absolute_error: 54.6488\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5362 - mean_absolute_error: 0.6475 - val_loss: 3036.8354 - val_mean_absolute_error: 54.9637\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4743 - mean_absolute_error: 0.5917 - val_loss: 3038.5559 - val_mean_absolute_error: 54.9749\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4301 - mean_absolute_error: 0.5984 - val_loss: 3002.0527 - val_mean_absolute_error: 54.6319\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3710 - mean_absolute_error: 0.4625 - val_loss: 2997.6655 - val_mean_absolute_error: 54.5884\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3388 - mean_absolute_error: 0.4229 - val_loss: 3033.0938 - val_mean_absolute_error: 54.9205\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2941 - mean_absolute_error: 0.5088 - val_loss: 3034.5293 - val_mean_absolute_error: 54.9409\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 674ms/step - loss: 5.9344 - mean_absolute_error: 1.9758 - val_loss: 3060.2295 - val_mean_absolute_error: 55.2637\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1840 - mean_absolute_error: 1.0610 - val_loss: 3067.4771 - val_mean_absolute_error: 55.3196\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.8191 - mean_absolute_error: 0.9717 - val_loss: 3114.7019 - val_mean_absolute_error: 55.7294\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5983 - mean_absolute_error: 0.8470 - val_loss: 3027.6282 - val_mean_absolute_error: 54.9442\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5885 - mean_absolute_error: 1.1257 - val_loss: 3102.5347 - val_mean_absolute_error: 55.6040\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2167 - mean_absolute_error: 0.7830 - val_loss: 3099.4590 - val_mean_absolute_error: 55.5665\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0834 - mean_absolute_error: 0.8017 - val_loss: 3023.0337 - val_mean_absolute_error: 54.8718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1929 - mean_absolute_error: 1.0178 - val_loss: 3095.6721 - val_mean_absolute_error: 55.5211\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9610 - mean_absolute_error: 0.8449 - val_loss: 3104.8650 - val_mean_absolute_error: 55.6030\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9525 - mean_absolute_error: 0.8819 - val_loss: 3045.8489 - val_mean_absolute_error: 55.0742\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8682 - mean_absolute_error: 0.8012 - val_loss: 3062.2930 - val_mean_absolute_error: 55.2286\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7490 - mean_absolute_error: 0.7272 - val_loss: 3117.1328 - val_mean_absolute_error: 55.7273\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7450 - mean_absolute_error: 0.7628 - val_loss: 3101.3157 - val_mean_absolute_error: 55.5886\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6044 - mean_absolute_error: 0.6287 - val_loss: 3065.8564 - val_mean_absolute_error: 55.2701\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6118 - mean_absolute_error: 0.7170 - val_loss: 3099.3796 - val_mean_absolute_error: 55.5733\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4448 - mean_absolute_error: 0.5491 - val_loss: 3131.1660 - val_mean_absolute_error: 55.8580\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4539 - mean_absolute_error: 0.6407 - val_loss: 3105.3945 - val_mean_absolute_error: 55.6269\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 644ms/step - loss: 6.5943 - mean_absolute_error: 2.1169 - val_loss: 3131.3228 - val_mean_absolute_error: 55.8911\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.1677 - mean_absolute_error: 0.9453 - val_loss: 2934.6816 - val_mean_absolute_error: 54.1198\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.4821 - mean_absolute_error: 1.2746 - val_loss: 2969.5515 - val_mean_absolute_error: 54.4321\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.7681 - mean_absolute_error: 1.0824 - val_loss: 3050.6611 - val_mean_absolute_error: 55.1593\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3099 - mean_absolute_error: 0.8074 - val_loss: 3093.5684 - val_mean_absolute_error: 55.5353\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3507 - mean_absolute_error: 0.7921 - val_loss: 3057.2329 - val_mean_absolute_error: 55.2037\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0666 - mean_absolute_error: 0.6870 - val_loss: 2993.7158 - val_mean_absolute_error: 54.6212\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0495 - mean_absolute_error: 0.9430 - val_loss: 2995.1636 - val_mean_absolute_error: 54.6235\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9378 - mean_absolute_error: 0.9106 - val_loss: 3045.8450 - val_mean_absolute_error: 55.0752\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8017 - mean_absolute_error: 0.7751 - val_loss: 3075.6499 - val_mean_absolute_error: 55.3394\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8580 - mean_absolute_error: 0.8203 - val_loss: 3053.5518 - val_mean_absolute_error: 55.1357\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7386 - mean_absolute_error: 0.8066 - val_loss: 3015.8525 - val_mean_absolute_error: 54.7921\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 675ms/step - loss: 6.3769 - mean_absolute_error: 2.0779 - val_loss: 3172.8171 - val_mean_absolute_error: 56.2595\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.8433 - mean_absolute_error: 1.2584 - val_loss: 2992.2642 - val_mean_absolute_error: 54.6493\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6264 - mean_absolute_error: 1.0025 - val_loss: 2867.7744 - val_mean_absolute_error: 53.5048\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5888 - mean_absolute_error: 1.3860 - val_loss: 2952.3433 - val_mean_absolute_error: 54.2780\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.4728 - mean_absolute_error: 1.0137 - val_loss: 3043.1204 - val_mean_absolute_error: 55.0975\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2574 - mean_absolute_error: 0.7554 - val_loss: 3085.0623 - val_mean_absolute_error: 55.4694\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.4074 - mean_absolute_error: 0.8206 - val_loss: 3078.3669 - val_mean_absolute_error: 55.4039\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2503 - mean_absolute_error: 0.7916 - val_loss: 3034.4775 - val_mean_absolute_error: 55.0035\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9432 - mean_absolute_error: 0.6532 - val_loss: 2973.8018 - val_mean_absolute_error: 54.4451\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9178 - mean_absolute_error: 0.8782 - val_loss: 2944.8079 - val_mean_absolute_error: 54.1723\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0418 - mean_absolute_error: 0.9838 - val_loss: 2971.9106 - val_mean_absolute_error: 54.4152\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8464 - mean_absolute_error: 0.8512 - val_loss: 3021.2305 - val_mean_absolute_error: 54.8629\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7196 - mean_absolute_error: 0.7517 - val_loss: 3058.8489 - val_mean_absolute_error: 55.2046\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 619ms/step - loss: 5.4573 - mean_absolute_error: 1.9629 - val_loss: 3184.3765 - val_mean_absolute_error: 56.3615\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6063 - mean_absolute_error: 0.6544 - val_loss: 3046.9626 - val_mean_absolute_error: 55.1437\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2898 - mean_absolute_error: 1.0084 - val_loss: 3103.7183 - val_mean_absolute_error: 55.6521\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4383 - mean_absolute_error: 0.5061 - val_loss: 3169.2913 - val_mean_absolute_error: 56.2311\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3894 - mean_absolute_error: 0.5209 - val_loss: 3185.1606 - val_mean_absolute_error: 56.3709\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4971 - mean_absolute_error: 0.6209 - val_loss: 3162.3274 - val_mean_absolute_error: 56.1706\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3160 - mean_absolute_error: 0.4535 - val_loss: 3130.1216 - val_mean_absolute_error: 55.8866\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2629 - mean_absolute_error: 0.4352 - val_loss: 3110.9255 - val_mean_absolute_error: 55.7169\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3330 - mean_absolute_error: 0.4087 - val_loss: 3120.1064 - val_mean_absolute_error: 55.7987\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2598 - mean_absolute_error: 0.3792 - val_loss: 3144.2246 - val_mean_absolute_error: 56.0124\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1867 - mean_absolute_error: 0.3613 - val_loss: 3163.6772 - val_mean_absolute_error: 56.1841\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2139 - mean_absolute_error: 0.4183 - val_loss: 3164.3850 - val_mean_absolute_error: 56.1911\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 622ms/step - loss: 6.6032 - mean_absolute_error: 2.1247 - val_loss: 3095.1333 - val_mean_absolute_error: 55.5742\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0996 - mean_absolute_error: 0.9238 - val_loss: 2973.5205 - val_mean_absolute_error: 54.4719\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.9436 - mean_absolute_error: 1.5164 - val_loss: 3077.0220 - val_mean_absolute_error: 55.3979\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5255 - mean_absolute_error: 0.8640 - val_loss: 3137.9102 - val_mean_absolute_error: 55.9331\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.6932 - mean_absolute_error: 0.8302 - val_loss: 3109.0103 - val_mean_absolute_error: 55.6703\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3335 - mean_absolute_error: 0.7901 - val_loss: 3033.9326 - val_mean_absolute_error: 54.9904\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1457 - mean_absolute_error: 0.9170 - val_loss: 3011.9268 - val_mean_absolute_error: 54.7793\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0531 - mean_absolute_error: 0.9576 - val_loss: 3052.5818 - val_mean_absolute_error: 55.1340\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7101 - mean_absolute_error: 0.7082 - val_loss: 3080.2664 - val_mean_absolute_error: 55.3691\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7239 - mean_absolute_error: 0.7700 - val_loss: 3054.0574 - val_mean_absolute_error: 55.1167\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5719 - mean_absolute_error: 0.6885 - val_loss: 3002.9360 - val_mean_absolute_error: 54.6378\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6255 - mean_absolute_error: 0.6433 - val_loss: 3019.2642 - val_mean_absolute_error: 54.7845\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.3327 - mean_absolute_error: 2.0713 - val_loss: 3145.6689 - val_mean_absolute_error: 56.0191\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.2392 - mean_absolute_error: 0.9410 - val_loss: 2961.6831 - val_mean_absolute_error: 54.3662\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4496 - mean_absolute_error: 1.6514 - val_loss: 3043.0542 - val_mean_absolute_error: 55.0973\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8843 - mean_absolute_error: 1.1188 - val_loss: 3123.9194 - val_mean_absolute_error: 55.8160\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7263 - mean_absolute_error: 0.8483 - val_loss: 3149.9133 - val_mean_absolute_error: 56.0410\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8869 - mean_absolute_error: 0.9333 - val_loss: 3127.7720 - val_mean_absolute_error: 55.8408\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5751 - mean_absolute_error: 0.8468 - val_loss: 3074.3823 - val_mean_absolute_error: 55.3599\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2560 - mean_absolute_error: 0.8142 - val_loss: 3017.1533 - val_mean_absolute_error: 54.8371\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3983 - mean_absolute_error: 1.1030 - val_loss: 3014.6948 - val_mean_absolute_error: 54.8065\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3091 - mean_absolute_error: 1.0714 - val_loss: 3054.3745 - val_mean_absolute_error: 55.1589\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0364 - mean_absolute_error: 0.8047 - val_loss: 3089.6404 - val_mean_absolute_error: 55.4714\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0660 - mean_absolute_error: 0.8573 - val_loss: 3102.0615 - val_mean_absolute_error: 55.5782\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 634ms/step - loss: 3.3363 - mean_absolute_error: 1.3842 - val_loss: 2902.7778 - val_mean_absolute_error: 53.8411\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2394 - mean_absolute_error: 1.3817 - val_loss: 3009.1221 - val_mean_absolute_error: 54.8040\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7347 - mean_absolute_error: 1.0313 - val_loss: 3103.6357 - val_mean_absolute_error: 55.6433\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8307 - mean_absolute_error: 0.9008 - val_loss: 3084.5635 - val_mean_absolute_error: 55.4686\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5666 - mean_absolute_error: 0.8368 - val_loss: 3006.4607 - val_mean_absolute_error: 54.7643\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2268 - mean_absolute_error: 0.8417 - val_loss: 2941.4443 - val_mean_absolute_error: 54.1671\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3485 - mean_absolute_error: 1.0534 - val_loss: 2970.0178 - val_mean_absolute_error: 54.4196\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0337 - mean_absolute_error: 0.9061 - val_loss: 3025.6599 - val_mean_absolute_error: 54.9155\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8957 - mean_absolute_error: 0.7193 - val_loss: 3054.4595 - val_mean_absolute_error: 55.1678\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9365 - mean_absolute_error: 0.7824 - val_loss: 3037.5278 - val_mean_absolute_error: 55.0083\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8121 - mean_absolute_error: 0.8005 - val_loss: 2994.2842 - val_mean_absolute_error: 54.6097\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 642ms/step - loss: 6.1141 - mean_absolute_error: 2.0194 - val_loss: 3080.7529 - val_mean_absolute_error: 55.4450\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8479 - mean_absolute_error: 0.8376 - val_loss: 2851.3311 - val_mean_absolute_error: 53.3530\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2513 - mean_absolute_error: 1.5197 - val_loss: 2969.4006 - val_mean_absolute_error: 54.4344\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5464 - mean_absolute_error: 0.9870 - val_loss: 3090.4678 - val_mean_absolute_error: 55.5231\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6302 - mean_absolute_error: 0.8440 - val_loss: 3107.8506 - val_mean_absolute_error: 55.6757\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7467 - mean_absolute_error: 0.9093 - val_loss: 3062.3916 - val_mean_absolute_error: 55.2655\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3013 - mean_absolute_error: 0.7532 - val_loss: 2988.5229 - val_mean_absolute_error: 54.5941\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1273 - mean_absolute_error: 0.8798 - val_loss: 2944.6406 - val_mean_absolute_error: 54.1893\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3158 - mean_absolute_error: 1.0691 - val_loss: 2972.5686 - val_mean_absolute_error: 54.4389\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0402 - mean_absolute_error: 0.9326 - val_loss: 3022.9561 - val_mean_absolute_error: 54.8946\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8904 - mean_absolute_error: 0.7020 - val_loss: 3055.5371 - val_mean_absolute_error: 55.1869\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9366 - mean_absolute_error: 0.6998 - val_loss: 3057.8062 - val_mean_absolute_error: 55.2032\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 3.9022 - mean_absolute_error: 1.5551 - val_loss: 2678.7075 - val_mean_absolute_error: 51.7366\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 26.9911 - mean_absolute_error: 4.6819 - val_loss: 2951.5522 - val_mean_absolute_error: 54.2869\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9702 - mean_absolute_error: 1.7793 - val_loss: 3246.4619 - val_mean_absolute_error: 56.9053\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.1843 - mean_absolute_error: 1.2209 - val_loss: 3391.6826 - val_mean_absolute_error: 58.1508\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.8355 - mean_absolute_error: 2.5297 - val_loss: 3376.0515 - val_mean_absolute_error: 58.0197\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.7893 - mean_absolute_error: 2.3777 - val_loss: 3274.3042 - val_mean_absolute_error: 57.1512\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7833 - mean_absolute_error: 1.3685 - val_loss: 3146.2539 - val_mean_absolute_error: 56.0370\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2124 - mean_absolute_error: 0.4051 - val_loss: 3037.3372 - val_mean_absolute_error: 55.0704\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3690 - mean_absolute_error: 1.0138 - val_loss: 2978.8076 - val_mean_absolute_error: 54.5433\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3319 - mean_absolute_error: 1.6118 - val_loss: 2975.1963 - val_mean_absolute_error: 54.5111\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5363 - mean_absolute_error: 1.6564 - val_loss: 3015.7954 - val_mean_absolute_error: 54.8782\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 7.6571 - mean_absolute_error: 2.3114 - val_loss: 2872.3086 - val_mean_absolute_error: 53.5391\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6.3320 - mean_absolute_error: 2.1933 - val_loss: 2912.2056 - val_mean_absolute_error: 53.8929\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9861 - mean_absolute_error: 1.8079 - val_loss: 3068.3936 - val_mean_absolute_error: 55.2930\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9344 - mean_absolute_error: 0.7845 - val_loss: 3188.1240 - val_mean_absolute_error: 56.3412\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2055 - mean_absolute_error: 1.2170 - val_loss: 3208.3772 - val_mean_absolute_error: 56.5138\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.5817 - mean_absolute_error: 1.3106 - val_loss: 3151.4722 - val_mean_absolute_error: 56.0139\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3575 - mean_absolute_error: 1.0067 - val_loss: 3062.7834 - val_mean_absolute_error: 55.2272\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6414 - mean_absolute_error: 0.6955 - val_loss: 2987.2231 - val_mean_absolute_error: 54.5470\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1926 - mean_absolute_error: 1.0617 - val_loss: 2963.3347 - val_mean_absolute_error: 54.3277\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4505 - mean_absolute_error: 1.1513 - val_loss: 2986.0249 - val_mean_absolute_error: 54.5290\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9507 - mean_absolute_error: 0.9512 - val_loss: 3036.4167 - val_mean_absolute_error: 54.9786\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 538ms/step - loss: 14.0091 - mean_absolute_error: 3.2290 - val_loss: 2916.2319 - val_mean_absolute_error: 53.9695\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.6939 - mean_absolute_error: 2.0535 - val_loss: 2838.7380 - val_mean_absolute_error: 53.2426\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.9013 - mean_absolute_error: 2.4132 - val_loss: 2938.3491 - val_mean_absolute_error: 54.1521\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4064 - mean_absolute_error: 1.6970 - val_loss: 3077.0439 - val_mean_absolute_error: 55.3920\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2992 - mean_absolute_error: 0.7900 - val_loss: 3185.7939 - val_mean_absolute_error: 56.3404\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.3458 - mean_absolute_error: 1.2596 - val_loss: 3224.2246 - val_mean_absolute_error: 56.6663\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2120 - mean_absolute_error: 1.4986 - val_loss: 3190.8948 - val_mean_absolute_error: 56.3708\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.3961 - mean_absolute_error: 1.3540 - val_loss: 3115.4709 - val_mean_absolute_error: 55.7045\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1859 - mean_absolute_error: 0.9554 - val_loss: 3028.6995 - val_mean_absolute_error: 54.9296\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1134 - mean_absolute_error: 0.9682 - val_loss: 2973.1597 - val_mean_absolute_error: 54.4289\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8306 - mean_absolute_error: 1.3016 - val_loss: 2974.8281 - val_mean_absolute_error: 54.4453\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8040 - mean_absolute_error: 1.2921 - val_loss: 3018.9763 - val_mean_absolute_error: 54.8464\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 539ms/step - loss: 9.0665 - mean_absolute_error: 2.4012 - val_loss: 2780.8369 - val_mean_absolute_error: 52.6612\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 5.3640 - mean_absolute_error: 1.9470 - val_loss: 2773.2205 - val_mean_absolute_error: 52.5808\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.4842 - mean_absolute_error: 1.9621 - val_loss: 2941.6812 - val_mean_absolute_error: 54.1368\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3958 - mean_absolute_error: 1.1436 - val_loss: 3117.8501 - val_mean_absolute_error: 55.7164\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4604 - mean_absolute_error: 0.9094 - val_loss: 3208.4761 - val_mean_absolute_error: 56.5115\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.9643 - mean_absolute_error: 1.2336 - val_loss: 3197.3298 - val_mean_absolute_error: 56.4146\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.6177 - mean_absolute_error: 1.1501 - val_loss: 3125.1650 - val_mean_absolute_error: 55.7822\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3678 - mean_absolute_error: 0.8554 - val_loss: 3032.8125 - val_mean_absolute_error: 54.9607\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8268 - mean_absolute_error: 0.7219 - val_loss: 2955.8586 - val_mean_absolute_error: 54.2654\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2012 - mean_absolute_error: 1.0554 - val_loss: 2920.4927 - val_mean_absolute_error: 53.9431\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6572 - mean_absolute_error: 1.2190 - val_loss: 2929.1367 - val_mean_absolute_error: 54.0233\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5346 - mean_absolute_error: 1.1770 - val_loss: 2972.7207 - val_mean_absolute_error: 54.4213\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 540ms/step - loss: 14.9537 - mean_absolute_error: 3.3586 - val_loss: 2917.4343 - val_mean_absolute_error: 53.9870\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1780 - mean_absolute_error: 1.3966 - val_loss: 2701.2832 - val_mean_absolute_error: 51.9568\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 7.7369 - mean_absolute_error: 2.1229 - val_loss: 2770.2930 - val_mean_absolute_error: 52.6063\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.1433 - mean_absolute_error: 1.7983 - val_loss: 2921.4927 - val_mean_absolute_error: 54.0035\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9250 - mean_absolute_error: 1.1355 - val_loss: 3074.2715 - val_mean_absolute_error: 55.3766\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3386 - mean_absolute_error: 0.7605 - val_loss: 3176.6060 - val_mean_absolute_error: 56.2733\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.3465 - mean_absolute_error: 1.1461 - val_loss: 3200.0073 - val_mean_absolute_error: 56.4715\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.6855 - mean_absolute_error: 1.2384 - val_loss: 3157.1709 - val_mean_absolute_error: 56.0928\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9170 - mean_absolute_error: 1.0027 - val_loss: 3080.2600 - val_mean_absolute_error: 55.4112\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0416 - mean_absolute_error: 0.7451 - val_loss: 2989.8647 - val_mean_absolute_error: 54.6001\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8303 - mean_absolute_error: 0.7644 - val_loss: 2917.7344 - val_mean_absolute_error: 53.9441\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2604 - mean_absolute_error: 1.0550 - val_loss: 2892.6377 - val_mean_absolute_error: 53.7126\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 538ms/step - loss: 2.3473 - mean_absolute_error: 1.1964 - val_loss: 3731.1836 - val_mean_absolute_error: 60.9563\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 36.4790 - mean_absolute_error: 5.2968 - val_loss: 3318.2224 - val_mean_absolute_error: 57.5281\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5522 - mean_absolute_error: 1.5396 - val_loss: 2946.2524 - val_mean_absolute_error: 54.2430\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.5526 - mean_absolute_error: 2.1237 - val_loss: 2841.8210 - val_mean_absolute_error: 53.2803\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 12.1996 - mean_absolute_error: 3.1600 - val_loss: 2907.3130 - val_mean_absolute_error: 53.8848\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 7.5582 - mean_absolute_error: 2.4919 - val_loss: 3040.0349 - val_mean_absolute_error: 55.0871\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7891 - mean_absolute_error: 1.2070 - val_loss: 3173.7026 - val_mean_absolute_error: 56.2696\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2202 - mean_absolute_error: 0.4021 - val_loss: 3265.7729 - val_mean_absolute_error: 57.0709\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6100 - mean_absolute_error: 1.0685 - val_loss: 3309.4541 - val_mean_absolute_error: 57.4490\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.8440 - mean_absolute_error: 1.3874 - val_loss: 3307.8877 - val_mean_absolute_error: 57.4379\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7103 - mean_absolute_error: 1.3606 - val_loss: 3269.1921 - val_mean_absolute_error: 57.1076\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5718 - mean_absolute_error: 1.0401 - val_loss: 3208.2358 - val_mean_absolute_error: 56.5814\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5443 - mean_absolute_error: 0.6271 - val_loss: 3141.9834 - val_mean_absolute_error: 56.0028\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2912 - mean_absolute_error: 0.5163 - val_loss: 3089.1758 - val_mean_absolute_error: 55.5366\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.4766 - mean_absolute_error: 1.7895 - val_loss: 2644.2700 - val_mean_absolute_error: 51.3927\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 20.9903 - mean_absolute_error: 3.5377 - val_loss: 2885.3179 - val_mean_absolute_error: 53.6529\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6500 - mean_absolute_error: 1.8475 - val_loss: 3160.7217 - val_mean_absolute_error: 56.1183\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.1601 - mean_absolute_error: 1.1045 - val_loss: 3298.2925 - val_mean_absolute_error: 57.3020\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.5093 - mean_absolute_error: 2.1288 - val_loss: 3282.8401 - val_mean_absolute_error: 57.1620\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.9671 - mean_absolute_error: 2.0367 - val_loss: 3178.0598 - val_mean_absolute_error: 56.2472\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.4541 - mean_absolute_error: 1.2817 - val_loss: 3043.1514 - val_mean_absolute_error: 55.0504\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6676 - mean_absolute_error: 0.6071 - val_loss: 2931.1104 - val_mean_absolute_error: 54.0339\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.7328 - mean_absolute_error: 1.2678 - val_loss: 2879.3906 - val_mean_absolute_error: 53.5559\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.0309 - mean_absolute_error: 1.5796 - val_loss: 2886.1484 - val_mean_absolute_error: 53.6142\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.6713 - mean_absolute_error: 1.4944 - val_loss: 2933.0085 - val_mean_absolute_error: 54.0392\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 3.7096 - mean_absolute_error: 1.4115 - val_loss: 2709.2634 - val_mean_absolute_error: 52.0069\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 15.0423 - mean_absolute_error: 3.1764 - val_loss: 2942.3503 - val_mean_absolute_error: 54.1800\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3664 - mean_absolute_error: 1.6747 - val_loss: 3185.2393 - val_mean_absolute_error: 56.3548\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.4879 - mean_absolute_error: 1.1250 - val_loss: 3299.3655 - val_mean_absolute_error: 57.3443\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.5693 - mean_absolute_error: 1.9345 - val_loss: 3285.5801 - val_mean_absolute_error: 57.2217\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.9426 - mean_absolute_error: 1.8067 - val_loss: 3204.4863 - val_mean_absolute_error: 56.5133\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6126 - mean_absolute_error: 1.2363 - val_loss: 3106.8613 - val_mean_absolute_error: 55.6497\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2898 - mean_absolute_error: 0.8460 - val_loss: 3020.0681 - val_mean_absolute_error: 54.8702\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5757 - mean_absolute_error: 1.1497 - val_loss: 2969.9580 - val_mean_absolute_error: 54.4150\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.3768 - mean_absolute_error: 1.4469 - val_loss: 2963.1938 - val_mean_absolute_error: 54.3509\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4148 - mean_absolute_error: 1.4590 - val_loss: 2994.0657 - val_mean_absolute_error: 54.6299\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 5.0250 - mean_absolute_error: 1.8157 - val_loss: 2640.2373 - val_mean_absolute_error: 51.3563\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 13.4663 - mean_absolute_error: 2.6960 - val_loss: 2855.4175 - val_mean_absolute_error: 53.3824\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6637 - mean_absolute_error: 1.6025 - val_loss: 3136.2129 - val_mean_absolute_error: 55.9057\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.7459 - mean_absolute_error: 0.9851 - val_loss: 3280.9116 - val_mean_absolute_error: 57.1508\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 4.9035 - mean_absolute_error: 1.6914 - val_loss: 3258.4775 - val_mean_absolute_error: 56.9467\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1606 - mean_absolute_error: 1.5149 - val_loss: 3140.0610 - val_mean_absolute_error: 55.9098\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5768 - mean_absolute_error: 0.9458 - val_loss: 2993.0288 - val_mean_absolute_error: 54.6011\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8846 - mean_absolute_error: 0.8776 - val_loss: 2889.7998 - val_mean_absolute_error: 53.6630\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.1396 - mean_absolute_error: 1.3605 - val_loss: 2865.9766 - val_mean_absolute_error: 53.4443\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6605 - mean_absolute_error: 1.4732 - val_loss: 2907.0813 - val_mean_absolute_error: 53.8221\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8296 - mean_absolute_error: 1.2757 - val_loss: 2982.9097 - val_mean_absolute_error: 54.5116\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 540ms/step - loss: 10.8954 - mean_absolute_error: 2.7604 - val_loss: 2830.4709 - val_mean_absolute_error: 53.1742\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5673 - mean_absolute_error: 1.5183 - val_loss: 2710.2529 - val_mean_absolute_error: 52.0383\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.6227 - mean_absolute_error: 2.0375 - val_loss: 2810.1663 - val_mean_absolute_error: 52.9776\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3934 - mean_absolute_error: 1.5550 - val_loss: 2972.6216 - val_mean_absolute_error: 54.4685\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3295 - mean_absolute_error: 0.8933 - val_loss: 3115.6763 - val_mean_absolute_error: 55.7429\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0842 - mean_absolute_error: 1.0814 - val_loss: 3181.3857 - val_mean_absolute_error: 56.3129\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1113 - mean_absolute_error: 1.3342 - val_loss: 3169.2505 - val_mean_absolute_error: 56.2006\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.7806 - mean_absolute_error: 1.2312 - val_loss: 3105.6489 - val_mean_absolute_error: 55.6360\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7003 - mean_absolute_error: 0.9910 - val_loss: 3019.7195 - val_mean_absolute_error: 54.8664\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0166 - mean_absolute_error: 0.7352 - val_loss: 2937.5339 - val_mean_absolute_error: 54.1193\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1828 - mean_absolute_error: 1.0220 - val_loss: 2883.5566 - val_mean_absolute_error: 53.6216\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7636 - mean_absolute_error: 1.2652 - val_loss: 2876.8018 - val_mean_absolute_error: 53.5584\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 575ms/step - loss: 2.8511 - mean_absolute_error: 1.3359 - val_loss: 2573.9292 - val_mean_absolute_error: 50.7038\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 40.3266 - mean_absolute_error: 5.9276 - val_loss: 2944.2241 - val_mean_absolute_error: 54.2050\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.7541 - mean_absolute_error: 2.0629 - val_loss: 3275.1123 - val_mean_absolute_error: 57.1484\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.3449 - mean_absolute_error: 1.2554 - val_loss: 3403.0962 - val_mean_absolute_error: 58.2481\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.0570 - mean_absolute_error: 2.4288 - val_loss: 3386.4771 - val_mean_absolute_error: 58.1109\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 7.3416 - mean_absolute_error: 2.3167 - val_loss: 3313.6113 - val_mean_absolute_error: 57.4875\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8989 - mean_absolute_error: 1.6315 - val_loss: 3223.0312 - val_mean_absolute_error: 56.7027\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1449 - mean_absolute_error: 0.9406 - val_loss: 3131.6777 - val_mean_absolute_error: 55.9017\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2477 - mean_absolute_error: 0.4264 - val_loss: 3064.2881 - val_mean_absolute_error: 55.3016\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7477 - mean_absolute_error: 0.7645 - val_loss: 3030.5396 - val_mean_absolute_error: 54.9984\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3484 - mean_absolute_error: 1.0790 - val_loss: 3031.1250 - val_mean_absolute_error: 55.0039\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 7.5935 - mean_absolute_error: 2.3192 - val_loss: 2912.5825 - val_mean_absolute_error: 53.9269\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 5.2657 - mean_absolute_error: 1.9853 - val_loss: 2950.2200 - val_mean_absolute_error: 54.2670\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5935 - mean_absolute_error: 1.6710 - val_loss: 3049.6958 - val_mean_absolute_error: 55.1612\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6556 - mean_absolute_error: 0.9784 - val_loss: 3130.9766 - val_mean_absolute_error: 55.8792\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6410 - mean_absolute_error: 0.7804 - val_loss: 3161.6536 - val_mean_absolute_error: 56.1425\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9091 - mean_absolute_error: 1.0011 - val_loss: 3139.5630 - val_mean_absolute_error: 55.9412\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5072 - mean_absolute_error: 0.8592 - val_loss: 3082.4714 - val_mean_absolute_error: 55.4288\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0475 - mean_absolute_error: 0.7194 - val_loss: 3021.0908 - val_mean_absolute_error: 54.8721\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2289 - mean_absolute_error: 1.0321 - val_loss: 3011.2427 - val_mean_absolute_error: 54.7763\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1781 - mean_absolute_error: 1.0420 - val_loss: 3041.1514 - val_mean_absolute_error: 55.0384\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7850 - mean_absolute_error: 0.7908 - val_loss: 3080.7539 - val_mean_absolute_error: 55.3864\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 13.6852 - mean_absolute_error: 3.1720 - val_loss: 2904.1587 - val_mean_absolute_error: 53.8542\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.9001 - mean_absolute_error: 2.0713 - val_loss: 2898.6990 - val_mean_absolute_error: 53.7942\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.5684 - mean_absolute_error: 2.0535 - val_loss: 3003.5164 - val_mean_absolute_error: 54.7406\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2860 - mean_absolute_error: 1.3500 - val_loss: 3118.4250 - val_mean_absolute_error: 55.7605\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4055 - mean_absolute_error: 0.8247 - val_loss: 3186.0923 - val_mean_absolute_error: 56.3508\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.1324 - mean_absolute_error: 1.1259 - val_loss: 3189.0371 - val_mean_absolute_error: 56.3727\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.1478 - mean_absolute_error: 1.1681 - val_loss: 3145.6133 - val_mean_absolute_error: 55.9882\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4485 - mean_absolute_error: 0.9703 - val_loss: 3085.5942 - val_mean_absolute_error: 55.4519\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0080 - mean_absolute_error: 0.7951 - val_loss: 3026.1147 - val_mean_absolute_error: 54.9160\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1566 - mean_absolute_error: 0.9873 - val_loss: 2999.3088 - val_mean_absolute_error: 54.6698\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4063 - mean_absolute_error: 1.1347 - val_loss: 3010.5552 - val_mean_absolute_error: 54.7684\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1967 - mean_absolute_error: 1.0333 - val_loss: 3044.0742 - val_mean_absolute_error: 55.0687\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 5.3346 - mean_absolute_error: 1.8639 - val_loss: 2874.9438 - val_mean_absolute_error: 53.5839\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1465 - mean_absolute_error: 1.5501 - val_loss: 2930.5935 - val_mean_absolute_error: 54.0830\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.1267 - mean_absolute_error: 1.2013 - val_loss: 3025.4829 - val_mean_absolute_error: 54.9330\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1020 - mean_absolute_error: 0.7360 - val_loss: 3084.2061 - val_mean_absolute_error: 55.4452\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2252 - mean_absolute_error: 0.8026 - val_loss: 3068.1204 - val_mean_absolute_error: 55.2923\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0551 - mean_absolute_error: 0.7848 - val_loss: 3011.7246 - val_mean_absolute_error: 54.7797\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8107 - mean_absolute_error: 0.7363 - val_loss: 2956.6924 - val_mean_absolute_error: 54.2762\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9815 - mean_absolute_error: 0.9603 - val_loss: 2965.3628 - val_mean_absolute_error: 54.3515\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8878 - mean_absolute_error: 0.9003 - val_loss: 3015.1167 - val_mean_absolute_error: 54.8001\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7188 - mean_absolute_error: 0.7827 - val_loss: 3062.4248 - val_mean_absolute_error: 55.2261\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7910 - mean_absolute_error: 0.8137 - val_loss: 3071.6299 - val_mean_absolute_error: 55.3104\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 1.9893 - mean_absolute_error: 0.9060 - val_loss: 2693.1594 - val_mean_absolute_error: 51.8437\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 7.4004 - mean_absolute_error: 2.1844 - val_loss: 3080.4980 - val_mean_absolute_error: 55.4121\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2520 - mean_absolute_error: 0.8191 - val_loss: 3252.2671 - val_mean_absolute_error: 56.9253\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9784 - mean_absolute_error: 1.5695 - val_loss: 3207.1206 - val_mean_absolute_error: 56.5366\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.8951 - mean_absolute_error: 1.3117 - val_loss: 3074.0112 - val_mean_absolute_error: 55.3646\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2264 - mean_absolute_error: 0.7377 - val_loss: 2940.2646 - val_mean_absolute_error: 54.1581\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5097 - mean_absolute_error: 1.0865 - val_loss: 2888.6016 - val_mean_absolute_error: 53.6824\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.0402 - mean_absolute_error: 1.2869 - val_loss: 2922.2158 - val_mean_absolute_error: 53.9855\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4692 - mean_absolute_error: 1.1242 - val_loss: 2993.8892 - val_mean_absolute_error: 54.6322\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8566 - mean_absolute_error: 0.7891 - val_loss: 3064.0581 - val_mean_absolute_error: 55.2557\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8598 - mean_absolute_error: 0.7015 - val_loss: 3103.9788 - val_mean_absolute_error: 55.6047\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.3925 - mean_absolute_error: 1.1820 - val_loss: 3889.8711 - val_mean_absolute_error: 62.2216\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 56.9233 - mean_absolute_error: 6.7240 - val_loss: 3385.5215 - val_mean_absolute_error: 58.1039\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.9004 - mean_absolute_error: 2.1070 - val_loss: 2930.2451 - val_mean_absolute_error: 54.0993\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.3933 - mean_absolute_error: 2.3635 - val_loss: 2765.9390 - val_mean_absolute_error: 52.5722\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 20.8922 - mean_absolute_error: 4.0542 - val_loss: 2825.9492 - val_mean_absolute_error: 53.1355\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 15.2421 - mean_absolute_error: 3.4555 - val_loss: 2974.2808 - val_mean_absolute_error: 54.5017\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4414 - mean_absolute_error: 1.8519 - val_loss: 3144.5442 - val_mean_absolute_error: 56.0250\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1846 - mean_absolute_error: 0.4052 - val_loss: 3281.0732 - val_mean_absolute_error: 57.2172\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.9833 - mean_absolute_error: 1.2071 - val_loss: 3357.6572 - val_mean_absolute_error: 57.8743\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.9684 - mean_absolute_error: 1.9641 - val_loss: 3370.2471 - val_mean_absolute_error: 57.9812\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.7009 - mean_absolute_error: 2.1081 - val_loss: 3334.5679 - val_mean_absolute_error: 57.6760\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1239 - mean_absolute_error: 1.7769 - val_loss: 3268.0737 - val_mean_absolute_error: 57.1030\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8088 - mean_absolute_error: 1.1380 - val_loss: 3185.3301 - val_mean_absolute_error: 56.3814\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2378 - mean_absolute_error: 0.4684 - val_loss: 3101.1052 - val_mean_absolute_error: 55.6384\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 539ms/step - loss: 2.9150 - mean_absolute_error: 1.2213 - val_loss: 3504.7478 - val_mean_absolute_error: 59.0624\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 17.0698 - mean_absolute_error: 3.4574 - val_loss: 3106.8425 - val_mean_absolute_error: 55.6376\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0630 - mean_absolute_error: 0.7549 - val_loss: 2787.2610 - val_mean_absolute_error: 52.7240\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.5714 - mean_absolute_error: 2.4396 - val_loss: 2803.0852 - val_mean_absolute_error: 52.8701\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.2494 - mean_absolute_error: 2.2727 - val_loss: 2937.2539 - val_mean_absolute_error: 54.1045\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0935 - mean_absolute_error: 1.3801 - val_loss: 3092.4414 - val_mean_absolute_error: 55.4980\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8401 - mean_absolute_error: 0.7445 - val_loss: 3200.1106 - val_mean_absolute_error: 56.4424\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 2.6457 - mean_absolute_error: 1.3676 - val_loss: 3228.3477 - val_mean_absolute_error: 56.6841\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5253 - mean_absolute_error: 1.5854 - val_loss: 3192.2441 - val_mean_absolute_error: 56.3680\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.4724 - mean_absolute_error: 1.3191 - val_loss: 3119.9526 - val_mean_absolute_error: 55.7295\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0329 - mean_absolute_error: 0.9236 - val_loss: 3038.0015 - val_mean_absolute_error: 54.9966\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5142 - mean_absolute_error: 0.6005 - val_loss: 2970.1157 - val_mean_absolute_error: 54.3823\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0712 - mean_absolute_error: 1.0162 - val_loss: 2935.0996 - val_mean_absolute_error: 54.0616\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 7.9419 - mean_absolute_error: 2.3277 - val_loss: 2684.3198 - val_mean_absolute_error: 51.7895\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 17.9997 - mean_absolute_error: 3.4496 - val_loss: 2867.0879 - val_mean_absolute_error: 53.4982\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.9267 - mean_absolute_error: 2.1705 - val_loss: 3100.9731 - val_mean_absolute_error: 55.6005\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7643 - mean_absolute_error: 0.8803 - val_loss: 3245.3782 - val_mean_absolute_error: 56.8497\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.7993 - mean_absolute_error: 1.7488 - val_loss: 3259.4167 - val_mean_absolute_error: 56.9585\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.4767 - mean_absolute_error: 1.8984 - val_loss: 3180.4429 - val_mean_absolute_error: 56.2662\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.9425 - mean_absolute_error: 1.5045 - val_loss: 3058.2471 - val_mean_absolute_error: 55.1853\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1656 - mean_absolute_error: 0.8537 - val_loss: 2945.2957 - val_mean_absolute_error: 54.1669\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0315 - mean_absolute_error: 1.3732 - val_loss: 2904.9028 - val_mean_absolute_error: 53.7988\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.9467 - mean_absolute_error: 1.6199 - val_loss: 2930.9753 - val_mean_absolute_error: 54.0392\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2499 - mean_absolute_error: 1.4382 - val_loss: 2995.3467 - val_mean_absolute_error: 54.6245\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 540ms/step - loss: 6.6934 - mean_absolute_error: 2.1356 - val_loss: 2775.7952 - val_mean_absolute_error: 52.6398\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.6755 - mean_absolute_error: 1.9459 - val_loss: 2830.1775 - val_mean_absolute_error: 53.1412\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8507 - mean_absolute_error: 1.6827 - val_loss: 2983.8853 - val_mean_absolute_error: 54.5488\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2276 - mean_absolute_error: 0.9399 - val_loss: 3118.8713 - val_mean_absolute_error: 55.7529\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5428 - mean_absolute_error: 0.9266 - val_loss: 3169.4709 - val_mean_absolute_error: 56.1917\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.1575 - mean_absolute_error: 1.0935 - val_loss: 3135.4766 - val_mean_absolute_error: 55.8860\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5793 - mean_absolute_error: 0.9581 - val_loss: 3056.7578 - val_mean_absolute_error: 55.1816\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8818 - mean_absolute_error: 0.7652 - val_loss: 2974.0178 - val_mean_absolute_error: 54.4325\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9693 - mean_absolute_error: 0.9454 - val_loss: 2933.1782 - val_mean_absolute_error: 54.0570\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3465 - mean_absolute_error: 1.1300 - val_loss: 2943.7439 - val_mean_absolute_error: 54.1517\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1954 - mean_absolute_error: 1.0674 - val_loss: 2988.4592 - val_mean_absolute_error: 54.5578\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 1.7605 - mean_absolute_error: 0.8947 - val_loss: 2406.6406 - val_mean_absolute_error: 49.0364\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 20.9084 - mean_absolute_error: 3.6397 - val_loss: 2931.9880 - val_mean_absolute_error: 54.0756\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1024 - mean_absolute_error: 0.8840 - val_loss: 3377.5195 - val_mean_absolute_error: 57.9924\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 10.3280 - mean_absolute_error: 2.4680 - val_loss: 3387.5938 - val_mean_absolute_error: 58.0811\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.9516 - mean_absolute_error: 2.4702 - val_loss: 3214.7300 - val_mean_absolute_error: 56.5972\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9281 - mean_absolute_error: 1.4586 - val_loss: 2994.8491 - val_mean_absolute_error: 54.6493\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0805 - mean_absolute_error: 0.7312 - val_loss: 2818.1067 - val_mean_absolute_error: 53.0294\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.7500 - mean_absolute_error: 1.4959 - val_loss: 2743.5273 - val_mean_absolute_error: 52.3303\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6189 - mean_absolute_error: 1.8264 - val_loss: 2764.4392 - val_mean_absolute_error: 52.5278\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0845 - mean_absolute_error: 1.7380 - val_loss: 2847.9482 - val_mean_absolute_error: 53.3076\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.2826 - mean_absolute_error: 1.3789 - val_loss: 2960.4116 - val_mean_absolute_error: 54.3391\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 650ms/step - loss: 1.9667 - mean_absolute_error: 1.1468 - val_loss: 2894.3862 - val_mean_absolute_error: 53.7532\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.6696 - mean_absolute_error: 2.5481 - val_loss: 3074.8701 - val_mean_absolute_error: 55.3904\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8469 - mean_absolute_error: 0.7359 - val_loss: 3201.3433 - val_mean_absolute_error: 56.5100\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7876 - mean_absolute_error: 0.7543 - val_loss: 3236.9673 - val_mean_absolute_error: 56.8207\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3514 - mean_absolute_error: 0.9932 - val_loss: 3223.3408 - val_mean_absolute_error: 56.7025\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0555 - mean_absolute_error: 0.8927 - val_loss: 3185.5337 - val_mean_absolute_error: 56.3731\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5010 - mean_absolute_error: 0.6086 - val_loss: 3137.2998 - val_mean_absolute_error: 55.9499\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3054 - mean_absolute_error: 0.4896 - val_loss: 3102.3210 - val_mean_absolute_error: 55.6398\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4689 - mean_absolute_error: 0.5254 - val_loss: 3098.5552 - val_mean_absolute_error: 55.6076\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4916 - mean_absolute_error: 0.5137 - val_loss: 3119.0522 - val_mean_absolute_error: 55.7906\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3191 - mean_absolute_error: 0.4591 - val_loss: 3147.9014 - val_mean_absolute_error: 56.0467\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 638ms/step - loss: 6.1027 - mean_absolute_error: 2.0306 - val_loss: 2933.5159 - val_mean_absolute_error: 54.1176\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8040 - mean_absolute_error: 1.8318 - val_loss: 3019.7817 - val_mean_absolute_error: 54.8901\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.1669 - mean_absolute_error: 1.2007 - val_loss: 3114.8105 - val_mean_absolute_error: 55.7315\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.5076 - mean_absolute_error: 0.8620 - val_loss: 3137.8291 - val_mean_absolute_error: 55.9279\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4546 - mean_absolute_error: 0.7905 - val_loss: 3098.6604 - val_mean_absolute_error: 55.5742\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0673 - mean_absolute_error: 0.7538 - val_loss: 3037.6436 - val_mean_absolute_error: 55.0201\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9984 - mean_absolute_error: 0.8681 - val_loss: 3030.6406 - val_mean_absolute_error: 54.9436\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8053 - mean_absolute_error: 0.8222 - val_loss: 3069.6672 - val_mean_absolute_error: 55.2772\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5711 - mean_absolute_error: 0.6320 - val_loss: 3084.5771 - val_mean_absolute_error: 55.3956\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6064 - mean_absolute_error: 0.7530 - val_loss: 3047.5020 - val_mean_absolute_error: 55.0501\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4728 - mean_absolute_error: 0.5838 - val_loss: 3009.7959 - val_mean_absolute_error: 54.7006\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 6.0164 - mean_absolute_error: 1.9983 - val_loss: 2917.6604 - val_mean_absolute_error: 53.9690\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1926 - mean_absolute_error: 1.9705 - val_loss: 3010.6653 - val_mean_absolute_error: 54.8132\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6574 - mean_absolute_error: 1.3573 - val_loss: 3116.2661 - val_mean_absolute_error: 55.7554\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9128 - mean_absolute_error: 0.9428 - val_loss: 3157.0544 - val_mean_absolute_error: 56.1122\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.1227 - mean_absolute_error: 0.8950 - val_loss: 3142.7744 - val_mean_absolute_error: 55.9829\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8518 - mean_absolute_error: 0.8496 - val_loss: 3099.1316 - val_mean_absolute_error: 55.5935\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5638 - mean_absolute_error: 0.8770 - val_loss: 3054.2642 - val_mean_absolute_error: 55.1910\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5798 - mean_absolute_error: 0.9990 - val_loss: 3042.7998 - val_mean_absolute_error: 55.0841\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5092 - mean_absolute_error: 1.0303 - val_loss: 3060.5400 - val_mean_absolute_error: 55.2374\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2657 - mean_absolute_error: 0.8809 - val_loss: 3086.4575 - val_mean_absolute_error: 55.4618\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1481 - mean_absolute_error: 0.8032 - val_loss: 3098.4009 - val_mean_absolute_error: 55.5603\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 600ms/step - loss: 5.9033 - mean_absolute_error: 1.9969 - val_loss: 2765.5874 - val_mean_absolute_error: 52.5657\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.0718 - mean_absolute_error: 1.9885 - val_loss: 2938.6953 - val_mean_absolute_error: 54.1700\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.3916 - mean_absolute_error: 1.2228 - val_loss: 3072.0488 - val_mean_absolute_error: 55.3685\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6636 - mean_absolute_error: 0.8888 - val_loss: 3137.3057 - val_mean_absolute_error: 55.9429\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.0176 - mean_absolute_error: 0.9817 - val_loss: 3132.0688 - val_mean_absolute_error: 55.8930\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8682 - mean_absolute_error: 0.9223 - val_loss: 3073.9924 - val_mean_absolute_error: 55.3757\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4239 - mean_absolute_error: 0.8161 - val_loss: 3003.4507 - val_mean_absolute_error: 54.7402\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4128 - mean_absolute_error: 0.9535 - val_loss: 2975.0571 - val_mean_absolute_error: 54.4783\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4323 - mean_absolute_error: 1.0056 - val_loss: 2998.8542 - val_mean_absolute_error: 54.6877\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1017 - mean_absolute_error: 0.8696 - val_loss: 3047.3823 - val_mean_absolute_error: 55.1183\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9401 - mean_absolute_error: 0.6500 - val_loss: 3077.6772 - val_mean_absolute_error: 55.3826\n",
      "1/1 [==============================] - 1s 592ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 8.5540 - mean_absolute_error: 2.4503 - val_loss: 3050.0444 - val_mean_absolute_error: 55.1722\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7557 - mean_absolute_error: 0.8958 - val_loss: 2889.5518 - val_mean_absolute_error: 53.7094\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2841 - mean_absolute_error: 1.2788 - val_loss: 2920.2896 - val_mean_absolute_error: 53.9849\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6343 - mean_absolute_error: 1.1079 - val_loss: 3020.8018 - val_mean_absolute_error: 54.8909\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2063 - mean_absolute_error: 0.7148 - val_loss: 3073.1587 - val_mean_absolute_error: 55.3532\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3965 - mean_absolute_error: 0.8643 - val_loss: 3034.0061 - val_mean_absolute_error: 54.9975\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0845 - mean_absolute_error: 0.7330 - val_loss: 2964.3013 - val_mean_absolute_error: 54.3623\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0299 - mean_absolute_error: 0.9072 - val_loss: 2936.9570 - val_mean_absolute_error: 54.1063\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1162 - mean_absolute_error: 1.0087 - val_loss: 2976.6050 - val_mean_absolute_error: 54.4629\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8841 - mean_absolute_error: 0.8278 - val_loss: 3033.5659 - val_mean_absolute_error: 54.9770\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8568 - mean_absolute_error: 0.7948 - val_loss: 3058.7324 - val_mean_absolute_error: 55.2032\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8865 - mean_absolute_error: 0.7943 - val_loss: 3037.9934 - val_mean_absolute_error: 55.0152\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 3.7789 - mean_absolute_error: 1.6928 - val_loss: 2628.2434 - val_mean_absolute_error: 51.2553\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 35.9596 - mean_absolute_error: 5.3993 - val_loss: 2949.2153 - val_mean_absolute_error: 54.2732\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.9412 - mean_absolute_error: 2.0050 - val_loss: 3305.9697 - val_mean_absolute_error: 57.4300\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.9375 - mean_absolute_error: 1.4586 - val_loss: 3482.0586 - val_mean_absolute_error: 58.9199\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 12.5273 - mean_absolute_error: 3.1184 - val_loss: 3461.1196 - val_mean_absolute_error: 58.7439\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 11.0577 - mean_absolute_error: 2.9252 - val_loss: 3339.6543 - val_mean_absolute_error: 57.7163\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3686 - mean_absolute_error: 1.8027 - val_loss: 3189.4370 - val_mean_absolute_error: 56.4181\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3775 - mean_absolute_error: 0.6052 - val_loss: 3056.8247 - val_mean_absolute_error: 55.2438\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2061 - mean_absolute_error: 0.9537 - val_loss: 2975.5818 - val_mean_absolute_error: 54.5108\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8858 - mean_absolute_error: 1.7642 - val_loss: 2956.5952 - val_mean_absolute_error: 54.3376\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.7384 - mean_absolute_error: 1.9535 - val_loss: 2985.6895 - val_mean_absolute_error: 54.6013\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 2.0315 - mean_absolute_error: 1.0093 - val_loss: 3489.9050 - val_mean_absolute_error: 58.9085\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 16.7535 - mean_absolute_error: 3.3640 - val_loss: 2913.0142 - val_mean_absolute_error: 53.8808\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2128 - mean_absolute_error: 1.6612 - val_loss: 2743.9683 - val_mean_absolute_error: 52.3105\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 11.3056 - mean_absolute_error: 2.7563 - val_loss: 2880.8901 - val_mean_absolute_error: 53.5853\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0672 - mean_absolute_error: 1.8269 - val_loss: 3083.4268 - val_mean_absolute_error: 55.4180\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9143 - mean_absolute_error: 0.7040 - val_loss: 3231.2275 - val_mean_absolute_error: 56.7151\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6823 - mean_absolute_error: 1.6030 - val_loss: 3272.4453 - val_mean_absolute_error: 57.0700\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1560 - mean_absolute_error: 1.9039 - val_loss: 3218.1992 - val_mean_absolute_error: 56.5991\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3166 - mean_absolute_error: 1.5132 - val_loss: 3112.3291 - val_mean_absolute_error: 55.6711\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1637 - mean_absolute_error: 0.8915 - val_loss: 3000.9155 - val_mean_absolute_error: 54.6762\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0504 - mean_absolute_error: 0.9671 - val_loss: 2924.4590 - val_mean_absolute_error: 53.9819\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.3246 - mean_absolute_error: 1.4364 - val_loss: 2904.0713 - val_mean_absolute_error: 53.7939\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.7614 - mean_absolute_error: 1.5402 - val_loss: 2936.6831 - val_mean_absolute_error: 54.0890\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 546ms/step - loss: 3.3225 - mean_absolute_error: 1.4134 - val_loss: 2631.0427 - val_mean_absolute_error: 51.2783\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 25.5082 - mean_absolute_error: 3.9028 - val_loss: 2934.9160 - val_mean_absolute_error: 54.1205\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2459 - mean_absolute_error: 1.8269 - val_loss: 3248.1875 - val_mean_absolute_error: 56.8890\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2561 - mean_absolute_error: 1.4676 - val_loss: 3390.4180 - val_mean_absolute_error: 58.0927\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 9.1873 - mean_absolute_error: 2.4978 - val_loss: 3349.8647 - val_mean_absolute_error: 57.7405\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.5022 - mean_absolute_error: 2.2372 - val_loss: 3228.6350 - val_mean_absolute_error: 56.6948\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.0807 - mean_absolute_error: 1.4717 - val_loss: 3085.7422 - val_mean_absolute_error: 55.4400\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9379 - mean_absolute_error: 0.7466 - val_loss: 2962.1201 - val_mean_absolute_error: 54.3299\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0598 - mean_absolute_error: 1.3741 - val_loss: 2903.8833 - val_mean_absolute_error: 53.7996\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.6286 - mean_absolute_error: 1.7419 - val_loss: 2912.0916 - val_mean_absolute_error: 53.8759\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.4670 - mean_absolute_error: 1.7108 - val_loss: 2964.4756 - val_mean_absolute_error: 54.3549\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 10.0997 - mean_absolute_error: 2.6814 - val_loss: 2831.3120 - val_mean_absolute_error: 53.1815\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3011 - mean_absolute_error: 1.6181 - val_loss: 2758.5649 - val_mean_absolute_error: 52.4927\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.4973 - mean_absolute_error: 1.8667 - val_loss: 2885.1304 - val_mean_absolute_error: 53.6651\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.0210 - mean_absolute_error: 1.2357 - val_loss: 3045.7397 - val_mean_absolute_error: 55.1142\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0552 - mean_absolute_error: 0.6777 - val_loss: 3130.5540 - val_mean_absolute_error: 55.8598\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8502 - mean_absolute_error: 1.0031 - val_loss: 3109.9985 - val_mean_absolute_error: 55.6721\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6448 - mean_absolute_error: 0.9674 - val_loss: 3026.9136 - val_mean_absolute_error: 54.9256\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8127 - mean_absolute_error: 0.7796 - val_loss: 2926.0493 - val_mean_absolute_error: 54.0051\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0075 - mean_absolute_error: 0.9826 - val_loss: 2893.3765 - val_mean_absolute_error: 53.7018\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3629 - mean_absolute_error: 1.1287 - val_loss: 2936.0898 - val_mean_absolute_error: 54.0924\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9070 - mean_absolute_error: 0.9284 - val_loss: 3011.5400 - val_mean_absolute_error: 54.7770\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6543 - mean_absolute_error: 0.7576 - val_loss: 3071.7046 - val_mean_absolute_error: 55.3179\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 2.7293 - mean_absolute_error: 1.1971 - val_loss: 2516.3975 - val_mean_absolute_error: 50.1262\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 17.1629 - mean_absolute_error: 3.2518 - val_loss: 3056.7271 - val_mean_absolute_error: 55.1950\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0459 - mean_absolute_error: 0.7154 - val_loss: 3428.0942 - val_mean_absolute_error: 58.4204\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.8507 - mean_absolute_error: 2.5035 - val_loss: 3357.4431 - val_mean_absolute_error: 57.8186\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.2249 - mean_absolute_error: 2.1273 - val_loss: 3123.2480 - val_mean_absolute_error: 55.7846\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6290 - mean_absolute_error: 0.9985 - val_loss: 2892.7566 - val_mean_absolute_error: 53.7059\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7501 - mean_absolute_error: 1.2581 - val_loss: 2768.0054 - val_mean_absolute_error: 52.5452\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5038 - mean_absolute_error: 1.8071 - val_loss: 2769.5059 - val_mean_absolute_error: 52.5588\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4240 - mean_absolute_error: 1.7930 - val_loss: 2855.4619 - val_mean_absolute_error: 53.3616\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.3268 - mean_absolute_error: 1.4067 - val_loss: 2978.0977 - val_mean_absolute_error: 54.4862\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8893 - mean_absolute_error: 0.8618 - val_loss: 3095.0894 - val_mean_absolute_error: 55.5372\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 612ms/step - loss: 3.9432 - mean_absolute_error: 1.5852 - val_loss: 2955.3254 - val_mean_absolute_error: 54.3095\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2111 - mean_absolute_error: 1.8814 - val_loss: 3104.1140 - val_mean_absolute_error: 55.6487\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5812 - mean_absolute_error: 0.6773 - val_loss: 3202.4719 - val_mean_absolute_error: 56.5178\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8479 - mean_absolute_error: 0.7912 - val_loss: 3201.1760 - val_mean_absolute_error: 56.5086\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7020 - mean_absolute_error: 0.7582 - val_loss: 3150.9238 - val_mean_absolute_error: 56.0693\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2113 - mean_absolute_error: 0.3750 - val_loss: 3095.5654 - val_mean_absolute_error: 55.5804\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4095 - mean_absolute_error: 0.5372 - val_loss: 3088.0796 - val_mean_absolute_error: 55.5152\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4816 - mean_absolute_error: 0.5989 - val_loss: 3117.8462 - val_mean_absolute_error: 55.7811\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2191 - mean_absolute_error: 0.3528 - val_loss: 3156.0776 - val_mean_absolute_error: 56.1197\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1807 - mean_absolute_error: 0.3895 - val_loss: 3179.4875 - val_mean_absolute_error: 56.3260\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3083 - mean_absolute_error: 0.5448 - val_loss: 3177.3914 - val_mean_absolute_error: 56.3082\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 13.3828 - mean_absolute_error: 3.1414 - val_loss: 3084.0288 - val_mean_absolute_error: 55.4764\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.1918 - mean_absolute_error: 0.9674 - val_loss: 2992.6626 - val_mean_absolute_error: 54.6545\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.0985 - mean_absolute_error: 1.4892 - val_loss: 3033.8210 - val_mean_absolute_error: 55.0232\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2939 - mean_absolute_error: 1.2176 - val_loss: 3109.6416 - val_mean_absolute_error: 55.6989\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8373 - mean_absolute_error: 0.9200 - val_loss: 3162.5122 - val_mean_absolute_error: 56.1642\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.0909 - mean_absolute_error: 0.9344 - val_loss: 3141.1516 - val_mean_absolute_error: 55.9724\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7454 - mean_absolute_error: 0.8520 - val_loss: 3077.7786 - val_mean_absolute_error: 55.4066\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4514 - mean_absolute_error: 0.8529 - val_loss: 3035.6418 - val_mean_absolute_error: 55.0249\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5657 - mean_absolute_error: 1.0778 - val_loss: 3054.8896 - val_mean_absolute_error: 55.1922\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2324 - mean_absolute_error: 0.9192 - val_loss: 3100.1326 - val_mean_absolute_error: 55.5909\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0137 - mean_absolute_error: 0.7275 - val_loss: 3121.6843 - val_mean_absolute_error: 55.7758\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9983 - mean_absolute_error: 0.7172 - val_loss: 3099.3682 - val_mean_absolute_error: 55.5685\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 610ms/step - loss: 7.5936 - mean_absolute_error: 2.2986 - val_loss: 3099.6362 - val_mean_absolute_error: 55.6158\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.1644 - mean_absolute_error: 0.9385 - val_loss: 3014.1794 - val_mean_absolute_error: 54.8429\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4102 - mean_absolute_error: 1.3217 - val_loss: 3054.0022 - val_mean_absolute_error: 55.1931\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6957 - mean_absolute_error: 1.0080 - val_loss: 3110.3765 - val_mean_absolute_error: 55.6881\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5113 - mean_absolute_error: 0.8634 - val_loss: 3119.2542 - val_mean_absolute_error: 55.7584\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4365 - mean_absolute_error: 0.8632 - val_loss: 3077.3779 - val_mean_absolute_error: 55.3761\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0976 - mean_absolute_error: 0.8456 - val_loss: 3022.8540 - val_mean_absolute_error: 54.8758\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1451 - mean_absolute_error: 0.9623 - val_loss: 3030.1743 - val_mean_absolute_error: 54.9327\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0048 - mean_absolute_error: 0.8538 - val_loss: 3077.2046 - val_mean_absolute_error: 55.3518\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9071 - mean_absolute_error: 0.8247 - val_loss: 3102.1528 - val_mean_absolute_error: 55.5762\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9491 - mean_absolute_error: 0.9119 - val_loss: 3085.6025 - val_mean_absolute_error: 55.4326\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7748 - mean_absolute_error: 0.7698 - val_loss: 3056.1694 - val_mean_absolute_error: 55.1764\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 638ms/step - loss: 5.3679 - mean_absolute_error: 1.8895 - val_loss: 3005.6799 - val_mean_absolute_error: 54.7716\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0093 - mean_absolute_error: 1.1019 - val_loss: 2939.6118 - val_mean_absolute_error: 54.1617\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.1592 - mean_absolute_error: 1.2120 - val_loss: 3023.8135 - val_mean_absolute_error: 54.9211\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3301 - mean_absolute_error: 0.8732 - val_loss: 3081.9263 - val_mean_absolute_error: 55.4367\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2733 - mean_absolute_error: 0.7329 - val_loss: 3068.7969 - val_mean_absolute_error: 55.3116\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0571 - mean_absolute_error: 0.6826 - val_loss: 3016.1184 - val_mean_absolute_error: 54.8274\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8490 - mean_absolute_error: 0.7730 - val_loss: 2979.7598 - val_mean_absolute_error: 54.4846\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8699 - mean_absolute_error: 0.8994 - val_loss: 3013.2095 - val_mean_absolute_error: 54.7797\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6902 - mean_absolute_error: 0.7394 - val_loss: 3058.8479 - val_mean_absolute_error: 55.1907\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6820 - mean_absolute_error: 0.7782 - val_loss: 3068.6128 - val_mean_absolute_error: 55.2822\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6410 - mean_absolute_error: 0.7458 - val_loss: 3041.3584 - val_mean_absolute_error: 55.0398\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4829 - mean_absolute_error: 0.6599 - val_loss: 3013.7153 - val_mean_absolute_error: 54.7958\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 5.1439 - mean_absolute_error: 1.8606 - val_loss: 2994.7583 - val_mean_absolute_error: 54.6583\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2684 - mean_absolute_error: 0.8822 - val_loss: 2891.0859 - val_mean_absolute_error: 53.6937\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8398 - mean_absolute_error: 1.2840 - val_loss: 3002.2861 - val_mean_absolute_error: 54.7064\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8413 - mean_absolute_error: 0.7685 - val_loss: 3095.2222 - val_mean_absolute_error: 55.5431\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1265 - mean_absolute_error: 0.8047 - val_loss: 3080.3169 - val_mean_absolute_error: 55.4054\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9022 - mean_absolute_error: 0.7090 - val_loss: 3009.0188 - val_mean_absolute_error: 54.7590\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6471 - mean_absolute_error: 0.7184 - val_loss: 2967.9062 - val_mean_absolute_error: 54.3808\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7822 - mean_absolute_error: 0.8756 - val_loss: 3012.9907 - val_mean_absolute_error: 54.7906\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5119 - mean_absolute_error: 0.6651 - val_loss: 3079.8662 - val_mean_absolute_error: 55.3957\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5206 - mean_absolute_error: 0.6236 - val_loss: 3091.9045 - val_mean_absolute_error: 55.5030\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5002 - mean_absolute_error: 0.6034 - val_loss: 3056.5757 - val_mean_absolute_error: 55.1832\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3249 - mean_absolute_error: 0.5434 - val_loss: 3020.1025 - val_mean_absolute_error: 54.8531\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 2.8307 - mean_absolute_error: 1.5391 - val_loss: 3701.2969 - val_mean_absolute_error: 60.7088\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 36.1028 - mean_absolute_error: 5.2375 - val_loss: 3313.5928 - val_mean_absolute_error: 57.4807\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7637 - mean_absolute_error: 1.5566 - val_loss: 2990.3726 - val_mean_absolute_error: 54.6288\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.7726 - mean_absolute_error: 1.5725 - val_loss: 2851.3328 - val_mean_absolute_error: 53.3532\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 9.8165 - mean_absolute_error: 2.9578 - val_loss: 2870.9639 - val_mean_absolute_error: 53.5340\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 8.6935 - mean_absolute_error: 2.7894 - val_loss: 2973.1350 - val_mean_absolute_error: 54.4690\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5990 - mean_absolute_error: 1.8131 - val_loss: 3098.9431 - val_mean_absolute_error: 55.5989\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4853 - mean_absolute_error: 0.5951 - val_loss: 3214.6602 - val_mean_absolute_error: 56.6168\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7898 - mean_absolute_error: 0.8206 - val_loss: 3293.4663 - val_mean_absolute_error: 57.2995\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.6107 - mean_absolute_error: 1.3573 - val_loss: 3318.0391 - val_mean_absolute_error: 57.5128\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3969 - mean_absolute_error: 1.5117 - val_loss: 3298.0210 - val_mean_absolute_error: 57.3451\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.6943 - mean_absolute_error: 1.3719 - val_loss: 3248.1340 - val_mean_absolute_error: 56.9185\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2920 - mean_absolute_error: 1.0105 - val_loss: 3183.9756 - val_mean_absolute_error: 56.3627\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3523 - mean_absolute_error: 0.5439 - val_loss: 3121.2314 - val_mean_absolute_error: 55.8129\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 2.9061 - mean_absolute_error: 1.4392 - val_loss: 3629.8816 - val_mean_absolute_error: 60.1145\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 26.5843 - mean_absolute_error: 4.4049 - val_loss: 3241.3381 - val_mean_absolute_error: 56.8424\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4931 - mean_absolute_error: 1.5500 - val_loss: 2893.9839 - val_mean_absolute_error: 53.7405\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.9092 - mean_absolute_error: 1.9469 - val_loss: 2770.9976 - val_mean_absolute_error: 52.5942\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 10.9517 - mean_absolute_error: 2.7134 - val_loss: 2809.6929 - val_mean_absolute_error: 52.9535\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 8.1847 - mean_absolute_error: 2.4013 - val_loss: 2918.4736 - val_mean_absolute_error: 53.9537\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2388 - mean_absolute_error: 1.6362 - val_loss: 3045.5234 - val_mean_absolute_error: 55.0995\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9549 - mean_absolute_error: 0.8087 - val_loss: 3155.6514 - val_mean_absolute_error: 56.0722\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5060 - mean_absolute_error: 0.9559 - val_loss: 3228.5115 - val_mean_absolute_error: 56.7029\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.1214 - mean_absolute_error: 1.4870 - val_loss: 3247.9578 - val_mean_absolute_error: 56.8636\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7272 - mean_absolute_error: 1.6258 - val_loss: 3221.6396 - val_mean_absolute_error: 56.6266\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.0014 - mean_absolute_error: 1.4445 - val_loss: 3164.0283 - val_mean_absolute_error: 56.1132\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6195 - mean_absolute_error: 1.0991 - val_loss: 3089.4771 - val_mean_absolute_error: 55.4472\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6131 - mean_absolute_error: 0.7173 - val_loss: 3005.5293 - val_mean_absolute_error: 54.6915\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 542ms/step - loss: 8.6189 - mean_absolute_error: 2.3917 - val_loss: 2604.9548 - val_mean_absolute_error: 51.0312\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 29.7633 - mean_absolute_error: 4.1660 - val_loss: 2894.0400 - val_mean_absolute_error: 53.7650\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.9046 - mean_absolute_error: 2.1430 - val_loss: 3221.0586 - val_mean_absolute_error: 56.6804\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7945 - mean_absolute_error: 1.4286 - val_loss: 3364.9180 - val_mean_absolute_error: 57.9064\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.9419 - mean_absolute_error: 2.4683 - val_loss: 3325.6260 - val_mean_absolute_error: 57.5625\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.9918 - mean_absolute_error: 2.1714 - val_loss: 3191.0000 - val_mean_absolute_error: 56.3915\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.5469 - mean_absolute_error: 1.2341 - val_loss: 3036.0249 - val_mean_absolute_error: 55.0150\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4949 - mean_absolute_error: 1.0618 - val_loss: 2923.6577 - val_mean_absolute_error: 53.9927\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5140 - mean_absolute_error: 1.7363 - val_loss: 2894.0112 - val_mean_absolute_error: 53.7181\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.3411 - mean_absolute_error: 1.8981 - val_loss: 2932.3428 - val_mean_absolute_error: 54.0668\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.9918 - mean_absolute_error: 1.6292 - val_loss: 3008.6177 - val_mean_absolute_error: 54.7554\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 3.0454 - mean_absolute_error: 1.3224 - val_loss: 2770.6289 - val_mean_absolute_error: 52.5826\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6277 - mean_absolute_error: 1.9438 - val_loss: 2894.4863 - val_mean_absolute_error: 53.7328\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1459 - mean_absolute_error: 1.3230 - val_loss: 3064.7751 - val_mean_absolute_error: 55.2737\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0528 - mean_absolute_error: 0.6978 - val_loss: 3161.6421 - val_mean_absolute_error: 56.1251\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0068 - mean_absolute_error: 1.0481 - val_loss: 3156.0464 - val_mean_absolute_error: 56.0701\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8050 - mean_absolute_error: 1.0089 - val_loss: 3086.6948 - val_mean_absolute_error: 55.4529\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9835 - mean_absolute_error: 0.7623 - val_loss: 2998.4441 - val_mean_absolute_error: 54.6589\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7619 - mean_absolute_error: 0.7900 - val_loss: 2939.9211 - val_mean_absolute_error: 54.1239\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1571 - mean_absolute_error: 1.0463 - val_loss: 2934.2188 - val_mean_absolute_error: 54.0699\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2183 - mean_absolute_error: 1.0671 - val_loss: 2968.4746 - val_mean_absolute_error: 54.3815\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8533 - mean_absolute_error: 0.8997 - val_loss: 3022.7148 - val_mean_absolute_error: 54.8727\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 534ms/step - loss: 7.2137 - mean_absolute_error: 2.1351 - val_loss: 2552.6924 - val_mean_absolute_error: 50.4913\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 12.9000 - mean_absolute_error: 2.7687 - val_loss: 2757.6606 - val_mean_absolute_error: 52.4635\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2800 - mean_absolute_error: 1.8073 - val_loss: 3053.1724 - val_mean_absolute_error: 55.1777\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4152 - mean_absolute_error: 0.8148 - val_loss: 3232.3022 - val_mean_absolute_error: 56.7605\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1041 - mean_absolute_error: 1.5763 - val_loss: 3247.6968 - val_mean_absolute_error: 56.8947\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.4129 - mean_absolute_error: 1.6501 - val_loss: 3162.0122 - val_mean_absolute_error: 56.1460\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.5063 - mean_absolute_error: 1.1703 - val_loss: 3040.0151 - val_mean_absolute_error: 55.0623\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1330 - mean_absolute_error: 0.6914 - val_loss: 2925.4983 - val_mean_absolute_error: 54.0216\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4115 - mean_absolute_error: 1.0980 - val_loss: 2857.3433 - val_mean_absolute_error: 53.3902\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.2073 - mean_absolute_error: 1.3745 - val_loss: 2850.0762 - val_mean_absolute_error: 53.3180\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.2127 - mean_absolute_error: 1.3847 - val_loss: 2892.1914 - val_mean_absolute_error: 53.7022\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 4.9545 - mean_absolute_error: 1.6666 - val_loss: 2774.6152 - val_mean_absolute_error: 52.6408\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 18.0231 - mean_absolute_error: 3.8120 - val_loss: 2997.7798 - val_mean_absolute_error: 54.7028\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5454 - mean_absolute_error: 1.5864 - val_loss: 3256.0952 - val_mean_absolute_error: 56.9929\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5955 - mean_absolute_error: 1.0239 - val_loss: 3381.5063 - val_mean_absolute_error: 58.0697\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.9723 - mean_absolute_error: 2.1029 - val_loss: 3368.1494 - val_mean_absolute_error: 57.9563\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.2338 - mean_absolute_error: 1.9766 - val_loss: 3279.0620 - val_mean_absolute_error: 57.1927\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9000 - mean_absolute_error: 1.1633 - val_loss: 3163.8247 - val_mean_absolute_error: 56.1890\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1967 - mean_absolute_error: 0.3863 - val_loss: 3063.4766 - val_mean_absolute_error: 55.2988\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0270 - mean_absolute_error: 0.8920 - val_loss: 3008.2031 - val_mean_absolute_error: 54.8019\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.4056 - mean_absolute_error: 1.4148 - val_loss: 3008.6089 - val_mean_absolute_error: 54.8052\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.3846 - mean_absolute_error: 1.4117 - val_loss: 3049.2266 - val_mean_absolute_error: 55.1704\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 8.6335 - mean_absolute_error: 2.4868 - val_loss: 2965.3879 - val_mean_absolute_error: 54.4129\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.2378 - mean_absolute_error: 1.7438 - val_loss: 2904.1865 - val_mean_absolute_error: 53.8466\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3642 - mean_absolute_error: 1.9871 - val_loss: 2981.1060 - val_mean_absolute_error: 54.5372\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.4500 - mean_absolute_error: 1.3633 - val_loss: 3085.5029 - val_mean_absolute_error: 55.4595\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2173 - mean_absolute_error: 0.8277 - val_loss: 3152.3418 - val_mean_absolute_error: 56.0340\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8037 - mean_absolute_error: 1.0863 - val_loss: 3151.1504 - val_mean_absolute_error: 56.0090\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7856 - mean_absolute_error: 1.1426 - val_loss: 3100.5356 - val_mean_absolute_error: 55.5497\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9967 - mean_absolute_error: 0.9230 - val_loss: 3026.4336 - val_mean_absolute_error: 54.8778\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5468 - mean_absolute_error: 0.6082 - val_loss: 2960.6238 - val_mean_absolute_error: 54.2747\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9681 - mean_absolute_error: 0.9362 - val_loss: 2942.9775 - val_mean_absolute_error: 54.1091\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1800 - mean_absolute_error: 1.0095 - val_loss: 2967.9978 - val_mean_absolute_error: 54.3351\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7685 - mean_absolute_error: 0.8065 - val_loss: 3013.8965 - val_mean_absolute_error: 54.7502\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.0323 - mean_absolute_error: 3.0738 - val_loss: 2959.9727 - val_mean_absolute_error: 54.3558\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9147 - mean_absolute_error: 1.6660 - val_loss: 2850.3506 - val_mean_absolute_error: 53.3405\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.2937 - mean_absolute_error: 2.2891 - val_loss: 2938.5906 - val_mean_absolute_error: 54.1453\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5620 - mean_absolute_error: 1.6719 - val_loss: 3061.9668 - val_mean_absolute_error: 55.2506\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4417 - mean_absolute_error: 0.9585 - val_loss: 3151.1892 - val_mean_absolute_error: 56.0329\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.0111 - mean_absolute_error: 1.1457 - val_loss: 3178.6313 - val_mean_absolute_error: 56.2675\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.5682 - mean_absolute_error: 1.3514 - val_loss: 3152.8157 - val_mean_absolute_error: 56.0332\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0275 - mean_absolute_error: 1.2467 - val_loss: 3093.9658 - val_mean_absolute_error: 55.5073\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2336 - mean_absolute_error: 0.9500 - val_loss: 3024.8047 - val_mean_absolute_error: 54.8867\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1220 - mean_absolute_error: 0.8893 - val_loss: 2979.3213 - val_mean_absolute_error: 54.4748\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5496 - mean_absolute_error: 1.1618 - val_loss: 2977.5840 - val_mean_absolute_error: 54.4592\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5481 - mean_absolute_error: 1.1691 - val_loss: 3009.4583 - val_mean_absolute_error: 54.7489\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 33.1456 - mean_absolute_error: 4.9518 - val_loss: 3018.3062 - val_mean_absolute_error: 54.9024\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.6995 - mean_absolute_error: 1.2007 - val_loss: 2651.7085 - val_mean_absolute_error: 51.4783\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 12.0906 - mean_absolute_error: 2.5711 - val_loss: 2660.0688 - val_mean_absolute_error: 51.5539\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 10.8690 - mean_absolute_error: 2.4908 - val_loss: 2795.1921 - val_mean_absolute_error: 52.8344\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.0096 - mean_absolute_error: 1.8167 - val_loss: 2963.7251 - val_mean_absolute_error: 54.3882\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7561 - mean_absolute_error: 1.0356 - val_loss: 3114.2207 - val_mean_absolute_error: 55.7349\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.1640 - mean_absolute_error: 1.0471 - val_loss: 3207.6848 - val_mean_absolute_error: 56.5510\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.9000 - mean_absolute_error: 1.5754 - val_loss: 3232.9829 - val_mean_absolute_error: 56.7650\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4985 - mean_absolute_error: 1.6935 - val_loss: 3200.4143 - val_mean_absolute_error: 56.4753\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5492 - mean_absolute_error: 1.4746 - val_loss: 3130.3081 - val_mean_absolute_error: 55.8549\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.0088 - mean_absolute_error: 1.0549 - val_loss: 3044.5317 - val_mean_absolute_error: 55.0878\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0563 - mean_absolute_error: 0.7498 - val_loss: 2961.5537 - val_mean_absolute_error: 54.3369\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 2.7222 - mean_absolute_error: 1.1174 - val_loss: 2603.6602 - val_mean_absolute_error: 50.9980\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 11.8349 - mean_absolute_error: 2.6396 - val_loss: 2884.2417 - val_mean_absolute_error: 53.6496\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.1739 - mean_absolute_error: 1.3192 - val_loss: 3166.2107 - val_mean_absolute_error: 56.1793\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.3365 - mean_absolute_error: 1.1361 - val_loss: 3279.7954 - val_mean_absolute_error: 57.1585\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4612 - mean_absolute_error: 1.6811 - val_loss: 3253.1982 - val_mean_absolute_error: 56.9171\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5888 - mean_absolute_error: 1.4799 - val_loss: 3158.8403 - val_mean_absolute_error: 56.0848\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.7584 - mean_absolute_error: 0.9492 - val_loss: 3044.1597 - val_mean_absolute_error: 55.0610\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8151 - mean_absolute_error: 0.7910 - val_loss: 2942.8181 - val_mean_absolute_error: 54.1415\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1165 - mean_absolute_error: 1.0360 - val_loss: 2890.9468 - val_mean_absolute_error: 53.6651\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7784 - mean_absolute_error: 1.2721 - val_loss: 2895.1650 - val_mean_absolute_error: 53.7044\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7266 - mean_absolute_error: 1.2568 - val_loss: 2940.0256 - val_mean_absolute_error: 54.1190\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 8.0107 - mean_absolute_error: 2.4127 - val_loss: 3187.0176 - val_mean_absolute_error: 56.3866\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6298 - mean_absolute_error: 0.6374 - val_loss: 3055.5327 - val_mean_absolute_error: 55.2230\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2300 - mean_absolute_error: 0.9095 - val_loss: 3081.7705 - val_mean_absolute_error: 55.4579\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7581 - mean_absolute_error: 0.6573 - val_loss: 3144.5974 - val_mean_absolute_error: 56.0153\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3359 - mean_absolute_error: 0.5215 - val_loss: 3175.8369 - val_mean_absolute_error: 56.2914\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4366 - mean_absolute_error: 0.5570 - val_loss: 3170.8750 - val_mean_absolute_error: 56.2491\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3606 - mean_absolute_error: 0.5019 - val_loss: 3143.9922 - val_mean_absolute_error: 56.0136\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2376 - mean_absolute_error: 0.4510 - val_loss: 3116.1812 - val_mean_absolute_error: 55.7684\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2846 - mean_absolute_error: 0.4205 - val_loss: 3117.3257 - val_mean_absolute_error: 55.7792\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2451 - mean_absolute_error: 0.3777 - val_loss: 3140.8516 - val_mean_absolute_error: 55.9874\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1533 - mean_absolute_error: 0.3392 - val_loss: 3164.1687 - val_mean_absolute_error: 56.1928\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1881 - mean_absolute_error: 0.4140 - val_loss: 3163.1838 - val_mean_absolute_error: 56.1842\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 649ms/step - loss: 6.4190 - mean_absolute_error: 2.0830 - val_loss: 3021.4722 - val_mean_absolute_error: 54.9215\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.8981 - mean_absolute_error: 1.3510 - val_loss: 3024.0908 - val_mean_absolute_error: 54.9379\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.4774 - mean_absolute_error: 1.2712 - val_loss: 3096.4189 - val_mean_absolute_error: 55.5765\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6922 - mean_absolute_error: 0.8655 - val_loss: 3123.9619 - val_mean_absolute_error: 55.8129\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6460 - mean_absolute_error: 0.8001 - val_loss: 3084.8025 - val_mean_absolute_error: 55.4586\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3230 - mean_absolute_error: 0.7920 - val_loss: 3030.6960 - val_mean_absolute_error: 54.9652\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2600 - mean_absolute_error: 0.9647 - val_loss: 3041.6931 - val_mean_absolute_error: 55.0492\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9375 - mean_absolute_error: 0.7942 - val_loss: 3070.3450 - val_mean_absolute_error: 55.2906\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8000 - mean_absolute_error: 0.7073 - val_loss: 3055.8796 - val_mean_absolute_error: 55.1434\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6971 - mean_absolute_error: 0.7293 - val_loss: 3007.5100 - val_mean_absolute_error: 54.6881\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6631 - mean_absolute_error: 0.6559 - val_loss: 2998.9119 - val_mean_absolute_error: 54.5967\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6704 - mean_absolute_error: 0.6134 - val_loss: 3032.9568 - val_mean_absolute_error: 54.9029\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6437 - mean_absolute_error: 0.7526 - val_loss: 3039.6899 - val_mean_absolute_error: 54.9685\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5968 - mean_absolute_error: 0.7360 - val_loss: 3014.7437 - val_mean_absolute_error: 54.7498\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5044 - mean_absolute_error: 0.5564 - val_loss: 3011.5649 - val_mean_absolute_error: 54.7331\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4788 - mean_absolute_error: 0.5795 - val_loss: 3044.8179 - val_mean_absolute_error: 55.0475\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4200 - mean_absolute_error: 0.5370 - val_loss: 3063.0557 - val_mean_absolute_error: 55.2205\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4362 - mean_absolute_error: 0.5720 - val_loss: 3045.7246 - val_mean_absolute_error: 55.0671\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3817 - mean_absolute_error: 0.4962 - val_loss: 3028.5669 - val_mean_absolute_error: 54.9099\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3604 - mean_absolute_error: 0.5461 - val_loss: 3041.4780 - val_mean_absolute_error: 55.0214\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2848 - mean_absolute_error: 0.4238 - val_loss: 3055.3413 - val_mean_absolute_error: 55.1397\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 12.2034 - mean_absolute_error: 2.9913 - val_loss: 3132.7534 - val_mean_absolute_error: 55.9081\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1471 - mean_absolute_error: 0.9422 - val_loss: 2969.6978 - val_mean_absolute_error: 54.4442\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4484 - mean_absolute_error: 1.6411 - val_loss: 3019.9688 - val_mean_absolute_error: 54.8950\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.2790 - mean_absolute_error: 1.3088 - val_loss: 3098.9766 - val_mean_absolute_error: 55.5990\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6629 - mean_absolute_error: 0.8642 - val_loss: 3146.9263 - val_mean_absolute_error: 56.0201\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.8545 - mean_absolute_error: 0.8490 - val_loss: 3145.5168 - val_mean_absolute_error: 56.0043\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.7519 - mean_absolute_error: 0.8553 - val_loss: 3109.8801 - val_mean_absolute_error: 55.6851\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3866 - mean_absolute_error: 0.8196 - val_loss: 3059.2944 - val_mean_absolute_error: 55.2296\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2579 - mean_absolute_error: 0.9207 - val_loss: 3029.8501 - val_mean_absolute_error: 54.9582\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3118 - mean_absolute_error: 1.0620 - val_loss: 3041.1919 - val_mean_absolute_error: 55.0534\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0558 - mean_absolute_error: 0.9282 - val_loss: 3070.9023 - val_mean_absolute_error: 55.3142\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8701 - mean_absolute_error: 0.7455 - val_loss: 3093.0298 - val_mean_absolute_error: 55.5063\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 589ms/step - loss: 5.5469 - mean_absolute_error: 1.9164 - val_loss: 2937.7578 - val_mean_absolute_error: 54.1553\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.4382 - mean_absolute_error: 1.2148 - val_loss: 2960.7126 - val_mean_absolute_error: 54.3555\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.7975 - mean_absolute_error: 1.0845 - val_loss: 3043.2178 - val_mean_absolute_error: 55.0961\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2913 - mean_absolute_error: 0.8048 - val_loss: 3082.9629 - val_mean_absolute_error: 55.4441\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3105 - mean_absolute_error: 0.7647 - val_loss: 3045.0581 - val_mean_absolute_error: 55.0989\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0491 - mean_absolute_error: 0.6790 - val_loss: 2985.9165 - val_mean_absolute_error: 54.5552\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0065 - mean_absolute_error: 0.9133 - val_loss: 2997.6968 - val_mean_absolute_error: 54.6520\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8747 - mean_absolute_error: 0.8414 - val_loss: 3046.7915 - val_mean_absolute_error: 55.0858\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8330 - mean_absolute_error: 0.7971 - val_loss: 3052.5908 - val_mean_absolute_error: 55.1311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8157 - mean_absolute_error: 0.8321 - val_loss: 3014.1455 - val_mean_absolute_error: 54.7795\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7601 - mean_absolute_error: 0.7978 - val_loss: 3005.0928 - val_mean_absolute_error: 54.6973\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 621ms/step - loss: 7.5854 - mean_absolute_error: 2.3041 - val_loss: 3074.7837 - val_mean_absolute_error: 55.3958\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.9077 - mean_absolute_error: 0.8454 - val_loss: 2874.5852 - val_mean_absolute_error: 53.5751\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.5008 - mean_absolute_error: 1.3305 - val_loss: 2914.3591 - val_mean_absolute_error: 53.9369\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.7659 - mean_absolute_error: 1.1299 - val_loss: 3011.5217 - val_mean_absolute_error: 54.8146\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2012 - mean_absolute_error: 0.7698 - val_loss: 3074.6584 - val_mean_absolute_error: 55.3743\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2895 - mean_absolute_error: 0.8056 - val_loss: 3056.1956 - val_mean_absolute_error: 55.2026\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0540 - mean_absolute_error: 0.7290 - val_loss: 2990.5303 - val_mean_absolute_error: 54.6037\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8320 - mean_absolute_error: 0.7577 - val_loss: 2941.3364 - val_mean_absolute_error: 54.1481\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9788 - mean_absolute_error: 0.9496 - val_loss: 2964.1567 - val_mean_absolute_error: 54.3511\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8191 - mean_absolute_error: 0.8392 - val_loss: 3023.1133 - val_mean_absolute_error: 54.8835\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7042 - mean_absolute_error: 0.7503 - val_loss: 3061.1240 - val_mean_absolute_error: 55.2260\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7751 - mean_absolute_error: 0.7625 - val_loss: 3051.7368 - val_mean_absolute_error: 55.1423\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 16.1320 - mean_absolute_error: 3.5227 - val_loss: 2915.6025 - val_mean_absolute_error: 53.9382\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.4085 - mean_absolute_error: 2.2177 - val_loss: 2849.2849 - val_mean_absolute_error: 53.3282\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.1174 - mean_absolute_error: 2.8713 - val_loss: 2977.0127 - val_mean_absolute_error: 54.5066\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.8879 - mean_absolute_error: 1.6040 - val_loss: 3149.5657 - val_mean_absolute_error: 56.0570\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2928 - mean_absolute_error: 0.4355 - val_loss: 3278.5811 - val_mean_absolute_error: 57.1885\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.5553 - mean_absolute_error: 1.3274 - val_loss: 3318.4556 - val_mean_absolute_error: 57.5343\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8683 - mean_absolute_error: 1.6774 - val_loss: 3285.7969 - val_mean_absolute_error: 57.2538\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.6062 - mean_absolute_error: 1.3602 - val_loss: 3214.6382 - val_mean_absolute_error: 56.6363\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8055 - mean_absolute_error: 0.8149 - val_loss: 3133.1196 - val_mean_absolute_error: 55.9202\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1707 - mean_absolute_error: 0.3561 - val_loss: 3065.9648 - val_mean_absolute_error: 55.3229\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8100 - mean_absolute_error: 0.7866 - val_loss: 3032.7131 - val_mean_absolute_error: 55.0244\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5359 - mean_absolute_error: 1.1212 - val_loss: 3034.4341 - val_mean_absolute_error: 55.0399\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 5.9143 - mean_absolute_error: 1.9948 - val_loss: 2699.4399 - val_mean_absolute_error: 51.9402\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 19.7621 - mean_absolute_error: 3.5262 - val_loss: 2916.5928 - val_mean_absolute_error: 53.9607\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.8389 - mean_absolute_error: 1.9363 - val_loss: 3168.4951 - val_mean_absolute_error: 56.2117\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9312 - mean_absolute_error: 1.0048 - val_loss: 3303.5884 - val_mean_absolute_error: 57.3760\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.6028 - mean_absolute_error: 2.0102 - val_loss: 3289.6599 - val_mean_absolute_error: 57.2435\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.1762 - mean_absolute_error: 1.9238 - val_loss: 3193.3552 - val_mean_absolute_error: 56.3985\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2145 - mean_absolute_error: 1.2021 - val_loss: 3055.9878 - val_mean_absolute_error: 55.1801\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8699 - mean_absolute_error: 0.7526 - val_loss: 2943.8650 - val_mean_absolute_error: 54.1651\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.2476 - mean_absolute_error: 1.4301 - val_loss: 2912.4695 - val_mean_absolute_error: 53.8740\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.9572 - mean_absolute_error: 1.5967 - val_loss: 2949.1206 - val_mean_absolute_error: 54.2041\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9060 - mean_absolute_error: 1.3317 - val_loss: 3020.2817 - val_mean_absolute_error: 54.8432\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 25.8725 - mean_absolute_error: 4.3281 - val_loss: 2802.8086 - val_mean_absolute_error: 52.8909\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 9.7158 - mean_absolute_error: 2.6452 - val_loss: 2715.7104 - val_mean_absolute_error: 52.0668\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 14.9836 - mean_absolute_error: 3.1505 - val_loss: 2885.0229 - val_mean_absolute_error: 53.6503\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.0250 - mean_absolute_error: 2.0220 - val_loss: 3111.2075 - val_mean_absolute_error: 55.6892\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3416 - mean_absolute_error: 0.7715 - val_loss: 3270.9749 - val_mean_absolute_error: 57.0810\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9857 - mean_absolute_error: 1.6008 - val_loss: 3312.8948 - val_mean_absolute_error: 57.4363\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.5225 - mean_absolute_error: 1.9109 - val_loss: 3260.9241 - val_mean_absolute_error: 56.9834\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8173 - mean_absolute_error: 1.5640 - val_loss: 3154.0430 - val_mean_absolute_error: 56.0482\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5185 - mean_absolute_error: 1.0476 - val_loss: 3036.5640 - val_mean_absolute_error: 55.0019\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1200 - mean_absolute_error: 0.9558 - val_loss: 2950.2678 - val_mean_absolute_error: 54.2206\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.3573 - mean_absolute_error: 1.4637 - val_loss: 2922.8491 - val_mean_absolute_error: 53.9709\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 3.0306 - mean_absolute_error: 1.6253 - val_loss: 2948.2275 - val_mean_absolute_error: 54.2030\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 5.1967 - mean_absolute_error: 1.8821 - val_loss: 2669.7256 - val_mean_absolute_error: 51.6464\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 12.4547 - mean_absolute_error: 2.5372 - val_loss: 2856.7629 - val_mean_absolute_error: 53.4066\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1588 - mean_absolute_error: 1.6152 - val_loss: 3112.8091 - val_mean_absolute_error: 55.7166\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4875 - mean_absolute_error: 0.8457 - val_loss: 3259.2095 - val_mean_absolute_error: 56.9865\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8191 - mean_absolute_error: 1.5654 - val_loss: 3265.6167 - val_mean_absolute_error: 57.0332\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9118 - mean_absolute_error: 1.5646 - val_loss: 3187.3101 - val_mean_absolute_error: 56.3461\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0727 - mean_absolute_error: 1.0825 - val_loss: 3066.8638 - val_mean_absolute_error: 55.2801\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8812 - mean_absolute_error: 0.6418 - val_loss: 2956.2539 - val_mean_absolute_error: 54.2837\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4359 - mean_absolute_error: 1.1294 - val_loss: 2902.0278 - val_mean_absolute_error: 53.7865\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2543 - mean_absolute_error: 1.3706 - val_loss: 2908.9805 - val_mean_absolute_error: 53.8481\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0569 - mean_absolute_error: 1.3246 - val_loss: 2959.2188 - val_mean_absolute_error: 54.3037\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 4.6131 - mean_absolute_error: 1.7545 - val_loss: 2794.1641 - val_mean_absolute_error: 52.8096\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.7920 - mean_absolute_error: 1.8234 - val_loss: 2861.6196 - val_mean_absolute_error: 53.4328\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.7761 - mean_absolute_error: 1.4776 - val_loss: 3015.2759 - val_mean_absolute_error: 54.8336\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0267 - mean_absolute_error: 0.7838 - val_loss: 3138.4148 - val_mean_absolute_error: 55.9273\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6511 - mean_absolute_error: 0.9720 - val_loss: 3173.4590 - val_mean_absolute_error: 56.2280\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0818 - mean_absolute_error: 1.0855 - val_loss: 3132.0186 - val_mean_absolute_error: 55.8516\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4764 - mean_absolute_error: 0.9444 - val_loss: 3050.4365 - val_mean_absolute_error: 55.1153\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8604 - mean_absolute_error: 0.8510 - val_loss: 2966.2903 - val_mean_absolute_error: 54.3504\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9554 - mean_absolute_error: 0.8946 - val_loss: 2920.2217 - val_mean_absolute_error: 53.9278\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3449 - mean_absolute_error: 1.0939 - val_loss: 2928.0605 - val_mean_absolute_error: 54.0003\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2678 - mean_absolute_error: 1.0665 - val_loss: 2970.5264 - val_mean_absolute_error: 54.3909\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 586ms/step - loss: 9.1819 - mean_absolute_error: 2.5851 - val_loss: 3144.7085 - val_mean_absolute_error: 56.0137\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7221 - mean_absolute_error: 0.7674 - val_loss: 3045.9031 - val_mean_absolute_error: 55.1329\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6434 - mean_absolute_error: 1.0560 - val_loss: 3088.1663 - val_mean_absolute_error: 55.5119\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8084 - mean_absolute_error: 0.7017 - val_loss: 3156.2754 - val_mean_absolute_error: 56.1179\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3737 - mean_absolute_error: 0.5368 - val_loss: 3196.6411 - val_mean_absolute_error: 56.4735\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5843 - mean_absolute_error: 0.6690 - val_loss: 3190.3149 - val_mean_absolute_error: 56.4196\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4426 - mean_absolute_error: 0.5961 - val_loss: 3156.7817 - val_mean_absolute_error: 56.1263\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2144 - mean_absolute_error: 0.4233 - val_loss: 3120.1304 - val_mean_absolute_error: 55.8033\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2797 - mean_absolute_error: 0.4201 - val_loss: 3112.6404 - val_mean_absolute_error: 55.7372\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3061 - mean_absolute_error: 0.4673 - val_loss: 3138.0542 - val_mean_absolute_error: 55.9622\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1504 - mean_absolute_error: 0.2866 - val_loss: 3171.3572 - val_mean_absolute_error: 56.2555\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1802 - mean_absolute_error: 0.4188 - val_loss: 3181.5200 - val_mean_absolute_error: 56.3447\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 5.0365 - mean_absolute_error: 1.7952 - val_loss: 3003.1892 - val_mean_absolute_error: 54.7498\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.9449 - mean_absolute_error: 1.4133 - val_loss: 3020.6528 - val_mean_absolute_error: 54.8981\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1196 - mean_absolute_error: 1.1889 - val_loss: 3102.8364 - val_mean_absolute_error: 55.6221\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4637 - mean_absolute_error: 0.8531 - val_loss: 3115.4194 - val_mean_absolute_error: 55.7215\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3123 - mean_absolute_error: 0.7712 - val_loss: 3050.0654 - val_mean_absolute_error: 55.1240\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8768 - mean_absolute_error: 0.7448 - val_loss: 2998.9517 - val_mean_absolute_error: 54.6470\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9310 - mean_absolute_error: 0.9238 - val_loss: 3040.1519 - val_mean_absolute_error: 55.0023\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5398 - mean_absolute_error: 0.6008 - val_loss: 3077.5122 - val_mean_absolute_error: 55.3224\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6741 - mean_absolute_error: 0.8047 - val_loss: 3038.2195 - val_mean_absolute_error: 54.9531\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4663 - mean_absolute_error: 0.6209 - val_loss: 2983.4304 - val_mean_absolute_error: 54.4482\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6200 - mean_absolute_error: 0.6331 - val_loss: 3025.1719 - val_mean_absolute_error: 54.8315\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3766 - mean_absolute_error: 0.4804 - val_loss: 3074.5508 - val_mean_absolute_error: 55.2902\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4264 - mean_absolute_error: 0.6509 - val_loss: 3065.6167 - val_mean_absolute_error: 55.2227\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2862 - mean_absolute_error: 0.5161 - val_loss: 3026.6892 - val_mean_absolute_error: 54.8819\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2863 - mean_absolute_error: 0.5045 - val_loss: 3031.6719 - val_mean_absolute_error: 54.9351\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2768 - mean_absolute_error: 0.5083 - val_loss: 3072.6943 - val_mean_absolute_error: 55.3093\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2033 - mean_absolute_error: 0.3905 - val_loss: 3090.3472 - val_mean_absolute_error: 55.4682\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2200 - mean_absolute_error: 0.4432 - val_loss: 3063.8225 - val_mean_absolute_error: 55.2259\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1201 - mean_absolute_error: 0.2819 - val_loss: 3032.8416 - val_mean_absolute_error: 54.9400\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1613 - mean_absolute_error: 0.3512 - val_loss: 3047.4531 - val_mean_absolute_error: 55.0708\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 3.2168 - mean_absolute_error: 1.2702 - val_loss: 2798.8567 - val_mean_absolute_error: 52.8792\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 11.5641 - mean_absolute_error: 2.7668 - val_loss: 3056.7612 - val_mean_absolute_error: 55.2293\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9395 - mean_absolute_error: 1.0172 - val_loss: 3219.9377 - val_mean_absolute_error: 56.6586\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1905 - mean_absolute_error: 1.3680 - val_loss: 3241.6812 - val_mean_absolute_error: 56.8418\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6372 - mean_absolute_error: 1.4963 - val_loss: 3183.7776 - val_mean_absolute_error: 56.3337\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.3261 - mean_absolute_error: 1.1330 - val_loss: 3091.6953 - val_mean_absolute_error: 55.5166\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3276 - mean_absolute_error: 0.8344 - val_loss: 2998.2227 - val_mean_absolute_error: 54.6753\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7592 - mean_absolute_error: 1.2333 - val_loss: 2980.6196 - val_mean_absolute_error: 54.5083\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8965 - mean_absolute_error: 1.3090 - val_loss: 3022.2471 - val_mean_absolute_error: 54.8793\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2564 - mean_absolute_error: 1.0138 - val_loss: 3075.4229 - val_mean_absolute_error: 55.3548\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0419 - mean_absolute_error: 0.8201 - val_loss: 3111.0991 - val_mean_absolute_error: 55.6694\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 4.1897 - mean_absolute_error: 1.6258 - val_loss: 2922.3723 - val_mean_absolute_error: 54.0063\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.3798 - mean_absolute_error: 1.2764 - val_loss: 2961.9326 - val_mean_absolute_error: 54.3621\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6436 - mean_absolute_error: 1.0725 - val_loss: 3037.8640 - val_mean_absolute_error: 55.0445\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1490 - mean_absolute_error: 0.7620 - val_loss: 3073.2166 - val_mean_absolute_error: 55.3517\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0996 - mean_absolute_error: 0.7057 - val_loss: 3047.5837 - val_mean_absolute_error: 55.1103\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8652 - mean_absolute_error: 0.6791 - val_loss: 2986.5562 - val_mean_absolute_error: 54.5484\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8679 - mean_absolute_error: 0.8831 - val_loss: 2991.3142 - val_mean_absolute_error: 54.5825\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7936 - mean_absolute_error: 0.8262 - val_loss: 3039.3276 - val_mean_absolute_error: 55.0113\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7201 - mean_absolute_error: 0.7960 - val_loss: 3062.7861 - val_mean_absolute_error: 55.2225\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7415 - mean_absolute_error: 0.8020 - val_loss: 3046.5181 - val_mean_absolute_error: 55.0767\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6222 - mean_absolute_error: 0.7493 - val_loss: 3017.9067 - val_mean_absolute_error: 54.8201\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.1740 - mean_absolute_error: 1.3702 - val_loss: 2812.9341 - val_mean_absolute_error: 52.9910\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9878 - mean_absolute_error: 1.6984 - val_loss: 2967.1006 - val_mean_absolute_error: 54.4046\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4158 - mean_absolute_error: 0.9993 - val_loss: 3110.0854 - val_mean_absolute_error: 55.6830\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5752 - mean_absolute_error: 0.9091 - val_loss: 3128.9338 - val_mean_absolute_error: 55.8443\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6611 - mean_absolute_error: 0.9509 - val_loss: 3072.6018 - val_mean_absolute_error: 55.3384\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1109 - mean_absolute_error: 0.7519 - val_loss: 2993.0657 - val_mean_absolute_error: 54.6182\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9644 - mean_absolute_error: 0.8543 - val_loss: 2948.0835 - val_mean_absolute_error: 54.2046\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1457 - mean_absolute_error: 1.0283 - val_loss: 2963.7158 - val_mean_absolute_error: 54.3421\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0105 - mean_absolute_error: 0.9506 - val_loss: 3010.8330 - val_mean_absolute_error: 54.7663\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8411 - mean_absolute_error: 0.7603 - val_loss: 3055.7534 - val_mean_absolute_error: 55.1707\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8860 - mean_absolute_error: 0.7996 - val_loss: 3070.7048 - val_mean_absolute_error: 55.3049\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 1.7045 - mean_absolute_error: 1.1059 - val_loss: 2923.9058 - val_mean_absolute_error: 54.0390\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.3496 - mean_absolute_error: 2.2586 - val_loss: 3100.3711 - val_mean_absolute_error: 55.6287\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5430 - mean_absolute_error: 0.5457 - val_loss: 3232.6035 - val_mean_absolute_error: 56.7864\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2620 - mean_absolute_error: 0.9706 - val_loss: 3246.6848 - val_mean_absolute_error: 56.9087\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6222 - mean_absolute_error: 1.0794 - val_loss: 3212.5659 - val_mean_absolute_error: 56.6132\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9195 - mean_absolute_error: 0.8346 - val_loss: 3162.1089 - val_mean_absolute_error: 56.1719\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3767 - mean_absolute_error: 0.5019 - val_loss: 3114.6445 - val_mean_absolute_error: 55.7529\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3540 - mean_absolute_error: 0.4970 - val_loss: 3097.0903 - val_mean_absolute_error: 55.5977\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4503 - mean_absolute_error: 0.4976 - val_loss: 3113.0186 - val_mean_absolute_error: 55.7399\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3085 - mean_absolute_error: 0.4160 - val_loss: 3142.3528 - val_mean_absolute_error: 55.9994\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1926 - mean_absolute_error: 0.3956 - val_loss: 3167.1025 - val_mean_absolute_error: 56.2173\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 7.5806 - mean_absolute_error: 2.2854 - val_loss: 3077.3164 - val_mean_absolute_error: 55.4208\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.3002 - mean_absolute_error: 1.0047 - val_loss: 2999.9758 - val_mean_absolute_error: 54.7159\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.5649 - mean_absolute_error: 1.3860 - val_loss: 3062.8301 - val_mean_absolute_error: 55.2709\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5654 - mean_absolute_error: 0.9258 - val_loss: 3110.4268 - val_mean_absolute_error: 55.6863\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3935 - mean_absolute_error: 0.7293 - val_loss: 3100.4702 - val_mean_absolute_error: 55.5858\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1341 - mean_absolute_error: 0.6825 - val_loss: 3038.9629 - val_mean_absolute_error: 55.0217\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8656 - mean_absolute_error: 0.7908 - val_loss: 3000.4622 - val_mean_absolute_error: 54.6571\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8691 - mean_absolute_error: 0.8974 - val_loss: 3041.0571 - val_mean_absolute_error: 55.0067\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5776 - mean_absolute_error: 0.6573 - val_loss: 3066.9946 - val_mean_absolute_error: 55.2248\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6441 - mean_absolute_error: 0.7811 - val_loss: 3027.5681 - val_mean_absolute_error: 54.8548\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5025 - mean_absolute_error: 0.6323 - val_loss: 2982.8335 - val_mean_absolute_error: 54.4401\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5826 - mean_absolute_error: 0.5738 - val_loss: 3012.9272 - val_mean_absolute_error: 54.7229\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4152 - mean_absolute_error: 0.5274 - val_loss: 3048.9739 - val_mean_absolute_error: 55.0660\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4133 - mean_absolute_error: 0.6152 - val_loss: 3042.6191 - val_mean_absolute_error: 55.0221\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3423 - mean_absolute_error: 0.5019 - val_loss: 3016.2896 - val_mean_absolute_error: 54.7921\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3741 - mean_absolute_error: 0.5474 - val_loss: 3025.9834 - val_mean_absolute_error: 54.8841\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3432 - mean_absolute_error: 0.5173 - val_loss: 3057.3809 - val_mean_absolute_error: 55.1686\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3006 - mean_absolute_error: 0.4611 - val_loss: 3065.6504 - val_mean_absolute_error: 55.2395\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2884 - mean_absolute_error: 0.4870 - val_loss: 3041.1790 - val_mean_absolute_error: 55.0112\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2341 - mean_absolute_error: 0.3637 - val_loss: 3020.0237 - val_mean_absolute_error: 54.8127\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2614 - mean_absolute_error: 0.3583 - val_loss: 3035.3901 - val_mean_absolute_error: 54.9529\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 5.8904 - mean_absolute_error: 1.9602 - val_loss: 3072.4219 - val_mean_absolute_error: 55.3751\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.1996 - mean_absolute_error: 1.0273 - val_loss: 3029.1514 - val_mean_absolute_error: 54.9807\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2119 - mean_absolute_error: 1.2308 - val_loss: 3076.7397 - val_mean_absolute_error: 55.3974\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5535 - mean_absolute_error: 0.8687 - val_loss: 3112.1665 - val_mean_absolute_error: 55.7000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3747 - mean_absolute_error: 0.8028 - val_loss: 3070.7456 - val_mean_absolute_error: 55.3175\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1052 - mean_absolute_error: 0.7869 - val_loss: 3029.7480 - val_mean_absolute_error: 54.9370\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1472 - mean_absolute_error: 0.9702 - val_loss: 3084.6914 - val_mean_absolute_error: 55.4193\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9827 - mean_absolute_error: 0.8365 - val_loss: 3093.1899 - val_mean_absolute_error: 55.4900\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9818 - mean_absolute_error: 0.8884 - val_loss: 3048.2529 - val_mean_absolute_error: 55.0871\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9020 - mean_absolute_error: 0.7589 - val_loss: 3055.3022 - val_mean_absolute_error: 55.1572\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8192 - mean_absolute_error: 0.7260 - val_loss: 3099.6472 - val_mean_absolute_error: 55.5637\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7632 - mean_absolute_error: 0.7578 - val_loss: 3099.1584 - val_mean_absolute_error: 55.5673\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 6.2701 - mean_absolute_error: 2.0455 - val_loss: 3013.9712 - val_mean_absolute_error: 54.8401\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7030 - mean_absolute_error: 0.9986 - val_loss: 2923.2139 - val_mean_absolute_error: 54.0004\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9294 - mean_absolute_error: 1.2385 - val_loss: 3004.6353 - val_mean_absolute_error: 54.7351\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0730 - mean_absolute_error: 0.8242 - val_loss: 3074.9941 - val_mean_absolute_error: 55.3589\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1133 - mean_absolute_error: 0.7424 - val_loss: 3063.3916 - val_mean_absolute_error: 55.2469\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9402 - mean_absolute_error: 0.7409 - val_loss: 3001.5698 - val_mean_absolute_error: 54.6793\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8182 - mean_absolute_error: 0.8141 - val_loss: 2972.4207 - val_mean_absolute_error: 54.4080\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9162 - mean_absolute_error: 0.9271 - val_loss: 3010.2007 - val_mean_absolute_error: 54.7526\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6991 - mean_absolute_error: 0.7325 - val_loss: 3060.2573 - val_mean_absolute_error: 55.2103\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6837 - mean_absolute_error: 0.7290 - val_loss: 3071.4385 - val_mean_absolute_error: 55.3155\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6549 - mean_absolute_error: 0.6849 - val_loss: 3043.4346 - val_mean_absolute_error: 55.0657\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5022 - mean_absolute_error: 0.6119 - val_loss: 3008.8606 - val_mean_absolute_error: 54.7530\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 609ms/step - loss: 4.1072 - mean_absolute_error: 1.6232 - val_loss: 2887.4185 - val_mean_absolute_error: 53.6965\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.9646 - mean_absolute_error: 1.3722 - val_loss: 2949.7561 - val_mean_absolute_error: 54.2569\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6597 - mean_absolute_error: 1.0579 - val_loss: 3051.2461 - val_mean_absolute_error: 55.1636\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2440 - mean_absolute_error: 0.7229 - val_loss: 3070.9475 - val_mean_absolute_error: 55.3289\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2417 - mean_absolute_error: 0.8103 - val_loss: 3005.6646 - val_mean_absolute_error: 54.7320\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9308 - mean_absolute_error: 0.7433 - val_loss: 2941.6853 - val_mean_absolute_error: 54.1416\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1148 - mean_absolute_error: 1.0048 - val_loss: 2974.3613 - val_mean_absolute_error: 54.4358\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9095 - mean_absolute_error: 0.8465 - val_loss: 3036.5190 - val_mean_absolute_error: 54.9976\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8775 - mean_absolute_error: 0.8349 - val_loss: 3057.5918 - val_mean_absolute_error: 55.1895\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9031 - mean_absolute_error: 0.8215 - val_loss: 3033.1235 - val_mean_absolute_error: 54.9711\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7317 - mean_absolute_error: 0.7559 - val_loss: 2993.5356 - val_mean_absolute_error: 54.6134\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 3.1960 - mean_absolute_error: 1.4314 - val_loss: 2962.7410 - val_mean_absolute_error: 54.3774\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8423 - mean_absolute_error: 1.8388 - val_loss: 3085.4199 - val_mean_absolute_error: 55.4859\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6454 - mean_absolute_error: 0.6404 - val_loss: 3207.8010 - val_mean_absolute_error: 56.5700\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8172 - mean_absolute_error: 0.7943 - val_loss: 3210.6738 - val_mean_absolute_error: 56.5963\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7517 - mean_absolute_error: 0.7858 - val_loss: 3160.2039 - val_mean_absolute_error: 56.1547\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2323 - mean_absolute_error: 0.4017 - val_loss: 3103.7944 - val_mean_absolute_error: 55.6577\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3795 - mean_absolute_error: 0.4945 - val_loss: 3108.4885 - val_mean_absolute_error: 55.6995\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3131 - mean_absolute_error: 0.4475 - val_loss: 3147.8862 - val_mean_absolute_error: 56.0478\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1585 - mean_absolute_error: 0.3188 - val_loss: 3177.4075 - val_mean_absolute_error: 56.3081\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2627 - mean_absolute_error: 0.5062 - val_loss: 3172.0476 - val_mean_absolute_error: 56.2621\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2012 - mean_absolute_error: 0.4441 - val_loss: 3145.3018 - val_mean_absolute_error: 56.0274\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 7.2961 - mean_absolute_error: 2.2215 - val_loss: 2980.0085 - val_mean_absolute_error: 54.5510\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2717 - mean_absolute_error: 1.6942 - val_loss: 3043.9897 - val_mean_absolute_error: 55.1164\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2805 - mean_absolute_error: 1.1473 - val_loss: 3139.7681 - val_mean_absolute_error: 55.9564\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8215 - mean_absolute_error: 0.8616 - val_loss: 3146.2964 - val_mean_absolute_error: 56.0031\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6745 - mean_absolute_error: 0.8543 - val_loss: 3078.9604 - val_mean_absolute_error: 55.4005\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1290 - mean_absolute_error: 0.7475 - val_loss: 3012.4907 - val_mean_absolute_error: 54.7964\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2839 - mean_absolute_error: 1.0654 - val_loss: 3034.5688 - val_mean_absolute_error: 54.9839\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8529 - mean_absolute_error: 0.8380 - val_loss: 3092.4058 - val_mean_absolute_error: 55.4911\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7874 - mean_absolute_error: 0.7449 - val_loss: 3092.5293 - val_mean_absolute_error: 55.4805\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7478 - mean_absolute_error: 0.7897 - val_loss: 3033.1885 - val_mean_absolute_error: 54.9367\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5337 - mean_absolute_error: 0.6049 - val_loss: 2992.8740 - val_mean_absolute_error: 54.5619\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 8.9773 - mean_absolute_error: 2.5271 - val_loss: 2923.3735 - val_mean_absolute_error: 54.0308\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.4954 - mean_absolute_error: 2.0100 - val_loss: 2997.3059 - val_mean_absolute_error: 54.6920\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.7078 - mean_absolute_error: 1.4464 - val_loss: 3134.6465 - val_mean_absolute_error: 55.9087\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7467 - mean_absolute_error: 0.8528 - val_loss: 3157.8511 - val_mean_absolute_error: 56.1044\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.9069 - mean_absolute_error: 1.0165 - val_loss: 3082.0986 - val_mean_absolute_error: 55.4277\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2764 - mean_absolute_error: 0.8113 - val_loss: 2997.2993 - val_mean_absolute_error: 54.6619\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7183 - mean_absolute_error: 1.2489 - val_loss: 3039.4619 - val_mean_absolute_error: 55.0351\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1666 - mean_absolute_error: 0.9309 - val_loss: 3102.5957 - val_mean_absolute_error: 55.5937\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2020 - mean_absolute_error: 0.9117 - val_loss: 3116.0271 - val_mean_absolute_error: 55.7081\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2843 - mean_absolute_error: 1.0033 - val_loss: 3080.8491 - val_mean_absolute_error: 55.3909\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0241 - mean_absolute_error: 0.8388 - val_loss: 3028.6174 - val_mean_absolute_error: 54.9205\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.9646 - mean_absolute_error: 1.7995 - val_loss: 2938.6895 - val_mean_absolute_error: 54.1680\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.2115 - mean_absolute_error: 1.1863 - val_loss: 2925.5322 - val_mean_absolute_error: 54.0361\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9243 - mean_absolute_error: 1.1679 - val_loss: 3007.3074 - val_mean_absolute_error: 54.7677\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1201 - mean_absolute_error: 0.7861 - val_loss: 3065.1792 - val_mean_absolute_error: 55.2729\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0882 - mean_absolute_error: 0.7435 - val_loss: 3042.2500 - val_mean_absolute_error: 55.0569\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9070 - mean_absolute_error: 0.7498 - val_loss: 2981.2568 - val_mean_absolute_error: 54.4966\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8903 - mean_absolute_error: 0.8746 - val_loss: 2984.8269 - val_mean_absolute_error: 54.5222\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8226 - mean_absolute_error: 0.8260 - val_loss: 3033.3975 - val_mean_absolute_error: 54.9605\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7297 - mean_absolute_error: 0.7974 - val_loss: 3057.0142 - val_mean_absolute_error: 55.1777\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7254 - mean_absolute_error: 0.7691 - val_loss: 3034.5090 - val_mean_absolute_error: 54.9794\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6080 - mean_absolute_error: 0.6906 - val_loss: 3002.6384 - val_mean_absolute_error: 54.6943\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6032 - mean_absolute_error: 0.7359 - val_loss: 3011.4705 - val_mean_absolute_error: 54.7781\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 5.0541 - mean_absolute_error: 1.8133 - val_loss: 2926.8567 - val_mean_absolute_error: 54.0606\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2486 - mean_absolute_error: 1.1935 - val_loss: 2938.0239 - val_mean_absolute_error: 54.1567\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8762 - mean_absolute_error: 1.0891 - val_loss: 3022.9810 - val_mean_absolute_error: 54.9222\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.3871 - mean_absolute_error: 0.8566 - val_loss: 3070.2563 - val_mean_absolute_error: 55.3390\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3528 - mean_absolute_error: 0.7649 - val_loss: 3047.3367 - val_mean_absolute_error: 55.1241\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0742 - mean_absolute_error: 0.6740 - val_loss: 2987.4380 - val_mean_absolute_error: 54.5735\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9154 - mean_absolute_error: 0.8374 - val_loss: 2967.2583 - val_mean_absolute_error: 54.3808\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9002 - mean_absolute_error: 0.8989 - val_loss: 3018.9314 - val_mean_absolute_error: 54.8442\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7180 - mean_absolute_error: 0.7278 - val_loss: 3066.4473 - val_mean_absolute_error: 55.2682\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7490 - mean_absolute_error: 0.7613 - val_loss: 3058.7622 - val_mean_absolute_error: 55.1961\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6158 - mean_absolute_error: 0.7237 - val_loss: 3019.7637 - val_mean_absolute_error: 54.8412\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 3.9414 - mean_absolute_error: 1.6038 - val_loss: 3075.2314 - val_mean_absolute_error: 55.3963\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7863 - mean_absolute_error: 0.7380 - val_loss: 3103.6729 - val_mean_absolute_error: 55.6495\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4466 - mean_absolute_error: 0.5164 - val_loss: 3172.8354 - val_mean_absolute_error: 56.2610\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3985 - mean_absolute_error: 0.5448 - val_loss: 3176.5024 - val_mean_absolute_error: 56.2940\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3993 - mean_absolute_error: 0.5637 - val_loss: 3137.5659 - val_mean_absolute_error: 55.9516\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2303 - mean_absolute_error: 0.4000 - val_loss: 3106.8315 - val_mean_absolute_error: 55.6801\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3480 - mean_absolute_error: 0.4500 - val_loss: 3124.7256 - val_mean_absolute_error: 55.8393\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2212 - mean_absolute_error: 0.3303 - val_loss: 3158.8948 - val_mean_absolute_error: 56.1413\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1933 - mean_absolute_error: 0.3912 - val_loss: 3171.9800 - val_mean_absolute_error: 56.2572\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2360 - mean_absolute_error: 0.4717 - val_loss: 3154.3401 - val_mean_absolute_error: 56.1034\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1525 - mean_absolute_error: 0.3355 - val_loss: 3128.1123 - val_mean_absolute_error: 55.8729\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 680ms/step - loss: 5.9803 - mean_absolute_error: 1.9931 - val_loss: 3061.1733 - val_mean_absolute_error: 55.2769\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.4308 - mean_absolute_error: 1.1093 - val_loss: 3072.6284 - val_mean_absolute_error: 55.3716\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.0230 - mean_absolute_error: 0.9701 - val_loss: 3132.2671 - val_mean_absolute_error: 55.8927\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.8763 - mean_absolute_error: 0.8384 - val_loss: 3084.9294 - val_mean_absolute_error: 55.4659\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4963 - mean_absolute_error: 0.8306 - val_loss: 3032.1934 - val_mean_absolute_error: 54.9835\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4177 - mean_absolute_error: 1.0158 - val_loss: 3068.3833 - val_mean_absolute_error: 55.2937\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0048 - mean_absolute_error: 0.7500 - val_loss: 3082.3252 - val_mean_absolute_error: 55.4001\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8976 - mean_absolute_error: 0.7673 - val_loss: 3008.1565 - val_mean_absolute_error: 54.7147\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8045 - mean_absolute_error: 0.8296 - val_loss: 3043.4185 - val_mean_absolute_error: 55.0173\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6370 - mean_absolute_error: 0.7038 - val_loss: 3048.5923 - val_mean_absolute_error: 55.0525\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6469 - mean_absolute_error: 0.7671 - val_loss: 2993.6519 - val_mean_absolute_error: 54.5496\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6494 - mean_absolute_error: 0.6280 - val_loss: 3032.7983 - val_mean_absolute_error: 54.9121\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4954 - mean_absolute_error: 0.6245 - val_loss: 3053.4097 - val_mean_absolute_error: 55.1130\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4397 - mean_absolute_error: 0.6297 - val_loss: 3026.1445 - val_mean_absolute_error: 54.8806\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3904 - mean_absolute_error: 0.5498 - val_loss: 3041.4700 - val_mean_absolute_error: 55.0295\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3628 - mean_absolute_error: 0.5217 - val_loss: 3075.3267 - val_mean_absolute_error: 55.3398\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3624 - mean_absolute_error: 0.5163 - val_loss: 3058.3411 - val_mean_absolute_error: 55.1870\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2850 - mean_absolute_error: 0.4177 - val_loss: 3039.3320 - val_mean_absolute_error: 55.0108\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2582 - mean_absolute_error: 0.4475 - val_loss: 3062.0659 - val_mean_absolute_error: 55.2099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2062 - mean_absolute_error: 0.3890 - val_loss: 3065.1270 - val_mean_absolute_error: 55.2338\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2033 - mean_absolute_error: 0.3873 - val_loss: 3044.1450 - val_mean_absolute_error: 55.0462\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 677ms/step - loss: 5.2170 - mean_absolute_error: 1.8281 - val_loss: 2967.1875 - val_mean_absolute_error: 54.4218\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5929 - mean_absolute_error: 1.6328 - val_loss: 3051.9951 - val_mean_absolute_error: 55.1835\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.0731 - mean_absolute_error: 1.0882 - val_loss: 3126.2454 - val_mean_absolute_error: 55.8424\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.9502 - mean_absolute_error: 0.9006 - val_loss: 3136.0352 - val_mean_absolute_error: 55.9272\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.9647 - mean_absolute_error: 0.8658 - val_loss: 3102.4419 - val_mean_absolute_error: 55.6270\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6864 - mean_absolute_error: 0.8654 - val_loss: 3051.6748 - val_mean_absolute_error: 55.1684\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6184 - mean_absolute_error: 1.0187 - val_loss: 3038.5659 - val_mean_absolute_error: 55.0451\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5674 - mean_absolute_error: 1.0725 - val_loss: 3070.9370 - val_mean_absolute_error: 55.3310\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3223 - mean_absolute_error: 0.8547 - val_loss: 3101.0300 - val_mean_absolute_error: 55.5945\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2914 - mean_absolute_error: 0.8043 - val_loss: 3098.2021 - val_mean_absolute_error: 55.5614\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2039 - mean_absolute_error: 0.7954 - val_loss: 3061.3257 - val_mean_absolute_error: 55.2229\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 647ms/step - loss: 4.6873 - mean_absolute_error: 1.7400 - val_loss: 3058.4819 - val_mean_absolute_error: 55.2508\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.9568 - mean_absolute_error: 0.9951 - val_loss: 2913.4355 - val_mean_absolute_error: 53.9291\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6806 - mean_absolute_error: 1.3246 - val_loss: 3030.1924 - val_mean_absolute_error: 54.9831\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4133 - mean_absolute_error: 0.8951 - val_loss: 3117.5903 - val_mean_absolute_error: 55.7562\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6540 - mean_absolute_error: 0.8914 - val_loss: 3087.0400 - val_mean_absolute_error: 55.4778\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2462 - mean_absolute_error: 0.7679 - val_loss: 2995.2825 - val_mean_absolute_error: 54.6439\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0118 - mean_absolute_error: 0.8904 - val_loss: 2956.8760 - val_mean_absolute_error: 54.2834\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1199 - mean_absolute_error: 1.0291 - val_loss: 3008.4019 - val_mean_absolute_error: 54.7421\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7703 - mean_absolute_error: 0.7730 - val_loss: 3069.1123 - val_mean_absolute_error: 55.2849\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8232 - mean_absolute_error: 0.7973 - val_loss: 3079.4478 - val_mean_absolute_error: 55.3726\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8448 - mean_absolute_error: 0.8227 - val_loss: 3042.8799 - val_mean_absolute_error: 55.0377\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6796 - mean_absolute_error: 0.8022 - val_loss: 3002.9502 - val_mean_absolute_error: 54.6758\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 652ms/step - loss: 5.2247 - mean_absolute_error: 1.8559 - val_loss: 3091.7612 - val_mean_absolute_error: 55.5478\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.0971 - mean_absolute_error: 0.8665 - val_loss: 2875.8442 - val_mean_absolute_error: 53.5846\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.9555 - mean_absolute_error: 1.4165 - val_loss: 2957.4893 - val_mean_absolute_error: 54.3300\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7197 - mean_absolute_error: 1.0371 - val_loss: 3061.9702 - val_mean_absolute_error: 55.2713\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5036 - mean_absolute_error: 0.7855 - val_loss: 3098.4790 - val_mean_absolute_error: 55.5921\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6323 - mean_absolute_error: 0.8659 - val_loss: 3070.6133 - val_mean_absolute_error: 55.3369\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3078 - mean_absolute_error: 0.7710 - val_loss: 3008.0503 - val_mean_absolute_error: 54.7674\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0464 - mean_absolute_error: 0.7948 - val_loss: 2951.4871 - val_mean_absolute_error: 54.2445\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1789 - mean_absolute_error: 1.0291 - val_loss: 2962.5908 - val_mean_absolute_error: 54.3373\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0286 - mean_absolute_error: 0.9644 - val_loss: 3012.3167 - val_mean_absolute_error: 54.7855\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8264 - mean_absolute_error: 0.7425 - val_loss: 3054.4292 - val_mean_absolute_error: 55.1650\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8677 - mean_absolute_error: 0.7721 - val_loss: 3061.8838 - val_mean_absolute_error: 55.2319\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 2.8112 - mean_absolute_error: 1.3641 - val_loss: 3033.9092 - val_mean_absolute_error: 55.0277\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.6617 - mean_absolute_error: 1.1642 - val_loss: 3121.4019 - val_mean_absolute_error: 55.8090\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2762 - mean_absolute_error: 0.3927 - val_loss: 3208.9839 - val_mean_absolute_error: 56.5804\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6310 - mean_absolute_error: 0.7355 - val_loss: 3195.7554 - val_mean_absolute_error: 56.4648\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4106 - mean_absolute_error: 0.6148 - val_loss: 3143.6299 - val_mean_absolute_error: 56.0074\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1748 - mean_absolute_error: 0.3310 - val_loss: 3105.2922 - val_mean_absolute_error: 55.6681\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4043 - mean_absolute_error: 0.5272 - val_loss: 3116.1648 - val_mean_absolute_error: 55.7641\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2978 - mean_absolute_error: 0.4455 - val_loss: 3153.0825 - val_mean_absolute_error: 56.0896\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1549 - mean_absolute_error: 0.3020 - val_loss: 3182.7524 - val_mean_absolute_error: 56.3500\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2648 - mean_absolute_error: 0.5068 - val_loss: 3182.4465 - val_mean_absolute_error: 56.3478\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2366 - mean_absolute_error: 0.4820 - val_loss: 3159.1284 - val_mean_absolute_error: 56.1445\n",
      "1/1 [==============================] - 0s 81ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.9919 - mean_absolute_error: 1.5290 - val_loss: 2900.4248 - val_mean_absolute_error: 53.8159\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.1228 - mean_absolute_error: 2.1068 - val_loss: 3064.2817 - val_mean_absolute_error: 55.2957\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.0283 - mean_absolute_error: 1.0100 - val_loss: 3186.2397 - val_mean_absolute_error: 56.3695\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.5993 - mean_absolute_error: 1.1386 - val_loss: 3177.9709 - val_mean_absolute_error: 56.2951\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.3563 - mean_absolute_error: 1.0640 - val_loss: 3114.3142 - val_mean_absolute_error: 55.7324\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6581 - mean_absolute_error: 0.8318 - val_loss: 3042.3105 - val_mean_absolute_error: 55.0884\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7436 - mean_absolute_error: 1.0851 - val_loss: 3026.1450 - val_mean_absolute_error: 54.9382\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7069 - mean_absolute_error: 1.1371 - val_loss: 3059.4102 - val_mean_absolute_error: 55.2308\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2369 - mean_absolute_error: 0.8746 - val_loss: 3099.5669 - val_mean_absolute_error: 55.5820\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0826 - mean_absolute_error: 0.7154 - val_loss: 3113.0730 - val_mean_absolute_error: 55.6922\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0303 - mean_absolute_error: 0.7472 - val_loss: 3087.9976 - val_mean_absolute_error: 55.4567\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 4.3534 - mean_absolute_error: 1.6153 - val_loss: 2971.8809 - val_mean_absolute_error: 54.4649\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.5526 - mean_absolute_error: 1.6006 - val_loss: 3058.1372 - val_mean_absolute_error: 55.2341\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.9252 - mean_absolute_error: 1.0148 - val_loss: 3124.0542 - val_mean_absolute_error: 55.8143\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8135 - mean_absolute_error: 0.9058 - val_loss: 3116.7397 - val_mean_absolute_error: 55.7421\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6249 - mean_absolute_error: 0.8881 - val_loss: 3059.6558 - val_mean_absolute_error: 55.2246\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3600 - mean_absolute_error: 0.9040 - val_loss: 3027.0139 - val_mean_absolute_error: 54.9230\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3580 - mean_absolute_error: 1.0360 - val_loss: 3068.5449 - val_mean_absolute_error: 55.2854\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0588 - mean_absolute_error: 0.7729 - val_loss: 3101.8398 - val_mean_absolute_error: 55.5734\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1302 - mean_absolute_error: 0.9202 - val_loss: 3073.4116 - val_mean_absolute_error: 55.3130\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9683 - mean_absolute_error: 0.7948 - val_loss: 3030.2188 - val_mean_absolute_error: 54.9220\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0329 - mean_absolute_error: 0.8767 - val_loss: 3057.4028 - val_mean_absolute_error: 55.1685\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 612ms/step - loss: 4.0367 - mean_absolute_error: 1.5725 - val_loss: 2900.7139 - val_mean_absolute_error: 53.8122\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2714 - mean_absolute_error: 1.4345 - val_loss: 2988.3843 - val_mean_absolute_error: 54.6064\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8038 - mean_absolute_error: 1.0497 - val_loss: 3089.3774 - val_mean_absolute_error: 55.5069\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5517 - mean_absolute_error: 0.7794 - val_loss: 3107.3284 - val_mean_absolute_error: 55.6597\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5384 - mean_absolute_error: 0.8375 - val_loss: 3059.1870 - val_mean_absolute_error: 55.2232\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1296 - mean_absolute_error: 0.6570 - val_loss: 2988.6646 - val_mean_absolute_error: 54.5776\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0902 - mean_absolute_error: 0.9434 - val_loss: 2971.0747 - val_mean_absolute_error: 54.4064\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0820 - mean_absolute_error: 0.9941 - val_loss: 3013.6536 - val_mean_absolute_error: 54.7834\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8402 - mean_absolute_error: 0.7738 - val_loss: 3063.6465 - val_mean_absolute_error: 55.2289\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8944 - mean_absolute_error: 0.8476 - val_loss: 3071.2910 - val_mean_absolute_error: 55.2964\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8849 - mean_absolute_error: 0.8485 - val_loss: 3041.2070 - val_mean_absolute_error: 55.0257\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 3.9168 - mean_absolute_error: 1.5626 - val_loss: 2884.7454 - val_mean_absolute_error: 53.6688\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.0631 - mean_absolute_error: 1.4207 - val_loss: 2965.7947 - val_mean_absolute_error: 54.4060\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7123 - mean_absolute_error: 1.0365 - val_loss: 3053.9324 - val_mean_absolute_error: 55.1909\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3299 - mean_absolute_error: 0.7487 - val_loss: 3066.5288 - val_mean_absolute_error: 55.2935\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2071 - mean_absolute_error: 0.7422 - val_loss: 3009.0232 - val_mean_absolute_error: 54.7647\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9579 - mean_absolute_error: 0.7899 - val_loss: 2964.2571 - val_mean_absolute_error: 54.3458\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0651 - mean_absolute_error: 0.9812 - val_loss: 3001.7607 - val_mean_absolute_error: 54.6783\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8644 - mean_absolute_error: 0.8023 - val_loss: 3058.8062 - val_mean_absolute_error: 55.1894\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8808 - mean_absolute_error: 0.8346 - val_loss: 3067.2185 - val_mean_absolute_error: 55.2632\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8500 - mean_absolute_error: 0.8288 - val_loss: 3031.5952 - val_mean_absolute_error: 54.9415\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7094 - mean_absolute_error: 0.7731 - val_loss: 3000.6431 - val_mean_absolute_error: 54.6642\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 1.6065 - mean_absolute_error: 1.0392 - val_loss: 2736.7266 - val_mean_absolute_error: 52.2776\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 19.6326 - mean_absolute_error: 4.1246 - val_loss: 3022.5786 - val_mean_absolute_error: 54.9225\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8641 - mean_absolute_error: 1.2196 - val_loss: 3272.8662 - val_mean_absolute_error: 57.1338\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.4174 - mean_absolute_error: 1.2816 - val_loss: 3347.6426 - val_mean_absolute_error: 57.7779\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1999 - mean_absolute_error: 1.9105 - val_loss: 3319.7578 - val_mean_absolute_error: 57.5384\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8898 - mean_absolute_error: 1.6242 - val_loss: 3251.8420 - val_mean_absolute_error: 56.9523\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6928 - mean_absolute_error: 1.1128 - val_loss: 3178.4102 - val_mean_absolute_error: 56.3138\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4300 - mean_absolute_error: 0.5816 - val_loss: 3114.4810 - val_mean_absolute_error: 55.7509\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3305 - mean_absolute_error: 0.4649 - val_loss: 3068.7046 - val_mean_absolute_error: 55.3441\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8112 - mean_absolute_error: 0.7577 - val_loss: 3054.8220 - val_mean_absolute_error: 55.2208\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0548 - mean_absolute_error: 0.8901 - val_loss: 3065.9241 - val_mean_absolute_error: 55.3207\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 6.3356 - mean_absolute_error: 2.0670 - val_loss: 2875.2219 - val_mean_absolute_error: 53.5878\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.9458 - mean_absolute_error: 2.2810 - val_loss: 2975.3096 - val_mean_absolute_error: 54.4987\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2455 - mean_absolute_error: 1.5773 - val_loss: 3106.3115 - val_mean_absolute_error: 55.6679\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8132 - mean_absolute_error: 0.7527 - val_loss: 3173.4207 - val_mean_absolute_error: 56.2532\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.3503 - mean_absolute_error: 1.0888 - val_loss: 3165.1699 - val_mean_absolute_error: 56.1734\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.1433 - mean_absolute_error: 1.0402 - val_loss: 3110.3027 - val_mean_absolute_error: 55.6830\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4420 - mean_absolute_error: 0.7614 - val_loss: 3039.0640 - val_mean_absolute_error: 55.0419\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3226 - mean_absolute_error: 0.9597 - val_loss: 2994.2622 - val_mean_absolute_error: 54.6313\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5606 - mean_absolute_error: 1.1720 - val_loss: 3005.8003 - val_mean_absolute_error: 54.7281\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2608 - mean_absolute_error: 1.0495 - val_loss: 3047.2373 - val_mean_absolute_error: 55.0937\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9110 - mean_absolute_error: 0.7524 - val_loss: 3086.8367 - val_mean_absolute_error: 55.4402\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 4.6488 - mean_absolute_error: 1.7045 - val_loss: 2687.7695 - val_mean_absolute_error: 51.8170\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 19.7757 - mean_absolute_error: 3.4744 - val_loss: 2949.4590 - val_mean_absolute_error: 54.2576\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0473 - mean_absolute_error: 1.7372 - val_loss: 3170.1235 - val_mean_absolute_error: 56.2269\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.1456 - mean_absolute_error: 0.9487 - val_loss: 3274.5969 - val_mean_absolute_error: 57.1319\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5665 - mean_absolute_error: 1.7273 - val_loss: 3285.9722 - val_mean_absolute_error: 57.2263\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.8848 - mean_absolute_error: 1.7958 - val_loss: 3241.4238 - val_mean_absolute_error: 56.8388\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4259 - mean_absolute_error: 1.4486 - val_loss: 3167.6494 - val_mean_absolute_error: 56.1921\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9085 - mean_absolute_error: 0.9687 - val_loss: 3086.7939 - val_mean_absolute_error: 55.4765\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3402 - mean_absolute_error: 0.8758 - val_loss: 3018.0857 - val_mean_absolute_error: 54.8583\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7763 - mean_absolute_error: 1.1960 - val_loss: 2982.4263 - val_mean_absolute_error: 54.5324\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2847 - mean_absolute_error: 1.3965 - val_loss: 2985.2939 - val_mean_absolute_error: 54.5562\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 10.1753 - mean_absolute_error: 2.6445 - val_loss: 3072.5278 - val_mean_absolute_error: 55.3650\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.6517 - mean_absolute_error: 0.8183 - val_loss: 2831.8218 - val_mean_absolute_error: 53.1660\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0272 - mean_absolute_error: 1.6729 - val_loss: 2870.3701 - val_mean_absolute_error: 53.5214\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8396 - mean_absolute_error: 1.4531 - val_loss: 2971.3850 - val_mean_absolute_error: 54.4433\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3160 - mean_absolute_error: 0.9715 - val_loss: 3061.3892 - val_mean_absolute_error: 55.2535\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0845 - mean_absolute_error: 0.6318 - val_loss: 3110.6284 - val_mean_absolute_error: 55.6876\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3173 - mean_absolute_error: 0.7843 - val_loss: 3116.1296 - val_mean_absolute_error: 55.7291\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2485 - mean_absolute_error: 0.7756 - val_loss: 3085.0615 - val_mean_absolute_error: 55.4439\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9112 - mean_absolute_error: 0.6919 - val_loss: 3032.6218 - val_mean_absolute_error: 54.9648\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6792 - mean_absolute_error: 0.6804 - val_loss: 2979.7959 - val_mean_absolute_error: 54.4802\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7885 - mean_absolute_error: 0.8457 - val_loss: 2960.2996 - val_mean_absolute_error: 54.2984\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9140 - mean_absolute_error: 0.9217 - val_loss: 2977.8137 - val_mean_absolute_error: 54.4562\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 5.4106 - mean_absolute_error: 1.8923 - val_loss: 2871.4121 - val_mean_absolute_error: 53.5452\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2069 - mean_absolute_error: 1.4648 - val_loss: 2899.7380 - val_mean_absolute_error: 53.7993\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.2818 - mean_absolute_error: 1.2917 - val_loss: 3009.0366 - val_mean_absolute_error: 54.7875\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1320 - mean_absolute_error: 0.7972 - val_loss: 3087.7126 - val_mean_absolute_error: 55.4830\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2540 - mean_absolute_error: 0.8281 - val_loss: 3088.7161 - val_mean_absolute_error: 55.4800\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1756 - mean_absolute_error: 0.8315 - val_loss: 3028.3088 - val_mean_absolute_error: 54.9288\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8146 - mean_absolute_error: 0.7711 - val_loss: 2955.1067 - val_mean_absolute_error: 54.2592\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9592 - mean_absolute_error: 0.9428 - val_loss: 2950.9978 - val_mean_absolute_error: 54.2185\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9797 - mean_absolute_error: 0.9551 - val_loss: 3000.8638 - val_mean_absolute_error: 54.6714\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7392 - mean_absolute_error: 0.7590 - val_loss: 3055.5857 - val_mean_absolute_error: 55.1665\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7537 - mean_absolute_error: 0.7850 - val_loss: 3078.8406 - val_mean_absolute_error: 55.3770\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 12.3623 - mean_absolute_error: 3.2187 - val_loss: 3413.2214 - val_mean_absolute_error: 58.3379\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.5075 - mean_absolute_error: 2.5395 - val_loss: 3381.5410 - val_mean_absolute_error: 58.0675\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.7080 - mean_absolute_error: 2.2384 - val_loss: 3195.7412 - val_mean_absolute_error: 56.4648\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5262 - mean_absolute_error: 0.6895 - val_loss: 3031.0337 - val_mean_absolute_error: 55.0042\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5823 - mean_absolute_error: 1.1557 - val_loss: 2970.9502 - val_mean_absolute_error: 54.4606\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.5558 - mean_absolute_error: 1.7462 - val_loss: 3002.6411 - val_mean_absolute_error: 54.7474\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.3650 - mean_absolute_error: 1.4218 - val_loss: 3083.7729 - val_mean_absolute_error: 55.4749\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5541 - mean_absolute_error: 0.6329 - val_loss: 3172.8921 - val_mean_absolute_error: 56.2631\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3012 - mean_absolute_error: 0.4998 - val_loss: 3237.9836 - val_mean_absolute_error: 56.8319\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1617 - mean_absolute_error: 0.9375 - val_loss: 3260.1401 - val_mean_absolute_error: 57.0248\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.6427 - mean_absolute_error: 1.0843 - val_loss: 3244.5518 - val_mean_absolute_error: 56.8904\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2179 - mean_absolute_error: 0.9587 - val_loss: 3202.5815 - val_mean_absolute_error: 56.5247\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4765 - mean_absolute_error: 0.6562 - val_loss: 3150.4963 - val_mean_absolute_error: 56.0676\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1350 - mean_absolute_error: 0.2869 - val_loss: 3103.8345 - val_mean_absolute_error: 55.6553\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3427 - mean_absolute_error: 0.4932 - val_loss: 3076.0310 - val_mean_absolute_error: 55.4086\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 7.7940 - mean_absolute_error: 2.3828 - val_loss: 2776.6140 - val_mean_absolute_error: 52.6582\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 11.9362 - mean_absolute_error: 2.8179 - val_loss: 2879.3828 - val_mean_absolute_error: 53.6044\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.0644 - mean_absolute_error: 1.9633 - val_loss: 3084.4312 - val_mean_absolute_error: 55.4498\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9036 - mean_absolute_error: 0.6333 - val_loss: 3234.8130 - val_mean_absolute_error: 56.7569\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.1257 - mean_absolute_error: 1.4929 - val_loss: 3253.4148 - val_mean_absolute_error: 56.9049\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8076 - mean_absolute_error: 1.6397 - val_loss: 3173.1108 - val_mean_absolute_error: 56.1947\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6595 - mean_absolute_error: 1.1039 - val_loss: 3049.9990 - val_mean_absolute_error: 55.0952\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4718 - mean_absolute_error: 0.6079 - val_loss: 2945.0195 - val_mean_absolute_error: 54.1411\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4791 - mean_absolute_error: 1.1254 - val_loss: 2912.0171 - val_mean_absolute_error: 53.8345\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.1238 - mean_absolute_error: 1.2889 - val_loss: 2941.9058 - val_mean_absolute_error: 54.1050\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4087 - mean_absolute_error: 1.0797 - val_loss: 3007.2485 - val_mean_absolute_error: 54.6954\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 545ms/step - loss: 11.1166 - mean_absolute_error: 2.8664 - val_loss: 2933.2217 - val_mean_absolute_error: 54.1159\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.9090 - mean_absolute_error: 1.9659 - val_loss: 2879.0708 - val_mean_absolute_error: 53.6099\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.1797 - mean_absolute_error: 2.2050 - val_loss: 2991.8293 - val_mean_absolute_error: 54.6314\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.4080 - mean_absolute_error: 1.4386 - val_loss: 3114.3032 - val_mean_absolute_error: 55.7193\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4475 - mean_absolute_error: 0.8019 - val_loss: 3190.2373 - val_mean_absolute_error: 56.3806\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.4697 - mean_absolute_error: 1.2614 - val_loss: 3200.6826 - val_mean_absolute_error: 56.4648\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7526 - mean_absolute_error: 1.3709 - val_loss: 3160.6787 - val_mean_absolute_error: 56.1079\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9189 - mean_absolute_error: 1.1975 - val_loss: 3090.3579 - val_mean_absolute_error: 55.4786\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1131 - mean_absolute_error: 0.8582 - val_loss: 3017.3569 - val_mean_absolute_error: 54.8207\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2057 - mean_absolute_error: 1.0070 - val_loss: 2971.5884 - val_mean_absolute_error: 54.4050\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7212 - mean_absolute_error: 1.2642 - val_loss: 2966.7910 - val_mean_absolute_error: 54.3616\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7855 - mean_absolute_error: 1.2870 - val_loss: 2993.8083 - val_mean_absolute_error: 54.6072\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 2.4741 - mean_absolute_error: 1.1220 - val_loss: 2592.6338 - val_mean_absolute_error: 50.8962\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.2561 - mean_absolute_error: 2.9059 - val_loss: 2912.9204 - val_mean_absolute_error: 53.9165\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.5579 - mean_absolute_error: 1.3330 - val_loss: 3214.9207 - val_mean_absolute_error: 56.6019\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.9391 - mean_absolute_error: 1.3421 - val_loss: 3326.4067 - val_mean_absolute_error: 57.5560\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.8612 - mean_absolute_error: 1.9349 - val_loss: 3295.9612 - val_mean_absolute_error: 57.2889\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.8212 - mean_absolute_error: 1.7383 - val_loss: 3188.5759 - val_mean_absolute_error: 56.3551\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 2.1946 - mean_absolute_error: 1.1151 - val_loss: 3049.4673 - val_mean_absolute_error: 55.1228\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8269 - mean_absolute_error: 0.6736 - val_loss: 2925.7732 - val_mean_absolute_error: 54.0018\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4574 - mean_absolute_error: 1.1651 - val_loss: 2860.1018 - val_mean_absolute_error: 53.3960\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4928 - mean_absolute_error: 1.4481 - val_loss: 2862.8677 - val_mean_absolute_error: 53.4193\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.3444 - mean_absolute_error: 1.4164 - val_loss: 2914.5063 - val_mean_absolute_error: 53.8948\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 2.8555 - mean_absolute_error: 1.3474 - val_loss: 2499.1560 - val_mean_absolute_error: 49.9720\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 21.5010 - mean_absolute_error: 3.4003 - val_loss: 2854.0098 - val_mean_absolute_error: 53.3748\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5752 - mean_absolute_error: 1.5720 - val_loss: 3207.2207 - val_mean_absolute_error: 56.5445\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.8942 - mean_absolute_error: 1.3531 - val_loss: 3383.4238 - val_mean_absolute_error: 58.0538\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.9595 - mean_absolute_error: 2.3015 - val_loss: 3358.5029 - val_mean_absolute_error: 57.8389\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.1412 - mean_absolute_error: 2.1679 - val_loss: 3233.9705 - val_mean_absolute_error: 56.7648\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5011 - mean_absolute_error: 1.4840 - val_loss: 3080.0549 - val_mean_absolute_error: 55.4109\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1721 - mean_absolute_error: 0.8220 - val_loss: 2942.0015 - val_mean_absolute_error: 54.1650\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3515 - mean_absolute_error: 1.0737 - val_loss: 2856.6943 - val_mean_absolute_error: 53.3799\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.5645 - mean_absolute_error: 1.4437 - val_loss: 2834.1377 - val_mean_absolute_error: 53.1696\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.9497 - mean_absolute_error: 1.5289 - val_loss: 2862.7856 - val_mean_absolute_error: 53.4345\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 534ms/step - loss: 0.6047 - mean_absolute_error: 0.6758 - val_loss: 3781.6602 - val_mean_absolute_error: 61.3764\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 41.7499 - mean_absolute_error: 5.7964 - val_loss: 3272.5872 - val_mean_absolute_error: 57.1421\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8461 - mean_absolute_error: 1.1487 - val_loss: 2852.2578 - val_mean_absolute_error: 53.3756\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 10.6708 - mean_absolute_error: 2.9786 - val_loss: 2758.5112 - val_mean_absolute_error: 52.4961\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 18.7218 - mean_absolute_error: 3.9467 - val_loss: 2838.0093 - val_mean_absolute_error: 53.2415\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 11.6556 - mean_absolute_error: 3.1224 - val_loss: 2985.2559 - val_mean_absolute_error: 54.5931\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2479 - mean_absolute_error: 1.6504 - val_loss: 3138.4077 - val_mean_absolute_error: 55.9625\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1853 - mean_absolute_error: 0.3630 - val_loss: 3261.4902 - val_mean_absolute_error: 57.0387\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7093 - mean_absolute_error: 1.1198 - val_loss: 3338.2712 - val_mean_absolute_error: 57.6998\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3064 - mean_absolute_error: 1.7649 - val_loss: 3362.2715 - val_mean_absolute_error: 57.9047\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.3314 - mean_absolute_error: 1.9813 - val_loss: 3342.5859 - val_mean_absolute_error: 57.7372\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3820 - mean_absolute_error: 1.7847 - val_loss: 3291.2605 - val_mean_absolute_error: 57.2976\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4805 - mean_absolute_error: 1.3020 - val_loss: 3223.6406 - val_mean_absolute_error: 56.7120\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8743 - mean_absolute_error: 0.8363 - val_loss: 3151.4092 - val_mean_absolute_error: 56.0797\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 2.1401 - mean_absolute_error: 0.8244 - val_loss: 2748.8699 - val_mean_absolute_error: 52.3610\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 12.0399 - mean_absolute_error: 2.8174 - val_loss: 3086.0615 - val_mean_absolute_error: 55.4344\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8020 - mean_absolute_error: 0.7094 - val_loss: 3311.1719 - val_mean_absolute_error: 57.3940\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6.4061 - mean_absolute_error: 2.1159 - val_loss: 3278.9839 - val_mean_absolute_error: 57.1128\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.1604 - mean_absolute_error: 1.9018 - val_loss: 3151.6570 - val_mean_absolute_error: 55.9984\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3910 - mean_absolute_error: 1.0812 - val_loss: 3019.5684 - val_mean_absolute_error: 54.8206\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6552 - mean_absolute_error: 0.7637 - val_loss: 2929.6260 - val_mean_absolute_error: 54.0057\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9962 - mean_absolute_error: 1.2824 - val_loss: 2915.1060 - val_mean_absolute_error: 53.8741\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.4174 - mean_absolute_error: 1.3737 - val_loss: 2956.5947 - val_mean_absolute_error: 54.2556\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4707 - mean_absolute_error: 1.1257 - val_loss: 3024.5151 - val_mean_absolute_error: 54.8721\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5451 - mean_absolute_error: 0.7037 - val_loss: 3094.9104 - val_mean_absolute_error: 55.5041\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 546ms/step - loss: 2.2558 - mean_absolute_error: 1.0170 - val_loss: 3506.9321 - val_mean_absolute_error: 59.0818\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 17.5688 - mean_absolute_error: 3.4743 - val_loss: 3118.8762 - val_mean_absolute_error: 55.7524\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1417 - mean_absolute_error: 0.7831 - val_loss: 2797.9106 - val_mean_absolute_error: 52.8313\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.1160 - mean_absolute_error: 2.5070 - val_loss: 2817.3154 - val_mean_absolute_error: 53.0135\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 7.9368 - mean_absolute_error: 2.3683 - val_loss: 2958.2266 - val_mean_absolute_error: 54.3114\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.5246 - mean_absolute_error: 1.4839 - val_loss: 3109.2544 - val_mean_absolute_error: 55.6674\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9988 - mean_absolute_error: 0.7016 - val_loss: 3219.6255 - val_mean_absolute_error: 56.6385\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 2.4937 - mean_absolute_error: 1.2567 - val_loss: 3266.7495 - val_mean_absolute_error: 57.0472\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7219 - mean_absolute_error: 1.5678 - val_loss: 3255.7905 - val_mean_absolute_error: 56.9520\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3169 - mean_absolute_error: 1.4720 - val_loss: 3204.0718 - val_mean_absolute_error: 56.5019\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.0082 - mean_absolute_error: 1.1360 - val_loss: 3131.8662 - val_mean_absolute_error: 55.8676\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0570 - mean_absolute_error: 0.7568 - val_loss: 3059.0000 - val_mean_absolute_error: 55.2188\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0492 - mean_absolute_error: 0.9076 - val_loss: 3003.9336 - val_mean_absolute_error: 54.7226\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 4.2200 - mean_absolute_error: 1.5798 - val_loss: 2611.4497 - val_mean_absolute_error: 51.0637\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 14.5060 - mean_absolute_error: 2.8312 - val_loss: 2850.1843 - val_mean_absolute_error: 53.3172\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.3819 - mean_absolute_error: 1.6232 - val_loss: 3123.1067 - val_mean_absolute_error: 55.7761\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5460 - mean_absolute_error: 0.9192 - val_loss: 3262.0547 - val_mean_absolute_error: 56.9755\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3898 - mean_absolute_error: 1.5332 - val_loss: 3246.4585 - val_mean_absolute_error: 56.8310\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0357 - mean_absolute_error: 1.4049 - val_loss: 3132.4453 - val_mean_absolute_error: 55.8333\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5020 - mean_absolute_error: 0.9650 - val_loss: 2980.5972 - val_mean_absolute_error: 54.4795\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9464 - mean_absolute_error: 0.9271 - val_loss: 2882.6846 - val_mean_absolute_error: 53.5888\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2457 - mean_absolute_error: 1.3773 - val_loss: 2883.2053 - val_mean_absolute_error: 53.5952\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2970 - mean_absolute_error: 1.3803 - val_loss: 2945.5703 - val_mean_absolute_error: 54.1685\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2460 - mean_absolute_error: 1.0817 - val_loss: 3032.4111 - val_mean_absolute_error: 54.9545\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.9081 - mean_absolute_error: 2.9165 - val_loss: 2901.1743 - val_mean_absolute_error: 53.8106\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.8754 - mean_absolute_error: 1.4177 - val_loss: 2746.4546 - val_mean_absolute_error: 52.3552\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6.0202 - mean_absolute_error: 2.0330 - val_loss: 2851.1680 - val_mean_absolute_error: 53.3285\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.8645 - mean_absolute_error: 1.5301 - val_loss: 3008.5396 - val_mean_absolute_error: 54.7638\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9894 - mean_absolute_error: 0.8064 - val_loss: 3136.5388 - val_mean_absolute_error: 55.9008\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5574 - mean_absolute_error: 0.9267 - val_loss: 3195.2812 - val_mean_absolute_error: 56.4126\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2893 - mean_absolute_error: 1.1350 - val_loss: 3187.6125 - val_mean_absolute_error: 56.3427\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.1200 - mean_absolute_error: 1.0736 - val_loss: 3136.6033 - val_mean_absolute_error: 55.8913\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3754 - mean_absolute_error: 0.8718 - val_loss: 3065.6543 - val_mean_absolute_error: 55.2579\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8245 - mean_absolute_error: 0.7676 - val_loss: 2994.4182 - val_mean_absolute_error: 54.6141\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8296 - mean_absolute_error: 0.8567 - val_loss: 2942.9048 - val_mean_absolute_error: 54.1449\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1695 - mean_absolute_error: 1.0631 - val_loss: 2923.3823 - val_mean_absolute_error: 53.9667\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 639ms/step - loss: 2.9281 - mean_absolute_error: 1.3945 - val_loss: 3075.3018 - val_mean_absolute_error: 55.3973\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7673 - mean_absolute_error: 0.7087 - val_loss: 3153.0159 - val_mean_absolute_error: 56.0873\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3975 - mean_absolute_error: 0.5286 - val_loss: 3145.6958 - val_mean_absolute_error: 56.0260\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2749 - mean_absolute_error: 0.4680 - val_loss: 3109.9900 - val_mean_absolute_error: 55.7120\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3414 - mean_absolute_error: 0.4350 - val_loss: 3171.0493 - val_mean_absolute_error: 56.2502\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3000 - mean_absolute_error: 0.5067 - val_loss: 3150.2559 - val_mean_absolute_error: 56.0689\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1857 - mean_absolute_error: 0.3672 - val_loss: 3117.0967 - val_mean_absolute_error: 55.7777\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2517 - mean_absolute_error: 0.4216 - val_loss: 3153.0991 - val_mean_absolute_error: 56.0961\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1485 - mean_absolute_error: 0.3226 - val_loss: 3171.8687 - val_mean_absolute_error: 56.2615\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2055 - mean_absolute_error: 0.4504 - val_loss: 3130.4668 - val_mean_absolute_error: 55.8987\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1681 - mean_absolute_error: 0.3517 - val_loss: 3131.8569 - val_mean_absolute_error: 55.9116\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 641ms/step - loss: 6.1591 - mean_absolute_error: 2.0369 - val_loss: 3135.9219 - val_mean_absolute_error: 55.9309\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.1416 - mean_absolute_error: 0.9115 - val_loss: 2960.6711 - val_mean_absolute_error: 54.3544\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2879 - mean_absolute_error: 1.6148 - val_loss: 3034.1636 - val_mean_absolute_error: 55.0164\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8708 - mean_absolute_error: 1.1232 - val_loss: 3111.2446 - val_mean_absolute_error: 55.7054\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6919 - mean_absolute_error: 0.8120 - val_loss: 3138.0015 - val_mean_absolute_error: 55.9399\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8409 - mean_absolute_error: 0.8356 - val_loss: 3121.9451 - val_mean_absolute_error: 55.7920\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6046 - mean_absolute_error: 0.7810 - val_loss: 3075.6089 - val_mean_absolute_error: 55.3730\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2663 - mean_absolute_error: 0.7715 - val_loss: 3019.5654 - val_mean_absolute_error: 54.8602\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2650 - mean_absolute_error: 1.0091 - val_loss: 3007.9619 - val_mean_absolute_error: 54.7425\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1132 - mean_absolute_error: 0.9892 - val_loss: 3034.1094 - val_mean_absolute_error: 54.9665\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8079 - mean_absolute_error: 0.7423 - val_loss: 3058.7007 - val_mean_absolute_error: 55.1768\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7449 - mean_absolute_error: 0.7181 - val_loss: 3060.0100 - val_mean_absolute_error: 55.1774\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 674ms/step - loss: 6.6981 - mean_absolute_error: 2.1323 - val_loss: 3099.9990 - val_mean_absolute_error: 55.6163\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0629 - mean_absolute_error: 0.9541 - val_loss: 2970.4111 - val_mean_absolute_error: 54.4464\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3070 - mean_absolute_error: 1.5911 - val_loss: 3076.6616 - val_mean_absolute_error: 55.4017\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7891 - mean_absolute_error: 0.9241 - val_loss: 3155.4741 - val_mean_absolute_error: 56.0998\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1163 - mean_absolute_error: 0.8881 - val_loss: 3144.9971 - val_mean_absolute_error: 56.0041\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9581 - mean_absolute_error: 0.8782 - val_loss: 3092.0493 - val_mean_absolute_error: 55.5308\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6129 - mean_absolute_error: 0.9329 - val_loss: 3037.2480 - val_mean_absolute_error: 55.0355\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6844 - mean_absolute_error: 1.0824 - val_loss: 3042.0586 - val_mean_absolute_error: 55.0731\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4839 - mean_absolute_error: 1.0257 - val_loss: 3079.8657 - val_mean_absolute_error: 55.4088\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2565 - mean_absolute_error: 0.8700 - val_loss: 3104.4053 - val_mean_absolute_error: 55.6238\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2607 - mean_absolute_error: 0.8344 - val_loss: 3093.9658 - val_mean_absolute_error: 55.5234\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1347 - mean_absolute_error: 0.8175 - val_loss: 3056.5347 - val_mean_absolute_error: 55.1782\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 645ms/step - loss: 6.0070 - mean_absolute_error: 2.0006 - val_loss: 2995.1777 - val_mean_absolute_error: 54.6803\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.1250 - mean_absolute_error: 1.1453 - val_loss: 2964.4324 - val_mean_absolute_error: 54.3946\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0510 - mean_absolute_error: 1.1346 - val_loss: 3047.1646 - val_mean_absolute_error: 55.1355\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5067 - mean_absolute_error: 0.8657 - val_loss: 3079.6196 - val_mean_absolute_error: 55.4199\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4640 - mean_absolute_error: 0.7855 - val_loss: 3030.5137 - val_mean_absolute_error: 54.9728\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1560 - mean_absolute_error: 0.7614 - val_loss: 2977.1711 - val_mean_absolute_error: 54.4802\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1339 - mean_absolute_error: 0.9640 - val_loss: 3010.8789 - val_mean_absolute_error: 54.7757\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8788 - mean_absolute_error: 0.7863 - val_loss: 3057.7900 - val_mean_absolute_error: 55.1910\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8536 - mean_absolute_error: 0.7757 - val_loss: 3049.2563 - val_mean_absolute_error: 55.1091\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7576 - mean_absolute_error: 0.7834 - val_loss: 3011.5427 - val_mean_absolute_error: 54.7639\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6862 - mean_absolute_error: 0.7520 - val_loss: 3009.5708 - val_mean_absolute_error: 54.7516\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6169 - mean_absolute_error: 0.7020 - val_loss: 3046.0527 - val_mean_absolute_error: 55.0926\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 5.5416 - mean_absolute_error: 1.9071 - val_loss: 3092.4824 - val_mean_absolute_error: 55.5495\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.9430 - mean_absolute_error: 0.8677 - val_loss: 2869.4192 - val_mean_absolute_error: 53.5277\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.9395 - mean_absolute_error: 1.4110 - val_loss: 2942.2080 - val_mean_absolute_error: 54.1906\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6867 - mean_absolute_error: 1.0620 - val_loss: 3040.4749 - val_mean_absolute_error: 55.0749\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2916 - mean_absolute_error: 0.7662 - val_loss: 3084.8225 - val_mean_absolute_error: 55.4654\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4062 - mean_absolute_error: 0.8246 - val_loss: 3071.1765 - val_mean_absolute_error: 55.3371\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2064 - mean_absolute_error: 0.7633 - val_loss: 3017.8250 - val_mean_absolute_error: 54.8507\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9401 - mean_absolute_error: 0.7278 - val_loss: 2958.5566 - val_mean_absolute_error: 54.3045\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0429 - mean_absolute_error: 0.9721 - val_loss: 2959.9363 - val_mean_absolute_error: 54.3094\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9739 - mean_absolute_error: 0.9470 - val_loss: 3008.8213 - val_mean_absolute_error: 54.7493\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7700 - mean_absolute_error: 0.7546 - val_loss: 3053.8921 - val_mean_absolute_error: 55.1560\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8150 - mean_absolute_error: 0.7915 - val_loss: 3065.6250 - val_mean_absolute_error: 55.2621\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 625ms/step - loss: 6.0034 - mean_absolute_error: 2.0868 - val_loss: 2973.6147 - val_mean_absolute_error: 54.4858\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6287 - mean_absolute_error: 1.7229 - val_loss: 3060.1399 - val_mean_absolute_error: 55.2646\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1427 - mean_absolute_error: 0.8791 - val_loss: 3167.0779 - val_mean_absolute_error: 56.2128\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4001 - mean_absolute_error: 0.5093 - val_loss: 3215.5762 - val_mean_absolute_error: 56.6385\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9077 - mean_absolute_error: 0.8379 - val_loss: 3207.3801 - val_mean_absolute_error: 56.5678\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7335 - mean_absolute_error: 0.7724 - val_loss: 3167.9517 - val_mean_absolute_error: 56.2235\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3009 - mean_absolute_error: 0.4989 - val_loss: 3118.7612 - val_mean_absolute_error: 55.7902\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2432 - mean_absolute_error: 0.3853 - val_loss: 3088.4160 - val_mean_absolute_error: 55.5212\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4733 - mean_absolute_error: 0.5646 - val_loss: 3093.7915 - val_mean_absolute_error: 55.5692\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3952 - mean_absolute_error: 0.5119 - val_loss: 3122.1497 - val_mean_absolute_error: 55.8199\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1970 - mean_absolute_error: 0.3252 - val_loss: 3153.8882 - val_mean_absolute_error: 56.0991\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 4.3018 - mean_absolute_error: 1.5937 - val_loss: 2887.9746 - val_mean_absolute_error: 53.7032\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.8030 - mean_absolute_error: 2.2097 - val_loss: 3052.2432 - val_mean_absolute_error: 55.1876\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0918 - mean_absolute_error: 1.0801 - val_loss: 3181.3193 - val_mean_absolute_error: 56.3234\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.5150 - mean_absolute_error: 1.1217 - val_loss: 3172.4019 - val_mean_absolute_error: 56.2393\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2721 - mean_absolute_error: 1.0539 - val_loss: 3093.7356 - val_mean_absolute_error: 55.5399\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4674 - mean_absolute_error: 0.8443 - val_loss: 3009.5034 - val_mean_absolute_error: 54.7809\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7184 - mean_absolute_error: 1.1552 - val_loss: 3001.3135 - val_mean_absolute_error: 54.7001\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6037 - mean_absolute_error: 1.1532 - val_loss: 3045.6594 - val_mean_absolute_error: 55.0916\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0706 - mean_absolute_error: 0.8323 - val_loss: 3087.7532 - val_mean_absolute_error: 55.4600\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9902 - mean_absolute_error: 0.7257 - val_loss: 3098.3384 - val_mean_absolute_error: 55.5453\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9808 - mean_absolute_error: 0.7919 - val_loss: 3077.0503 - val_mean_absolute_error: 55.3434\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.5426 - mean_absolute_error: 1.9105 - val_loss: 2901.1421 - val_mean_absolute_error: 53.8181\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.4558 - mean_absolute_error: 2.0500 - val_loss: 3004.0571 - val_mean_absolute_error: 54.7429\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.2033 - mean_absolute_error: 1.3026 - val_loss: 3126.4971 - val_mean_absolute_error: 55.8307\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7806 - mean_absolute_error: 0.8910 - val_loss: 3150.0166 - val_mean_absolute_error: 56.0336\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9315 - mean_absolute_error: 1.0303 - val_loss: 3097.3464 - val_mean_absolute_error: 55.5639\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4047 - mean_absolute_error: 0.8229 - val_loss: 3029.7397 - val_mean_absolute_error: 54.9564\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4009 - mean_absolute_error: 1.0394 - val_loss: 3008.9502 - val_mean_absolute_error: 54.7623\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4433 - mean_absolute_error: 1.1155 - val_loss: 3040.5178 - val_mean_absolute_error: 55.0374\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1491 - mean_absolute_error: 0.8865 - val_loss: 3080.3389 - val_mean_absolute_error: 55.3856\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1381 - mean_absolute_error: 0.8810 - val_loss: 3090.9250 - val_mean_absolute_error: 55.4719\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1980 - mean_absolute_error: 0.9801 - val_loss: 3067.3655 - val_mean_absolute_error: 55.2530\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 6.7486 - mean_absolute_error: 2.1532 - val_loss: 3038.4888 - val_mean_absolute_error: 55.0722\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.0388 - mean_absolute_error: 1.0665 - val_loss: 2943.4927 - val_mean_absolute_error: 54.2074\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.3751 - mean_absolute_error: 1.2117 - val_loss: 2985.8228 - val_mean_absolute_error: 54.5870\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7085 - mean_absolute_error: 1.0309 - val_loss: 3060.3772 - val_mean_absolute_error: 55.2529\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4416 - mean_absolute_error: 0.7903 - val_loss: 3084.2175 - val_mean_absolute_error: 55.4581\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4112 - mean_absolute_error: 0.8192 - val_loss: 3035.0605 - val_mean_absolute_error: 55.0103\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0553 - mean_absolute_error: 0.6850 - val_loss: 2964.0188 - val_mean_absolute_error: 54.3603\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0978 - mean_absolute_error: 0.9744 - val_loss: 2963.9399 - val_mean_absolute_error: 54.3512\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9892 - mean_absolute_error: 0.9428 - val_loss: 3017.1968 - val_mean_absolute_error: 54.8265\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8112 - mean_absolute_error: 0.7768 - val_loss: 3056.7622 - val_mean_absolute_error: 55.1772\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8876 - mean_absolute_error: 0.8391 - val_loss: 3049.3965 - val_mean_absolute_error: 55.1079\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7978 - mean_absolute_error: 0.8280 - val_loss: 3014.4607 - val_mean_absolute_error: 54.7901\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 7.2638 - mean_absolute_error: 2.2503 - val_loss: 3020.4919 - val_mean_absolute_error: 54.9069\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6306 - mean_absolute_error: 0.9727 - val_loss: 2895.6714 - val_mean_absolute_error: 53.7605\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0868 - mean_absolute_error: 1.2548 - val_loss: 2984.4392 - val_mean_absolute_error: 54.5674\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1421 - mean_absolute_error: 0.8495 - val_loss: 3077.5120 - val_mean_absolute_error: 55.4015\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2595 - mean_absolute_error: 0.7783 - val_loss: 3071.5415 - val_mean_absolute_error: 55.3406\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0885 - mean_absolute_error: 0.7340 - val_loss: 3003.7705 - val_mean_absolute_error: 54.7213\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8443 - mean_absolute_error: 0.7919 - val_loss: 2962.7231 - val_mean_absolute_error: 54.3385\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9603 - mean_absolute_error: 0.9575 - val_loss: 3000.8628 - val_mean_absolute_error: 54.6756\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7060 - mean_absolute_error: 0.7685 - val_loss: 3065.4177 - val_mean_absolute_error: 55.2532\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7092 - mean_absolute_error: 0.7706 - val_loss: 3082.4167 - val_mean_absolute_error: 55.4030\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7336 - mean_absolute_error: 0.7776 - val_loss: 3049.5073 - val_mean_absolute_error: 55.1038\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5696 - mean_absolute_error: 0.7342 - val_loss: 3010.9075 - val_mean_absolute_error: 54.7556\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 14.3927 - mean_absolute_error: 3.2032 - val_loss: 2983.2524 - val_mean_absolute_error: 54.5606\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.0185 - mean_absolute_error: 1.6305 - val_loss: 2975.0376 - val_mean_absolute_error: 54.4911\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.1961 - mean_absolute_error: 1.6780 - val_loss: 3097.0481 - val_mean_absolute_error: 55.5877\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4756 - mean_absolute_error: 0.5292 - val_loss: 3221.6650 - val_mean_absolute_error: 56.6876\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9252 - mean_absolute_error: 0.8676 - val_loss: 3254.3127 - val_mean_absolute_error: 56.9729\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5100 - mean_absolute_error: 1.0656 - val_loss: 3215.0300 - val_mean_absolute_error: 56.6330\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7141 - mean_absolute_error: 0.7816 - val_loss: 3146.1167 - val_mean_absolute_error: 56.0303\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1684 - mean_absolute_error: 0.3352 - val_loss: 3088.0474 - val_mean_absolute_error: 55.5172\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6222 - mean_absolute_error: 0.6809 - val_loss: 3079.4541 - val_mean_absolute_error: 55.4420\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7329 - mean_absolute_error: 0.7503 - val_loss: 3112.9873 - val_mean_absolute_error: 55.7414\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2878 - mean_absolute_error: 0.4754 - val_loss: 3161.4385 - val_mean_absolute_error: 56.1697\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1588 - mean_absolute_error: 0.3717 - val_loss: 3196.6030 - val_mean_absolute_error: 56.4783\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 2.0759 - mean_absolute_error: 1.0201 - val_loss: 3617.0493 - val_mean_absolute_error: 59.9639\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 26.9172 - mean_absolute_error: 4.3071 - val_loss: 3112.7720 - val_mean_absolute_error: 55.6670\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0769 - mean_absolute_error: 0.8793 - val_loss: 2727.8691 - val_mean_absolute_error: 52.1491\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 11.2561 - mean_absolute_error: 2.7189 - val_loss: 2762.1865 - val_mean_absolute_error: 52.4754\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 8.9457 - mean_absolute_error: 2.4726 - val_loss: 2901.2222 - val_mean_absolute_error: 53.7711\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.0002 - mean_absolute_error: 1.5936 - val_loss: 3047.8599 - val_mean_absolute_error: 55.1041\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9089 - mean_absolute_error: 0.7677 - val_loss: 3159.2246 - val_mean_absolute_error: 56.0975\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7806 - mean_absolute_error: 1.0148 - val_loss: 3217.5854 - val_mean_absolute_error: 56.6129\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.0021 - mean_absolute_error: 1.4195 - val_loss: 3228.5728 - val_mean_absolute_error: 56.7115\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3285 - mean_absolute_error: 1.5081 - val_loss: 3207.5708 - val_mean_absolute_error: 56.5293\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.7711 - mean_absolute_error: 1.3601 - val_loss: 3165.7256 - val_mean_absolute_error: 56.1614\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8579 - mean_absolute_error: 1.0589 - val_loss: 3110.3423 - val_mean_absolute_error: 55.6692\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1039 - mean_absolute_error: 0.7495 - val_loss: 3050.1592 - val_mean_absolute_error: 55.1286\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 16.5723 - mean_absolute_error: 3.5274 - val_loss: 2983.9980 - val_mean_absolute_error: 54.5823\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3166 - mean_absolute_error: 1.5405 - val_loss: 2904.7163 - val_mean_absolute_error: 53.8503\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.1252 - mean_absolute_error: 1.9803 - val_loss: 2983.7817 - val_mean_absolute_error: 54.5643\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.5724 - mean_absolute_error: 1.4237 - val_loss: 3101.9067 - val_mean_absolute_error: 55.6138\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5908 - mean_absolute_error: 0.9655 - val_loss: 3182.7632 - val_mean_absolute_error: 56.3174\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.4244 - mean_absolute_error: 1.1831 - val_loss: 3174.3706 - val_mean_absolute_error: 56.2396\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2216 - mean_absolute_error: 1.1514 - val_loss: 3114.8716 - val_mean_absolute_error: 55.7115\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4702 - mean_absolute_error: 0.9584 - val_loss: 3042.2917 - val_mean_absolute_error: 55.0609\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3039 - mean_absolute_error: 0.9740 - val_loss: 2998.0190 - val_mean_absolute_error: 54.6573\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5809 - mean_absolute_error: 1.1483 - val_loss: 3002.4521 - val_mean_absolute_error: 54.6924\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4225 - mean_absolute_error: 1.0919 - val_loss: 3039.5242 - val_mean_absolute_error: 55.0213\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0697 - mean_absolute_error: 0.8777 - val_loss: 3083.2129 - val_mean_absolute_error: 55.4094\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 7.5526 - mean_absolute_error: 2.2902 - val_loss: 2977.1294 - val_mean_absolute_error: 54.5133\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.0550 - mean_absolute_error: 1.1505 - val_loss: 2888.3628 - val_mean_absolute_error: 53.6884\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.6840 - mean_absolute_error: 1.4058 - val_loss: 2961.6919 - val_mean_absolute_error: 54.3485\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4049 - mean_absolute_error: 1.0548 - val_loss: 3054.0117 - val_mean_absolute_error: 55.1750\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0011 - mean_absolute_error: 0.6547 - val_loss: 3096.1682 - val_mean_absolute_error: 55.5452\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0932 - mean_absolute_error: 0.7929 - val_loss: 3068.7778 - val_mean_absolute_error: 55.2949\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8505 - mean_absolute_error: 0.7134 - val_loss: 3001.4082 - val_mean_absolute_error: 54.6853\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7776 - mean_absolute_error: 0.8126 - val_loss: 2983.1802 - val_mean_absolute_error: 54.5146\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8007 - mean_absolute_error: 0.8616 - val_loss: 3022.4683 - val_mean_absolute_error: 54.8655\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6507 - mean_absolute_error: 0.7301 - val_loss: 3066.0254 - val_mean_absolute_error: 55.2556\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6864 - mean_absolute_error: 0.7789 - val_loss: 3064.0312 - val_mean_absolute_error: 55.2392\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6287 - mean_absolute_error: 0.7510 - val_loss: 3028.0686 - val_mean_absolute_error: 54.9201\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 1.9383 - mean_absolute_error: 0.9475 - val_loss: 2523.7512 - val_mean_absolute_error: 50.2029\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 16.0941 - mean_absolute_error: 3.0578 - val_loss: 2878.2258 - val_mean_absolute_error: 53.5961\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.4274 - mean_absolute_error: 1.3693 - val_loss: 3156.2368 - val_mean_absolute_error: 56.1094\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4845 - mean_absolute_error: 1.1482 - val_loss: 3219.7290 - val_mean_absolute_error: 56.6656\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6039 - mean_absolute_error: 1.4970 - val_loss: 3176.5464 - val_mean_absolute_error: 56.2850\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.7221 - mean_absolute_error: 1.2316 - val_loss: 3095.9155 - val_mean_absolute_error: 55.5715\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.7225 - mean_absolute_error: 0.8504 - val_loss: 3007.9456 - val_mean_absolute_error: 54.7817\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4007 - mean_absolute_error: 0.8949 - val_loss: 2943.4937 - val_mean_absolute_error: 54.1941\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5855 - mean_absolute_error: 1.0769 - val_loss: 2922.2065 - val_mean_absolute_error: 53.9951\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6711 - mean_absolute_error: 1.1558 - val_loss: 2938.1274 - val_mean_absolute_error: 54.1378\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4406 - mean_absolute_error: 1.0800 - val_loss: 2978.1174 - val_mean_absolute_error: 54.4987\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 17.2654 - mean_absolute_error: 3.5627 - val_loss: 2725.0215 - val_mean_absolute_error: 52.1801\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 21.4636 - mean_absolute_error: 4.1930 - val_loss: 2828.0737 - val_mean_absolute_error: 53.1449\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 11.4954 - mean_absolute_error: 3.1039 - val_loss: 3096.3140 - val_mean_absolute_error: 55.5785\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5112 - mean_absolute_error: 0.5790 - val_loss: 3329.8401 - val_mean_absolute_error: 57.6075\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.9544 - mean_absolute_error: 1.7788 - val_loss: 3391.8708 - val_mean_absolute_error: 58.1383\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.2186 - mean_absolute_error: 2.3663 - val_loss: 3329.7356 - val_mean_absolute_error: 57.6146\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8844 - mean_absolute_error: 1.7894 - val_loss: 3213.9600 - val_mean_absolute_error: 56.6209\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9536 - mean_absolute_error: 0.8984 - val_loss: 3095.0078 - val_mean_absolute_error: 55.5787\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4397 - mean_absolute_error: 0.5460 - val_loss: 3011.6111 - val_mean_absolute_error: 54.8347\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2543 - mean_absolute_error: 1.3564 - val_loss: 2978.4116 - val_mean_absolute_error: 54.5357\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4375 - mean_absolute_error: 1.6771 - val_loss: 2995.3386 - val_mean_absolute_error: 54.6895\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 4.6664 - mean_absolute_error: 1.7987 - val_loss: 3636.6128 - val_mean_absolute_error: 60.1929\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 27.3838 - mean_absolute_error: 4.5140 - val_loss: 3248.4038 - val_mean_absolute_error: 56.9143\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9194 - mean_absolute_error: 1.6256 - val_loss: 2877.3657 - val_mean_absolute_error: 53.5894\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.7085 - mean_absolute_error: 2.0799 - val_loss: 2769.1089 - val_mean_absolute_error: 52.5761\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 11.2103 - mean_absolute_error: 2.7363 - val_loss: 2847.1699 - val_mean_absolute_error: 53.3018\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6.5736 - mean_absolute_error: 2.1871 - val_loss: 2984.9150 - val_mean_absolute_error: 54.5619\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8250 - mean_absolute_error: 1.2569 - val_loss: 3123.6729 - val_mean_absolute_error: 55.8012\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1755 - mean_absolute_error: 0.7490 - val_loss: 3216.7090 - val_mean_absolute_error: 56.6128\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.9136 - mean_absolute_error: 1.4610 - val_loss: 3243.6445 - val_mean_absolute_error: 56.8418\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7051 - mean_absolute_error: 1.6567 - val_loss: 3214.3589 - val_mean_absolute_error: 56.5815\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.7747 - mean_absolute_error: 1.4206 - val_loss: 3142.8330 - val_mean_absolute_error: 55.9514\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2845 - mean_absolute_error: 0.9232 - val_loss: 3055.0051 - val_mean_absolute_error: 55.1685\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6873 - mean_absolute_error: 0.6655 - val_loss: 2977.5264 - val_mean_absolute_error: 54.4670\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3008 - mean_absolute_error: 1.1228 - val_loss: 2938.4775 - val_mean_absolute_error: 54.1077\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 13.6954 - mean_absolute_error: 3.1522 - val_loss: 2709.9536 - val_mean_absolute_error: 52.0329\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.2723 - mean_absolute_error: 3.2164 - val_loss: 2818.7026 - val_mean_absolute_error: 53.0524\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 9.1664 - mean_absolute_error: 2.4740 - val_loss: 3051.6575 - val_mean_absolute_error: 55.1787\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.7166 - mean_absolute_error: 0.9941 - val_loss: 3232.8896 - val_mean_absolute_error: 56.7745\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7675 - mean_absolute_error: 1.5595 - val_loss: 3290.6423 - val_mean_absolute_error: 57.2670\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.6412 - mean_absolute_error: 1.9664 - val_loss: 3240.7368 - val_mean_absolute_error: 56.8256\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.8374 - mean_absolute_error: 1.5805 - val_loss: 3131.7495 - val_mean_absolute_error: 55.8623\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4575 - mean_absolute_error: 1.0086 - val_loss: 3013.2134 - val_mean_absolute_error: 54.8005\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2040 - mean_absolute_error: 1.0303 - val_loss: 2932.4697 - val_mean_absolute_error: 54.0653\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.5478 - mean_absolute_error: 1.5150 - val_loss: 2917.4648 - val_mean_absolute_error: 53.9245\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 2.9500 - mean_absolute_error: 1.6044 - val_loss: 2953.8469 - val_mean_absolute_error: 54.2551\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 536ms/step - loss: 2.7997 - mean_absolute_error: 1.1784 - val_loss: 2376.8623 - val_mean_absolute_error: 48.7449\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 33.3021 - mean_absolute_error: 4.1096 - val_loss: 2837.6243 - val_mean_absolute_error: 53.2272\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1505 - mean_absolute_error: 1.6410 - val_loss: 3321.0435 - val_mean_absolute_error: 57.5310\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.1047 - mean_absolute_error: 2.0187 - val_loss: 3495.5337 - val_mean_absolute_error: 59.0000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 13.5026 - mean_absolute_error: 3.0227 - val_loss: 3425.1714 - val_mean_absolute_error: 58.4064\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 10.3520 - mean_absolute_error: 2.5980 - val_loss: 3246.3921 - val_mean_absolute_error: 56.8751\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0126 - mean_absolute_error: 1.5861 - val_loss: 3042.4373 - val_mean_absolute_error: 55.0790\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0917 - mean_absolute_error: 0.6809 - val_loss: 2872.1692 - val_mean_absolute_error: 53.5320\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.4978 - mean_absolute_error: 1.4074 - val_loss: 2780.3379 - val_mean_absolute_error: 52.6765\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.8301 - mean_absolute_error: 1.8215 - val_loss: 2769.9307 - val_mean_absolute_error: 52.5758\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.0184 - mean_absolute_error: 1.8506 - val_loss: 2820.8086 - val_mean_absolute_error: 53.0482\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 30.9894 - mean_absolute_error: 4.7114 - val_loss: 3067.8938 - val_mean_absolute_error: 55.3256\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6384 - mean_absolute_error: 0.8555 - val_loss: 2635.3794 - val_mean_absolute_error: 51.3017\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.9395 - mean_absolute_error: 2.3173 - val_loss: 2580.8271 - val_mean_absolute_error: 50.7683\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 11.3112 - mean_absolute_error: 2.6166 - val_loss: 2694.6323 - val_mean_absolute_error: 51.8662\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.3921 - mean_absolute_error: 2.0304 - val_loss: 2866.8591 - val_mean_absolute_error: 53.4869\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9291 - mean_absolute_error: 1.2714 - val_loss: 3040.2598 - val_mean_absolute_error: 55.0692\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9684 - mean_absolute_error: 0.6791 - val_loss: 3170.7163 - val_mean_absolute_error: 56.2271\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.3362 - mean_absolute_error: 1.1829 - val_loss: 3236.1592 - val_mean_absolute_error: 56.7962\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.5336 - mean_absolute_error: 1.5089 - val_loss: 3239.7607 - val_mean_absolute_error: 56.8247\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5589 - mean_absolute_error: 1.5110 - val_loss: 3202.0295 - val_mean_absolute_error: 56.4925\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.7244 - mean_absolute_error: 1.2874 - val_loss: 3142.0276 - val_mean_absolute_error: 55.9590\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6921 - mean_absolute_error: 0.9715 - val_loss: 3067.1670 - val_mean_absolute_error: 55.2895\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9154 - mean_absolute_error: 0.7351 - val_loss: 2989.2273 - val_mean_absolute_error: 54.5862\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 640ms/step - loss: 2.0104 - mean_absolute_error: 1.1661 - val_loss: 2992.8105 - val_mean_absolute_error: 54.6559\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.0515 - mean_absolute_error: 1.5613 - val_loss: 3127.3333 - val_mean_absolute_error: 55.8597\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4215 - mean_absolute_error: 0.5633 - val_loss: 3212.1270 - val_mean_absolute_error: 56.6062\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9389 - mean_absolute_error: 0.8243 - val_loss: 3211.1802 - val_mean_absolute_error: 56.5995\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8732 - mean_absolute_error: 0.7942 - val_loss: 3176.8862 - val_mean_absolute_error: 56.2997\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4862 - mean_absolute_error: 0.5530 - val_loss: 3133.2573 - val_mean_absolute_error: 55.9163\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3563 - mean_absolute_error: 0.5426 - val_loss: 3105.0059 - val_mean_absolute_error: 55.6661\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4755 - mean_absolute_error: 0.5187 - val_loss: 3111.9419 - val_mean_absolute_error: 55.7280\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3756 - mean_absolute_error: 0.4742 - val_loss: 3137.8245 - val_mean_absolute_error: 55.9568\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2346 - mean_absolute_error: 0.4324 - val_loss: 3160.5972 - val_mean_absolute_error: 56.1572\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2410 - mean_absolute_error: 0.4101 - val_loss: 3166.2710 - val_mean_absolute_error: 56.2073\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 6.8859 - mean_absolute_error: 2.1783 - val_loss: 3152.4282 - val_mean_absolute_error: 56.0865\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.5148 - mean_absolute_error: 1.0414 - val_loss: 3000.5430 - val_mean_absolute_error: 54.7288\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.0923 - mean_absolute_error: 1.4603 - val_loss: 3059.8240 - val_mean_absolute_error: 55.2577\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0909 - mean_absolute_error: 1.0661 - val_loss: 3124.7896 - val_mean_absolute_error: 55.8315\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8593 - mean_absolute_error: 0.8619 - val_loss: 3133.8066 - val_mean_absolute_error: 55.9070\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7931 - mean_absolute_error: 0.8318 - val_loss: 3092.7083 - val_mean_absolute_error: 55.5360\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4657 - mean_absolute_error: 0.8138 - val_loss: 3042.0293 - val_mean_absolute_error: 55.0746\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4241 - mean_absolute_error: 0.9955 - val_loss: 3042.6499 - val_mean_absolute_error: 55.0705\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1966 - mean_absolute_error: 0.9314 - val_loss: 3079.7964 - val_mean_absolute_error: 55.3938\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9453 - mean_absolute_error: 0.7065 - val_loss: 3093.6660 - val_mean_absolute_error: 55.5064\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8818 - mean_absolute_error: 0.7406 - val_loss: 3060.6792 - val_mean_absolute_error: 55.1944\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6625 - mean_absolute_error: 0.6231 - val_loss: 3013.9214 - val_mean_absolute_error: 54.7526\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 637ms/step - loss: 6.9249 - mean_absolute_error: 2.1920 - val_loss: 3113.4280 - val_mean_absolute_error: 55.7396\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0770 - mean_absolute_error: 0.8736 - val_loss: 2971.9097 - val_mean_absolute_error: 54.4654\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5347 - mean_absolute_error: 1.6497 - val_loss: 3061.4531 - val_mean_absolute_error: 55.2707\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9488 - mean_absolute_error: 1.0628 - val_loss: 3145.4019 - val_mean_absolute_error: 56.0147\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0142 - mean_absolute_error: 0.8477 - val_loss: 3167.9189 - val_mean_absolute_error: 56.2108\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2454 - mean_absolute_error: 0.9693 - val_loss: 3141.5342 - val_mean_absolute_error: 55.9764\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8781 - mean_absolute_error: 0.8352 - val_loss: 3086.5547 - val_mean_absolute_error: 55.4854\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5605 - mean_absolute_error: 0.8575 - val_loss: 3033.7700 - val_mean_absolute_error: 55.0083\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7280 - mean_absolute_error: 1.1439 - val_loss: 3032.1887 - val_mean_absolute_error: 54.9896\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6120 - mean_absolute_error: 1.1251 - val_loss: 3067.0479 - val_mean_absolute_error: 55.2986\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2853 - mean_absolute_error: 0.8814 - val_loss: 3102.9937 - val_mean_absolute_error: 55.6163\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2411 - mean_absolute_error: 0.8144 - val_loss: 3116.3257 - val_mean_absolute_error: 55.7303\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 639ms/step - loss: 7.2281 - mean_absolute_error: 2.2146 - val_loss: 3120.5173 - val_mean_absolute_error: 55.7993\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.2719 - mean_absolute_error: 0.9521 - val_loss: 2899.2021 - val_mean_absolute_error: 53.8006\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.1397 - mean_absolute_error: 1.4148 - val_loss: 2962.8799 - val_mean_absolute_error: 54.3793\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9427 - mean_absolute_error: 1.1054 - val_loss: 3064.9219 - val_mean_absolute_error: 55.2965\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6039 - mean_absolute_error: 0.8373 - val_loss: 3106.8340 - val_mean_absolute_error: 55.6654\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7674 - mean_absolute_error: 0.8940 - val_loss: 3077.8843 - val_mean_absolute_error: 55.4030\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4569 - mean_absolute_error: 0.7899 - val_loss: 3011.9482 - val_mean_absolute_error: 54.8064\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2055 - mean_absolute_error: 0.8274 - val_loss: 2959.6936 - val_mean_absolute_error: 54.3260\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3009 - mean_absolute_error: 1.0407 - val_loss: 2973.0786 - val_mean_absolute_error: 54.4404\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0892 - mean_absolute_error: 0.9584 - val_loss: 3019.6135 - val_mean_absolute_error: 54.8553\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9037 - mean_absolute_error: 0.7327 - val_loss: 3055.3691 - val_mean_absolute_error: 55.1698\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9444 - mean_absolute_error: 0.8083 - val_loss: 3052.3569 - val_mean_absolute_error: 55.1355\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.2573 - mean_absolute_error: 2.3933 - val_loss: 3162.2910 - val_mean_absolute_error: 56.1692\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.8893 - mean_absolute_error: 1.2398 - val_loss: 2976.1946 - val_mean_absolute_error: 54.5048\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8517 - mean_absolute_error: 1.0638 - val_loss: 2894.1724 - val_mean_absolute_error: 53.7488\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2595 - mean_absolute_error: 1.2896 - val_loss: 2961.5317 - val_mean_absolute_error: 54.3608\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4750 - mean_absolute_error: 0.9819 - val_loss: 3037.1738 - val_mean_absolute_error: 55.0402\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2942 - mean_absolute_error: 0.7392 - val_loss: 3059.2939 - val_mean_absolute_error: 55.2324\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2817 - mean_absolute_error: 0.7736 - val_loss: 3029.7139 - val_mean_absolute_error: 54.9578\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0465 - mean_absolute_error: 0.7213 - val_loss: 2970.5005 - val_mean_absolute_error: 54.4116\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9907 - mean_absolute_error: 0.8851 - val_loss: 2947.8511 - val_mean_absolute_error: 54.1975\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0578 - mean_absolute_error: 0.9630 - val_loss: 2988.6226 - val_mean_absolute_error: 54.5670\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8888 - mean_absolute_error: 0.8027 - val_loss: 3035.7046 - val_mean_absolute_error: 54.9953\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8889 - mean_absolute_error: 0.8172 - val_loss: 3051.4260 - val_mean_absolute_error: 55.1388\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8989 - mean_absolute_error: 0.8027 - val_loss: 3032.7886 - val_mean_absolute_error: 54.9700\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 2.3183 - mean_absolute_error: 1.3141 - val_loss: 3652.9634 - val_mean_absolute_error: 60.3650\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 26.1534 - mean_absolute_error: 4.7219 - val_loss: 3339.4150 - val_mean_absolute_error: 57.7376\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0000 - mean_absolute_error: 1.8531 - val_loss: 3034.6011 - val_mean_absolute_error: 55.0555\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6803 - mean_absolute_error: 1.0972 - val_loss: 2892.3159 - val_mean_absolute_error: 53.7549\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 7.8787 - mean_absolute_error: 2.5113 - val_loss: 2909.9531 - val_mean_absolute_error: 53.9155\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6.8166 - mean_absolute_error: 2.3463 - val_loss: 3007.1555 - val_mean_absolute_error: 54.7997\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.3412 - mean_absolute_error: 1.3696 - val_loss: 3130.7788 - val_mean_absolute_error: 55.9036\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1366 - mean_absolute_error: 0.3087 - val_loss: 3238.3486 - val_mean_absolute_error: 56.8455\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1316 - mean_absolute_error: 0.9279 - val_loss: 3297.3193 - val_mean_absolute_error: 57.3544\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.8023 - mean_absolute_error: 1.4364 - val_loss: 3304.1892 - val_mean_absolute_error: 57.4123\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.0863 - mean_absolute_error: 1.5042 - val_loss: 3270.3823 - val_mean_absolute_error: 57.1197\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.0727 - mean_absolute_error: 1.1984 - val_loss: 3213.2998 - val_mean_absolute_error: 56.6227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8032 - mean_absolute_error: 0.8128 - val_loss: 3149.2559 - val_mean_absolute_error: 56.0605\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1732 - mean_absolute_error: 0.3776 - val_loss: 3092.2383 - val_mean_absolute_error: 55.5551\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 10.0076 - mean_absolute_error: 2.6752 - val_loss: 2770.7959 - val_mean_absolute_error: 52.6004\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 11.7439 - mean_absolute_error: 2.8160 - val_loss: 2854.6599 - val_mean_absolute_error: 53.3727\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6.1887 - mean_absolute_error: 2.1402 - val_loss: 3054.6338 - val_mean_absolute_error: 55.1835\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1530 - mean_absolute_error: 0.8158 - val_loss: 3213.1926 - val_mean_absolute_error: 56.5731\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.9100 - mean_absolute_error: 1.3819 - val_loss: 3259.0107 - val_mean_absolute_error: 56.9615\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3461 - mean_absolute_error: 1.7238 - val_loss: 3206.2041 - val_mean_absolute_error: 56.4931\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7271 - mean_absolute_error: 1.3532 - val_loss: 3100.5918 - val_mean_absolute_error: 55.5553\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8418 - mean_absolute_error: 0.8228 - val_loss: 2987.9546 - val_mean_absolute_error: 54.5390\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0072 - mean_absolute_error: 0.9627 - val_loss: 2923.5732 - val_mean_absolute_error: 53.9494\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.1711 - mean_absolute_error: 1.3446 - val_loss: 2923.3594 - val_mean_absolute_error: 53.9454\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.0634 - mean_absolute_error: 1.3103 - val_loss: 2968.7671 - val_mean_absolute_error: 54.3581\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 20.2216 - mean_absolute_error: 3.9101 - val_loss: 3108.6880 - val_mean_absolute_error: 55.6931\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.0889 - mean_absolute_error: 0.8736 - val_loss: 2867.8616 - val_mean_absolute_error: 53.5055\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.0552 - mean_absolute_error: 2.3130 - val_loss: 2857.8374 - val_mean_absolute_error: 53.4050\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.7834 - mean_absolute_error: 2.2865 - val_loss: 2941.8638 - val_mean_absolute_error: 54.1701\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3521 - mean_absolute_error: 1.6962 - val_loss: 3057.4448 - val_mean_absolute_error: 55.2080\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4331 - mean_absolute_error: 0.9640 - val_loss: 3153.7173 - val_mean_absolute_error: 56.0587\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.8246 - mean_absolute_error: 1.0611 - val_loss: 3207.1477 - val_mean_absolute_error: 56.5232\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.8729 - mean_absolute_error: 1.3757 - val_loss: 3215.7446 - val_mean_absolute_error: 56.5948\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.0705 - mean_absolute_error: 1.4368 - val_loss: 3191.6802 - val_mean_absolute_error: 56.3810\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.4007 - mean_absolute_error: 1.3054 - val_loss: 3145.9878 - val_mean_absolute_error: 55.9766\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5009 - mean_absolute_error: 1.0417 - val_loss: 3087.5815 - val_mean_absolute_error: 55.4566\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0396 - mean_absolute_error: 0.7330 - val_loss: 3032.1211 - val_mean_absolute_error: 54.9592\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2455 - mean_absolute_error: 1.0410 - val_loss: 2997.3145 - val_mean_absolute_error: 54.6445\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 5.2898 - mean_absolute_error: 1.8422 - val_loss: 2532.6548 - val_mean_absolute_error: 50.3235\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 21.8695 - mean_absolute_error: 3.1582 - val_loss: 2817.4219 - val_mean_absolute_error: 53.0553\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.0871 - mean_absolute_error: 1.6945 - val_loss: 3150.2368 - val_mean_absolute_error: 56.0566\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0882 - mean_absolute_error: 1.0920 - val_loss: 3333.8464 - val_mean_absolute_error: 57.6245\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.4593 - mean_absolute_error: 2.0265 - val_loss: 3318.4404 - val_mean_absolute_error: 57.4749\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.6809 - mean_absolute_error: 1.8548 - val_loss: 3188.3281 - val_mean_absolute_error: 56.3436\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.3976 - mean_absolute_error: 1.1383 - val_loss: 3032.5908 - val_mean_absolute_error: 54.9663\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7461 - mean_absolute_error: 0.6992 - val_loss: 2898.2954 - val_mean_absolute_error: 53.7502\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.7718 - mean_absolute_error: 1.2574 - val_loss: 2832.7385 - val_mean_absolute_error: 53.1456\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.1334 - mean_absolute_error: 1.5586 - val_loss: 2840.6865 - val_mean_absolute_error: 53.2177\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.8673 - mean_absolute_error: 1.5077 - val_loss: 2899.6326 - val_mean_absolute_error: 53.7588\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 4.7843 - mean_absolute_error: 1.7609 - val_loss: 2508.4619 - val_mean_absolute_error: 50.0698\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 17.9372 - mean_absolute_error: 3.0708 - val_loss: 2806.8276 - val_mean_absolute_error: 52.9319\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1100 - mean_absolute_error: 1.7103 - val_loss: 3166.7979 - val_mean_absolute_error: 56.1778\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1742 - mean_absolute_error: 1.0718 - val_loss: 3347.6748 - val_mean_absolute_error: 57.7329\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.2119 - mean_absolute_error: 1.9860 - val_loss: 3316.5371 - val_mean_absolute_error: 57.4635\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2530 - mean_absolute_error: 1.8040 - val_loss: 3166.2275 - val_mean_absolute_error: 56.1615\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9817 - mean_absolute_error: 1.0309 - val_loss: 2982.6099 - val_mean_absolute_error: 54.5263\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0102 - mean_absolute_error: 0.8930 - val_loss: 2850.1851 - val_mean_absolute_error: 53.3140\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.4335 - mean_absolute_error: 1.4280 - val_loss: 2813.1328 - val_mean_absolute_error: 52.9686\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.0555 - mean_absolute_error: 1.5570 - val_loss: 2856.4219 - val_mean_absolute_error: 53.3692\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.1229 - mean_absolute_error: 1.3542 - val_loss: 2946.5425 - val_mean_absolute_error: 54.1937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 545ms/step - loss: 5.2195 - mean_absolute_error: 1.9020 - val_loss: 3015.7778 - val_mean_absolute_error: 54.8718\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.3880 - mean_absolute_error: 1.3643 - val_loss: 3048.7190 - val_mean_absolute_error: 55.1699\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.6000 - mean_absolute_error: 1.0762 - val_loss: 3145.7598 - val_mean_absolute_error: 56.0342\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2676 - mean_absolute_error: 0.4972 - val_loss: 3219.3777 - val_mean_absolute_error: 56.6789\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6799 - mean_absolute_error: 0.7434 - val_loss: 3220.2239 - val_mean_absolute_error: 56.6854\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6917 - mean_absolute_error: 0.7574 - val_loss: 3177.0608 - val_mean_absolute_error: 56.3073\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2196 - mean_absolute_error: 0.4556 - val_loss: 3122.7290 - val_mean_absolute_error: 55.8271\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1877 - mean_absolute_error: 0.3465 - val_loss: 3095.9131 - val_mean_absolute_error: 55.5884\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3839 - mean_absolute_error: 0.5390 - val_loss: 3103.4697 - val_mean_absolute_error: 55.6555\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2848 - mean_absolute_error: 0.4509 - val_loss: 3129.9124 - val_mean_absolute_error: 55.8906\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1151 - mean_absolute_error: 0.2405 - val_loss: 3160.5530 - val_mean_absolute_error: 56.1612\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 574ms/step - loss: 10.2989 - mean_absolute_error: 2.7210 - val_loss: 2802.4580 - val_mean_absolute_error: 52.9021\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 10.0989 - mean_absolute_error: 2.6750 - val_loss: 2890.6191 - val_mean_absolute_error: 53.7158\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4772 - mean_absolute_error: 2.0515 - val_loss: 3076.8733 - val_mean_absolute_error: 55.3997\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.5980 - mean_absolute_error: 0.8419 - val_loss: 3209.3193 - val_mean_absolute_error: 56.5605\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.0197 - mean_absolute_error: 1.3824 - val_loss: 3227.5850 - val_mean_absolute_error: 56.7152\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3683 - mean_absolute_error: 1.4935 - val_loss: 3170.5068 - val_mean_absolute_error: 56.2134\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0722 - mean_absolute_error: 1.0724 - val_loss: 3085.4746 - val_mean_absolute_error: 55.4573\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2269 - mean_absolute_error: 0.7585 - val_loss: 3003.4453 - val_mean_absolute_error: 54.7179\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5766 - mean_absolute_error: 1.1546 - val_loss: 2972.0532 - val_mean_absolute_error: 54.4297\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9220 - mean_absolute_error: 1.3136 - val_loss: 2988.7134 - val_mean_absolute_error: 54.5771\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5140 - mean_absolute_error: 1.1686 - val_loss: 3027.1851 - val_mean_absolute_error: 54.9208\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 6.1487 - mean_absolute_error: 1.9877 - val_loss: 2779.5815 - val_mean_absolute_error: 52.6751\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 10.3353 - mean_absolute_error: 2.7228 - val_loss: 2924.9092 - val_mean_absolute_error: 54.0167\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6258 - mean_absolute_error: 1.7488 - val_loss: 3107.8337 - val_mean_absolute_error: 55.6628\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5579 - mean_absolute_error: 0.8806 - val_loss: 3209.9585 - val_mean_absolute_error: 56.5563\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.0107 - mean_absolute_error: 1.3490 - val_loss: 3206.7988 - val_mean_absolute_error: 56.5207\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.8376 - mean_absolute_error: 1.3564 - val_loss: 3141.5039 - val_mean_absolute_error: 55.9406\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6516 - mean_absolute_error: 1.0728 - val_loss: 3054.5959 - val_mean_absolute_error: 55.1615\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1219 - mean_absolute_error: 0.8273 - val_loss: 2984.4634 - val_mean_absolute_error: 54.5237\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6746 - mean_absolute_error: 1.2414 - val_loss: 2974.9456 - val_mean_absolute_error: 54.4364\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7637 - mean_absolute_error: 1.2760 - val_loss: 3007.9377 - val_mean_absolute_error: 54.7373\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3020 - mean_absolute_error: 1.0684 - val_loss: 3056.6646 - val_mean_absolute_error: 55.1779\n",
      "1/1 [==============================] - 1s 587ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 10.1180 - mean_absolute_error: 2.6542 - val_loss: 3013.3008 - val_mean_absolute_error: 54.8422\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7765 - mean_absolute_error: 1.0587 - val_loss: 2859.1318 - val_mean_absolute_error: 53.4299\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6088 - mean_absolute_error: 1.5399 - val_loss: 2931.6411 - val_mean_absolute_error: 54.0916\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.0031 - mean_absolute_error: 1.1854 - val_loss: 3041.9138 - val_mean_absolute_error: 55.0825\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1675 - mean_absolute_error: 0.7709 - val_loss: 3111.5376 - val_mean_absolute_error: 55.6956\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3965 - mean_absolute_error: 0.8686 - val_loss: 3105.6575 - val_mean_absolute_error: 55.6367\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2416 - mean_absolute_error: 0.8370 - val_loss: 3050.7295 - val_mean_absolute_error: 55.1382\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8340 - mean_absolute_error: 0.7123 - val_loss: 2978.2947 - val_mean_absolute_error: 54.4784\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8330 - mean_absolute_error: 0.8551 - val_loss: 2950.2920 - val_mean_absolute_error: 54.2185\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9614 - mean_absolute_error: 0.9611 - val_loss: 2974.4365 - val_mean_absolute_error: 54.4333\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7902 - mean_absolute_error: 0.8420 - val_loss: 3020.7539 - val_mean_absolute_error: 54.8500\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6529 - mean_absolute_error: 0.7602 - val_loss: 3060.9717 - val_mean_absolute_error: 55.2132\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 575ms/step - loss: 4.0352 - mean_absolute_error: 1.5781 - val_loss: 2685.0254 - val_mean_absolute_error: 51.7874\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.8667 - mean_absolute_error: 2.1959 - val_loss: 2907.5347 - val_mean_absolute_error: 53.8726\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.1223 - mean_absolute_error: 1.2263 - val_loss: 3123.9658 - val_mean_absolute_error: 55.8173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8388 - mean_absolute_error: 0.9382 - val_loss: 3197.1147 - val_mean_absolute_error: 56.4549\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7538 - mean_absolute_error: 1.2682 - val_loss: 3152.2900 - val_mean_absolute_error: 56.0568\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9275 - mean_absolute_error: 0.9872 - val_loss: 3056.2017 - val_mean_absolute_error: 55.2006\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0869 - mean_absolute_error: 0.6628 - val_loss: 2961.8154 - val_mean_absolute_error: 54.3447\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2205 - mean_absolute_error: 1.0037 - val_loss: 2921.5615 - val_mean_absolute_error: 53.9719\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4899 - mean_absolute_error: 1.1540 - val_loss: 2941.8210 - val_mean_absolute_error: 54.1524\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1859 - mean_absolute_error: 1.0416 - val_loss: 2995.8313 - val_mean_absolute_error: 54.6396\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8293 - mean_absolute_error: 0.7865 - val_loss: 3054.0076 - val_mean_absolute_error: 55.1602\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 6.2397 - mean_absolute_error: 2.0435 - val_loss: 2984.1465 - val_mean_absolute_error: 54.5801\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2047 - mean_absolute_error: 1.5967 - val_loss: 3016.4534 - val_mean_absolute_error: 54.8713\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0131 - mean_absolute_error: 1.2667 - val_loss: 3106.2456 - val_mean_absolute_error: 55.6777\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4595 - mean_absolute_error: 0.5431 - val_loss: 3188.6118 - val_mean_absolute_error: 56.4077\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5341 - mean_absolute_error: 0.6215 - val_loss: 3219.3372 - val_mean_absolute_error: 56.6773\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8968 - mean_absolute_error: 0.8207 - val_loss: 3208.1558 - val_mean_absolute_error: 56.5798\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6929 - mean_absolute_error: 0.7455 - val_loss: 3172.5513 - val_mean_absolute_error: 56.2670\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3232 - mean_absolute_error: 0.5096 - val_loss: 3131.3477 - val_mean_absolute_error: 55.9025\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2250 - mean_absolute_error: 0.4249 - val_loss: 3102.0518 - val_mean_absolute_error: 55.6419\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3693 - mean_absolute_error: 0.4687 - val_loss: 3096.0312 - val_mean_absolute_error: 55.5884\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4118 - mean_absolute_error: 0.5089 - val_loss: 3112.3337 - val_mean_absolute_error: 55.7337\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 3.4498 - mean_absolute_error: 1.2562 - val_loss: 2730.8240 - val_mean_absolute_error: 52.2129\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 14.3091 - mean_absolute_error: 3.0276 - val_loss: 2980.5186 - val_mean_absolute_error: 54.5213\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2734 - mean_absolute_error: 1.3283 - val_loss: 3203.6006 - val_mean_absolute_error: 56.5030\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.8010 - mean_absolute_error: 1.2897 - val_loss: 3271.6055 - val_mean_absolute_error: 57.0911\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6462 - mean_absolute_error: 1.7730 - val_loss: 3232.4492 - val_mean_absolute_error: 56.7492\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4215 - mean_absolute_error: 1.4929 - val_loss: 3142.8276 - val_mean_absolute_error: 55.9666\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6537 - mean_absolute_error: 0.8574 - val_loss: 3042.8992 - val_mean_absolute_error: 55.0792\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4140 - mean_absolute_error: 0.9536 - val_loss: 2980.5352 - val_mean_absolute_error: 54.5144\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.1037 - mean_absolute_error: 1.3086 - val_loss: 2974.8127 - val_mean_absolute_error: 54.4577\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0230 - mean_absolute_error: 1.3004 - val_loss: 3003.0923 - val_mean_absolute_error: 54.7082\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3901 - mean_absolute_error: 1.0754 - val_loss: 3042.0854 - val_mean_absolute_error: 55.0533\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 15.5961 - mean_absolute_error: 3.3724 - val_loss: 3077.2104 - val_mean_absolute_error: 55.4088\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.0256 - mean_absolute_error: 0.9798 - val_loss: 2918.9612 - val_mean_absolute_error: 53.9660\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4598 - mean_absolute_error: 1.8989 - val_loss: 2948.0195 - val_mean_absolute_error: 54.2208\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.9246 - mean_absolute_error: 1.6005 - val_loss: 3032.6348 - val_mean_absolute_error: 54.9818\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3087 - mean_absolute_error: 1.0304 - val_loss: 3116.9712 - val_mean_absolute_error: 55.7313\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1672 - mean_absolute_error: 0.8328 - val_loss: 3162.3506 - val_mean_absolute_error: 56.1269\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6098 - mean_absolute_error: 1.0907 - val_loss: 3155.9507 - val_mean_absolute_error: 56.0657\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4877 - mean_absolute_error: 1.0831 - val_loss: 3111.8989 - val_mean_absolute_error: 55.6708\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0418 - mean_absolute_error: 0.8985 - val_loss: 3052.7329 - val_mean_absolute_error: 55.1384\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9106 - mean_absolute_error: 0.7688 - val_loss: 3012.6174 - val_mean_absolute_error: 54.7754\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1775 - mean_absolute_error: 1.0141 - val_loss: 3016.1538 - val_mean_absolute_error: 54.8091\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1285 - mean_absolute_error: 0.9929 - val_loss: 3048.4355 - val_mean_absolute_error: 55.1045\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 574ms/step - loss: 3.7914 - mean_absolute_error: 1.5210 - val_loss: 2588.2354 - val_mean_absolute_error: 50.8570\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 13.6912 - mean_absolute_error: 2.7446 - val_loss: 2840.1804 - val_mean_absolute_error: 53.2484\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2297 - mean_absolute_error: 1.5275 - val_loss: 3089.2339 - val_mean_absolute_error: 55.5054\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5766 - mean_absolute_error: 0.8915 - val_loss: 3211.7314 - val_mean_absolute_error: 56.5772\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3739 - mean_absolute_error: 1.4453 - val_loss: 3203.8074 - val_mean_absolute_error: 56.5039\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.1029 - mean_absolute_error: 1.3785 - val_loss: 3121.9207 - val_mean_absolute_error: 55.7832\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6715 - mean_absolute_error: 0.9652 - val_loss: 3006.6497 - val_mean_absolute_error: 54.7537\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9136 - mean_absolute_error: 0.7087 - val_loss: 2910.1831 - val_mean_absolute_error: 53.8770\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4120 - mean_absolute_error: 1.1257 - val_loss: 2879.2593 - val_mean_absolute_error: 53.5904\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7211 - mean_absolute_error: 1.2446 - val_loss: 2906.0894 - val_mean_absolute_error: 53.8340\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3197 - mean_absolute_error: 1.1137 - val_loss: 2960.4424 - val_mean_absolute_error: 54.3272\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 8.4846 - mean_absolute_error: 2.4551 - val_loss: 2883.4202 - val_mean_absolute_error: 53.6554\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.6979 - mean_absolute_error: 1.3575 - val_loss: 2826.3579 - val_mean_absolute_error: 53.1139\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.1494 - mean_absolute_error: 1.5534 - val_loss: 2922.9185 - val_mean_absolute_error: 53.9960\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4359 - mean_absolute_error: 1.1051 - val_loss: 3034.0747 - val_mean_absolute_error: 54.9981\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9547 - mean_absolute_error: 0.6622 - val_loss: 3101.5913 - val_mean_absolute_error: 55.5979\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2971 - mean_absolute_error: 0.8339 - val_loss: 3105.0674 - val_mean_absolute_error: 55.6243\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2702 - mean_absolute_error: 0.8255 - val_loss: 3064.6968 - val_mean_absolute_error: 55.2573\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9090 - mean_absolute_error: 0.7741 - val_loss: 3002.2522 - val_mean_absolute_error: 54.6880\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7386 - mean_absolute_error: 0.7466 - val_loss: 2949.5688 - val_mean_absolute_error: 54.2056\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9262 - mean_absolute_error: 0.9203 - val_loss: 2942.4636 - val_mean_absolute_error: 54.1407\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9478 - mean_absolute_error: 0.9357 - val_loss: 2976.6926 - val_mean_absolute_error: 54.4546\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7269 - mean_absolute_error: 0.7931 - val_loss: 3027.3682 - val_mean_absolute_error: 54.9188\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 1.0272 - mean_absolute_error: 0.8857 - val_loss: 2611.5591 - val_mean_absolute_error: 51.0829\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 34.8955 - mean_absolute_error: 5.4208 - val_loss: 2997.0647 - val_mean_absolute_error: 54.6935\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.7011 - mean_absolute_error: 1.4348 - val_loss: 3319.9111 - val_mean_absolute_error: 57.5325\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.4943 - mean_absolute_error: 1.6846 - val_loss: 3417.6978 - val_mean_absolute_error: 58.3648\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 9.0852 - mean_absolute_error: 2.5461 - val_loss: 3385.1797 - val_mean_absolute_error: 58.0904\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.9688 - mean_absolute_error: 2.2136 - val_loss: 3296.3567 - val_mean_absolute_error: 57.3310\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.9894 - mean_absolute_error: 1.3946 - val_loss: 3196.8208 - val_mean_absolute_error: 56.4706\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6301 - mean_absolute_error: 0.6999 - val_loss: 3104.6577 - val_mean_absolute_error: 55.6611\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4374 - mean_absolute_error: 0.4749 - val_loss: 3051.1855 - val_mean_absolute_error: 55.1857\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2418 - mean_absolute_error: 0.9798 - val_loss: 3043.2490 - val_mean_absolute_error: 55.1164\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4319 - mean_absolute_error: 1.0488 - val_loss: 3065.7266 - val_mean_absolute_error: 55.3191\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 600ms/step - loss: 23.1788 - mean_absolute_error: 4.1798 - val_loss: 2924.5132 - val_mean_absolute_error: 54.0453\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.6476 - mean_absolute_error: 2.0394 - val_loss: 2832.1694 - val_mean_absolute_error: 53.1849\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.7926 - mean_absolute_error: 2.5014 - val_loss: 2957.7524 - val_mean_absolute_error: 54.3352\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.4326 - mean_absolute_error: 1.6317 - val_loss: 3112.8071 - val_mean_absolute_error: 55.7194\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6265 - mean_absolute_error: 0.7918 - val_loss: 3218.2952 - val_mean_absolute_error: 56.6377\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.1387 - mean_absolute_error: 1.4188 - val_loss: 3236.7051 - val_mean_absolute_error: 56.7912\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.5970 - mean_absolute_error: 1.5569 - val_loss: 3188.3726 - val_mean_absolute_error: 56.3644\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.4116 - mean_absolute_error: 1.2208 - val_loss: 3106.0044 - val_mean_absolute_error: 55.6348\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2122 - mean_absolute_error: 0.7621 - val_loss: 3018.5293 - val_mean_absolute_error: 54.8493\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1351 - mean_absolute_error: 0.9441 - val_loss: 2961.8455 - val_mean_absolute_error: 54.3310\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.7311 - mean_absolute_error: 1.2552 - val_loss: 2954.1523 - val_mean_absolute_error: 54.2554\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6653 - mean_absolute_error: 1.2383 - val_loss: 2983.6841 - val_mean_absolute_error: 54.5168\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 616ms/step - loss: 8.1883 - mean_absolute_error: 2.4012 - val_loss: 2741.0566 - val_mean_absolute_error: 52.3204\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 14.2843 - mean_absolute_error: 3.0442 - val_loss: 2920.2539 - val_mean_absolute_error: 53.9861\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.3851 - mean_absolute_error: 1.8392 - val_loss: 3135.9141 - val_mean_absolute_error: 55.9214\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.6505 - mean_absolute_error: 0.8254 - val_loss: 3253.6331 - val_mean_absolute_error: 56.9421\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7252 - mean_absolute_error: 1.5573 - val_loss: 3241.3723 - val_mean_absolute_error: 56.8279\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3231 - mean_absolute_error: 1.4530 - val_loss: 3156.0479 - val_mean_absolute_error: 56.0771\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6083 - mean_absolute_error: 1.0253 - val_loss: 3055.6050 - val_mean_absolute_error: 55.1826\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1281 - mean_absolute_error: 0.8731 - val_loss: 2984.0835 - val_mean_absolute_error: 54.5352\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8851 - mean_absolute_error: 1.2887 - val_loss: 2973.5459 - val_mean_absolute_error: 54.4360\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0004 - mean_absolute_error: 1.3300 - val_loss: 3008.3115 - val_mean_absolute_error: 54.7469\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3736 - mean_absolute_error: 1.0952 - val_loss: 3063.8687 - val_mean_absolute_error: 55.2432\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 7.5814 - mean_absolute_error: 2.2661 - val_loss: 2945.9932 - val_mean_absolute_error: 54.2285\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.3659 - mean_absolute_error: 1.2043 - val_loss: 2883.7317 - val_mean_absolute_error: 53.6486\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.9819 - mean_absolute_error: 1.4544 - val_loss: 2949.4087 - val_mean_absolute_error: 54.2418\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6309 - mean_absolute_error: 1.1196 - val_loss: 3037.4380 - val_mean_absolute_error: 55.0290\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0077 - mean_absolute_error: 0.6954 - val_loss: 3092.3818 - val_mean_absolute_error: 55.5108\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1374 - mean_absolute_error: 0.7900 - val_loss: 3090.4561 - val_mean_absolute_error: 55.4854\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0415 - mean_absolute_error: 0.7809 - val_loss: 3050.2979 - val_mean_absolute_error: 55.1178\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7674 - mean_absolute_error: 0.7610 - val_loss: 2997.1357 - val_mean_absolute_error: 54.6309\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7862 - mean_absolute_error: 0.8174 - val_loss: 2975.2495 - val_mean_absolute_error: 54.4284\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8874 - mean_absolute_error: 0.8996 - val_loss: 2996.0781 - val_mean_absolute_error: 54.6175\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7466 - mean_absolute_error: 0.7902 - val_loss: 3037.7683 - val_mean_absolute_error: 54.9973\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6401 - mean_absolute_error: 0.7585 - val_loss: 3069.5911 - val_mean_absolute_error: 55.2896\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 14.7263 - mean_absolute_error: 3.2812 - val_loss: 2989.8594 - val_mean_absolute_error: 54.6394\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0259 - mean_absolute_error: 1.1183 - val_loss: 2806.3511 - val_mean_absolute_error: 52.9419\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0197 - mean_absolute_error: 1.6434 - val_loss: 2841.8376 - val_mean_absolute_error: 53.2654\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.9490 - mean_absolute_error: 1.4761 - val_loss: 2939.6792 - val_mean_absolute_error: 54.1623\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4833 - mean_absolute_error: 1.0393 - val_loss: 3043.9292 - val_mean_absolute_error: 55.0993\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2171 - mean_absolute_error: 0.7366 - val_loss: 3106.7930 - val_mean_absolute_error: 55.6530\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5738 - mean_absolute_error: 0.9422 - val_loss: 3112.5762 - val_mean_absolute_error: 55.6964\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5392 - mean_absolute_error: 0.9441 - val_loss: 3075.1379 - val_mean_absolute_error: 55.3574\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1690 - mean_absolute_error: 0.8215 - val_loss: 3014.1912 - val_mean_absolute_error: 54.8073\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8829 - mean_absolute_error: 0.7533 - val_loss: 2956.6479 - val_mean_absolute_error: 54.2824\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9886 - mean_absolute_error: 0.9320 - val_loss: 2930.4785 - val_mean_absolute_error: 54.0410\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1531 - mean_absolute_error: 1.0340 - val_loss: 2944.9634 - val_mean_absolute_error: 54.1722\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 3.6150 - mean_absolute_error: 1.5755 - val_loss: 2717.9768 - val_mean_absolute_error: 52.1028\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 21.3530 - mean_absolute_error: 4.3018 - val_loss: 2983.3130 - val_mean_absolute_error: 54.5712\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.0425 - mean_absolute_error: 1.6149 - val_loss: 3267.5044 - val_mean_absolute_error: 57.0922\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9892 - mean_absolute_error: 1.1735 - val_loss: 3388.7991 - val_mean_absolute_error: 58.1358\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.0307 - mean_absolute_error: 2.3058 - val_loss: 3360.1401 - val_mean_absolute_error: 57.8936\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.6810 - mean_absolute_error: 2.0648 - val_loss: 3262.9585 - val_mean_absolute_error: 57.0584\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9490 - mean_absolute_error: 1.1601 - val_loss: 3151.9468 - val_mean_absolute_error: 56.0881\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1990 - mean_absolute_error: 0.4068 - val_loss: 3059.9048 - val_mean_absolute_error: 55.2704\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0107 - mean_absolute_error: 0.8801 - val_loss: 3012.9878 - val_mean_absolute_error: 54.8487\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2221 - mean_absolute_error: 1.3478 - val_loss: 3015.0713 - val_mean_absolute_error: 54.8675\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.1321 - mean_absolute_error: 1.3224 - val_loss: 3052.8003 - val_mean_absolute_error: 55.2064\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 5.3013 - mean_absolute_error: 1.8743 - val_loss: 2800.7515 - val_mean_absolute_error: 52.8765\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 10.3006 - mean_absolute_error: 2.6796 - val_loss: 2933.5474 - val_mean_absolute_error: 54.0981\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7685 - mean_absolute_error: 1.7333 - val_loss: 3123.2144 - val_mean_absolute_error: 55.7963\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5756 - mean_absolute_error: 0.8577 - val_loss: 3243.0198 - val_mean_absolute_error: 56.8374\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7860 - mean_absolute_error: 1.5745 - val_loss: 3240.6460 - val_mean_absolute_error: 56.8118\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.7630 - mean_absolute_error: 1.5780 - val_loss: 3169.5254 - val_mean_absolute_error: 56.1880\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0194 - mean_absolute_error: 1.0862 - val_loss: 3072.7739 - val_mean_absolute_error: 55.3291\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9860 - mean_absolute_error: 0.7665 - val_loss: 2985.1055 - val_mean_absolute_error: 54.5378\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3827 - mean_absolute_error: 1.1171 - val_loss: 2939.0425 - val_mean_absolute_error: 54.1144\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0766 - mean_absolute_error: 1.3690 - val_loss: 2941.5684 - val_mean_absolute_error: 54.1322\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8610 - mean_absolute_error: 1.3060 - val_loss: 2977.6628 - val_mean_absolute_error: 54.4536\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 12.5104 - mean_absolute_error: 2.9576 - val_loss: 2867.3638 - val_mean_absolute_error: 53.5081\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.6864 - mean_absolute_error: 2.2162 - val_loss: 2859.4331 - val_mean_absolute_error: 53.4289\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.6957 - mean_absolute_error: 2.2313 - val_loss: 3011.2769 - val_mean_absolute_error: 54.8099\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9851 - mean_absolute_error: 1.2549 - val_loss: 3164.8486 - val_mean_absolute_error: 56.1661\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8776 - mean_absolute_error: 1.0610 - val_loss: 3232.7842 - val_mean_absolute_error: 56.7481\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2609 - mean_absolute_error: 1.4671 - val_loss: 3211.6982 - val_mean_absolute_error: 56.5580\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.6188 - mean_absolute_error: 1.3650 - val_loss: 3139.7866 - val_mean_absolute_error: 55.9241\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3077 - mean_absolute_error: 0.9794 - val_loss: 3051.8242 - val_mean_absolute_error: 55.1420\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0577 - mean_absolute_error: 0.9093 - val_loss: 2988.7329 - val_mean_absolute_error: 54.5729\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7597 - mean_absolute_error: 1.2908 - val_loss: 2973.5825 - val_mean_absolute_error: 54.4336\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9963 - mean_absolute_error: 1.3673 - val_loss: 2999.6338 - val_mean_absolute_error: 54.6673\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4600 - mean_absolute_error: 1.1739 - val_loss: 3049.2434 - val_mean_absolute_error: 55.1114\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 5.8336 - mean_absolute_error: 1.9574 - val_loss: 2677.2170 - val_mean_absolute_error: 51.6954\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 9.7952 - mean_absolute_error: 2.4151 - val_loss: 2821.5349 - val_mean_absolute_error: 53.0536\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7913 - mean_absolute_error: 1.6845 - val_loss: 3058.2046 - val_mean_absolute_error: 55.2078\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9828 - mean_absolute_error: 0.6706 - val_loss: 3225.7593 - val_mean_absolute_error: 56.6790\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.0502 - mean_absolute_error: 1.3449 - val_loss: 3251.3857 - val_mean_absolute_error: 56.8957\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6289 - mean_absolute_error: 1.4639 - val_loss: 3174.1052 - val_mean_absolute_error: 56.2176\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.0167 - mean_absolute_error: 1.0375 - val_loss: 3053.4556 - val_mean_absolute_error: 55.1451\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7986 - mean_absolute_error: 0.7669 - val_loss: 2943.0986 - val_mean_absolute_error: 54.1450\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2221 - mean_absolute_error: 1.0828 - val_loss: 2889.1238 - val_mean_absolute_error: 53.6481\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0399 - mean_absolute_error: 1.3323 - val_loss: 2900.4895 - val_mean_absolute_error: 53.7532\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8255 - mean_absolute_error: 1.2720 - val_loss: 2955.2393 - val_mean_absolute_error: 54.2558\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 9.6904 - mean_absolute_error: 2.5460 - val_loss: 2802.0042 - val_mean_absolute_error: 52.8949\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5213 - mean_absolute_error: 1.5903 - val_loss: 2733.1274 - val_mean_absolute_error: 52.2450\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.4858 - mean_absolute_error: 1.8901 - val_loss: 2858.4141 - val_mean_absolute_error: 53.4182\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.3215 - mean_absolute_error: 1.3323 - val_loss: 3029.0176 - val_mean_absolute_error: 54.9706\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0385 - mean_absolute_error: 0.7053 - val_loss: 3156.3203 - val_mean_absolute_error: 56.0955\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.1157 - mean_absolute_error: 1.0952 - val_loss: 3187.4226 - val_mean_absolute_error: 56.3615\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4704 - mean_absolute_error: 1.2164 - val_loss: 3139.4619 - val_mean_absolute_error: 55.9351\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6130 - mean_absolute_error: 0.9625 - val_loss: 3053.7031 - val_mean_absolute_error: 55.1676\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8096 - mean_absolute_error: 0.6700 - val_loss: 2962.4048 - val_mean_absolute_error: 54.3395\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9821 - mean_absolute_error: 0.9544 - val_loss: 2913.7974 - val_mean_absolute_error: 53.8925\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4747 - mean_absolute_error: 1.1637 - val_loss: 2920.3633 - val_mean_absolute_error: 53.9505\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3628 - mean_absolute_error: 1.1264 - val_loss: 2962.5889 - val_mean_absolute_error: 54.3354\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 13.4262 - mean_absolute_error: 3.0851 - val_loss: 2784.8691 - val_mean_absolute_error: 52.7353\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 7.1609 - mean_absolute_error: 2.2907 - val_loss: 2754.8389 - val_mean_absolute_error: 52.4450\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 7.8163 - mean_absolute_error: 2.4105 - val_loss: 2915.0967 - val_mean_absolute_error: 53.9300\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2854 - mean_absolute_error: 1.3623 - val_loss: 3092.5876 - val_mean_absolute_error: 55.5243\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.1024 - mean_absolute_error: 1.0308 - val_loss: 3174.5083 - val_mean_absolute_error: 56.2392\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0302 - mean_absolute_error: 1.5420 - val_loss: 3151.5220 - val_mean_absolute_error: 56.0287\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3576 - mean_absolute_error: 1.3864 - val_loss: 3059.6201 - val_mean_absolute_error: 55.2087\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5078 - mean_absolute_error: 0.9810 - val_loss: 2951.2231 - val_mean_absolute_error: 54.2267\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2225 - mean_absolute_error: 1.0168 - val_loss: 2879.2864 - val_mean_absolute_error: 53.5645\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2109 - mean_absolute_error: 1.4547 - val_loss: 2876.7690 - val_mean_absolute_error: 53.5404\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2230 - mean_absolute_error: 1.4579 - val_loss: 2925.2329 - val_mean_absolute_error: 53.9868\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3630 - mean_absolute_error: 1.1415 - val_loss: 2996.4316 - val_mean_absolute_error: 54.6353\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x00000246A1D70790&gt;,\n",
       "                   n_iter=50,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.001683454924600351,\n",
       "                                                          0.02390836445593178,\n",
       "                                                          0.008731907739399206,\n",
       "                                                          0.004725396149933917,\n",
       "                                                          0.0006154014789262348,\n",
       "                                                          0.0006153331256530192,\n",
       "                                                          0.0003920021771415983,\n",
       "                                                          0.01619845322936229,\n",
       "                                                          0.004779156784872302,\n",
       "                                                          0.0078...\n",
       "                                                          0.001151888789941251,\n",
       "                                                          0.001621231156394198,\n",
       "                                                          0.0024505367684280487,\n",
       "                                                          0.011155092541719619,\n",
       "                                                          0.0007524347058135697,\n",
       "                                                          0.0032032448128444043,\n",
       "                                                          0.004591455636549438,\n",
       "                                                          0.0003715541189658278, ...],\n",
       "                                        &#x27;n_hidden&#x27;: [2, 3, 4, 5],\n",
       "                                        &#x27;n_neurons&#x27;: [200, 201, 202, 203, 204,\n",
       "                                                      205, 206, 207, 208, 209,\n",
       "                                                      210, 211, 212, 213, 214,\n",
       "                                                      215, 216, 217, 218, 219,\n",
       "                                                      220, 221, 222, 223, 224,\n",
       "                                                      225, 226, 227, 228, 229, ...]},\n",
       "                   scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x00000246A1D70790&gt;,\n",
       "                   n_iter=50,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.001683454924600351,\n",
       "                                                          0.02390836445593178,\n",
       "                                                          0.008731907739399206,\n",
       "                                                          0.004725396149933917,\n",
       "                                                          0.0006154014789262348,\n",
       "                                                          0.0006153331256530192,\n",
       "                                                          0.0003920021771415983,\n",
       "                                                          0.01619845322936229,\n",
       "                                                          0.004779156784872302,\n",
       "                                                          0.0078...\n",
       "                                                          0.001151888789941251,\n",
       "                                                          0.001621231156394198,\n",
       "                                                          0.0024505367684280487,\n",
       "                                                          0.011155092541719619,\n",
       "                                                          0.0007524347058135697,\n",
       "                                                          0.0032032448128444043,\n",
       "                                                          0.004591455636549438,\n",
       "                                                          0.0003715541189658278, ...],\n",
       "                                        &#x27;n_hidden&#x27;: [2, 3, 4, 5],\n",
       "                                        &#x27;n_neurons&#x27;: [200, 201, 202, 203, 204,\n",
       "                                                      205, 206, 207, 208, 209,\n",
       "                                                      210, 211, 212, 213, 214,\n",
       "                                                      215, 216, 217, 218, 219,\n",
       "                                                      220, 221, 222, 223, 224,\n",
       "                                                      225, 226, 227, 228, 229, ...]},\n",
       "                   scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x00000246A1D70790&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x00000246A1D70790&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x00000246A1D70790>,\n",
       "                   n_iter=50,\n",
       "                   param_distributions={'learning_rate': [0.001683454924600351,\n",
       "                                                          0.02390836445593178,\n",
       "                                                          0.008731907739399206,\n",
       "                                                          0.004725396149933917,\n",
       "                                                          0.0006154014789262348,\n",
       "                                                          0.0006153331256530192,\n",
       "                                                          0.0003920021771415983,\n",
       "                                                          0.01619845322936229,\n",
       "                                                          0.004779156784872302,\n",
       "                                                          0.0078...\n",
       "                                                          0.001151888789941251,\n",
       "                                                          0.001621231156394198,\n",
       "                                                          0.0024505367684280487,\n",
       "                                                          0.011155092541719619,\n",
       "                                                          0.0007524347058135697,\n",
       "                                                          0.0032032448128444043,\n",
       "                                                          0.004591455636549438,\n",
       "                                                          0.0003715541189658278, ...],\n",
       "                                        'n_hidden': [2, 3, 4, 5],\n",
       "                                        'n_neurons': [200, 201, 202, 203, 204,\n",
       "                                                      205, 206, 207, 208, 209,\n",
       "                                                      210, 211, 212, 213, 214,\n",
       "                                                      215, 216, 217, 218, 219,\n",
       "                                                      220, 221, 222, 223, 224,\n",
       "                                                      225, 226, 227, 228, 229, ...]},\n",
       "                   scoring='accuracy')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [2, 3, 4, 5],\n",
    "    \"n_neurons\": np.arange(200, 300)               .tolist(),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2)      .rvs(1000).tolist(),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_clf, param_distribs, n_iter=50, scoring = \"accuracy\", cv=5)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=30,\n",
    "                  validation_data=(X_val, y_val),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e9233d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_250\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1315 (Dense)          (None, 128)               768       \n",
      "                                                                 \n",
      " dense_1316 (Dense)          (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_1317 (Dense)          (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_1318 (Dense)          (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 99,841\n",
      "Trainable params: 99,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9ec75855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step - loss: 1647.0480 - mean_absolute_error: 37.6880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1647.0479736328125, 37.68799591064453]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c779d506",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
